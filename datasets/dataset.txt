adversarial attacks on cognitive selforganizing
networks the challenge and the way forward
muhammad usama
information technology university
punjab pakistan
muhammadusamaituedupk
junaid qadir
information technology university
punjab pakistan
junaidqadirituedupk
ala alfuqaha
western michigan university usa
alaalfuqahawmichedu
abstractfuture communications and data networks are ex
pected to be largely cognitive selforganizing networks cson
such networks will have the essential property of cognitive self
organization which can be achieved using machine learning
techniques eg deep learning despite the potential of these
techniques these techniques in their current form are vulnerable
to adversarial attacks that can cause cascaded damages with
detrimental consequences for the whole network in this paper
we explore the effect of adversarial attacks on cson our
experiments highlight the level of threat that cson have to deal
with in order to meet the challenges of nextgeneration networks
and point out promising directions for future work
i introduction
the idea that networks should learn to drive themselves is
gaining traction  taking inspiration from selfdriving cars
where driving and related functionality do not require human
intervention the networking community wants to build a
similar cognitive control in networks where networks are able
to conﬁgure manage and protect themselves by interacting
with the dynamic networking environmentwe refer to such
networks as cognitive selforganizing networks cson the ex
pected complexity and heterogeneity of cson makes machine
learning ml a reasonable choice for realizing this ambitious
goal recently artiﬁcial intelligence ai based cson have
attained a lot of attention in industry and academia
in  clark et al  proposed that ml and cognitive
techniques should be used for operating the network this
knowledge plane incorporation will bring many advantages
in networks such as automation of network management
efﬁcient and realtime anomaly and intrusion detection and
many related tasks due to limited computational resources
and lack of ml abilities the idea of knowledge plane was not
implemented in networks in recent years the ﬁeld of ml
especially neural networks have evolved rapidly and we
have witnessed its success in vision speech and language
processing this huge success motivated networking research
community to utilize deep ml tools for building cson
deep ml or deep learning dl is a branch of ml
where hierarchical architectures of neural networks are used
for unsupervised feature learning and these learned features
are then used for classiﬁcation and other related tasks dl
classiﬁers are function approximators that require a lot of data
for generalization although they have outperformed all other
statistical approaches on large datasets due to generalization
error they are very vulnerable to adversarial examples adver
sarial examples are carefully crafted perturbations in the input
which when mldl algorithms are subjected to get classiﬁed
in a different class with high probability
in this paper we take security to encompass the securing
of all of the functional areas of cson ie iso deﬁned func
tional areas often abbreviated as fcaps fault conﬁguration
accounting performance and security and experiment with
multiple adversarial attacks on mldl based malware clas
siﬁcation systems our experimental results demonstrate that
the current state of the art mldl based networking solutions
do not have substantial deterrence against adversarial attacks
speciﬁcally our experiments utilize the highly cited malware
image dataset provided by nataraj et al  to perform
adversarial attacks on malware classiﬁer to demonstrate that
using current mldl techniques in conjunction with csons
can be a potential security risk
contributions in this paper we have made the following
contributions
 to the best of our knowledge we have made the ﬁrst
attempt to show that cson utilizing mldl techniques
are very vulnerable to attacks based on adversarial per
turbations
 we have argued that existing defenses to overcome ad
versarial perturbations are not appropriate and efﬁcient
for cson applications we have also highlighted that
protection schemes against adversarial examples create
an arms race between adversaries
the rest of the paper is organized as follow in the next
section we review related research studies that focus on
cson and adversarial attacks on networking applications
section iii describes our research methodology particularly
with reference to the dataset the mldl model used dataset
and threat model assumptions and the adversarial attacks
in section iv we provide the details of our experimental
evaluations and the potential defense against these attacks in
section v we discuss the posed questions as well as some
future directions and challenges finally section vi concludes
our study
ii related work
many applications of mldl in networking have been
proposed in the last few years highlighting the applications
arxivv  cscr   sep 
opportunities and challenges of using mldl in networking
domain          
although many mlbased solutions for networking appli
cations have been proposed the networking community has
not yet standardized any mlbased solutions for csons this
arises partly from the complexity of the cson environment
that is characterized by dynamically changing network envi
ronment data sparsity expected tussles between control loops
high dimensionality label data scarcity heterogeneity ofﬂine
data processing and many other architectural issues
cson are expected to resolve the challenges of op
timization conﬁguration healing and coordination in the
communication and data networks by incorporating aiml
based cognitive techniques latif et al  highlights ai
as a potential enabler for cson similar ideas based on
deep reinforcement learning for learning from environment
and experience termed as experiencedriven networking are
presented in  feamster et al  termed this idea of
learning from network environment for measuring analyzing
and conﬁguring network without any human intervention as
selfdriving networks jiang et al  highlighted the ben
eﬁts and challenges in developing an intelligent datadriven
network with the ability of learning from dynamic nature of the
networking environment by using exploration and exploitation
processes koley et al  proposed and provided a frame
work for zerotouch networking and highlighted the need for
cson using googles infrastructure network as an example
mestres et al  revisited the possibilities of embedding
artiﬁcial intelligence in networking and proposed an mldl
based knowledge plane for networking applications and this
new networking paradigm was termed as knowledge deﬁned
networking
while mldl applications will be a core part of cson
recent studies demonstrated that mldl models are very
susceptible to adversarial examples   although most
existing studies in this domain have targeted image classi
ﬁcation applications in which highdimensional images are
perturbed in a way that fools the algorithm without being the
change being conspicuous to naked human eye these attacks
also pose a signiﬁcant challenge to cson since the underlying
algorithms are largely similar
such adversarial attacks are performed to compromise the
integrity in terms of misclassiﬁcation accuracy reduction
targeted misclassiﬁcation or decision boundary evasion of the
mldl techniques we can divide these adversarial attacks
into two broader categories based on the adversarysattackers
knowledge
 whitebox attack this attack assumes that the adver
sary has complete knowledge about the mldl architec
ture training data and hyperparameters for adversarial
attacks on cson we assume a whitebox attack setting
 blackbox attack this attack assumes that the ad
versaryattacker has no information about the mldl
technique and hyperparameters the adversary acts as
a standard user who can query the mldl based system
and gets a response these queryresponse pairs are later
used for crafting the adversarial examples
most of the adversarial attacks are whitebox attacks but
whitebox adversarial examples can be converted into black
box attacks by exploiting the mldl transferability property
since these adversarial attacks on ml algorithms have not
yet been applied much in the case of networks we will initially
review their applications in other domains szegedy et al
 proposed the ﬁrst successful adversarial attack that has
fooled the state of the art image classiﬁers with very high
probability goodfellow et al  proposed an adversarial
sample generation method called fast gradient sign method
where adversarial perturbation was generated by taking the
sign of the gradient of the cost function with respect to the
input kurakin et al  explored the vulnerability of mldl
techniques in the physical world and demonstrated that a small
invisible tweak to the input of an mldl techniques can result
in incorrect results carlini et al  proposed three attacks by
exploiting the three different distance matrices l l and
l and showed that the defensive distillation method 
used to prevent against adversarial attacks does not increase
the robustness of the mldl techniques papernot et al 
proposed a saliency map based attack where saliency map
is used to ﬁnd the most discriminative features of the input
that are then fractionally perturbed to form an adversarial
attack on the mldl based classiﬁers in  papernot et
al  proposed a blackbox attack where adversarial attack
transferability  is exploited to form a successful evasion
attack further details about adversarial attacks on different
vision language and text processing systems can be found in
 and 
adversarial attacks have not yet been explored for cson
we will cover some general networking applications in 
corona et al  highlighted the possibilities and open re
search challenges of adversarial attacks on intrusion detection
systems hu et al  proposed a generative adversarial
network gan based blackbox attack on malware examples
but training a gan on malware examples is difﬁcult and
computationally exhaustive grosse et al  proposed an
adversarial perturbation attack against deep neural networks
for malware classiﬁcation where a restricted amount of feature
perturbations are used to fool a deep neural network with 
probability which was previously classifying malware with
 accuracy in the next section we provide the details of
the proposed approach to perform multiple adversarial attacks
on cson
iii methodology
in this section we describe the approach followed in
designing adversarial examples to evade the mldl based
malware classiﬁcation system which we use as a proxy for
the functional areas of cson to the best of our knowledge
no standardized deep learning based solution for malware
classiﬁcation in the cson has been proposed yet in this
work we propose a deep neural network based solution for
malware classiﬁcation before delving deep into the details of
fig  depiction of malware executable as an image
the proposed model we describe the threat model and few
related assumptions
a threat model
in the following we outline the salient assumptions regard
ing the adversarial threat
 the adversary may have the knowledge about the trained
model which includes model architecture and hyper
parameters but the adversary cannot make any changes to
the architecture or model parameters this is a common
assumption in the adversarial machine learning domain
 the adversary can only perform attacks during the testing
phase attacks on the training data ie poisoning attacks
are not within the scope of this study
 for malware classiﬁcation we assume that similar fam
ilies of malware when represented as grayscale images
exhibit similar visual and texture representations this
hypothesis was proposed and defended in  in this
work we utilize convolutional neural networks cnn
for malware classiﬁcation because cnn is by far the best
feature extractors
 the goal of an attack is to compromise the integrity
of the mldl based classiﬁcation techniques through
a reduction in the classiﬁcation accuracy with small
perturbations
b malware image representation
in this paper we have used grayscale malware image dataset
provided in  where a malware executable is converted
to a grayscale image this approach of conversion includes
both static and dynamic code analysis the executable code
is converted to binary and then represented as bit unsigned
vectors these bit unsigned vectors are then reshaped to a d
array which can be visualized as a grayscale image figure 
is depicting the procedure of converting malware executable
to a grayscale image
c malware classiﬁcation model
we propose a cnn based malware classiﬁcation architec
ture table i depicts the proposed architecture cnn is a pow
erful dl technique that learns spatial feature representations
using convolutional ﬁlters cnn has the capability to tolerate
the distortion and spatial shifts in the input data and extract
features from raw input data cnn provides the stateoftheart
solution for network trafﬁc feature extraction and classiﬁcation
 motivated by these successes we explore the use of cnn
for grayscale malware image classiﬁcation
in the proposed architecture we rescale the input grayscale
images of various sizes to  pixel wide and  pixel high
where pixel values are between  to  these input values
are subjected to a twodimensional convolutional layer with
 ﬁlters of receptive ﬁeld  pixel wide and  pixel high
after that we use a rectiﬁed linear unit ie relu as an
activation function the resultant activation values are then
passed on to a second convolution layer with  ﬁlters and
   receptive ﬁeld again we use a relu as an activation
function similarly the third convolution layer follows the
same procedure mentioned earlier but with  ﬁlters of
   receptive ﬁeld after the third convolution layer the
resultant activation values are ﬂattened and passed on to a
fully connected layer with softmax as an activation function
producing resulting probabilities we use a variant of the
stochastic gradient descent sgd as an optimization function
and categorical crossentropy as a loss function to train the
cnn
table i proposed cnn architecture for malware classiﬁca
tion
input malware gray scale image
size 
d convolution layer
filter size 
no of ﬁlters 
activation function relu
d convolution layer
filter size 
no of ﬁlters 
activation
function relu
d convolution layer
filter size 
no of ﬁlters 
activation
function relu
dense layer
number of neurons 
activation function softmax
output
malware
classiﬁcation probabilities
d adversarial attacks
we performed fast gradient sign method basic iterative
method and jacobianbased saliency map attacks on mal
ware classiﬁers to demonstrate that mldl based malware
classiﬁcation methods in cson are vulnerable to adversarial
examples
 fast gradient sign method goodfellow et al 
proposed a fast method of generating adversarial examples
this method is called the fast gradient sign method fgsm
this method exploits the vulnerability of deep neural networks
to adversarial perturbations fgsm performs one step gradient
update along the sign of the gradient to solve the optimization
problem formally the perturbation is calculated as
η  ϵsignxjθx l
in equation  ϵ represents the update step width or magnitude
of the perturbation η is the difference between original and
perturbed input x represents the gradient with respect to
each example lastly jθx l is the loss function used for
training the neural network for original example x and its
corresponding label l the generated adversarial example x
is calculated as
x
  x  η
fgsm is a very powerful attack because it is resilient to
the regularization techniques such as dropout and normbased
regularization methods
 basic iterative method kurakin et al  proposed
an elementwise basic iterative method bim for adversarial
falsiﬁcation it is an iterative procedure for generating adver
sarial example for physical world applications they improved
the success rate of the fgsm attack by including an iterative
clipping method for each pixel to avoid large changes in the
pixel valuesthe generated adversarial example is calculated
via multiple iterations the adversarial example generation
procedure is given as
x  x
xn  clipxξxn  ϵsignxjθx l
where xn is an adversarial example after n   iterations
the rest of the parameters are similar to the one utilized in
the fgsm attack
 jacobianbased saliency map attack papernot et al
 proposed a new efﬁcient method for generating adver
sarial examples called the jacobianbased saliency map attack
jsma this attack is an iterative method for generating a
saliency map to ﬁnd out the most discriminative features a
small perturbation is added to these discriminative features
to fool the classiﬁer this attack is based on calculating the
jacobian of the forward propagating examples with respect to
the input sample the procedure of generating the saliency
map of each sample is given as
jx  fx
x
 f jx
xi 
this attack achieved  accuracy by altering only  of
the input features although this attack provides very effective
adversarial examples but it is computationally very expensive
iv experimental evaluation
we evaluated the cnn based malware classiﬁer against
adversarial examples through our experiments we want to
answer the following questions
 question  since mldl techniques are necessary to
fuel the cson do these techniques provide the necessary
robustness required to deal with adversarial perturba
tions
 question  how to build deterrence against adversarial
attacks in cson
 question  do the deterrence techniques against ad
versarial examples create an arms race between adver
saries
before answering these questions we provide the details of
the dataset used for our experiments
fig  malware image and related features in the image
a dataset
nataraj et al  provided a malware grayscale images
dataset based on their novel image processing technique where
malware executeable are viewed as a grayscale image for
visualizing malware families for classiﬁcation purposes we
evaluated the performance of our proposed cnn architec
ture and adversarial attacks on malware classiﬁers using this
dataset the dataset consists of   malware images divided
into  different malware families like allaplel allaplea
lolyda aa etc these malware families belong to major
malware types such as worm pws trojan dialer tdown
loader rouge and backdoor more details about malware types
and related families in the dataset is available in  here
we want to highlight that to keep the excutability of the
malware we have limited the scope of the perturbation to the
uninitialized data and zero padding portion of the malware
image we utilized  of the data for training and 
for testing figure  depicts a sample malware image and its
associated attributes
b results
we evaluated the performance of adversarial attacks on
cson using malware classiﬁers as a proxy the dataset details
are provided in section iva both fgsm and bim attacks
are elementwise attacks with individual perturbation scope
nontargeted speciﬁcity and same perturbation magnitude pa
rameter ϵ we performed both attacks using multiple values
of ϵ with   and  epochs our experimental results
are shown in tables ii and iii jsma is a targeted iterative
euclidean distance based attack it has two major controlling
parameters namely maximum distortion parameter γ and rate
of perturbation in the features θ for this experiment we ﬁxed
θ to be  and varied the value of γ between   and
 for   and  epochs the achieved adversarial test
accuracy values along with the average number of features
perturbed for a successful adversarial example are reported in
table iv for all aforementioned experiments a batch size of
 and a learning rate of  were used
 performance impact the cnn based malware classiﬁer
has a classiﬁcation accuracy of  when trained on
legitimate examples this accuracy is better than the best
accuracy reported on the dataset in consideration adversarial
test examples created by employing fgsm have reduced the
classiﬁcation accuracy from approximately  to 
table ii fgsm attack and defense results with different values of epochs and ϵ
fast gradient sign method attack
epochs
epsilon
test accuracy on
legitimate samples in 
test accuracy of
adversarial examples in 
test accuracy after
adversarial training in 
table iii bim attack and defense results with different values of epochs and ϵ
basic iterative method attack
epochs
epsilon
test accuracy on
legitimate samples in 
test accuracy of
adversarial examples in 
test accuracy after
adversarial training in 
table iv jsma attack with average number of features perturbed for different values of epochs and γ
jacobianbased saliency map attack
epochs
gamma
test accuracy on
legitimate samples in 
test accuracy of
adversarial examples in 
average number of
features perturbed 
which is nearly  loss in the accuracy of classiﬁcation and
prevention against adversarial examples it also means that the
probability of an adversary evading the malware classiﬁer has
increased from  to  which is very alarming similarly
the bim attack reduces the test accuracy of adversarial samples
to  which is even worse than the fgsm attack in case
of jsma the classiﬁcation accuracy decreased from 
to  but it requires an  of average feature per
turbations to create successful adversarial examples which is
computationally very expensive the full experimental results
are summarized in tables  iii and iv
malware classiﬁers are an integral part of the security
architecture of cson and we demonstrated that a very small
perturbation in the test example has the potential to evade
the integrity of the classiﬁer this performance degradation
depicts the potential risks of applying mldl methods in
the context of cson without considering the robustness of
mldl classiﬁers and building proper deterrence against ad
versarial examples without such deterrence mldl models
might cause more harm than good in cson
 computational complexity adversarial attacks are not
just random noisevalues added to the test samples instead
they are carefully calculated perturbations these perturbations
are based on exploiting the inherent generalization error and
gradient variations in of mldl techniques as the shown in
table iv detecting and exploiting these errors to make effec
tive adversarial examples is a computationally very complex
and expensive process since jsma works on saliency maps
and forward derivatives to ﬁnd the most discriminant features
it becomes computationally very expensive table iv depicts
the average number of features perturbed to construct an adver
sarial example for each class these values are surprisingly very
high because for each example the underlying data contains
 features and each feature has a value greater than zero
which is not the case in other standard datasets like mnist
 this unusual property of the malware image dataset
increases the search space to ﬁnd the most discriminating
features thus resulting in rapid increase in that computational
complexity and poor performance of the jsma attack
c adversarial defense
we need to identify that adversarial settings have been
assumed in networks before through tools such as game theory
but unique challenges emerge and the stakes get higher when
we give more control of the network to ml and algorithms
in cson  barreno et al  provided a taxonomy of
defences against adversarial attacks they have highlighted
that regularization randomization and information hiding can
ensure defence against adversarial perturbation but these coun
termeasures are not very effective against attacks described in
section iiid
there are two major types of defenses against adversarial
examples namely proactive and reactive proactive defenses
include adversarial training and network distillation whereas
reactive defenses include input reconstruction and adversarial
detection in this paper we only consider proactive coun
termeasures against adversarial examples more detail about
reactive countermeasures against adversarial examples are
explored in 
 adversarial training one countermeasure against ad
versarial examples is to include adversarial examples in the
training data for mldl techniques goodfellow et al 
proposed this idea and showed that mldl classiﬁers can be
made more robust against adversarial examples by training
them with adversarial examples the purpose of including
adversarial examples in the training is to regularize the mldl
technique this regularization helps to avoid overﬁtting which
in turn increases the robustness of the mldl technique
against adversarial examples
in this paper we also explored adversarial training for
making cnn models robust against fgsm and bim attacks
test accuracies before and after the adversarial training are
reported in tables ii and iii the results clearly show that
performing adversarial training can increase the deterrence
against adversarial attacks but it only provides defense against
the adversarial examples on which it is trained while other
adversarial perturbations continue to pose a threat of evading
the integrity of the classiﬁer
 network distillation network distillation is another
approach of forming a defense against adversarial examples
hinton et al  proposed the idea of distillation to improve
the generalization of the deep neural networks papernot et al
 used the distillation process to form a defense against ad
versarial examples network distillation is a process of training
a classiﬁer such that the generation of adversarial examples
becomes very difﬁcult this defense is based on hiding the
gradients between presoftmax layers and the softmax output
which reduces the chances of developing a gradientbased
attack against deep neural networks since in this paper we
consider whitebox attacks where an adversary knows the
model parameters ie architecture hyperparameters gradi
ents etc this defensive scheme is not applicable to our study
more information on defence schemes against adversarial
examples can be found in 
v discussions challenges and future extensions
our experimental results clearly demonstrate that applying
mldl techniques in cson without taking into account
adversarial perturbation threats can potentially lead to major
security risks to date there does not exist any appropriate
solution that provides deterrence against all kinds of adversar
ial perturbations our experiments answer the questions posed
earlier in section iv furthermore they provide the following
insights
 robustness of mldl for cson in section ivb we
have shown that cson are very vulnerable to adversarial
attacks sparsity high dimensionality unstructured na
ture unique data packing scheme large salient feature
decision space of network data and less fault tolerance
makes adversarial attacks more lethal for cson as
compared to other vision and language data given the
adversarial threat networking community has to come
up with new mldl mechanism to ensure appropriate
deterrence against adversarial examples robustness can
be introduced by incorporating approximation and fault
tolerance on top of defense techniques against adversarial
threats
 deterrence against adversarial attacks in cson we
have performed proactive defense against adversarial at
tacks by training on adversarial examples this adver
sarial training procedure provides deterrence against the
adversarial examples it is trained on but an unknown
adversarial perturbation can evade the classiﬁer table
ii depicts that when the classiﬁer is trained via an
adversarial training procedure it enables the malware
classiﬁer to classify fgsm based adversarial examples
correctly with  accuracy after  epochs but
the same classiﬁer was unable to classify bim attacks
with appropriate accuracy even after  epochs of ad
versarial training this shows that before incorporating
mldl techniques in support of cson applications like
routing intrusion detection trafﬁc classiﬁcation malware
detection the research community needs to ﬁgure out an
appropriate defense against all adversarial perturbations
the margin of error in adversarial examples classiﬁcation
is very narrow in networking application when compared
to computer vision problems
building deterrence against adversarial examples requires
a method to improve generalization this can be achieved
via constraint objective function optimization distributed
denoising and exploiting vicinal risk minimization in
stead of empirical losses apple inc  proposed
a distributed denoising scheme for building deterrence
against adversarial attacks for securitycritical applica
tions whereas zhang et al  proposed a method for im
proving the generalization of the mldl schemes which
uses vicinal risk minimization rather than conventional
empirical loss minimization this procedure improves
the robustness of mldl techniques against adversarial
examples our experiments demonstrate that cson are
currently lacking the capability to provide appropriate
defense against adversarial attacks on mldl techniques
 arms race between adversaries our experiments also
highlight that using mldl techniques in cson can lead
to an arms race situation between adversaries conse
quently adversarial attacks and defense mechanisms will
be in an arms race where attackers keep on dynamically
changing the adversarial perturbations and defenders have
to adapt accordingly
mldl techniques will enable future cson but before their
deployments the research community has to ﬁgure out an
effective way to deal with adversarial attacks
a open issues
 standardized datasets progress in cson largely de
pends upon learning from data obtained from the user op
erating system and application unfortunately there does
not exist a single standardized dataset for benchmark
ing mldl techniques for realtime networking applica
tions in order to ensure a proper utilization of mldl
techniques with efﬁcient deterrence against adversarial
examples networking community has to come up with
standardized datasets for securitycritical applications
 learning from untapped network data building de
terrence in cson against adversarial examples can be
achieved by improving the generalization of mldl tech
niques generalization can be improved by harnessing the
features from untapped networking data network data
that is recorded but not utilized in decision making by
introducing new network telemetry schemes for cson
this can be a very promising way forward in realizing
security critical cson
 new mldl mechanisms conventional mldl tech
niques are very vulnerable to adversarial examples as
shown in section ivb and related defense schemes do not
qualify for cson applications developing new mldl
schemes for unstructured networking data which are
robust to adversarial threats is still an open avenue ge
ometric and graph mldl techniques have the potential
to solve this issue but have not yet been explored in this
context
vi conclusion
in this paper we evaluated the feasibility of employing
mldl techniques to realize cson in security critical appli
cations and their ability to defend against adversarial exam
ples we demonstrated that network data is highly susceptible
to adversarial attacks we also evaluated the proactive defense
mechanisms to build a defense against adversarial perturba
tions our experiments demonstrate that the application of
mldl techniques in networking can push the limits on
the stateoftheart in cson however without taking into
account the threat of adversarial examples signiﬁcant security
risks will be a major hindrance to the deployment of these
networks
blackbox adversarial ml attack on modulation classification
muhammad usama
muhammadusamaituedupk
information technology university
punjab pakistan
junaid qadir
junaidqadirituedupk
information technology university
punjab pakistan
ala alfuqaha
aalfuqahahbkueduqa
hamad bin khalifa university qatar
abstract
recently many deep neural network dnn based modulation clas
sification schemes have been proposed in the literature we have
evaluated the robustness of two famous such modulation classifiers
based on the techniques of convolutional neural networks and long
short term memory against adversarial machine learning attacks
in blackbox settings we have used carlini  wagner cw attack
for performing the adversarial attack to the best of our knowledge
the robustness of these modulation classifiers have not been evalu
ated through cw attack before our results clearly indicate that
stateofart deep machine learning based modulation classifiers are
not robust against adversarial attacks
keywords
adversarial ml modulation classification deep learning
acm reference format
muhammad usama junaid qadir and ala alfuqaha  blackbox
adversarial ml attack on modulation classification in proceedings of
acm conference conference acm new york ny usa  pages https
doiorgnnnnnnnnnnnnnn
introduction
machine learning ml especially deep ml schemes have beaten
humanlevel performance in many computer vision language and
speech processing tasks which were considered impossible a decade
ago this success of ml schemes has inspired the ideas of self
driving networks  and knowledge defined networking  where
ml schemes are profoundly utilized to ensure automation and
control of networking tasks such as dynamic resource allocation
modulation classification network traffic classification etc
despite the success of ml in different modern communication
and data networking applications there are some pitfalls in the
fundamental assumptions of ml schemes which can be exploited
by the adversaries to craft adversarial examples in order to com
promise the mlbased system an adversarial example is defined
as an input to the ml model specially crafted by an adversary by
adding a small imperceptible perturbation to the input sample to
compromise the performance of the ml model mathematically
an adversarial example xcan be formed by adding a typically
imperceptible perturbation δ to the legitimate test example x of
permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page copyrights for components of this work owned by others than acm
must be honored abstracting with credit is permitted to copy otherwise or republish
to post on servers or to redistribute to lists requires prior specific permission andor a
fee request permissions from permissionsacmorg
conference july  washington dc usa
  association for computing machinery
acm isbn xxxxxxxxxxyymm
httpsdoiorgnnnnnnnnnnnnnn
the deployed trained classifier f  the perturbation δ is computed
by approximating the following nonlinear optimization problem
provided in equation  where t is the targeted class in case of a
targeted attack or any other wrong class is the case of untargeted
attack
x x  arg min
ηx η f x  η  t
adversarial examples are possible because of two major faulty
assumptions in ml schemes firstly the underlying data distribu
tion experienced during the training phase of the ml model will
also be encountered in the testing phase this data stationarity is
not valid for most of the real world cases and the void created by
following this assumption is exploited by the adversary for craft
ing the adversarial examples secondly most of the ml schemes
are based on the empirical risk minimization erm which is an
approximation of the actual unknown probability distribution the
erm has an associated error with it which can be exploited by the
adversary to make an adversarial example
adversarial attacks can be classified broadly into whitebox and
blackbox attacks based on the knowledge of the adversary about
the deployed ml model in a whitebox attack it is assumed that
adversary has complete knowledge hyperparameters test data
etc of the deployed model whereas in a blackbox attack no such
knowledge is assumed and it is assumed that the adversary can
only act as a standard user and query the system for a response
in this paper we have taken modulation classification which
is an important component of modern communication and data
networks as a proxy of functional areas of cognitive selfdriving
networks we have performed a blackbox adversarial attack on
dnnbased modulation classification to highlight the brittleness of
ml schemes utilized in cognitive selfdriving networks
related work
there does not exist much literature on adversarial attacks on
modulation classification recently sadeghi et al  used a variant
of fast gradient sign method fgsm attack  on modulation
classification on cnnbased modulation classification to highlight
the threat of the adversarial examples fgsm is an adversarial
sample crafting algorithm where the adversarial perturbation is
calculated by taking a gradient step in the direction of the sign
of the gradient of test example kokalj et al  also crafted the
adversarial examples for modulation classification by using the
fgsm perturbation generation algorithm most of the available
results on the application of the adversarial attacks are reported by
using the fgsm attack
a shortcoming with the fgsm attack is its lack of optimality
in adversarial perturbation generation as fgsm was designed to
quickly craft adversarial examples irrespective of the optimality
arxivv  csni   aug 
conference july  washington dc usa
muhammad usama junaid qadir and ala alfuqaha
and the size of the perturbation in the test example to overcome
the lack of optimality and to highlight that optimal adversarial
example for modulation classification can be crafted we have used
carlini  wagner cw attack  where the adversarial examples
are crafted using the following optimization process provided in
equation 
minimize
η
ηp  cдx
such that
x n
figure  the step by step procedure followed for crafting
blackbox adversarial attack against dlbased modulation
classification is depicted in the figure
blackbox adversarial attack
procedure
in this section we will provide our blackbox adversarial attack
procedure illustrated in figure  the steps followed are  the
adversary queries the deployed modulation classifier with test ex
amples  the deployed modulation classifier provides a labeled
response to the adversary considering the adversary as a normal
user  the adversary stores the queryresponse pair in a database
which is later used as a substitute dataset for training a surrogate
dnn  once sufficient data is collected in the adversarial database
the adversary constructs a fully connected dnn model and trains it
for suitable classification performance  once the surrogate dnn
is trained the adversary launches a cw attack on the surrogate
dnn for crafting adversarial examples that compromises the per
formance of the surrogate dnn model  adversarial examples that
compromises the performance of surrogate dnnmodel are then
transferred to blackbox dlbased modulation classifier which ac
cording to the transferability property of adversarial examples will
compromise the performance of dlbased modulation classifier
since we are performing this experiment in lab settings we have
opted for training two modulation classifiers based on cnn and
lstm and then considered them as blackbox models we have
used highlycited gnu radio ml rmla dataset  which
provides  digital and analog modulation schemes on the snr
ranging from  db to db we have used only  of the test
examples to construct the surrogate classifier and then performed
cw attack the performance of the surrogate dnn model before
and after the attack is provided in figure  once the adversarial
attack on surrogate dnn is completed we have transferred the
adversarial examples that evaded the surrogate dnn to blackbox
modulation classifier by leveraging the transferability property of
adversarial ml the performance impact of the adversarial attack
is provided in figures  and  a clear drop in the accuracy of the
modulation classifier after the adversarial attack highlights that our
method of performing blackbox adversarial attack has successfully
compromised the performance crafted adversarial examples
figure  performance of blackbox adversarial attack on
cnnbased modulation classification
figure  performance of blackbox adversarial attack on
lstmbased modulation classification
conclusions
in this paper we have highlighted the lack of robustness in deep
learning based modulation classification by performing a blackbox
adversarial attack on cnn and lstm based modulation classifiers
we have used a surrogate deep neural network for crafting adver
sarial examples and then showed that adversarial examples crafted
for modulation classification are transferable to other deep learning
based models we have achieved a  performance drop in both
cnn and lstm based modulation classification
blackbox adversarial ml attack on modulation classification
conference july  washington dc usa
adversarial ml attack on self organizing cellular
networks
salahuddin farooq  muhammad usama junaid qadir muhammad ali imran
information technology university lahore punjab pakistan
university of glasgow scotland uk
email mscs muhammadusama junaidqadirituedupk muhammadimranglasgowacuk
abstractdeep neural networks dnn have been widely
adopted in selforganizing networks son for automating differ
ent networking tasks recently it has been shown that dnn lack
robustness against adversarial examples where an adversary can
fool the dnn model into incorrect classiﬁcation by introducing a
small imperceptible perturbation to the original example son is
expected to use dnn for multiple fundamental cellular tasks and
many dnnbased solutions for performing son tasks have been
proposed in the literature have not been tested against adversarial
examples in this paper we have tested and explained the
robustness of son against adversarial example and investigated
the performance of an important son use case in the face
of adversarial attacks we have also generated explanations
of incorrect classiﬁcations by utilizing an explainable artiﬁcial
intelligence ai technique
index termsadversarial machine learning self organizing
cellular networks
i introduction
driven by ambitious bandwidth and latency targets and the
development of new domains such as iot and connected vehi
cles g networks are becoming increasingly complex as they
incorporate disparate emerging trends such as network densi
ﬁcation and coexistence with existing cellular technologies
these networks also perform several challenging activities
such as planning dimensioning deployment testing network
optimization comprehensive performance monitoring failure
detection failure correction and general maintenancewhich
currently utilize large human resources in the loop this
results in a network that is both costlythus dissatisfying
for the cellular operator and errorpronebringing customer
dissatisfaction and resulting in increased churn 
in such scenarios artiﬁcial intelligence ai driven self
organized networks provides an attractive alternative by
providing the tools for performing automation with self
organization and intelligence the main objectives of the son
are to build an intelligent network that can guarantee the net
work resilience with reduced complexity simpliﬁed network
management and properly optimized network conﬁgurations
 son technology leverages advance in machine learning
ml and deep learning dl techniques to overcome the
multiple challenges of operating modern network through their
integral capability of handling and analyzing big data
even though ml and dl models can greatly outperform
traditional methods in obtaining excellent accuracy in benign
environments it is also important to verify the robustness of
these models in adversarial settings particularly since it has
been shown in recent work that adversarial examples can be
generated by malicious adversaries to fool the dl models very
easily by applying small perturbations to the original inputs
  more formally an adversarial sample xis created
by following the equation  where imperceptible perturbation
is denoted as δ legitimate test example is denoted as x the
deployed trained classiﬁer is described by f and t describes
the wrong class adversary wants to achieve
x x  arg min
ηx η fx  η  t
deep neural networks dnn work in a black box manner
and this lack of transparency can be a major drawback for
the security critical domains hence explainable ai xai
or blackbox model interpretability plays an important part
in mitigating this threat of adversaries tomsett et al 
proposed this phenomenon that xai and adversarial machine
learning aml are conceptually linked and insights into one
ot them can provide insights into the other this is because
most vulnerable features after adversarial attacks together
with the help of xai and aml can be identiﬁed and ulti
mately any relevant defensive technique can be applied this
interpretability becomes more important now because of the
recent adaptation of explainable ai at government levels like
general data protection regulation gdpr which expresses
the importance of explanations of the logic involved when
automated decision making takes place 
the main contributions of our work are
 experimentally validated the impact of adversarial attacks
in the domain of son
 demonstrated that the explainable ai and adversarial ml
are linked with each other and adversarial ml can be used
to describe feature representations of a dnn model
 to the best of our knowledge this study is ﬁrst in the
domain of son to test adversarial machine learning
aml
in the section ii we have provided a brief review of
the related research that focuses on son adversarial ml
and explainable ai section iii describes the methodology
gdpr is an eu law regulation aiming at data protection and privacy for
all individual citizens of the european union and the european economic
area
arxivv  cscr   sep 
where we have discussed the assumed threat model ml
models used for a son use case of detection of abnormal key
performance indicator kpi and dataset details used in this
experiment section iv provides the performance evaluation
of the adversarial attacks on the abnormal kpi detector before
and after the adversarial attack section iv provides the results
of adversarial training used as a defense against adversarial
attacks section v concludes the study and provides future
directions
ii related work
a son
to provide best cellular services to the endusers efﬁcient
network optimization is a continuous process of planning
parametric conﬁguration changes operations and maintenance
with the help of large human interventions therefore the
son is introduced as an intelligent network that provides
scalability agility and stability to maintain the operators and
consumers desired objectives  a fundamental property of
the son is the ability to interact and learn from the networking
environment to adapt to the changing circumstances
three main functions of son selfconﬁguration self
healing and selfoptimization perform these automatic tasks
 selfconﬁguration manages tasks of automatic conﬁgura
tion of cellular network nodes the main use cases are plan
ning and modifying the radio and transport parameters self
optimization manages solutions that target cellular network
performance optimization based on the operator speciﬁcations
the main use cases of this category are handover parameters
optimization qosrelated parameters optimization and load
balancing whereas selfhealing manages tasks to automatic
detection and rectiﬁcation of failures in network
in the context of cellular systems dnns are applied in
all three categories of son feng et al  used dnn to
implement cell outage detection daroczy et al  used
ml to predict radio access bearer rab sessions drops well
before the end of the session other important work for son
in cellular networks using dnn include resource optimization
 and mobility management  recently chen et al 
combined adversarial training with variational autoencoders to
unsupervised learning the behavior of abnormal kpi on the
internet
an adversary can affect dnn models of son through
internal and external attacks in the case of internal attacks
adversaries can corrupt training data and classiﬁers of dnn
models of son directly however these internal attacks are
not easily possible due to the difﬁcult task of adding adver
sarial examples directly into the input of the dnn model
whereas external attacks can utilize vulnerabilities of data
collection process of cellular networks base stations collect
measurement reports and pass it son function that uses this
collected data to implement its different functionalities for
network optimization adversarial examples can be injected
into this data collection process with the help of a rogue
base station shaik et al  demonstrated the security vul
nerabilities of sonenabled lte networks they injected the
fake data into the son ecosystem with the help of a rogue
base station there work is mainly concerning dos attacks on
cellular networks and user devices
b adversarial attacks on sons and cognitive networks
most of the current research of adversarial machine learning
is relevant to computer vision tasks such as szegedy et al 
shows that deep neural network can change its prediction by
using nonrandom perturbation in its inputs these changes are
imperceptible due to the extremely low probability of negative
adversaries in every test set goodfellow et al  and papernot
et al  extended this initial study and proposed fast
gradient sign method fgsm and jacobianbased saliency
map attack jsma respectively for generating adversarial
examples fgsm is a technique for crafting an adversarial
example where one step gradient update is performed in the
direction of the sign associated with the gradient at each
feature in the test example the fgsm perturbation η is
given as
η  ϵsignxjθx l
whereas jsma is based on the concept of saliency maps
this algorithm tries to ﬁnd input dimensions or features that
are most vulnerable due to possible perturbations by creating
a saliency map and an iterated process to ﬁnd misclassiﬁcation
in the model
jx  fx
x
 f jx
xi 
some recent studies of adversarial examples are performed
in the ﬁeld of network intrusion detection systems nids
in these studies signiﬁcant degradation in accuracy is ob
served for intrusion detection systems after exposing dnns
to adversarial examples  whereas usama et al 
investigated the vulnerability of cognitive self organizing
networks cson utilizing mldl techniques against adver
sarial attacks in this study we have performed fgsm and
jsma attack on dnnbased abnormal kpi detector to show
that adversarial attacks can be fatal for this important use case
of son
c adversarial defense methods
many methods have been proposed for making ml models
more robust and mitigating adversarial examples adversarial
training  and defensive distillation  are two famous de
fense techniques we have implemented adversarial training
as a defensive technique for our experiments the basic idea
of adversarial training is to train the model using adversarial
examples and assign the same labels of the original examples
to the adversarial examples
d explainable ai
current work of explainable ai or blackbox model inter
pretability lies within two categories global and local inter
pretability global interpretability describes the understanding
of the whole logic of a model and follows the entire reasoning
leading to all the different possible outcomes whereas local
interpretability is used to generate an individual explanation to
justify why the model made a speciﬁc decision for an instance
 some recent studies explored the link between xai
and aml tomsett et al  proposed this phenomenon that
xai and adversarial machine learning aml are conceptually
linked and insights in one can provide insights in the other
domain giurgiu et al  used recurrent neural networks and
attention mechanism for explaining the failure predictions in
time series data marino et al  proposed a methodology to
explain incorrect classiﬁcations made by intrusion detection
systems ids using the adversarial approach in this paper
we have used explainable ai to provide a deeper understanding
of the features involved in the adversarial ml attack on dnn
based kpi detector
iii methodology
in this section we will describe our procedure for perform
ing two types of adversarial attacks on abnormal kpi detector
but before that we will describe the threat model and the
dataset used in this experiment
a threat model
this subsection describes the major assumptions considered
for performing an adversarial attack on the use case of son
 adversary knowledge we have used two whitebox
attack algorithms which mean adversary has complete
knowledge about the model architecture features and
test data
 adversarial goals and defense our goal in this ex
periment is to check the vulnerabilities of son against
adversarial examples we have achieved this by measur
ing accuracy before and after implementing attacks we
have experimentally validated a defensive technique to
mitigate the effect of adversarial examples
b son use case  detection of abnormal kpi
figure  states the generic ﬂow chart of son methodology
consisting of its main use cases of selfoptimization and self
conﬁguration of a lte long term evolution network 
two main functions of lte architecture are i evolved uni
versal terrestrial radio access network eutran and ii
evolved packet core epc eutran consists of multiple
base stations termed as enodeb and user equipment ue
ue is typically a smartphone or an iot device for using call
or data services after setting up a connection to a cell of the
cellular network a cell is a speciﬁc terrestrial area controlled
by each enodeb
key performance indicators kpis explain the quality of
services qos and quality of experience qoe of these
connected devices for example kpis that are relevant to
call or data services setup and services completion belong to
accessibility and retainability classes of kpis respectively
the calculation of these kpis is based on the measurement
reports which are collected through various internal and
external data collection methods son continuously monitors
these kpis and in case of any abnormality automatically starts
relevant optimization and conﬁguration tasks
figure 
son methodology flow chart son function continuously
monitors the kpis and starts automatic optimization and conﬁguration actions
based on kpi measurements
erab drop rate is one of the signiﬁcant kpis to judge
user experience and belongs to the retainability class of kpis
effective and timely detection of this indicator is essential to
avoid users churn brief description of this kpi is mentioned
below
when a user equipment ue has data to send or receive
it sets up an end to end communication channel called eps
radio access bearer erab between itself and the core
network part of epc this erab is the access layer bearer for
carrying service data of a ue after the utilization of cellular
services ue releases its radio access bearer rab this
rab is considered as a drop if it is released abnormally ie
ongoing session is dropped requiring the user to initiate a new
connection to resume services this drop rate is measured as a
fraction of the total number of abnormal releases with normal
releases
erab drop rate     erab abnormal releases
erab normal releases
c dataset and data preprocessing
for the use case of erab drop rate detection records
are extracted from live lte network each row contains an
hourly record of a speciﬁc enodeb with a sudden increase in
erab drop rate is labeled as an anomaly initial experiments
involve total  records of two lte enodebs  records
are labeled as normal and  as anomalies based on domain
knowledge each sample has  features which are divided
into three main categories of i time and location ii de
pendent features erab drop reasons and iii independent
features signal strengths latency and the number of users
this dataset has binary and nominal data variables and we
have applied onehot encoding to convert nominal features to
numeric features since dnns cannot operate on nominal data
directly this resulted in the transformation of the feature
dataset into a feature dataset after onehot encoding
after analyzing the data we have noticed varying distri
butions of each feature for example the mean and standard
distribution of some features are larger by seven orders of
magnitude from some other features without performing
normalization these features would dominate other features
to mitigate this effect we have used minmax scaling using
scikitlearn library to normalize data for our use case of
anomaly detection in the dataset of erab drop rate we have
used multilayer perceptron mlp classiﬁer with the activation
function of relu using keras and tensorﬂow sequential
model the mlp model is composed of three hidden layers
of  neural units the output layer contains two neurons
since labels have two normal and abnormal classes for
regularization dropout with a rate of  and earlystopping
is used
iv performance evaluation
in this section we have provided a detailed evaluation of
our experiment results
a evaluation metric
we have used accuracy for performance evaluation of
results accuracy is deﬁned as the percentage of correctly
classiﬁed records over the total number of records after
training the dnn model and testing its accuracy we have
implemented both fgsm and jsma attacks for evaluation of
the impact of adversarial examples at the dataset accuracy is
again measured after implementation of adversarial training
as a defensive technique
b experiment results
 impact on accuracy figure  and ﬁgure  describe the
experimental results after implementing adversarial examples
and defensive technique of adversarial training at the dataset it
is clear that adversarial examples have signiﬁcantly degraded
the performance of dnns used in son we have observed
jsma caused more performance degradation than fgsm
however jsma requires more computation time for crafting
an adversarial example our results in ﬁgure  and  also
depict the performance of dnnbased abnormal kpi after
the adversarial training it is evident from the results that
adversarial training has performed better against fgsm as
compared to jsma
 features explanations most affected features are calcu
lated through the technique mentioned in  we have ranked
and sorted the features with their importance after generating
the adversarial test set this importance is calculated by
subtracting the original test set from the adversarial test set
the indexes where adversaries have no impact the value
of this subtraction is zero however for indexes which are
affected by the attack the value of this subtraction is nonzero
by calculating these nonzero values most affected features
are calculated
figure 
performance of abnormal kpi detector before and after fgsm
attack the ﬁgure also provides the results of adversarial training which tells
the recovery of the abnormal kpi detector
figure 
performance of abnormal kpi detector before and after jsma
attack the ﬁgure also provides the results of adversarial training which tells
the recovery of the abnormal kpi detector
as expected fgsm changed almost all features  out of
 however it is not possible to avoid human observation
when the scale of the adversary is on such a large level
whereas jsma changed six features and degraded the perfor
mance of model badly we have observed the most affected
features and compared them with the domain knowledge of
cellular networks for instance we have an understanding
from the dataset that most of the erab drops are due to the
transport network layer tnl problems and almost identical
features of tnl drops are observed after examining the most
vulnerable features by jsma attack
v conclusions
in this paper we have performed fgsm and jsma attack
on dnnbased abnormal kpi detector our results indicate
more than  drop in the performance of dnnbased
abnormal kpi detector making it very evident that dnn used
for detection does not provide robustness against adversarial
perturbation a prominent recovery in the performance of
abnormal kpi detector is noticed after we have used adver
sarial training as a defense against adversarial examples we
have also provided the reasons why adversarial attacks are so
effective against abnormal kpi detector by utilizing insights
from explainable ai our results also trhow the light on a
previously ignored area of machine learning security in the
son and provide good insights for developing a robust ml
based son solution
adversarial machine learning attack on
modulation classiﬁcation
muhammad usama muhammad asim junaid qadir ala alfuqaha muhammad ali imran
information technology university lahore punjab pakistan
hamad bin khalifa university qatar
university of glasgow scotland uk
email muhammadusama msee junaidqadirituedupk aalfuqahahbkueduqa muhammadimranglasgowacuk
abstractmodulation classiﬁcation is an important component
of cognitive selfdriving networks recently many mlbased
modulation classiﬁcation methods have been proposed we have
evaluated the robustness of  mlbased modulation classiﬁers
against the powerful carlini  wagner cw attack and showed
that the current mlbased modulation classiﬁers do not provide
any deterrence against adversarial ml examples to the best
of our knowledge we are the ﬁrst to report the results of the
application of the cw attack for creating adversarial examples
against various ml models for modulation classiﬁcation
index termsadversarial machine learning modulation clas
siﬁcation
i introduction
the success of machine learning ml in computer vi
sion and speech processing has motivated the networking
community to consider deploying ml for the automation of
networking operations recently new networking paradigms
like cognitive selfdriving networks  and most recently
knowledge deﬁned networking  have also emerged that de
pend on and facilitate the extensive utilization of ml schemes
for conducting networking tasks recently ml has success
fully applied on different cognitive selfdriving networking
tasks such as modulation classiﬁcation  and representation
learning of radio signals 
although ml schemes especially deep neural networks
dnn have outperformed traditional networking schemes in
many networking tasks it has been shown recently that dnn
and other ml schemes lacks robustness against adversarial
examples which are deﬁned as inputs to the ml model
specially crafted by an adversary to cause a malfunction in
the performance of the ml model these adversarial examples
are generated by adding small typicallyimperceptible pertur
bations to the legitimate examples for the express purpose of
misleading the ml model towards the production of wrong
results and to increase the prediction error of the model
based on the adversarys knowledge adversarial attacks are
classiﬁed into two major categories whitebox attacks and
blackbox attacks in whitebox attacks it is assumed that
the adversary has perfect knowledge about the victim model
whereas in blackbox attacks it is assumed that adversary has
no information about the victim model and the adversary can
only query the deployed ml model for a response and to later
use this information for crafting adversarial examples
more formally an adversarial example xis crafted by
adding a small imperceptible perturbation δ to the test example
x of the deployed trained classiﬁer f the perturbation
δ is computed by approximating iteratively the nonlinear
optimization problem given in equation  until the crafted
adversarial example gets classiﬁed by the trained ml classiﬁer
f in a wrong class t
x x  arg min
ηx η fx  η  t
adversarial examples are a direct consequence of an unsafe
assumption in ml that distribution encountered by the ml
model in training phase will also be encountered in the test
phase of the ml model
the effects of adversarial ml examples in cognitive self
driving networks have not been explored properly in the
literature in this paper we have performed an adversarial
attack on ml classiﬁers performing the task of modulation
classiﬁcation which is an important application in cogni
tive selfdriving networks our results clearly highlight that
a small optimallycalculated adversarial perturbation for the
test example can cause a serious drop in performance of
the classiﬁcation output of the ml model this paper also
highlights the vulnerability and brittleness associated with the
ml models used in the cognitive selfdriving networks
the major contributions of this work are
 we have performed an adversarial ml attack on  ml
based modulation classiﬁers to highlight the vulnerability
of these modulation classiﬁers to adversarial perturbation
 we demonstrate the transferability phenomenon in the
setting of modulation classiﬁers by showing that an
adversarial example compromising one ml scheme will
also be to evade other ml schemes with high probability
 to this best of our knowledge this is the ﬁrst experiment
where the carlini  wagner cw attack  has been
used to attack the modulation classiﬁcation task
the rest of the paper is organized as follows in the next sec
tion we will provide a brief review of the related research that
focuses on mlbased modulation classiﬁcation and adversarial
attacks on modulation classiﬁcation section iii describes the
methodology where we have discussed the assumed threat
model mlmodels used for modulation classiﬁcation and the
utilized adversarial attack for crafting adversarial examples
section iv provides the performance evaluation of the ad
versarial attack on the modulation classiﬁcation section v
concludes the study and provides future directions
arxivv  cscr   sep 
ii related work
a modulation classiﬁcation using ml schemes
the recent success of ml in computer vision and cyber
physical systems has inspired a surge in the utilization of ml
schemes in wireless and data networks it is conceived that ml
will be the backbone of future cognitive selfdriving networks
modulation classiﬁcation is an important problem in dynamic
spectrum allocation of cognitive selfdriving networks there
are few mlbased modulation classiﬁcation schemes available
in the literature wong et al  used a combination of
genetic algorithm and multilayer perceptron for digital modu
lation recognition aslam et al  used genetic programming
with knearest neighbor knn for modulation classiﬁcation
although genetic algorithms provides a good heuristicbased
solution but these algorithms do not scale efﬁciently with the
increase of the sample population
muller et al  employed a combination of discrimina
tive learning and support vector machines svm for mod
ulation classiﬁcation mendis et al  utilized deep belief
networks dbn for modulation classiﬁcation although dbn
has produced very impressive results but they are known
to be very difﬁcult to train and scale oshea at al 
used convolutional neural network cnn vgg and resnet
for performing modulation classiﬁcation schemes where they
have compared the deep mlbased modulation classiﬁcation
with the conventional modulation schemes under different
conﬁguration and noise levels and showed that mlbased
schemes performed better even in low signal to noise ratio
snr using ml schemes have produced very good results
but they are vulnerable to adversarial examples crafted by the
adversary to fool the mlbased classiﬁer to perform incorrect
classiﬁcation
b adversarial attacks on mlbased modulation classiﬁcation
there has not been much work available on exploring the
threat of adversarial ml examples on modulation classiﬁca
tion sadeghi et al  used a variant of fast gradient sign
method fgsm  to perform an adversarial ml attack on
cnnbased modulation classiﬁcation and successfully showed
a considerable drop in classiﬁcation accuracy fgsm is a
technique for crafting adversarial example where one step
gradient update is performed in the direction of the sign
associated with the gradient at each feature in the test example
the fgsm perturbation η is given as
η  ϵsignxjθx l
flowers et al  provided an evaluation framework for
testing modulation classiﬁers against adversarial ml attacks
they have tested the modulation classiﬁer against fgsm and
gaussian random noise base adversarial attacks and showed
that fgsm causes more destruction than the random gaussian
noise similarly kokalj et al  used the fgsm attack
to demonstrate the vulnerability of modulation classiﬁcation
against adversarial examples bair et al  highlighted the
limitations of the targeted adversarial attack on modulation
classiﬁcation in whitebox settings
most of the results of the adversarial attacks reported on
modulation classiﬁcation have used fgsm attack without con
sidering that fgsm was not designed to generate the optimal
amount of adversarial perturbation it was only designed with
an absolute motivation of generating adversarial perturbations
quickly rather than optimally  in this paper we have
performed cw attack  on modulation classiﬁcation to
compute the optimal adversarial perturbation
iii methodology
in this section we describe our procedure for performing an
adversarial attack on modulation classiﬁcation to the best of
our knowledge there is no standardized mlbased solution for
modulation classiﬁcation in the cognitive selfdriving networks
available yet in the literature so for completeness we have
used both conventional and deep ml schemes for modulation
classiﬁcation before delving deep into the details of the
mlmodels used for modulation classiﬁcation and adversarial
attack on it we describe the threat model and a few related
assumptions
a threat model
this subsection describes the major assumptions considered
for performing adversarial attack on modulation classiﬁer
 adversary knowledge we have assumed a whitebox
settings for performing an adversarial attack on dnn based
modulation classiﬁcation which means adversary has the
complete knowledge about the model architecture related
hyperparameters and the test data this assumption is fairly
standard in the adversarial ml domain we have transferred
the adversarial examples for dnnbased modulation classiﬁer
to other conventional mlbased modulation classiﬁers in this
paper we have only assumed test time adversarial attacks
poisoning attacks are left for future considerations
 adversarial goals our goal in this experiment is to
compromise the integrity of the modulation classiﬁer through
adversarial examples and the success of the adversarial attack
in this paper will be measured by the comparison of the
accuracy before and after the adversarial attack
b modulation classiﬁcation models
we have used dnn knn svm na
ıve bayes nb linear
discriminant analysis lda decision tree dt random
forest rf and ensemble methods for modulation classiﬁ
cation to the best of our knowledge this is the ﬁrst paper
that uses almost all the famous ml schemes for modulation
classiﬁcation and then performs adversarial ml attack on these
schemes to highlight that conventional ml deep ml and
ensemble methods do not provide robustness against small
carefullycrafted perturbations
for the dnn classiﬁer we have used four dense hidden
layers network with rectiﬁed linear units as a nonlinear
activation in hidden layers and softmax for calculating the
classiﬁcation probabilities of each class stochastic gradient
descent sgd has been used as an optimizer and categorical
crossentropy as the associated loss function for training the
dnn based modulation classiﬁer for the knn classiﬁer we
have used  neighbors as an optimal number of neighbors for
performing the classiﬁcation we have used radial basis func
tion rbf kernel for performing the svm based modulation
classiﬁcation for the nb classiﬁer we have assumed gaussian
distribution as the underlying modulation data distribution for
the ldabased classiﬁcation we have used singular value
decomposition svd solver as an svd solver can better
handle a large number of modulation data features for the
dt classiﬁer we have used maximum unfolding depth of 
for achieving good classiﬁcation result for the rf classiﬁer
we have a maximum of  trees forest for estimating the
classiﬁcation results for ensemble methods for modulation
classiﬁcation we have employed adaboost and gradient
boosting algorithms the obtained classiﬁcation results are
provided in section iv
c adversarial attack
we have performed cw  attack on mlbased mod
ulation classiﬁers to demonstrate the lack of robustness of
the mlbased modulation classiﬁcation scheme in cognitive
selfdriving networks carlini et al  proposed three very
powerful adversarial ml perturbation crafting techniques by
using three distance matrices l l and l and these
attacks have successfully evaded the defensive distillation
method  a popular early scheme for defending against
adversarial examples
we have used lbased cw attack for crafting adversarial
examples instead of formulating the adversarial ml problem
as in equation  which is highly nonlinear formulation that
is difﬁcult to optimize an alternative formulation provided
in equation  where gx is the new objective function such
that gx  iff gx  t here t can be any label but the
true label is used by the the cw attack that can be solved
by gradient descent the best performing objective function
g used for crafting adversarial examples for modulation
classiﬁcation is provided in equation  where z denotes the
softmax function
minimize
η
ηp  cgx
such that
x  n
gx  max max
it zxi zxt
we have only opted to use an lbased adversarial attack
because we want to keep the perturbation η to a minimum
while minimizing the squared error between adversarial mod
ulation example and the original modulation example
many defenses against adversarial examples have been
proposed in literature but this powerful attack has beaten all
of them  and to the best of our knowledge there does not
exist any defense that ensures robustness against lbased c
w adversarial attack
in our experiments we wish to achieve the following
objectives
 objective  do the ml schemes used for modulation
classiﬁcation in the literature provide necessary robust
ness against adversarial perturbations
 objective  we want to experimentally verify that the
adversarial examples breaching one ml schemes will
breach other ml models with high probability even if
the deployed ml model is unknown
before explaining how we have met these objectives through
our experiment in the next section we provide a detailed
description of the dataset used for performing the experiments
d dataset
we have used highly cited gnu radio ml rmla
dataset  for our experimentation the reason for selecting
this dataset is its public availability and utilization in the
literature dataset consists of  input examples where
each example is associated with a modulation scheme at a
speciﬁc snr dataset has  modulation schemes namely
amdsb amssb wbfm pam bpsk qpsk psk
qam qam cpfsk and gfsk out of these  mod
ulation schemes  are digital modulations and  are analog
modulation schemes
for this experiment we have used eight digital modulation
schemes and excluded three analog modulation schemes the
excluded schemes are amdsb amssb and wbfm the
total number of examples used in these experiments is 
each example is a  size vector with  inphase and 
quadraturephase components this dataset was generated for
 different snr levels from  db to  db more details
of the dataset preparations can be found in 
iv performance evaluation
in this section we have provided a detailed evaluation
of the mlbased modulation classiﬁers against adversarial
perturbations
a performance impact
we have evaluated the mlbased modulation classiﬁcation
before and after the adversarial attack we have used the
accuracy as the performance metric the decay in the modu
lation classiﬁcation describes the adversarial attack success
figure  provides a detailed comparison of accuracy and snr
before and after the adversarial attack the clear drop in the
accuracy of the classiﬁers with increasing snr fulﬁlls the
ﬁrst objective of this experiment where we set out to show
that the mlschemes proposed in the literature for modulation
classiﬁcation does not provide the necessary robustness against
adversarial examples
b transferability of adversarial examples
here we want to note that adversarial examples were only
crafted for dnnbased modulation classiﬁer under white
box assumptions the adversarial examples compromising
the integrity of the dnn classiﬁers were transferred to the
rest of ml classiﬁers under blackbox assumptions and it
turns out that modulation classiﬁers based on conventional
ml techniques are also equally vulnerable to the adversarial
examples which fulﬁll the second objective we wanted to
achieve through this experiment
v conclusions
in this paper we have highlighted the lack of robustness
of mlmodels utilized in modulation classiﬁcation by suc
cessfully evading  different mlbased modulation classiﬁers
we have also successfully shown that transferability of the
adversarial examples from one model to another model for
performing the adversarial attack this work has also provided
a glimpse of the security and robustness issues associated
with the utilization of ml models in cognitive selforganizing
networks designing new defenses against adversarial attacks
on cognitive selfdriving networks are left as a future direction
figure  the accuracy of ml models used for modulation classiﬁcation before and after adversarial ml attack is provided in the ﬁgure a clear drop in the
accuracy with improving snr after the adversarial attack clearly indicates the lack of deterrence against small carefully crafted adversarial perturbations
intelligent resource allocation in dense lora
networks using deep reinforcement learning
inaam ilahi muhammad usama muhammad omer farooq muhammad umar janjua and
junaid qadir
 information technology university itu punjab lahore pakistan
 lahore university of management sciences lums pakistan
 department of systems and computer engineering carleton university canada
 department of computer science and engineering college of engineering qatar university doha
qatar
abstract the anticipated increase in the count of iot
devices in the coming years motivates the development
of efﬁcient algorithms that can help in their effective
management while keeping the power consumption low in
this paper we propose an intelligent multichannel resource
allocation algorithm for dense lora networks termed as
loradrl and provide a detailed performance evaluation
our results demonstrate that the proposed algorithm not
only signiﬁcantly improves lorawans packet delivery
ratio pdr but is also able to support mobile enddevices
eds while ensuring lower power consumption hence
increasing both the lifetime and capacity of the network
most previous works focus on proposing different mac
protocols for improving the network capacity ie lo
rawan delay before transmit etc we show that through
the use of loradrl we can achieve the same efﬁciency
with aloha compared to lorasim and loramab
while moving the complexity from eds to the gateway thus
making the eds simpler and cheaper furthermore we test
the performance of loradrl under largescale frequency
jamming attacks and show its adaptiveness to the changes
in the environment we show that loradrls output
improves the performance of stateoftheart techniques
resulting in some cases an improvement of more than 
in terms of pdr compared to learningbased techniques
index termsresource allocation frequency jamming
attacks on networks internet of things iot deep
reinforcement learning drl and cognitive networks
i introduction
the count of internetofthing iot devices is antic
ipated to increase manifold in the coming years these
nonuniformly distributed dense networks will include
enddevices eds moving with different velocities this
puts forward a need for effective algorithms able to
manage all those devices while keeping the collisions
and the energy consumption as low as possible long
range lora is a leading low power wide area net
work lpwan technology and lorawan is a leading
lpwa networking protocol for lora lora uses the
chirp spread spectrum css technique which i is
resilient to interference ii uses low power iii is resis
tant to multipath fading iv is resistant to the doppler
effect and v has low communication link budget 
lorawan networks need a small infrastructure to be
deployed and their scalability can be increased by adding
more gateways to the network this makes lorawan
an attractive lowcost iot solution for transmitting data
from the ed to the user and control commands from the
user to the ed
broadly speaking there are two critical factors that
decide the usefulness of lpwan i better lifetime
and ii network capacity ie the maximum number
of eds supported by the network battery lifetime is
affected by the number of transmissions and the phy
layer parameters used for transmission while the network
capacity is affected by i the number of available
channels ii air time the time taken in air by the signal
to reach the receiver iii intertransmission time and
iv transmission power dynamic allocation of phy
layer parameters in lorawan can help to increase
the network scalability of lora networks by decreasing
the number of collisions among signals coming from
multiple eds hence increasing their ability to coexist
the network capacity of the lorawan can also be
increased by increasing the number of lora gateways
and reducing the overhearing of transmissions to other
gateways by their strategic placement
in lorawan a communication channel is observed
by the ed and in case of the channel being busy
the phylayer parameters speciﬁcally the spreading
factor sf and the channel frequency are adjusted
reactively the sfs are partially orthogonal and eds
using different sf values can transmit simultaneously
 however such a reactive approach is not appropriate
for lowpower eds because before any parameters se
lectionadjustment algorithm is invoked several packets
would have been retransmitted or lost moreover the
time delay inherent in the reactive approach is also not
acceptable in situations where decision making has to
be done in a bounded time hence there is an absolute
need for a proactive intelligent and adaptive phy
layer transmission parameters adjustment algorithm for
arxivv  csni   nov 
lorawan
the presence of a large number of iot devices in
creases both the intranetwork and internetwork inter
ference causing a performance drop  the integration
of cognitive radio technology into the lorawan stan
dard can signiﬁcantly reduce the energy consumption
and increase the network capacity  a lorawan
gateway can decode multiple simultaneous transmissions
based on different phylayer transmission parameters
moreover existing research focuses on a static associa
tion between the resources of the iot and the surround
ing real environment iot is extremely dynamic in nature
and may experience unpredictable mobility resulting in
sudden variations of communication capabilities
also the inherent broadcast nature of wireless com
munications makes them vulnerable to internetwork in
terference and adversarial attacks jamming of a wireless
signal involves the addition of noise to a signal to
decrease the signal to noise ratio it differs from the
normal interference in terms of its purpose lorawan
uses encryption techniques that only secure the packet
content leaving the transmissions vulnerable  
and  discuss the susceptibility of lora networks to
jamming attacks these attacks can lead the resource
constrained iot devices to i drain their batteries due
to repeated data transmissions  ii denialofservice
dos
as the networks are anticipated to become denser
in the coming years both the frequency jamming and
dynamicity problems will become more severe in case
of being deployed in realnetworks the performance
pdr and energy consumption of lora network is also
affected by interference coming from other deployed
networks in the area this internetwork interference can
cause severe performance drop if not managed there is
a need for algorithms that can sense this performance
drop and hence adjust the frequencies to minimize the
effect of internetwork interference
adaptive selection of the phylayer parameters in
dense lora networks can be performed using efﬁ
cient algorithms hence enabling collisionfree concurrent
transmissions  the intelligent selection of parameters
not only reduces the impact of frequency jamming
attacks but also causes a signiﬁcant drop in energy con
sumption because of fewer retransmissions required due
to lost or collided packets for this purpose we proposed
a deep reinforcement learning drlbased phylayer
parameters selection scheme for dense lora networks in
our previous work  in that article we evaluated our
proposed technique in uniformly distributed scenarios
with different percentages of intelligent devices and
with different power levels we showed our technique to
be not only able to achieve a high pdr but also reduce
energy usage
in this paper we build upon our previous work 
by increasing its ability to support multiple channel fre
quencies and perform extensive additional experiments
in dense networks containing mobile eds furthermore
we test our algorithm in case of largescale jamming
table i important acronyms used in the paper
bw
bandwidth
cr
code rate
csmaca
carriersense multiple access  collision avoidance
ddqn
double deep qlearning network
dl
deep learning
dnn
deep neural network
dqn
deep qnetwork
drl
deep reinforcement learning
ed
enddevice
iot
internet of things
ism
industrial scientiﬁc  medical
lora
longrange
lorawan
longrange wide area network
mab
multiarmed bandits
mac
medium access control
pdr
package delivery ratio
phy
physical
ml
machine learning
rl
reinforcement learning
sf
spreading factor
wan
wide area network
attacks on dense networks and show our algorithm to
adapt against such attacks
the rest of this paper is organized as follows in
section ii we have discussed the common terminologies
used in lora networks and have provided the related
work in section iii we have provided the complete
system setup of the network and the drl algorithm
in section iv we have provided a brief introduction
of our previously proposed scheme loradrl along
with discussing the computational complexity and the
applicability to real environments in section v we have
performed the performance evaluation of loradrl
in multiple scenarios and provided the multichannel
scheme finally the paper is concluded in section vi
a list of important acronyms used are given in table i
ii background and literature review
a lora networks
lorawan is laid out in a starofstars topology
it works in the unlicensed industrial scientiﬁc and
medical ism frequency band lorawan architecture
consists of lora end devices eds lora gateways
network servers and application user servers a basic
lorawan architecture containing transmitting eds
gateway and network server has been shown in fig 
the applications of deployed lora eds in lorawan
can be either eventdriven or scheduled the former one
involves the transmission of data whenever a speciﬁc
event occurs while the latter involves transmissions on
scheduled intervals parking sensors in parking lots to
sense the available parking spaces are an example of
eventdriven eds while the temperature sensors mounted
at the top of buildings to measure the temperature of the
area exemplify scheduled transmitters
in lora a transceiver can select a bandwidth bw in
the range  to  khz and mostly a lora transceiver
operates at  khz  khz or  khz spreading
factor sf deﬁnes the ratio between the symbol rate and
the bandwidth lora provides seven sf rates to choose
fig  architecture of lorawan consisting of lora eds lora gateway network server and enduser the eds serve different purposes and transmit the data
to the gateway based on the application requirements the received data packets are forwarded to the network server which in turn forwards them to the enduser
from sf to sf by modifying the sf parameter
we make a tradeoff between the communication range
and the data rate as discussed before that the sf
values are partially orthogonal they can be used to
make multiple simultaneous communications possible
with minimum collisions coding rate cr deﬁnes the
level of protection against interference lora deﬁnes
four coding rates 
 
 
 
 a lora radio can transmit
between  to  dbm in  db steps however due
to hardware limitations the mentioned range is mostly
limited between  to  dbm the useful bit rate rb
is given as
rb  sf  bw
sf   cr
this shows that the useful bit rate is directly propor
tional to bw  cr and inversely to sf lorawan
provides  transmission classes to satisfy the require
ments of different applications namely class a class
b and class c class a is the most energyefﬁcient
class and is normally used in batterypowered devices
in class a there are two downlink communication
slots after each uplink transmission class b involves
scheduled downlink communication slots and is less
energyefﬁcient than class a in class c the downlink
communication is always active and hence this class is
the least energy efﬁcient normally class c devices are
connected directly to the main power to get a broader
view of lorawan technology we refer the reader to
b deep reinforcement learning drl
the rapid evolution of deep learning dl and compu
tational technologies have enabled the conventional rl
to solve the complex sequential decision problem which
is previously deemed impossible due to dimensionality
issues a combination of dl with legacy rl is known
as drl mnih et al  proposed deep qnetworks
dqn a combination of deep neural network dnn
and qlearning  as a solution to the computational
complexity problem faced by qlearning in complex en
vironments mnih et al  also introduced the concept
of experience replay and target network to improve the
dqns performance the qvalues are updated as given
in equation 
equation  provides a detailed description of dqn
qs a  rs a  γ max a qs
 a
where s is the next state a is the next action r is
the reward of a stateaction pair q is the qvalue of the
stateaction pair and γ is the discount factor the policy
π in dqn is to take the action with the maximum q
value at a speciﬁc state ie qs a  maxa qπs a
and is represented by the dnn
why drl in case of normal qlearning a qtable is
built to store the qvalues corresponding to each state
action pair this table can only be built when the state
space and actionspace are both discrete in case any
of them is continuous the size of the table increases
exponentially with each possible value of actions and
states dqn  can support continuous state and action
spaces while keeping a ﬁxed size of the model they
approximate the relationship of the stateaction pairs and
qvalues by the use of deep neural networks dnns
thereby removing the requirement of populating tables
dqns were shown to be overestimating the qvalues by
 as a remedy they propose the value estimation be
done by the target network instead of the online network
this not only reduces the overestimation of qvalues
but also increases the stability of learning
c related work
a number of different phylayer parameters selection
algorithms for lorawan have been proposed so far we
discuss the stateoftheart algorithms only there are
two major schemes for handling dense lora networks
i by scheduling the transmissions and ii by an
efﬁcient selection of phylayer parameters in 
kim et al  argued that the adaptive data rate control
used by the lorawan protocol is inefﬁcient as it
doesnt see the congestion in the lora networks to
improve this shortcoming kim et al  used a linear
regression model and showed better performance by
reﬂecting congestion in the adaptive data rate control
bor et al  proposed a lorasim simulator for
experimenting with dense lora networks using different
phylayer parameter settings they use ﬁxed subsets of
the phylayer parameter combinations to ensure colli
sion avoidance the only problem with their technique
is that it suffers from the problems associated with a
rulebased mechanism ie their technique is based on
a ﬁxed system model and is not able to adapt to the
environment changes which are normal in real networks
slabicki et al  proposed an endtoend network
simulator called flora for lora networks and also
proposed and validated an adaptive data rate scheme for
dynamic selection of link parameters for scaleable and
efﬁcient network operation they showed their technique
to increase the network delivery ratio under stable chan
nel conditions while keeping the energy consumption
low they showed that the network delivery rate can
be further improved using a networkaware approach
wherein the link parameters are conﬁgured based on the
global knowledge of the network they did not consider
the collisions among packets which can signiﬁcantly
reduce the packet delivery ratio
bianchi et al  presented a sequential water
ﬁlling strategy for assigning spreading factors sfs to
all lora nodes their design focused on  equalizing
the timeonair in the different sf groups  balanc
ing the spreading factor across multiple gateways 
keeping into account the channel capture in lora their
work showed an improvement of  capacity over the
adaptive data rate provided by lorawan
abdelfadeel et al  propose free a ﬁnegrained
scheduling scheme for reliable and energyefﬁcient data
collection in lorawan they propose that instead of
transmitting the data as soon as it is generated it is
scheduled for ﬁxed time slots which are decided by
their algorithm although this eliminates the problem
of collisions in lorawan this scheduling solution is
not scalable for dense networks as each ed will have
to wait for its allocated time slot on the other hand
our algorithm helps efﬁciently transmit the data as soon
as it is generated at the ed with minimized collisions
this also removes the delay caused by the scheduling
scheme proposed by  which might be destructive in
eds deployed for timecritical applications
the lora network community has also utilized drl
schemes for automating different tasks such as load bal
ancing  and resource management  aihara et al
 proposed a qlearning aided resource allocation and
environment recognition scheme for lorawan with
csmaca they train different deep neural networks
dnns for each lora ed which is resourceintensive
our technique is only based on training a single dnn
for the whole network also the learning of each of
the dnn proposed by  is selﬁsh and every dnn
only focuses on its own reward while our technique
focuses on a joint reward of the system also such
schemes cannot be deployed in dense networks owing
to the computational requirements techniques like 
fail when they are tested against adversarial jamming
attacks because of the inability to adapt to the changes
in the environment
farhad et al  propose a proactive mobilityaware
resource assignment algorithm for lorawan they pro
pose to update the values of sf and transmission power
value on each uplink communication their algorithm is
not based on learning and hence is bound to fail in real
environments where the conditions are different from
simulation
aggarwal and nassipuri  propose to allocate dif
ferent sf values to the eds present in a small range
of the gateway this allocation leads to a better perfor
mance of the network by increasing the overall pdr
their algorithm requires to explicitly provide an sf
allocation ratio for the eds as our algorithm discussed
later is based on reinforcement learning it does this
automatically and there is no need to explicitly provide
an explicit sfallocation ratio an approach similar to
 has also been proposed by 
chinchilla et al  propose an algorithm for reduc
ing the collisions in lora networks their algorithm
works by dividing the wireless medium into resource
blocks where each research block is based on one sf
value and one channel frequency the objective of their
algorithm was only to increase the capacity of the
network and they did not consider the energy usage in
their algorithm furthermore they do not consider the
intersf collisions while our algorithm discussed later
takes all of these things into consideration
ta et al  proposed the use of rl for dynamic
phylayer transmission parameters selection for lora
based eds they pointed out multiple issues with lo
rasim for example using perfectly orthogonal spread
ing factors based on their identiﬁed weakness in lo
rasim they proposed another discrete event simulator
named loramab they used the multiarmed ban
dits technique to solve the collision issue we identify
multiple issues with loramab and hence propose our
centralized drlbased algorithm as a solution to these
issues the identiﬁed issues with loramab are listed
below
 loramab is exponentially complex in terms of
its computational complexity and hence not fea
sible for dense lora networks the convergence
time of the algorithm is high and is bound to
increase with an increase in the count of eds
 it does not account for the mobility of eds this
makes it inapplicable in a network consisting of
mobile eds such as healthcare smart vehicles
aging society and postemergency networks
 the focus on optimizing power consumption is not
done properly due to a missing specialized objec
tive function eds have the option of choosing any
of the available power levels without particularly
focusing on saving power this random choice
does not always lead to the optimal power level
selection
 the computations are being performed at the eds
without considering the power limitations in the
case of batterypowered eds
 to reduce the complexity of the problem lora
mab reduces the action space of individual eds
based on their distance from the gateway in case
the eds are mobile a change in their position
makes the learning suboptimal
we refer the reader to  and  for getting a
comprehensive review of the several adaptive resource
allocation schemes proposed for lorawan
in our previous work  we showed that the perfor
mance deteriorates in a loramab based system when
eds are mobile in this paper we perform further ex
periments with loradrl  and show the applicability
of loradrl to real lora networks furthermore we
test the performance of loradrl in case of largescale
jamming attacks and show its adaptability to changes
in the environment we also show the susceptibility of
rulebased techniques against these attacks
iii system setup
we have previously described the working of our
ddqnbased adaptive phylayer parameter selection
algorithm for dynamically deployed networks in 
in this paper we further discuss the complexity and
applicability aspects in detail in the following section
one of the major problems seen in the previously
proposed resource allocation techniques for lorawan
is the missing support for real dynamic environments
which keep on changing with time furthermore in the
experiments section we show that loradrl can sense
the performance drop due to frequency jamming and
hence can shift the system to the less interfered channels
and hence maintain the performance of the network we
also show the ineffectiveness of the rulebased system
lorasim against such attacks
a problem statement
lora provides multiple sf values for transmission
which lead to different data rates the signals generated
using different sf values are partially orthogonal to each
other by compromising the data rate the concurrent
transmissions can be increased by the use of different sf
values and transmission channels the efﬁcient selection
of these parameters in dense networks can not only save
energy but also increase the capacity of the network
b system model
in our proposed scheme we consider a singlegateway
lora network containing k lora eds uniformly dis
tributed over an area of a radius of m with the
gateway present in the center the eds can choose to
transmit the data using different phylayer parameter
combinations over multiple available transmission chan
nels we do not limit the sf values for the eds and
all the eds are free to use any of the sf values the
gateway acts as the agent whose goal is to decide the
phylayer parameters for each of the eds it is assumed
that a new ed arrives at each timestep and is located
at an arbitrary location the normalized count of each
of the actions taken until the current step and the
approximate distance of the newcoming lora ed is
taken as the state of the environment
the basic mapping of our algorithm on the workﬂow
of drl has been given in fig  the agent takes a
speciﬁc action choosing a phylayer parameters combi
nation for the new lora ed at a timestep and receives
a reward based on the achieved packet delivery ratio
pdr and powerusage based on that chosen action
fig  mapping of our problem setup on drl the gateway is considered the
agent and the lora network represents the environment
we use pdr and energy consumption as our per
formance metrics the pdr is deﬁned as the ratio of
correctly delivered messages to transmitted messages
over a period of time the achievable pdr depends on
the position count and behavior of lora eds
for experimental purposes we are assuming a lora
network consisting of class c devices for training after
training our model can be deployed with any class of
the lora devices we use the gaussmarkov model
for the mobility of the eds this model eliminates the
sudden stops and sharp turns encountered in the random
walk mobility model by allowing past velocities and
directions to inﬂuence future velocities and directions
our previous results  showed that when the mo
bility was introduced in the loramab system 
the performance started to degrade immediately due to
nonadaptability and no support for mobile eds the
learning in loradrl is performed on the gateway
which is independent of the eds and hence can handle
the mobility of eds as far as state calculation is
concerned our states are based on the actions taken
by the agent until the current step and the approximate
distance of the ed from the gateway the former one
can be easily calculated by populating a table while the
latter can be approximated using the received power of
the signals from the eds it is to be noted that the eds
present near buildings will show less received power
than in case of open space this will lead the algorithm
to choose higher sf values for such devices which is a
good choice
the lora devices can support a power level as low as
 db in case multiple power level choices are included
in the actionspace the energy consumption can reduce
considerably due to the high trainingconvergence time
of loradrl we propose the training of loradrl to
be performed in simulation and then the model be de
ployed in real networks with the learning to be continued
with a small learning rate this will help our proposed
model adapt and ﬁt itself to the real environment
it is to be noted that we assume that the number of
eds and packet arrival rate is known at the gateway
it takes around  packet transmissions for the gateway
to get a reliable estimate of pdr for mobile eds we
assume that the current pdr is being averaged with the
previous  transmissions pdr as we are not assuming
very high velocities hence the time required to get a
good estimate of pdr is acceptable
iv proposed scheme for adaptive phylayer
parameter selection
a reward function
to assist in the learning process we have designed a
specialized rewardcost function to optimize phylayer
transmission parameters selection for lora eds by
using this reward function the maximum reward is given
to the optimal combination of phylayer parameters
the reward function is given in the below equations
equation  is the reward for optimizing the pdr of the
network only equation  is the modiﬁed equivalent to
include power optimization
rt  α pdred β airtimeed
rt  αpdred βairtimeed γpowered 
where
powered  powermax powerchosen
powermax powermin
ed is the newcoming ed that has arrived in the
previous timestep pdr is the package delivery ratio
and airtimeed is the airtime of the speciﬁc ed in
seconds α β  γ are the relative constants used to
assign appropriate weights to pdr airtimeed and
powered these constants act as hyperparameters and
can be chosen depending on the dynamics of the lora
network power is the reward based on the power choice
for the ed this part of the reward function is designed
in such a way that if we have  available power levels
 db  db and  db the reward is also deﬁned in a
distributed fashion in this way more reward say x will
be given to the agent if it chooses  db power lesser
reward x will be given if it chooses the  db power
and the least reward x will be given if it chooses the 
db power
b proposed algorithm
the proposed ddqnbased algorithm for learning
the phylayer transmission parameters for eds in a
lora network has been given in algorithm  qnetwork
structure is taken as input to the model and it returns
a trained ddqn network at the output the algorithm
trains for a given number of episodes where each episode
is run for timesteps equal to the maximum number
of eds present in the system we assume that a new
ed arrives at each timestep the replay buffer is
populated by the agent by taking different actions at
different states samples from this replay buffer are then
used to train the neural network this trained network
provides the optimal policy for determining the best
phylayer parameters for the eds based on the state
of the environment
algorithm  loradrl
input qnetwork structure
output trained qnetwork
 initialize both the target  online qnetworks
 initialize the memory replay buffer
 for maxepisodes do
while steps  maxedcount do
initialize the lora network
compute state of the network st
feed the state to the dnn to get action at
taken action at at state st
simulate the environment
compute reward rt and next state st
collect m datapoints st at st rt using
policy π and add it to the memory
sample minibatch from memory
compute the change in values using target
qnetwork q
φ
yj  rj  γ maxa
j qφs
j a
j
update the online qnetwork
φ φ α p
j
dqφsjaj
dφ
qφsj aj yj
if steps  targetupdateinterval then
update the target qnetwork φ
end if
st st
end while
 end for
lora eds are sleeping except when they need to
transfer the data the transmissions are carried out on
the base of the different transmission classes ie class
a b  c we propose that the lora ed send the
packets to the gateway which in return either sends
an acknowledgment to use the previous parameters or
sends the new phylayer parameters combination to
be used for carrying out further transmissions through
the control packets using the ﬁxed bandwidth channel
of  khz in case the lora ed does not receive
the parameters or acknowledgment from the gateway
it either chooses the maximum available power and sf
to transmit the signal or uses the last allocated phy
layer parameters for the transmission this mechanism
has also been shown in fig  our algorithm also
works well on the reduced action space by allowing the
agent to choose from a speciﬁc subset of actions this
reduced subset can be made according to the datarate
requirements of different applications by ﬁxing a certain
sf cr or transmission channel
fig  proposed mechanism for implementing our proposed algorithm in real
lora networks
c drl speciﬁcations
the neural network is kept small to make the solution
more practical a discount factor of  has been used
to ensure the dependence of the current action on future
rewards furthermore we also use the ϵgreedy learning
procedure to fully explore the statespace where action
at timestep t is given as
at 
maxaqts a
with probability  ϵ
random action
with probability ϵ
we have chosen linear activation at the output layer
so that we get a probability for each of the actions in
this way if some of the eds can choose only a subset
of actions then that ed can choose the action with the
maximum probability from that subset of actions the
target qnetwork is updated on regular intervals with the
weights of the online network
d computational complexity
we have taken the same statespace as our previous
submission  ie the normalized count of each action
and the approximate distance of the newcoming ed
from the gateway due to this specialized statespace
the complexity of the problem does not increase with
the increase of the enddevices also we have chosen
a minimal size for the dnn which requires minimal
resources for training in the later sections we have
enhanced our previously proposed scheme to support
dense networks although the introduction of multiple
channels increases both the action and the state count
the same dnn can learn as the goal of the agent in both
these cases is the same the overall complexity of our
algorithm is onno where onn is the complexity
of the neural network which is a constant in our case
e applicability to real environments
we have kept the size of the neural networks the
smallest possible this makes it applicable to gateways
being backed by lowend computers the activation on
the last layer has been set to linear due to this our
neural network does not train itself to focus on just one
action but gives probability to each action in the action
space so in case a speciﬁc ed is only able to support
a subspace of actions the ed can choose the possible
action with the highest probability
the ddqn can see the change in the performance
of the network based on the reward achieved by taking
certain actions in certain states this ability makes the
algorithm adaptive as whenever the ddqn observes a
suboptimal action being performed it adapts the policy
in favor of the better available action this adaptive be
havior is a core beneﬁt of rl our proposed centralized
approach offers many signiﬁcant beneﬁts including the
ability to adapt a feature missing in previous solutions
and support for eds mobility
f multichannel extension of loradrl
in our previous work our focus was only on a single
channel and singlegateway scheme in this work we
have performed a performance evaluation of the scheme
under new scenarios and extended the scheme to multi
channel lora networks modiﬁcation of the action space
is involved in order to include multiple channels to
support dense lora deployments we have tested the
multichannel scheme in dense lora deployments and
shown its ability to manage we have also tested the
performance of loradrl against frequency blocking
and shown its ability to adapt to the environmental
interference
v experiments  results
for analysis and comparison of our algorithm with
the existing stateoftheart techniques   we
perform experiments to evaluate performance under i
different mobility velocities ii multichannel dense
scenarios iii multiple mac protocols and iv large
scale frequency jamming attacks these experiments
have been discussed in the following subsections all
of the provided results have just been simulated for
experimental purposes we have made certain design
choices just to make it easier for the reviewer to compare
the performance of our proposed technique with the
other counterparts
in our experiments we use a data frame size of
 bytes typical iot use cases generate small data
packets hence byte frame size can represent a large
number of iot use cases in our experiments the data
generation model is based on poisson distribution as
it can model multitude of iot usecases data trafﬁc
generation pattern we use a mean interarrival time ie
the average time between two consecutive transmissions
of the same ed of  minutes the available bandwidth
of the lora eds has been ﬁxed to  khz owing to
table ii speciﬁcations of the lora network simulations
average transmission interval
   milliseconds
mean rate
 minutes
bandwidth
 khz
radius
 meters
transmission class of eds
c
number of base stations
capture effect
true
inter sf interference
true
simulation time of  epoch
  mean rate
velocity
   kmh
table iii speciﬁcations of the ddqn in loradrl
no of layers
no of neurons
 
activations
relu relu linear
learning rate
memory capacity
batch size
gamma for qvalues
initial epsilon
final epsilon
change in epsilon
update frequency for online network
test the performance based on different limitations in
different regions an eds mean velocity is set to 
kmh with a variance of  we have chosen this velocity
to cover the use case of devices mounted on bicycles
uavs buildings etc for multiple purposes ranging from
tracking and transferring sensory data to the central
gateway the speciﬁcations of the lora simulation have
been provided in table ii the speciﬁcations of the
neural network have been provided in table iii
a performance under increasing mobility
as discussed in the introduction section the real
networks are a combination of mobile and nonmobile
eds the mobile eds move with varying velocities
between low and high in this subsection we perform
experiments to show the ability of loradrl to manage
such uniformly distributed heterogeneous networks we
consider a network of  eds and a single frequency
channel available for transmission the eds have only a
single power level to choose from ie  db different
velocities of mobile eds were chosen ie    kmhr
and    kmhr the former relates to the health
monitoring devices like smartwatches etc communicat
ing with the gateway while the latter relates to eds
mounted on bicycles carts etc as we are currently
considering a network consisting of a single gateway
we have not considered velocities greater than  kmhr
fig  shows the performance of loradrl the
rulebased algorithm proposed by bor et al  and
the decentralized algorithm loramab it is visible
that the performance of loramab drops more with
velocities while lorasim and loradrl can keep the
performance at the same level the performance of
loramab drops because of the slow learning process
however our proposed phylayer parameters selection
algorithm can support lora networks without any de
pendence on mobility velocities
fig  performance evaluation based on different mobility velocities
comparison of pdr of lora networks under lorasim loramab and
loradrl with a conﬁdence interval of  it can be seen that mobility
does not affect the performance of loradrl  lorasim while the increase in
velocity causes a deterioration in the performance of loramab
b performance in multichannel scenarios
as we know the spreading factors from sfsf
are partially orthogonal and transmissions with different
sfs can be received on the same channel concurrently
similarly the frequency channels are also orthogonal
and the same sf can be received on different channels
without any interchannel collisions current lora gate
ways can receive transmissions from lora devices on
 different channels simultaneously for this purpose
multichannel transceivers are used in the lora gateway
different frequencies do not interfere with each other
hence the devices can choose from the available sfs
without compromising on the pdr
in our previous work we had taken the combination of
sf and power as the action of the agent for converting
into a multichannel scheme we add the channel fre
quency to the action space hence increasing the action
count according to the available frequencies for testing
the performance of loradrl in dense deployments we
consider an environment consisting of  lora eds
and a single gateway the available choices of frequency
channels are set to  which is the maximum number
of frequency channels a lora gateway can receive and
decode simultaneous transmissions the eds have only
a single power level to choose from ie  db
the nodecount wise pdr of loradrl during learn
ing in dense lora networks has been shown in ta
ble iv the results show that our model can manage
these networks effectively in the table a very small
drop of pdr can be seen with the increase in the
count of eds table va shows the percentage of sf
values allocated to the devices in this dense network
across all the frequencies table vb shows the persf
pdr performance of the lora network these tables
show that loradrl allocates the phylayer parameter
values dynamically and adaptively on the other hand
lorasim and loramab allocate the values based on
the distance from the gateway
table iv table showing the performance of an channel loradrl in a dense
lora network consisting of a single basestation the values are presented with
 conﬁdence interval
no of nodes
der
  
  
  
  
table v a table showing the percentage of sf values of an channel
loradrl in a dense lora network consisting of a single basestation b
table showing the persf pdr performance of an channel loradrl in a
dense lora network consisting of a single basestation
sfvalue
percentage of devices
allocated
sf
sf
sf
sf
sf
sf
a
sfvalue
persf pdr performance
sf
sf
sf
sf
sf
sf
b
c performance with different mac protocols
much previous work has been focused on improving
the lora performance using different mac protocols
than pure aloha by using our proposed algorithm
loradrl we can use the basic aloha to perform
similar to complex mac protocols in this subsection
we test the performance of our proposed algorithm
loradrl with multiple mac protocols we consider
a channel lora network containing  uniformly
placed eds the delay in case of delay before transmit
is calculated using the following equation
td  edid  ud mod pktiat
where edid is the id of the respective ed ud is
the delay in microseconds and pktiat is the node mean
packet arrival time for these experiments ud was set
to  fig  shows the observed performance only
a minor difference in performance can be seen as all the
features of these mac protocols are already present in
loradrl furthermore loradrl reduces the burden
on ordinary nodes by pushing the complexity to a central
entity the gateway the performance of lorasim with
different mac protocols has been shown in 
channel sensing multiple access csma involves the
sensing of the channel before transmission and transmit
ting if the channel is free else waiting for a certain time
fig  figure showing the performance of loradrl with different mac
protocols it can be seen that there is a minor performance difference while
using different mac protocols with loradrl the bars are plotted with 
conﬁdence interval
interval and then sensing the transmission channel again
in this way the eds have to wait for the channel to
become free which is a rare case in dense networks
loradrl enables concurrent data transmissions and
removes the requirement of sensing the channel and
waiting this reduces the power requirement for the eds
and shifts the complexity from the resourceconstrained
eds to the gateway furthermore most of the stateof
theart mac layer protocols for lora are complex while
loradrl is based on aloha
d performance under adversarial frequency jamming
attacks
largescale
frequency
jamming
attacks
can
be
avoided by a continuous shifting of frequencies hence
making the jamming difﬁcult  however in realistic
settings the presence of an intermediary to continuously
change the settings is not necessary this puts forward
the need for intelligent algorithms that can adapt to the
changing environment in the favor of optimal settings
our technique can adapt to jamming attacks and can re
tain the performance of the lora network by frequency
hopping in the case of rl the learning and prediction
go hand in hand which makes it proactive to adversarial
attacks and adaptive to the changing conditions 
for this experiment we assume that there is another
network present in the area who is generating very high
internetwork interference hence reducing the perfor
mance of our lora network we consider a network
consisting of  lora eds and two frequency channels
available for transmission the eds have only a single
power level to choose from ie  db the network is
taken to be uniformly distributed with the eds moving
with random velocities under  kmhr
fig  shows the training of multichannel loradrl
algorithm at epoch  one frequency out of the two
fig  figure showing the performance of a multichannel loradrl and
lorasim scheme under frequency jamming attack a small drop of performance
is seen in the case of loradrl as it shifts to the other available frequency while
in the case of lorasim a sudden drop of performance can be seen because of
the absence of a feedback loop
available ones is jammed this jamming results in a
sudden drop in performance the system later learns on
the base of the current performance and can adapt to
the changing environment and achieve the performance
of singlechannel loradrl while in the case of a
frequency jamming attack on a rulebased lorasim
the performance drops to half the reason for this
is the random selection of a frequency channel for
each transmission the performance of lorasim under
frequency jamming attack has been shown in this ﬁgure
which shows no retention of performance it is to be
noted here that the collisions and jamming with respect
to the downlink communication is left as future work
all of the provided experiments were performed on
a lowend th generation i laptop it took on average
s for loradrl to make a decision while lorasim
took on average s to make a decision an important
aspect is the learning ability of the loradrl based on
the changes in the environment whereas lorasim assigns
parameters based on a deﬁned set of rules
vi conclusions
we have proposed an intelligent multichannel re
source allocation algorithm for dense lora networks
termed as loradrl we have provided a detailed
performance evaluation of this proposed algorithm by
testing it in lora networks consisting of lora end
devices eds having different mobility velocities and
in dense lora deployments our scheme has shown
exceptional results when compared with similar previous
techniques furthermore we have proposed a multi
channel scheme for loradrl to support multiple chan
nels we tested the performance of loradrl with
different mac protocols and show its ability to manage
the system while shifting the complexity from the eds to
the gateway we have also tested our proposed technique
under largescale jamming attacks where the rulebased
techniques fail badly the results show the effectiveness
of our proposed technique against such attacks and its
adaptiveness to the changes in the environment

aibased emotion recognition promise peril
and prescriptions for prosocial path
siddique latif haﬁz shehbaz ali muhammad usama rajib rana bj
orn schuller and junaid
qadir
university of southern queensland australia
emulation ai
national university of computer and emerging sciences nuces pakistan
imperial college london uk
university of augsburg germany
qatar university doha qatar
abstractautomated emotion recognition aer technology can detect humans emotional states in realtime using facial
expressions voice attributes text body movements and neurological signals and has a broad range of applications across many
sectors it helps businesses get a much deeper understanding of their customers enables monitoring of individuals moods in
healthcare education or the automotive industry and enables identiﬁcation of violence and threat in forensics to name a few
however aer technology also risks using artiﬁcial intelligence ai to interpret sensitive human emotions it can be used for economic
and political power and against individual rights human emotions are highly personal and users have justiﬁable concerns about
privacy invasion emotional manipulation and bias in this paper we present the promises and perils of aer applications we discuss
the ethical challenges related to the data and aer systems and highlight the prescriptions for prosocial perspectives for future aer
applications we hope this work will help ai researchers and developers design prosocial aer applications
index termsautomated emotion recognition artiﬁcial intelligence ethical concerns prosocial perspectives
introduction
automated emotion recognition aer is an emerging mul
tidisciplinary research area that leverages advances in ar
tiﬁcial intelligence ai to algorithmically retrieve a per
sons emotional state using knowledge from psychology
linguistics signal processing and machine learning ml
development of aer capabilities can have a transformative
effect on society with wideranging implications due to the
critical role emotions play in human lives ranging from
perception learning and decisionmaking    aer
is an umbrella term that encompasses various related terms
such as affective computing affect recognition emotional
ai or artiﬁcial emotional intelligence aei that have been
proposed in the literature for automated recognition of
human emotions 
in this paper we use the term aer and focus on human
target aer humantargeted aer starts with active or pas
sive sensors eg a video camera microphone physiologi
cal sensor that mainly captures contextual and behavioural
data related to affective facial expressions speech signals
body pose gestures gait or physiological signals it is im
perative to utilise contextual information while identifying
emotions  the data obtained through the sensing devices
extract emotional cues by the ai systems for categorical or
dimensional emotion recognition as depicted in figure 
email siddiquelatifusqeduau
fig  an overview of aer systems which can process emotional infor
mation from different emotional information sources to predict emotions
by utilising different ai techniques
aer has evolved over the years and achieved remark
able advances however it faces various complex and critical
challenges that escalate the need for further research to de
sign more trustful and beneﬁcial systems  some major
challenges faced in aer are
arxivv  cshc   nov 
table 
comparison of our paper with related articles
focus
paperauthor year
focus
promise
perils
ethical concerns
prescriptions
kolakowska et al  
aer
feng et al  
aer
batliner et al  
computational paralinguistics
liu et al  
aer eeg only
mohammad et al  
aer
our paper 
aer
unavailability of large datasets which restricts the
exploitation of powerful dl models to achieve bet
ter performance 
collection of reallife data for modalities such as
brain activity and neurotransmitters is very chal
lenging
varied idiosyncratic nature of human emotions due
to which it is hard to accurately recognise them
judging varying emotions in realtime is hard as
most vision and speechbased aer algorithms focus
on identifying the peak highintensity expression by
ignoring lowerintensity ones which can result in
inaccuracies and
cultural differences in manifesting emotions which
makes the problem of developing global aer very
difﬁcult
the public use of aer services also raises multiple
privacy and securityrelated concerns due to the intimate
nature that the aer systems detect process recognise and
communicate this paper presents promising applications of
aer and discusses its various perils in particular we focus
on presenting the ethical concerns related to aer systems
and databases to highlight the prescriptions for future aer
prosocial systems
we note here the speciﬁcity or universality of human
emotions has been a longstanding debate  the propo
nents of the universality of emotions suggest that emotions
can be recognised regardless of the different cultural back
grounds while theoretical studies   on multicultural
studies have suggested six basic universal emotions current
aer systems do not perform well in multicultural settings
the novelty and contributions of our paper are high
lighted in table  where we compare this paper with the
existing articles on aer the article by mohammad et al
 enlists the ethical challenges for aer and suggests
future directions but does not cover aer applications or
the challenges related to bias adversarial attacks explain
ability etc similarly other articles only focus on modality
speciﬁc applications  or general challenges  without
focusing on ethical issues in this paper we attempt to
present aers promise perils and ethical concerns we also
provide prescriptions for designing prosocial aer systems
we hope this paper will guide navigating research and
ethical implementation choices for anyone who wants to
build or use aer for research or commercial purposes
the rest of the paper is organised as follows the promise
of aer is described in section  the various perils of aers
are detailed in section  the major ethical concerns with
aer are discussed in section  we elucidate a prospective
path to a prosocial future for aer in section  the paper is
concluded in section 
promise of aer
aer has a wide range of applications in ﬁelds such as
healthcare entertainment advertising customer service
transportation employment decisions tutoring systems
law enforcement and humancomputer interaction appli
cations of aer are classiﬁed according to the input signal
provided in table  a broad description of frequently
targeted aer applications in different domains is presented
in table  and brieﬂy discussed below
table 
applications of aer and input data
human
expression
data
possible applications
vocal
expressions
audio
call centres meetings voice
assistants social robots educations
human resource healthcare etc
facial
expressions
visual
autonomous vehicles industrial
and social robots surveillance
social media gaming
education healthcare
body movements
and posture
visual
surveillance education healthcare
physiological
signals
eeg and ecg
records heart rate
wearable devices and
medical equipment
healthcare
developing aer methods in healthcare can greatly enhance
the quality of life enable individuals to better understand
and control their affective states eg fear happiness lone
liness anger interest and alertness and mitigate various
psychological issues that could have resulted in incidents
of suicide homicide disease and accident  this can
greatly improve quality of life and help achieve longterm
goals  it can help save many lives by monitoring people
and regulating their emotions through stressful times eg
in pandemics or economic crises it also minimises counter
productive behaviour such as suicidal tendencies and or
antisocial behaviour in healthcare settings aer services
play a pivotal role in shaping the healthcare functionality
and communication among professionals thereby improv
ing professionalpatient relations  it can help design
assessment and monitoring of emotional consequences due
to different illnesses for example aer systems can be
table 
summary of promises of aer technology in different domains
domains
promise
healthcare
monitoring people and regulating emotion
improves patientphysician relationships
analyses and understands emotions in
natural disasters and crises
education
improves studentteacher interaction
quantiﬁes student moods and engagement
in the classroom
promotes effective learning and increase
students interest
safety
improves workplace safety
enables help for emotionally suffered
coworkers
monitors the drivers fatigue stress etc
law enforcement
and forensics
helps identify threats of violence
and terrorism
provides additional aid in criminal
investigation
advertising and retail
helps maximise customers engagement
helps retailers to make decisions on
product pricing packaging branding etc
helps improve advertisement strategies
emotional and social
intelligence
helps inﬂuence the mood of the
overall population
helps leaders and decisionmakers to
handle highly challenging situations
monitoring and evaluation
enables monitoring of employees
performance
enables monitoring of major psychiatric
problems in both military and civilian
gaming
monitors players emotional states
and dynamics during gameplay
helps design affectaware video games
potentially used to monitor the patientphysician relation
ship in chronic diseases  this will help improve the
management of chronic illnesses
the importance of aer technology has also come to the
fore amid the ongoing global economic and public health
crisis during the covid pandemic  the pandemic
situation impacts people physically mentally and econom
ically aer systems can help to analyse and understand
emotional responses during such crises affecting mental
health studies    show that the negative emo
tions among the population increase during the pandemic
ie covid and people become optimistic over time by
adapting to the pandemic in global crisis situations like
covid aer systems can help measure crosscultural
emotional trends to learn the correlation among populations
despite the socioeconomic and cultural differences 
education
emotions are very crucial in the education systems due
to their important role in the cognitive processes respon
sible for assimilating and learning new information 
unfortunately the current education system fails to track
students emotions and hidden indicators of their internal
feelings thus making it delicate to adapt and keep the
communication channel intact it has been found that the
identiﬁcation and monitoring of the learners emotional
state greatly facilitates the teacher in taking actions that
signiﬁcantly enhance the tutoring quality and execution and
improve studentteacher interactions  therefore it is
worthwhile to utilise smart systems that can model the
relations between emotions cognition and action in the
learning context  in this regard aer systems can be
considered by schools to quantify student moods and en
gagement in the classroom  aer could help to reinforce
students attention motivation and selfregulation toward
studies it could also help promote effective learning by
increasing students interest  on the other hand aer
systems can improve certain emotional qualities teachers
must have to facilitate pedagogical approaches in education
safety
emotions are directly linked to human problemsolving
abilities  safety behaviours can be predicted from the
individuals ability to manage and process emotions during
a time of stress there is ample evidence that negative
emotions such as anger fear and anxiety strongly affect hu
man behaviour and occupational safety  for example
emotions can impact workplace safety and health in the
workplace the negative mood of a person can contaminate
an entire team or group this may damage workplace safety
and impair team performance if such behaviours are left
unaddressed negative emotions can be a workplace hazard
with visible effects on team safety aer systems can provide
better solutions to monitor an individuals mood and emo
tions in addition these systems can help ﬁnd workers who
might need help
in transport aer systems can be utilised to improve the
safety of drivers as well as anyone on the road driving
occupies a large portion of our daily life and is often
associated with the cognitive load that can trigger emotions
like anger or stress which can badly impact human health
and road safety   studies   show that in
duced negative emotions like anger can decrease a drivers
perceived safety and performance compared to neutral and
fearful emotional states aer services are being utilised in
automotive environment to monitor the drivers fatigue
alertness attention and stress level to improve automotive
and industrial safety by avoiding serious accidents 
mass adoption of aer systems to monitor psychological
and physiological parameters can signiﬁcantly enhance the
detection of dangerous situations
law enforcement and forensics
aer systems are increasingly being used for law enforce
ment and forensics where such systems have many pos
sible applications in identifying threats of violence and
terrorism and detecting lies and fraud  in a forensic
investigation a lie can arise from denial evasion distortion
outright fabrication and concealment by offenders to ap
pear nonaccountable for their exertions  aer systems
can help law enforcement agencies to detect deception or
malingering by identifying reliable emotional clues in this
way aer systems provide additional aid and insights to
lawenforcement agencies while pursuing criminal investi
gations  aer systems can also help detect and differen
tiate between acted and genuine victims 
advertising and retail
in marketing one of the best ways to sell products is
to engage the customers emotionally companies employ
vast resources for affective marketing by maximising user
engagement with ai they attempt to understand and
appeal to the customers interests and emotions  in
order to gauge a shoppers emotion aer systems use
sensing devices installed in hightrafﬁc locations including
entrances aisles checkouts etc aer systems detect the
emotional responses of individual shoppers which help
retailers in making decisions on crucial factors including
product pricing packaging branding or shelf placement
in this way aer systems help retailers understand how
consumers communicate both verbally and nonverbally
which may help fuel customers buying decisions
emotions highly impact individuals responses to re
ceiving marketing messages therefore sending an emo
tionally tailored message to the target audience increases
the customers attention to the advertisement this helps
companies to increase the products appeal and achieve a
higher level of brand recall  indeed advertisements
with emotional content have more potential to be remem
bered than those conveying notiﬁcation 
emotional and social intelligence
emotional and social intelligence involves understanding
inside oneself observing and interpreting others for cogni
tive and emotional empathy and responding constructively
in a given situation there is great interest in politics to
capture and inﬂuence the mood of the overall popula
tion or community to understand patterns of emotional
contagion  emotional and social intelligence can help
leaders and decisionmakers pick up emotional cues from a
population and handle highly challenging situations social
networks are particularly utilised to understand population
behaviours 
monitoring and evaluation
aer systems are being utilised to screen candidates in
interviews  and to evaluate and monitor employees
fatigue stress happiness and job performance  it is
widely accepted that emotional intelligence directly inﬂu
ences an employees intellectual capital organisational re
activity and retentively production employee appeal and
ability to provide good customer service  aer sys
tems can contribute to assess a candidates suitability for
a job and measure important traits like dependability and
cognitive abilities in particular embedded aer systems
enabled through iot can provide ﬁnegrained analysis of
emotions and sentiments  which can be used in various
ways for monitoring and evaluations in the military and
other defencerelated departments aer systems are par
tially used to track how sets of people or countries feel
about a government or other entities 
gaming
video games are related to the burgeoning area of enter
tainment applications millions of users across the globe
are entertained by violent games  and most selling
games contain violence and aggression these video games
are played by adolescents  for instance in the united
states  of adolescents have access to digital games and
on average a gamer spends  to  hours a week playing
video games  aer systems are highly suited to be
utilised for the design of affectaware gaming platforms
that can monitor players emotional states and dynamically
change the games theme to more effectively engage the
player  in these ways affectaware video games with
an entertainment character can also be utilised to initiate
prosocial behaviour by preventing antisocial actions along
with various applications such as elearning marketing
systems and psychological training or therapy
perils of aer
aer technology has a wide range of potentially intrusive
applications as discussed in the previous section  it uses
biometric data that may be used to reveal private informa
tion about individuals physical or mental states feelings
and thoughts it can also be used to interfere with the for
mation of beliefs ideas and opinions modern aer systems
often use deep learning dl models to obtain stateofthe
art performance however such dl models are known to be
inscrutable and are also not robust and are vulnerable to bias
and poor performance in the face of distribution shifts and
adversarial attacks  this raises concerns about using
the validity of aer services since it is not uncommon to see
that even wellintentioned technologies can have negative
consequences and how technologies can end up harming
rather than beneﬁtting people   we discuss some of
the prominent perils of aer next
risk of exploitative manipulation
aer technology can be exploited and used to inﬂuence
and control driving markets politics and violence al
ready there is a big concern in the community about major
technology companies morphing into empires of behaviour
modiﬁcation  with aer having access to intimate hu
man emotions the risk of exploitative manipulation rises
further as such information can be used to interfere with
the formation of beliefs ideas opinions and identity by
inﬂuencing emotions or feelings 
lack of consent and privacy violations
aer systems utilise ai technology in their design with
biometrics or other kinds of personal data speech facial
image among others this allows for information about
physical or mental health thoughts or feelingswhich an
individual may not want to choose to shareto be automat
ically inferred without the persons consent or knowledge
this has grave privacy concerns and can be used to establish
and strengthen oppressive dystopian societies
lack of explainabilityaccountability
aer systems usually lack explainability due to the complex
internal mechanics of the ai model and the widescale
adoption of blackbox models based on deep learning
technology this inability to understand how ai performs
in aer systems hinders its deployment in law healthcare
and enterprises from handling sensitive consumer data
understanding how aer data is handled and how ai has
reached a particular decision is even more critical for data
protection regulation explainability of aer services will
allow companies to track ai decisions and monitor biased
actions this will also ensure that aer processes align with
regulation and that decisionmaking is more systematic and
accountable
vulnerability to adversarial attacks
modern aerbased tools typically rely on deep learning
based models such as those built on deep neural networks
dnns which are composed of multiple hidden layers
dnns are also quite fragile to very small speciallycrafted
adversarial perturbations to their inputs this can cause
false prediction in aer systems  which might have
adverse consequences for instance an adversarially crafted
example can cause an aer system to diagnose mental
diseases inaccurately this is one of the critical concerns of
integrating aibased services like aer in reallife
vulnerability to bias
there is scepticism in the community regarding the efﬁcacy
of aer and fears that using aer may accentuate and
institutionalise bias  since getting accurately labelled
data is very expensive and timeconsuming any embedded
bias in large annotated emotional training data is likely to
be built into any systems developed using such data most
of the aer systems use laboratorydesigned datasets based
on actors simulating emotional states in front of a camera
furthermore the labels used by ml models typically rep
resent perceived emotion rather than felt emotion since the
majority of the existing aer datasets are labelled by human
annotators based on their perception  for instance
in facial emotion recognition the labels for a photograph
are provided by annotators not by the individual in the
photographs  this might not represent genuine inner
emotions and may contain hidden biases that may become
apparent only after deployment
reductionist emotional models
aer algorithms base their working on basic emotion theo
ries  that have been widely critiqued  for instance
the widely applied theory posited by paul ekman regarding
six universal emotions happiness sadness fear anger sur
prise and disgust that can be recognised across cultures
from facial expressions has been criticised by experts as
being too reductionist  an automatic link between facial
movements and emotions is assumede g a smile means
someone is happy however this might not always be
true for instance in the us and many other parts of the
world  it is common to smile at strangers which might
not represent inner feelings or states it follows that more
contextual details are required to understand the emotion
potentially requiring more data and invasive practices
ais white guy problem or neocolonialism
some ﬁndings indicate that ai technology suffers from
problems such as sexism racism and other forms of dis
crimination  a major aspect related to this arises from
homogeneous or unrepresentative data another reason
could be focusing on the majority class since optimising
for the majority class will usually improve overall accuracy
unfortunately this translates into discrimination against
the minority classes as ai models typically do not auto
matically provide fairness unless constraints are placed for
ensuring fairness in which case the overall accuracy will
usually reduce as fairness and accuracy are different objec
tives and it is not uncommon for them to have tradeoffs
 if we do not work to make ai more inclusive we
risk creating machine intelligence that mirrors a narrow
and privileged vision of society with its old familiar bi
ases and stereotypes kate crawford new york times
httpstinyurlcomhfudv experts are now calling
out for using decolonial theory as a tool for sociotechnical
foresight in ai to ensure that the hegemony resulting from
the domination of the ai industry by a limited number of
demographic groups and nations does not have harmful
effects globally 
ethical concerns with aer
giving emotions to a computer is another term for aer
technology  it is exciting and a pipe dream to have a
humanlike or superior emotion detection system in the last
decade techniques based on advanced techniques in ml
and deep learning have outperformed almost all classical
methods in recognising and understanding human emo
tions from facial speech and text inputs these advanced
learning techniques have produced effective and efﬁcient
results in aer and automated the whole process aer
systems are used in the commercial market for understand
ing user engagement sentiment analysis attention tracking
behaviour understanding etc however these aer systems
are also prone to shortcomings and biases in the training
and testing data the literature on the shortcomings of
traditional and deep ml techniques suggests that data and
algorithmic biases can impact the performance of these
learning techniques  aer systems are developed using
data acquired from humans and human biases are likely
to be translated into the learning process impairing aer
system judgements  there is a need to enforce respon
sible ai practices  and ethical guidelines for the design
development and integration of aer systems in the wild
the use of aer for emotional surveillance raises many
ethical concerns which motivates the need to identify basic
ethical principles and guidelines that address ethical issues
arising from the use of aer technology on human subjects
to ensure that human subjects are not exploited or manipu
lated in this regard we can look at a traditional consensus
on basic principles such as those expressed in the belmont
report produced in  by the us national commission
for the protection of human subjects of biomedical and
behavioural research httpstinyurlcomprrpe the
belmont report identiﬁed three main principles respect
for persons  beneﬁcence and  justicein their study
focused on documenting the basic ethical principles and
guidelines that should direct the conduct of biomedical and
behavioural research involving human subjects in light of
the described perils of uncritical use of technology and the
various ethical and moral dilemmas posed by ai  a
fig  summary of ethical concerns associated with aer
lot of attention has focused on incorporating ethics in the
ﬁeld of ai leading to a proliferation of ai ethics principles
and code of ethics interestingly jobin et al  have high
lighted  such codes of ethics related to ai in  and
found that four highlevel ethical principlesbeneﬁcence
nonmaleﬁcence autonomy and justicecapture the essence
of most ai declarations with floridi and cowls  also
adding explicability as a highlevel principle demanding that
ai models should not work as inscrutable blackboxes we
summarise the aerrelated ethical concerns in figure  and
discuss these concerns in detail next
ethical concerns related to justice
ai is being used in every facet of daily life including
criminal justice social media social justice health care
smart cities and urban computing although it has been
well stated in the literature that aibased systems are in
capable of understanding the concepts of justice and so
cial standards  buolamwini et al  emphasise that
the aibased facial detection system discriminates against
gender and people of colour they also demonstrated that
commercial aibased facial detection systems need a ﬁrmer
grasp of ethics and auditing  cathy oneil et al 
exposed the ﬂaws in employing big data and aibased
algorithms to make choices with reallife consequences
and these consequences are leading to a societal split and
shattered democracy the ethics of applying ai in law and
its obstacles are discussed in     in contrast
the ethical issues of employing aer systems for learning ex
pressions and privacy concerns are detailed in  wright
 explains the opacity of algorithms employed in aer
systems the inadequacy of ai in comprehending human
emotions and how these failings lead to an unjust society
 carrillo  discusses the ethical ai debate from the
standpoint of law and how ai shortcomings impede the
general application of the aibased judicial system finally
khan et al  present a thorough discussion of aienabled
face recognition systems and their ethical implications in the
criminal justice system
in the last few years aibased predictive policing tools
are becoming a part of global criminal justice systems these
systems are largely based on facial recognition technology
with added emotion recognition and dna matching these
tools have many ethical issues   millerai
provides a comprehensive discussion on the ethical issues of
predictive policing and facial recognition systems in crimi
nal justice systems they argued that these systems violate
privacy rights autonomy rights and basic human morality
they also discuss the misuse of aibased predictive policing
and facialemotion recognition tools in liberal democra
cies and the dangers of similar technology in authoritarian
states in order to use with aibased systems making critical
judgements about individuals hiring process advertising
process etc it is vital to consider and address ethical
concerns automated physiognomy refers to the use of ai
models to identify a persons gender emotional state level
of intellect and other characteristics from only one photo
graph of them engelmann et al  debated the fairness
and ethical concerns of automated physiognomy with a
comprehensive experiment in which thousands of nonai
individuals were invited to respond on what ai should
ethically infer from faces the questions also include the
number of characteristics inferred from faces by wellknown
ai models including aer models such as gender emo
tional expression likeability assertiveness intellect colour
trustworthiness and use of spectacles because all these
characteristics are subjective participants were asked to pro
vide a likert scale score and a written explanation of why
a particular score was awarded for two speciﬁc use cases
advertising and hiring  the overall ﬁndings show that
individuals independent of context substantially disagree
with the automated physiognomy regarding assertiveness
likeability trustworthiness and intellect participants were
also observed to be more dissatisﬁed ethically with the
ai inferences about race gender emotional expression and
wearing spectacles in the hiring use case  aer systems
suffer from the same issue and the results reveal that a lack
of auditing will result in an unfair automated judgement
which will have farreaching effects on the social justice
system
podoletz  investigated the use of emotional ai a
blend of affective computing  and ai that gives prob
abilistic predictions of a persons or communitys emotional
state based on data points about the individual or com
munity in criminology police and surveillance given the
ethical concerns algorithmic biases and annotation issues
podoletz urge that emotional ai not be implemented in
public spaces since these technologies will expand policing
authority raise privacy concerns and operate as an op
pressive instrument in authoritarian states podoletz goes
on to claim that deploying emotional ai tools like aer
would result in a highly regulated and controlled society
causing a severe schism in the social justice system lastly
 discusses the repercussions of using emotional ai tools
in crime predictions and preemptive deception detection
minsky  in his famous book the emotion machine
commonsense thinking artiﬁcial intelligence and the future
of the human mind talked about emotional ai and its rela
tion to basic cognition and neuroscience he also talks about
the ethical challenges in ai systems designed for emotion
recognition emotional ai affective computing paired with
ai technologies are used for reading interpreting repli
cating and inﬂuencing human behaviour and sentiments
according to yonck  in his book heart of the machine
our future in a world of artiﬁcial intelligence the author
also discusses the moral dilemmas raised by the commercial
application of these technologies he further contends that
the code of ethics designed for emotional ai tools like
aer systems would be subverted in markets in favour of
monetary and political gains thus undermining the sociopo
litical justice of society  van  elaborated upon the
ethical issues in aibased facial recognition technologies
face gender class race classiﬁcation aer systems and
others the report demonstrates how one could use face
recognition technology as an instrument of oppression with
a huge surveillance engine created to monitor and classify
minorities and by extension a whole country
the aer sector is predicted to be worth  billion by
  crawford et al  recommend that aer systems
be regulated as soon as possible she claims that several
technology businesses used the pandemic as a justiﬁcation
to introduce emotion detection systems to assess the emo
tional state of employees and even children she presented
the example of an aer system called  little things which
is used to infer childrens emotions while carrying out their
classwork with no supervision or regulation she also states
that with aer systems now being widely employed in
many socioeconomic areas hiring healthcare education
advertising among others it is important that this industry
be regulated to avoid injustice and the fostering of an unjust
society a report on the ethical issues related to biometric ap
plications including aer in public settings was published
by the citizens biometrics council  the suggestions
are based on conversations in public concerning the ethics of
using aer and other biometric technology the report urges
the establishment of a comprehensive regulatory framework
for biometric systems a credible oversight agency and
minimum standards for designing and deploying face and
aer systems 
as previously described it has been observed in the
literature that ai models do not automatically provide
fairness or justice unless it is explicitly asked for  as
stuart russell describes in his book a problem underlying
the model of conventional optimisationbased ai is that
you only get what you explicitly ask for with the unstated
assumption being that you implicitly agree that you do not
care at all about everything you do not specify  the
 httpswwwlittletreescom
author calls this the king midas problem of ai referring to
the greek mythological story in which king midas gets all
that he speciﬁes but the situation still ends unacceptably
since he did not specify exactly what he did not want
and unacceptable values were incorrectly inferred 
various studies have shown that aer technology is prone
to bias and can suffer from a lack of fairness accountability
and transparency this has real consequences when such
technology is used for critical decisions such as in judi
cial systems for making judgements about sentencing 
 therefore aer technology requires a continued and
concerted effort to address such issues because misreading
an individuals emotions can cause severe consequences in
speciﬁc scenarios
ethical concerns related to beneﬁcence non
maleﬁcence
ethical principles of beneﬁcence do only good and non
maleﬁcence do no harm are closely related beneﬁcence
encourages the creation of ai services to promote the well
being of humanity and the planet while nonmaleﬁcence
concerns the negative consequences of ai  these con
cerns are also important in the designing and deployment
of aer technology therefore aer services should avoid
causing both foreseeable and unintentional harm this re
quires a complete understanding of aer technology and
its scientiﬁc limitations to manage the attendant risks the
services should be designed to beneﬁt human beings and
increase their wellbeing to make aer prosocial
designing a prosocial aer system requires mitigation
of ethical concerns highlighted in the literature  with
the unprecedented penetration of social media applications
and the use of surveillance technologies the optin and opt
out model of data sharing is long gone now most of the
applications gather data irrespective of permissions and the
written conditions that one agrees to upon usage are written
in a language that is a challenge for the regular user it is
problematic and many incidents of unethical use of the data
are being reported in the literature unfortunately the idea
of beneﬁcence  nonmaleﬁcence is not considered as vital
as it should have been in designing aer systems
beneﬁcence  nonmaleﬁcence principles are based on
moral conscientiousness social good and trustworthiness
of people companies and algorithms raquib et al  pro
pose a virtuebased ethical design of ai systems although
the debate is philosophical and many areas of the subject
suffer from a lack of generality the topic of virtuebased
ethical systems and the ethical quandaries raised are also
pertinent to aer systems because aer systems are meant
to learn from user behaviour and how that behaviour may
be watched hugged and altered the essential nature of the
data and the inﬂuence of the aer system on society neces
sitates an aer design that is founded on beneﬁcence  non
maleﬁcence examination supervision technologies have
saturated the market under the guise of covid these
tools are often aibased with face and emotion recognition
algorithms used to monitor exam participants though these
methods are intended to assure that the examination is
conducted correctly they lack core ethical standards such
as privacy transparency fairness and beneﬁcence coghlan
et al  examined and reported ethical challenges with
aibased examination supervision tools arguing that the
issues will not be resolved until ethical standards are not
included in the basic design principles of aibased auto
mated systems like facial recognition and aer similarly
the reality of social robots is just around the horizon and
numerous aerbased robots are presently being employed
in a variety of social contexts and the number of these
robots is rapidly increasing the ethical challenges raised by
social robots originate from the fundamental debate about
the uncertainty and responsibility of ai systems bosch et al
 provide a brief description of the ethical risks involved
in social robotics including how the concept of doing only
good and not harm is required for social robots as well as
various technological and social challenges associated with
developing such ethics in robots
ethical concerns related to privacy
aer services mostly use dl algorithms that are trained
on masses of data to learn and perform decisionmaking
ethical concerns related to privacy require protecting in
dividuals data and preserving their privacy over the last
two decades the rise of surveillance capitalism went largely
unchallenged tech companies like google and facebook
provide free online services and use personal data for
mass surveillance over the internet such companies collect
and scrutinise users online behaviours including searches
purchases likes dislikes and more to predict modify and
control users behaviours lanier has coined the term bum
mer or behaviours of users modiﬁed and made into an
empire for rent for the economic model followed by big
tech corporations in the world of surveillance capitalism
the design of aer systems depends heavily on face
recognition technologies and it is advised in the literature
that emotion recognition systems should be regularly up
dated and audited  bowyer  discuss facial recogni
tion systems security vs the privacy dilemma the right to
privacy is a fundamental right guaranteed by practically ev
ery countrys constitution many countries use facial recog
nition systems and by extension aer systems for mass
surveillance without the agreement or scrutiny of regulatory
organisations which is a serious concern in the domain of
technologys social effect bowyer  argues that utilising
these recognition technologies violates the constitutionally
guaranteed right to privacy aer systems not only employ
facial recognition technologies but also infer the emotional
state and other aspects of the face without consent which
is an abuse of power and a blatant violation of the fun
damental right to privacy the effectiveness of a security
surveillance system is determined by the performance of
the facial recognition system and a combination of the
algorithms to measure the underlying emotional states and
motives from just an image of the face and body these
algorithms and facial recognition systems have shown to
be biased and unreliable in the literature  false positives
and negatives have lifethreatening repercussions and pri
vacy infringement concerns are unprecedented 
 httpswwwtheguardiancomtechnologymay
jaronlaniersixreasonswhysocialmediaisabummer
the discussion of privacy and the right to privacy
has become prevalent with the advent and adoption of
new technological applications such as internetofthings
iot robotics pervasive technologies biometric technolo
gies augmented and virtual reality and digital platforms
 aer systems are used in homes health care facilities
childcare centres social media apps and other digital plat
forms for monitoring data collecting emotion inference
and feedback translation because the data collected by
aer systems is the property of the device manufacturers
these spaces are becoming more open and prone to privacy
violation  though there are a few traditional privacy
limitations in place it is challenging to ensure privacy when
aidriven inference is involved without suitable monitoring
and regulatory mechanisms camerabased assistive aids
are quickly becoming popular among the sight impaired
aibased vision technologies and in certain situations aer
systems are actively used in these assistive technologies
akter et al  conducted a couple of surveys on the
privacy and ethical considerations associated with these
assistive devices according to their surveys the majority
of respondents were concerned about the fairness privacy
and other ethical concerns associated with these assistive
technologies
in the last few years ethical concerns related to pri
vacy have become a promising area of research thanks to
the active integration of aienabled applications such as
camerabased surveillance systems aer systems and oth
ers ribaric et al  surveyed deidentiﬁcation techniques
for ensuring privacy in visionbased applications such as
aer systems and healthcare applications where privacy is
critical and provide an insightful discussion on how de
identiﬁcation can help resolve ethical challenges das et
al  provide a procedure for identifying and mitigat
ing privacyrelated concerns in camerabased iot devices
in digital homes and other places through privacyaware
notiﬁcations and infrastructure their work also outlines the
technique for privacyaware video streaming and policy
related guidelines for ensuring privacy and mitigation of
the risks involved in vision data surveillance data aer
systems etc being misused by adversaries hunkenschroer
et al  conducted a systematic review of the literature
on ethical problems in aibased hiring procedures though
the emphasised problems concern the employment process
some of the issues human and algorithmic bias privacy
and data leakage hazards and fairness are also prevalent in
aer systems boutros et al  used class conditional gen
erative models to generate a privacyfriendly synthetic faces
dataset and trained facial recognition models and tested
its performance in three different experimental settings
multiclass classiﬁcation labelfree knowledge transfer and
combined learning settings their results indicate that the
synthetic dataset showed a promising performance and the
authors recommend that privacyfriendly synthetic data is
good enough to train facial recognition systems
privacy is not just about hiding information it is about
the agency the agency to optin or optout unfortunately
the concept of agency is frequently overlooked in the design
thinking component of aer systems resulting in biased
and untrustworthy aer systems because aer systems
predictinfer a persons or a social groups emotions the
agency to convey the emotional data through any input
methods such as voice video picture and language should
be with the individual or the social group woensel et al
 raised the problem of agency in aer systems and
linked it to data gathering from people and social groupings
without proper consent and agency the critical concern
raised in the paper was the potential of using aer systems
for targeted and mass surveillance which in any rational
society is considered a violation of social standards privacy
and ethics the paper recommended imposing strict con
trols on data collection for aer systems or for prohibiting
them until the necessary ethical standards are satisﬁed
cavoukian et al  outlined seven rules for introducing
privacy by design in systems we show these rules in figure
 these rules can help improve privacy while providing
a reasonable design path toward ethicscentred privacy for
aer systems 
fig  seven rules for introducing privacy by design in systems 
ethical concerns related to autonomy
when we adopt aer services in daily life we willingly cede
some of our decisionmaking power to ai this may un
dermine the ﬂourishing of human autonomy with artiﬁcial
autonomy therefore it is crucial to balance the decision
making power delegated to aer agents and that we retain
for ourselves aer systems must not impair the freedom of
their users so they can live according to their standards and
norms
for ai to yield any beneﬁts for the human race it
must be focused on the autonomy of humans rather than
the popular belief of giving more autonomy to machines
 this argument stems from the classical discussions
on whether ai techniques are tools to help improve life by
making tasks easier or ai understanding the problems by
itself and ﬁxing them without categorically consenting the
humans here it is essential to understand what autonomy
means autonomy is described as the sense of willingness
and a cognitive process of committing to a course of action
calvo et al  take a closer look at human autonomy and
technology under the pretext of ethics they highlight that
in  most of the literature around autonomy was focused
on machine autonomy whereas now this trend is shifted
towards human autonomybased technology design after
critical technical and ethical issues with machine autonomy
and design of machine autonomy were highlighted aer
systems are designed to translate the stateoftheart in
human psychology using ai and psycho graphs techniques
unfortunately human autonomy and ethical questions such
as willingness to interact and adopt are not appropriately
addressed abbass  and  argue that since ai
techniques are now being integrated into various aspects
of society it is paramount to prefer humans in the loop or
humans on the loopbased algorithms for decision making
it will ensure that human autonomy and ethical practices
are followed in making critical decisions
emotion recognition systems are trained on the data
harvested from social media and digital platforms to un
derstand and infer emotions andalibi et al  surveyed
 social media users about the fact that the data from
social media applications are used for training emotion
recognition systems without getting users consent even
if consent is taken it is collected through a terms and
condition form which is mainly forced and in a legal
language that is not userfriendly their results indicate
that most of the participants viewed it as scary invasive
unethical and a loss of power and human autonomy the
paper further recommends that ethical usage be ensured in
these critical applications at an individual and societal level
gender bias is another ethical quandary in the aer system
and using these tools in the ﬁeld necessitates a gender bias
evaluation in emotion recognition systems domnich et al
 assessed the performance of several ai approaches
and showed which kind of networks are employed for
certain types of emotions the results of the experiments
revealed that speciﬁc ai designs are discriminatory with
signiﬁcant differences in performance between males and
females in terms of emotion recognition another vertical
of this discussion on the autonomyrelated aer system is
the categorisation of complex human emotions into a set of
classes and then the offering solutionsinterventions based
on these categories unfortunately this classiﬁcation concept
has a fundamental weakness since human emotions both
as individuals and as social groupings are complicated
private unique and occasionally indeﬁnable and reducing
these aspects to a data point and using it to tweak the
behaviour raises various ethical issues
path to a prosocial future for aer
as motivated in the previous sections aer systems are
promising for contributing to social good in a wide variety
of applications such as healthcare education safety and law
enforcement but at the same time it is beset with several
risks and perils which must be addressed qadir et al
 have stressed the need for a more humane human
centred ai that is accountable and have outlined promising
directions for achieving accountable humancentred ai in
this section we highlight some approaches we can adopt to
pave the way for a prosocial future for aer systems
better awareness and education
the development of aer software is bringing enormous
changes to society through data analysis aer technology
has the positive effect of revolutionising many areas by
solving various existing problems on the other hand aer
technologies are twosided which can also cause problems
therefore it is crucial to raise awareness among the broader
population about aers role in our lives and the use and
purchase of aer services this can help to achieve large
scale adoption of aer services among the general popula
tion and minimise the risk of being negatively proﬁled by
aer technology
auditable aer
the auditability of ai describes the possibility of evaluating
models algorithms and datasets in terms of operation
results and effects it has two parts including technical
and ethical the technical part assesses the reliability and
accuracy of results however the ethical part apprehends its
individual and collective impacts and checks the risks of
breaching certain principles including equality or privacy
aer systems learn from the data they are exposed to and
make decisions using ml algorithms they can develop
or even amplify biases and discrimination therefore it is
essential to audit and test aer algorithms throughout their
life cycle to pinpoint the origin of errors and detect risks to
avoid their impact on the lives of individuals and society
it will help to systematically probe aer systems uncover
biases and avoid undesirable behaviour
explainable and interpretable aer
a key reason behind the fragility of aer services is the
blackbox nature of ml models used for the decision
making process these ml models are neither explainable
nor their outcomes interpretable to realise the real potential
of aer systems it is highly desirable to make them ex
plainable in a humanunderstandable way in recent years
signiﬁcant research has been devoted to developing novel
methods for explaining and interpreting ml models in the
literature different explainable approaches can be broadly
classiﬁed as whitebox and blackbox explanation methods
the whitebox explanation method describes the model by
identifying the most critical features that contributed to a
speciﬁc prediction  another method for whitebox ex
planation is to compute the predictions gradient concerning
individual input samples to discover the predictions rele
vant features whitebox explanation mainly provides the
modelspeciﬁc explanation while the blackbox technique
provides local explanations of a model for a prediction 
explaining ml models and their decision is critical as it
is the key enabling factor for building trust and ensuring
fairness in decision making this is also important for aer
applications where decisions directly impact human life
privacy preserving aer
in aer services the privacy of the users data is a growing
concern mainly when aer is performed on cloud plat
forms aer companies gather a large amount of user data
to perform emotion analysis the data gathered by these
companies is kept forever and the user does mostly not
have any or little control over it the images video and
voice samples but also textual bits also contain sensitive
background information such as faces gender language
etc the leakage of this data can be used maliciously without
the users consent by an eavesdropping adversary and may
cause threatening consequences to peoples lives therefore
it is crucial to utilise privacypreserving ai models in aer
systems to protect users privacy the methods and tech
niques for developing ai systems that ensure privacy falls
under the umbrella of privacypreserving ai
privacypreserving ai has four major pillars
training data privacy which can be ensured by
differentially private stochastic gradient descent
dpsgd and pate  and similar solutions
input privacy which can be ensured via homomor
phic encryption secure multiparty computation
mpc and federated learning
output privacy which can be ensured by using
homomorphic encryption secure multiparty com
putation mpc and federated learning
model privacy which can be ensured by applying
differential privacy on the output of an ai model
ethical framework for aer
in recent times there has been much work on developing
ethical principles and frameworks for ai  a report on
the ethics of ai and the applications of automated emotional
intelligence and its risk is presented in  there is a
need for similar efforts focused on developing an ethical
framework for aibased aer which can enable various
beneﬁts as presented in table 
table 
advantages of prosocial aer systems
ethical principles
advantages
transparency
reduces risk
increases fairness
satisﬁes regulatory and compliance laws
full disclosure
improves explainability
increases understanding
personal consent
improves reliability and safety
increases regulation
protects vulnerable participants
ethical data sharing
creates an ethical imperative
increases trust
data ownership
establishes accountability
assigns responsibility
security and privacy
consentbased data collection
regulated surveillance
improved privacy
we propose that in order to operate an ethical privacy
protective aer system an entity should embrace the fol
lowing principles
transparency an entity must describe its policies
related to the duration it retains data how the data
is used how the government might access the data
and the necessary technical speciﬁcations to verify
accountability
full disclosure an entity must receive informed
written and speciﬁc consent from individuals before
enrolling her him or them in an aer database
enrolment is the storage of personal data such as
voice and face prints to perform emotion recognition
or identiﬁcation
personal consent an entity must receive informed
written consent from an individual before using the
individuals data in a manner that was not men
tioned in the existing consent when individuals
consent to use an aer system for one purpose an
entity must seek consent from that individual for us
ing aer technology for another purpose however
users should be free to withdraw their consent at
any time an entity must not use the aer system
to determine an individuals colour race religion
gender age nationality or disability
ethical data sharing individuals data should not be
shared or sold without the informed written consent
of the individual whose information is being shared
or sold
data ownership an individual must have the right
to access correct and remove his or her data print
security and privacy aer data must be kept secure
and private by the entity maintaining the data
simply deﬁning principles is not sufﬁcient these princi
ples should be embedded into practice and operationalised
an entity must maintain a system that measures compliance
with these principles including an audit trail memorialising
the collection use and sharing of information in an aer
system the audit trail must include a record of the date
location consent veriﬁcation and provenance of emotional
data it must also allow evaluation of the aer algorithm for
accuracy this data may also be incorporated in a watermark
to ease the ability to audit
conclusions and recommendations
this paper discussed the promises and perils of artiﬁcial
intelligencebased automatic emotion recognition systems
we believe aer technology has a wide range of real
life applications however we aim to caution aer users
and service providers about ethical concerns aer systems
have biases that can lead to incorrect results just like any
other artiﬁcial intelligence ai based intelligent systems
we cannot fully rely on aer systems in making deci
sions however help from them can be taken to improve
the ﬁnal decision we also must carefully consider aer
systems fairness transparency accountability and ethics
during their development and applications for this we
proposed guidelines for designing future prosocial aer
solutions we are summarising below the recommendations
for designing such responsible aer systems
full examination across various dimensions is re
quired for the data used by aer systems expres
sions of emotion are variable across different lan
guages this variability must be taken into account
while designing datasets systems and deployment
of aer systems
one needs to examine the choice of ai techniques
across interpretability concerns privacy energy ef
ﬁciency and data needs ai tends to perform well
for individuals who are wellrepresented in the data
but fails for others therefore it is crucial to explore
inclusive methods to avoid spurious correlations that
perpetuate sexism racism and stereotypes
aer systems are often trained on static data how
ever emotions perceptions and behaviour change
over time it is important to incorporate adaptability
in aer services for predictions on current data this
may include drifting target learning approaches
privacy is not only secrecy but also a personal choice
applying aer to a mass gathering without personal
consent is an invasion of privacy harmful to the
individual and dangerous to society therefore it is
important to follow suited privacy principles such
as the seven by cavoukian while designing aer
systems
it is crucial to realise ethical concerns related to
privacy manipulation and bias while designing aer
systems therefore anonymisation of information at
various levels is required
the use of aer for fully automated decisionmaking
is unsuited aer systems may be utilised for assis
tance in decisionmaking aer services should be
transparent to all stakeholders
these
recommendations
are
primarily
for
the
re
searchers engineers educators and developers who build
make use of or teach about aer technologies these guide
lines will help engender trust with customers and also
improve the proﬁtable drive growth of aer technology
with all these guidelines in mind we shall be ready to
fully beneﬁt and enjoy the many good automatic emotion
recognition holds as promise

emotions beyond words nonspeech
audio emotion recognition with edge
computing
ibrahim malik siddique latif sanaullah manzoor muhammad usama junaid qadir and
raja jurdak
emulationai
queensland university of technology qut brisbane australia
university of the west scotland united kingdom
national university of computer and emerging sciences nuces pakistan
qatar university doha
abstractnonspeech emotion recognition has a
wide range of applications including healthcare crime
control and rescue and entertainment to name a few
providing these applications using edge computing has
great potential however recent studies are focused on
speechemotion recognition using complex architectures
in this paper a nonspeechbased emotion recognition
system is proposed which can rely on edge comput
ing to analyse emotions conveyed through nonspeech
expressions like screaming and crying in particular
we explore knowledge distillation to design a computa
tionally efﬁcient system that can be deployed on edge
devices with limited resources without degrading the
performance signiﬁcantly we comprehensively evaluate
our proposed framework using two publicly available
datasets and highlight its effectiveness by comparing
the results with the wellknown mobilenet model our
results demonstrate the feasibility and effectiveness of
using edge computing for nonspeech emotion detection
which can potentially improve applications that rely on
emotion detection in communication networks to the
best of our knowledge this is the ﬁrst work on an edge
computingbased framework for detecting emotions in
nonspeech audio offering promising directions for
future research
index termsnonspeech emotion recognition edge
computing knowledge distillation and computational
efﬁciency
i introduction
t
he age of the internet of things iot is
upon us the raging increase in iot devices
and the race among tech manufacturers to capture
the market share has reached a point where the
communication systems are struggling to fulﬁl the
quality of service and experience requirements the
merging of artiﬁcial intelligence ai with the iot
has resulted in a plethora of practical applications
in recent years these applications span a wide
range of ﬁelds from image classiﬁcation to stable
diffusion  and speech recognition to realtime
speech generation   the healthcare industry has
seen signiﬁcant progress in disease detection with ai
outperforming human doctors in the early detection
of disease  data collection and cleaning as well
as urban computing  have also beneﬁted from
email siddiquelatifquteduau
this combination additionally voice assistants and
adaptive emotion recognition  are just a few of the
many other applications that have emerged as a result
of the fusion of ai and iot these developments have
unprecedented levels of data storage and computa
tional requirements the traditional communication
system design was not enough to fulﬁl the needs
of these data and computehungry applications it
gave rise to cloud computing  the backbone of ai
enabled iot applications and the widespread adoption
of iot applications is also credited to cloud computing
technologies
edge
computing
is
a
distributed
computing
paradigm that decreases the data transmission load
to the cloud by bringing enterprise applications
near the data sources such as iot devices or edge
servers this proximity to data at its sources has the
potential to bring strong business beneﬁts including
better response times improved bandwidth availabil
ity faster decisionmaking and privacy preservation
the development of computational technologies like
graphics processing units tensor processing units etc
makes it feasible to ofﬂoad some computational tasks
to potent edge servers when it comes to realtime ser
vicesapplications eg trafﬁc monitoring systems fa
cial recognition control system applications latency
quality of service and experience become increasingly
critical in particular low latency is crucial in emotion
recognition applications where the computing device
needs to classify the users emotional state from given
input audio or visual data for a particular application
realtime emotion identiﬁcation becomes even more
important in a lifethreatening serious situation in
such cases edge computing has the potential to meet
the latency requirements in this work we present an
edge computingbased nonspeech emotion detection
system
emotion recognition systems gained traction and
their performance has increased dramatically owing
to cuttingedge dlenabled face voice language and
psychological signal models the majority of emotion
sensing services use a system paradigm in which raw
data collected via iot sensors is transferred to a distant
server for processing and decisionmaking as shown
arxivv  cssd   may 
fig  stateoftheart nonspeech emotionsensing system that transmits raw speech signals over the
communication network for emotion analysis
in figure  since emotion recognition systems are
intended to detect and classify emotion in realtime
it is critical to create a system with an acceptable
level of endtoend latency from data acquisition to
emotion classiﬁcation
existing studies on speechbased emotion detection
mainly focus on improving the accuracy of the
systems for enabling their realtime applications 
in these systems they use audio conversations and
pass them to different deeplearning models to predict
different emotions  the audio conversations used
in these systems contain scripted speech datasets
however emotions do not always exist in speech
nonspeech signals like screams also contain rich
emotions the timely identiﬁcation of screams has a
wide range of applications in public spaces healthcare
 age care rescue services crime control and
gaming the delays in classiﬁcation might result
in a fatality and the latency issue becomes even
more concerning in addition stateoftheart emotion
sensing applications follow the system model in which
raw speech is transmitted to the remote server for
processing and decisionmaking such systems are
successful in reallife however they involve complete
sharing of speech over the communication network
which may lead to adverse consequences to peoples
privacy   edge computing addresses the
latency concerns and privacy related concerns by
processing data at the edge server in a federated
environment 
most of the emotionsensing services follow the
system model in which raw speech is transmitted to
the remote server for processing and decisionmaking
this has been shown in figure  such systems
are successful in reallife however they involve
complete sharing of speech over the communication
network which may lead to adverse consequences to
peoples privacy   speech signal contains
sensitive information about the message speaker
gender language etc which may be misused by
eavesdropping adversary without users consent 
in this paper we propose a framework for iot
based edge computingenabled nonspeech emotion
recognition systems we have made the following
contributions
 we propose to leverage edge computing to
design a lowlatency nonspeechbased emotion
recognition system for resourceconstrained
devices
 we develop a computationally efﬁcient non
speech emotion detection system by utilising
knowledge distillation
 we provide a detailed discussion on the poten
tial of using nonspeech emotions for various
applications such as healthcare rescue services
etc
 we show the effectiveness of the proposed
framework by evaluating the system using
two publicly available datasets results show
that our proposed model can achieve bet
ter performance compared to the wellknown
mobilenetvsmall model  and provide
better computational efﬁciency
ii applications of scream recognition
in this section we will provide a brief description
of the available scream detection systems from the
literature the objective here is to provide a non
exhaustive list of works based on nonspeech emotion
recognitionbased systems
a healthcare and rescue services
understanding nonverbal emotions is a growing
area of investigation in healthcare research in the
recent pandemic many researchers investigated the
prospect of producing an early forecast of covid
 by understanding the sound of coughs similarly
many elderly patients care researchers sought to
comprehend the patients requirements by detecting
and interpreting coughs and screams  
psychologists are also seeking to detect and com
prehend nonverbal emotional activity to identify
various psychiatric disorders we have also seen
remarkable growth in assistive technology for the
sick and the elderly in recent years several of
them were in the form of wristhand bands and
lightweight sensors placed on and within the human
body these assistive technologies discern nonspeech
based human emotions and other human capabilities
by combining cuttingedge iot technology with
broadranging learning algorithms alam et al 
designed a portable hand band for scream detection
for dementia patients the band is inexpensive and
convivial that is healthband for monitoring the
activities of dementia patients and the vigilance of
the people in all the trouble
another application of nonverbal speech detection
which is partly related to healthcare is rescue services
scream detection techniques play a vital role in locat
ing the victim human or animal in catastrophes such
as earthquakes wildﬁres etc since rescuerelated
operations are time sensitive and require vigilance
using aiml techniques for scream detection can aid
in the rescue of the trapped victims under debris and
in the burning sites saeed et al  designed an
aimlenabled scream detection system mounted on a
small autonomous vehicle that can help rescue victims
from a burning site the scream detection model in
this system was based on support vector machines
svm and long shortterm memory lstm given
the dynamic inherent nature of their occupations
mobile workers are constantly at risk of being hurt
scream detectors can aid in the rescue of personnel
in the event of an emergency  
b crime control
with the advent of ai and advanced communi
cation technologies crime detection is becoming a
booming research direction scream detection has a
direct relation with violent crimes and using aiml
techniques aided by the data gathered from multiple
sensors deployed across urban spaces is an interesting
application lafﬁtte et al   proposed an
mlbased screamingshouting detection mechanism
marteau et al  proposed deep learningbased
methods to identify audio events such as screams
glass breaks gunshots and sprays unfortunately the
crimes of racism harassment and rape are on the rise
in society  urban spaces are increasingly
becoming unsafe for women transgenders and other
genders the application of scream detection with
other surveillance technologies can help protect people
from these crimes in  seoul metro korea
installed scream detectors in womens bathrooms in
metro stations to ensure womens safety similarly
the paris metro company is also considering ai
enabled scream detection technologies in the subways
to prevent abnormal situations   we strongly
believe that scream detection techniques can help
reduce a lot of crimes
c home applications
scream detection is becoming an essential tool
accompanying visual monitoring in homes security
applications nursing homes etc for instance huang
et al  proposed an energy continuitybased
approach for feature extraction from athome audio
recordings and then used the support vector machine
svm for identifying the screams in the recorded
data odonovan et al  proposed and evaluated
an mlbased method for scream detection behavioral
disorders in publicly available datasets of athome
voice recordings they used a pretrained cnn for
learning scream detection from an audio dataset for
validation they chose the dataset from the famous
tv show supernanny because of its similarity with
seoul metro installs scream detection system in womens
bathrooms korea herald httpswwwkoreaheraldcomviewphp
ud access date  april 
the clinical data these results indicate that using
public datasets for learning the behavioural disorders
screams and tantrums and then using them for
clinical recordings is more appropriate than collecting
a corpus of expensive private sensitive clinical data
for training the behavioural disorder detector models
domestic violence and violent relationships have
increased dramatically in recent years  scream
detection techniques along with iotenabled voice
assistive technology can identify these heinous crimes
and potentially save many individuals from harm
fleury et al  used recordings from eight micro
phones placed in a ﬂat and use speech recognition
algorithms to determine various elements of human
speech this notion of autonomous voice detection
may be expanded to identify screaming and assist a
large number of individuals suffering from domestic
violence and abusive relationships  despite its
technical feasibility signiﬁcant ethical and privacy is
sues remain in creating these security and surveillance
applications
d gaming applications
screams are a signiﬁcant component of speech and
comprehending the emotions associated with these
screams is vital for speech detection and translation
systems conventional speech dialogue datasets do not
contain enough screams for learning and investigating
the screams properly mori et al  used combat
games to record a dialogue corpus with more samples
of screams and used that corpus for analysing the
nature of social screams virtual and augmented
realitybased games are getting popular for training
rescue workers ﬁrst responders ordinary people
and kids for dealing with emergencies the scream
detection system is expected to play a vital role in
the gamiﬁed preparation for dealing with emergencies
iii proposed system
in this section we discuss the details of the
proposed edgebased nonspeech emotion recognition
system the proposed framework in this study figure
 offers data collection and analytics support within
the g network architecture which is commonly
referred to as the network data analytics framework
nwda according to gpp standards basically the
proposed framework can invoke nwda functions
to provide these two core functionalities ﬁrst data
collection from network functions nfs ie local
data processing and second data analytics and non
speech emotion recognition speciﬁcally the proposed
framework serves the following key layers including
sensing edge computing and decisionmaking layers
a nonspeech signal sensing layer
in order to perform edgebased nonspeech emotion
recognition we devised a specialised speech sensing
layer the nonspeech signalsensing layer enables
enduser devices to collect nonspeech data from
cyberphysical space nowadays we witness a vast
proliferation of smart edge devices ranging from
fig  components of the proposed system  a nonspeech signal sensing layer that collects speech data
from mobile phones personal assistants or smartwatches and converts it into speech features  an edge
computing layer that uses these features to train a deep learning model for nonspeech emotion recognition
and  a decisionmaking layer that analyses nonspeech emotions and makes decisions based on their
positivity or negativity potentially sending alerts to an ambulance or police
smartphones smartwatches and personal assistants
such as alexa home google assistant siri etc
these edge devices speciﬁcally the personal voice
assistants take speech input and perform certain
actions such as turning on lights shutting down
appliances or playing demanded music in most of
these applications the input speech is converted into
text that helps to determine the users intent using
natural language processing and the speciﬁc action
that needs to be taken in our proposed framework
the nonspeech signal sensing layer inputs raw speech
signals and essential preprocessing is performed
to mitigate the background noise effects the layer
processes the input signal and converts it into the
features ie melspectrograms as shown in fig  in
the nonspeech signal sensing layer the audio features
are propagated to the network instead of transmitting
raw signals directly to the cloud server
b edge computing layer
in our proposed model the system has edge and
core layers the edge layer consists of end devices
ie mobile phones tablets etc and the edge server
which is placed near the base station bs as mobile
edge computing mec server  it is assumed
that the mec server can process edge signals and is
also able to perform analytics on nonspeech emotion
data  it is also assumed that the edge server
has enough computational resources to execute data
intensive machinelearning tasks the proposed frame
work adopts the rd generation partnership project
gpp release  support for machine learningbased
datadriven optimization 
the edge server is an important component of
our proposed architecture the edge server leverages
lowconsumption computational and storage hardware
such ie edge cloudlets  and operates within a
radio access network ran in the close vicinity of
endusers  in our proposed architecture as shown
in figure  the edge server not only performs trafﬁc
aggregation gateway and network service control
but it also acts as an intelligent edge server that is
responsible for the identiﬁcation of screams from the
given speech features
deploying deep learning models on edge computing
devices is an active area of research and many
techniques have been proposed to improve the latency
and performance of these models some prominent
techniques include pruning quantization knowledge
distillation and training computationally efﬁcient
models in our experiments we use knowledge
distillation  to train a small and efﬁcient model
that can be deployed on edge devices
 knowledge distillation the process of knowl
edge distillation as the name suggests is the method of
transferring knowledge from a larger computationally
expensive model to a relatively smaller model the
larger and smaller models are called the teacher
and student models respectively thus knowledge
distillation consists of three principal components 
knowledge  distillation algorithm and  teacher
student architecture while there are now multiple
methods of distillation algorithms we selected the
responsebased algorithm as shown in figure  the
hypothesis is that the student model will learn to
mimic the predictions of the teacher model this
can be achieved by using a loss function termed the
distillation loss that captures the difference between
the logits of the student and the teacher model
respectively
fig  responsebased knowledge distillation the
output logits from the student and teacher model are
used to calculate the distillation loss between the
student and teacher
as this loss minimizes overtraining the student
model will improve at making the same predictions
as the teacher in the ofﬂine training scheme the
teacher model is ﬁrst trained and the weights are then
frozen next we train the student model using the
distillation loss and the logits from the teacher model
as targets following is the equation of the distillation
loss
ld  αt   kl
softmaxt   ft x
softmaxt   gt x
where
ld the loss function for knowledge distillation
α a hyperparameter that controls the tradeoff
between the classiﬁcation loss and the distillation
loss
t the temperature hyperparameter used to soften the
logits outputs of the last layer before softmax of
the teacher and student models
kl the kullbackleibler divergence a measure of
how different two probability distributions are
softmax a function that converts the logits to
probabilities
ft x the logits of the teacher model for input x
gt x the logits of the student model for input x
 teacher model generally for the teacher
model a larger and deeper network is chosen so
that it performs well on the task at hand we chose
resnet  as our teacher model resnet
contains  residual blocks stacked together which
alleviates the degradation and vanishing gradient
problem figure  shows a single layer where the
outputs of the previous layer are added to the outputs
of the next layer and figure  depicts the complete
architecture of resnet used for the teacher model
to ensure consistent size prior to addition the input
may undergo an operation that aligns it with the
output dimensions this operation is typically a
convolution
fig  residual layer the weights of the input are
added to the outputs from proceeding convolution
layers
fig  resnetteacher architecture the coloured
blocks represent the convolution layers and the
respective kernel sizes output ﬁlters and the reduction
of input size the lines between the convolution layers
represent residual connections whereas the dashed
represents that the input of the residual goes through
a convolution for dimension consistency the ﬁnal
fc layer is a dense layer
 student model unlike the teacher model the
student model is smaller and shallower making it
more computationally efﬁcient our proposed student
network simply consists of  convolutional layers
followed by  fully connected layers figure 
provides details on the relatively shallower student
model the ﬁrst convolution layer has a kernel size
of    and the remaining two have    each the
number of ﬁlters in each layer is   and  and
after each convolution layer we apply a maxpool layer
of  window size the fully connected layers have
the outputs in this order    for regularisation
we add a dropout after each convolution and fully
connected layer with a dropout probability of 
the nonlinear activation chosen between the layers
is rectiﬁed linear unit or commonly referred to as
relu
fig  student model each coloured block is a
convolution layer where k denotes the kernel size
and f denotes the number of output ﬁlters the ﬁnal
fc layers are dense layers
c decision making layer
we train our scream detection model at edge
devices edge device communicates with the cloud
server via cellular infrastructure and shares model
outcome the cloud server is responsible for scream
analytics decisionmaking and storage services we
deploy the proposed classiﬁer to the edge devices
to perform the identiﬁcation tasks the output from
the model is sent to the decisionmaking layer that
can take necessary action based on the situation for
instance if scream emotions are classiﬁed as negative
emotions ie the person is in pain or sorrow the cloud
system will send an alert to the healthcare centre or to
the police because the person can be injured or hurt
by someone if the scream emotions are classiﬁed as
positive emotions such as joyous screams the cloud
system would not be sending any alerts
iv experimental setup
in this section we preset the details on datasets
input features and training protocol
a datasets used in our experiments
 asvpesd the audio speech and vision pro
cessing lab emotional sound database asvp
esd is a dataset that contains speech and non
speech utterances there are a total of 
audio samples that are collected from various
sources the samples include both male and
female speakers and the emotions are boredom
sigh yawn neutral happiness laugh gaggle
sadness cry anger fear scream panic sur
prise amazed gasp disgust contempt excite
triumph elation pleasure desire pain groan
disappointment
 vivae the variably intense vocalizations of
affect and emotion corpus vivae dataset
 consists of human nonspeech emotion
utterances the fullset contains a total of 
samples from eleven speakers the utterances are
divided into three positive achievement triumph
sexual pleasure and surprise and three negative
anger fear physical pain emotional states the
audio has a sampling rate of khz
 demand we use this dataset to evaluate the
performance of the proposed framework in noisy
conditions the diverse environments multi
channel acoustic noise database demand
dataset  provides recordings that can be
used to evaluate algorithms using realistic noises
captured in various realworld settings the
dataset spans over  categories  of these are
in an inside environment and the remaining
category samples are collected in an outdoor
setting the dataset recordings are available
in khz and khz sample rates the audio
was initially recorded for a long duration and
afterwards trimmed to a total of  seconds
each
b input features
in speech and audio research melspectrograms
are a popular method to represent input signal 
similarly we chose to represent our audio samples as
melspectrograms using a shorttime fourier transform
of size  a hop size of  and a window size
of  the frequency range was chosen between
khz and a total of  bands were computed
each melspectrogram was normalized in the range
of   since the sample utterances were not
consistent in length we decided on a cutoff of 
seconds for larger audios and padded the smaller
ones with zeros giving us consistent second audios
before converting the audios to melspectrograms of
higher sampling rates we resample them to khz
this sampling rate is kept consistent throughout the
experiments and datasets
c training protocol
the training of the classiﬁcation tasks was done
using an nvidia geforce rtx  gb gpu
with pytorch as the framework of choice the model
was trained on a batch size of  using the binary
cross entropy loss as the criterion the weights of
each layer were randomly initialized with adam as
the optimizer with the following parameters β 
 β   ϵ  e we experimented with
multiple learning rates and found that a learning rate
of e gave better results with less training time
all experiments were conducted on  and 
random splits for training and testing respectively for
our scream detection task conducted on the asvp
esd dataset we had to balance the scream and non
scream utterances as scream utterances totalled 
samples to balance the dataset we randomly selected
 nonscream utterances giving us effectively
 samples to train the scream detector
during experimentation we noticed that the model
would overﬁt resulting in a high train and low test
accuracy this high bias could be attributed to small
dataset sizes and to mitigate this problem of high
bias we added augmentations to our training data
these augmentations were composed of stretching
and contracting audio samples and adding a low
amplitude gaussian noise additionally we randomly
masked the time and frequency axes of the computed
melspectrograms this augmentation scheme proved
helpful in terms of model generalisability and training
table i classiﬁcation results for experiments with
out added noise
model
task
accuracy
teacher
scream detection
scream type classiﬁcation
mobilenetvs
scream detection
scream type classiﬁcation
student proposed
scream detection
scream type classiﬁcation
v results and discussions
the objective of this proposed system is to detect
nonspeech emotions in the communication network
using edge computing we primarily focus on two
types of experiments scream detection and scream
emotion detection the former separates scream utter
ances from nonscream ones and the latter classiﬁes
whether a persons scream is in a situation of danger
or duress this is motivated by the fact that not
all screams warrant an investigation or point to
emergency situations it is thus important to cluster
screams in positive and negative categories so that the
user can be notiﬁed of the type of scream detected
by the system for each of our experiments we
provide a comparison between the teacher student
and a mobilenetvsmall model  a popular
choice for edge computing for brevity we refer to
mobilenetvsmall simply as mobilenetvs in the
proceeding sections
a nonspeech emotion detection
in this section we present the results of our scream
detection and scream type classiﬁcation tasks the
former was conducted on the asvpesd dataset and
the latter on the vivae dataset the results of the
experiments are presented in table i we can observe
that the model performs well in classifying scream and
nonscream samples however the model struggles
to cluster the utterances into positive and negative
categories
we can see how the samples might be clustered by
using the tsne algorithm  for dimensionality
reduction in figure  we provide tdistributed
stochastic neighbourhood embedding tsne plots
using the raw melspectrograms from the datasets
and the penultimate activations of the teacher and
student model the plots illustrate that there is little
to no clustering within the raw melspectrograms
this changes when we train the model on scream
classiﬁcation tasks we can observe that for the scream
detection task we get distinct clusters for both the
teacher and student models the clustering is sparse
for the scream type classiﬁcation from the teacher
and student models but still better than the results
from the raw melspectrograms this sparsity might
explain the complexity of this task
b evaluations in noisy conditions
in realworld scenarios the background is often
not static in nature which causes the inclusion of
noise in the environment to simulate a realworld
scenario we added noise from the demand dataset
to our audio samples and tested our evaluations in a
simulated noisy realworld environment the noise
samples were randomly selected from the following
environments bus metro cafe kitchen and ofﬁce
within each noise sample we randomly select a chunk
equal to the input audio sample table ii summarises
the results of this experiment to test the robustness
of the model performance we added noise only in the
test split the results show that the model generalises
well when the noise is added for evaluation only
table ii classiﬁcation results for experiments in a
noisy setting
model
task
accuracy
teacher
scream detection
scream type classiﬁcation
mobilenetvs
scream detection
scream type classiﬁcation
student proposed
scream detection
scream type classiﬁcation
to further test the performance of the student model
in noisy situations we compare the evaluation results
for each noise category used previously table iii
highlights that the results for individual noises do not
decrease drastically giving us overall similar results
as discussed earlier
table iii classiﬁcation results of student model
for individual noise categories
task
noise type
accuracy
scream
detection
cafe
kitchen
ofﬁce
metro
scream type
classiﬁcation
cafe
kitchen
ofﬁce
metro
c computational complexity
the benchmarks presented in this section are
conducted on an upboard shown in figure  having
an intelr atom e cpu operating at ghz
with an onboard memory of gbs the tests are
recorded on the standard ubuntu  lts operating
system we did not use the serverheadless version
and pytorch version  the results are concluded
without the use of postprocessing features offered by
pytorch these features claim to lower the inference
time but generally with some tradeoffs
the total time to load the model and the time
it takes for a single forward pass of an utterance
are two metrics that are of primary concern when it
comes to deploying models in production likewise
we benchmark these metrics for the teacher student
and mobilenetvs models figure  provides a
graphical comparison between the benchmarks of
the mentioned models which shows that in terms
of latency the student model is almost twice as fast
as the teacher model and is about ms faster than
the mobilenetvs model furthermore there is a
signiﬁcant difference in terms of load times where
the student model takes the least time to load into
the memory the difference between these metrics
might better be explained by the total parameters
and the size of each model presented in table iv
fig  tsne plots on raw melspectrograms and the penultimate activations embeddings of the teacher and
student model there is no clustering on raw melspectrogreams however the tsne plots after using the
trained models show samples getting clustered
fig  labelled diagram of upboard with intelr
atom e cpu source 
a larger number of parameters in a model increases
the computational cost similarly a large memory
footprint contributes to higher model loading times
these results highlight the deployment of the pro
posed system into memory and computation constraint
devices such as personal assistants alexa home
fig  comparison of latency and loading times in
milliseconds between teacher student proposed and
mobilenetvs models
google assistant and siri personal assistants are
table iv size and total parameters of the teacher
student and mobilenetvs models
model
total
parameters
size
mbs
teacher
mobilenetvs
student proposed
then made an effective choice for the tasks of scream
detection and classiﬁcation based on scream positive
or negative nature these personal assistants can send
alerts to the police or medical centre to help the
person
vi conclusions
this paper presents a knowledge distillationbased
nonspeech emotion identiﬁcation system for edge
computing we covered various applications of non
speech emotion identiﬁcation and provided a case
study based on reallife scenarios we evaluated
system performance based on two publicly available
datasets we designed our experiment setup to distin
guish scream sound from other utterances and classify
nonspeech utterances based on their emotional states
to highlight the robustness of the proposed system
we also evaluated these experiments by adding typical
realworld background noises to our inputs to mimic
realworld scenarios results demonstrated that the
proposed framework provides better computational
efﬁciency compared to the wellknown mobilenetv
and achieves improved performance these results
showed the feasibility and effectiveness of our pro
posed nonspeech emotion identiﬁcation system in
communication networks in the future we aim to
study the energy efﬁciency of the proposed non
speech emotion identiﬁcation system

can large language models aid in annotating
speech emotional data uncovering new frontiers
siddique latif muhammad usama mohammad ibrahim malik and
bj
orn w schuller fellow ieee
abstractdespite recent advancements in speech emotion
recognition ser models stateoftheart deep learning dl
approaches face the challenge of the limited availability of anno
tated data large language models llms have revolutionised
our understanding of natural language introducing emergent
properties that broaden comprehension in language speech and
vision this paper examines the potential of llms to annotate
abundant speech data aiming to enhance the stateoftheart in
ser we evaluate this capability across various settings using
publicly available speech emotion classification datasets lever
aging chatgpt we experimentally demonstrate the promising
role of llms in speech emotion data annotation our evalua
tion encompasses singleshot and fewshots scenarios revealing
performance variability in ser notably we achieve improved
results through data augmentation incorporating chatgpt
annotated samples into existing datasets our work uncovers
new frontiers in speech emotion classification highlighting the
increasing significance of llms in this field moving forward
index termsspeech emotion recognition data annotation
data augmentation large language models
i introduction
the rapid growth in natural language processing nlp
has led to the development of advanced conversational tools
often called large language models llm  these tools
are capable of assisting users with various languagerelated
tasks such as question answering semantic parsing proverbs
and grammar correction arithmetic code completion general
knowledge reading comprehensions summarisation logical
inferencing common sense reasoning pattern recognition
translation dialogues joke explanation educational content
and language understanding  llms are trained on an enor
mous amount of generalpurpose data and humanfeedback
enabled reinforcement learning a new field of study called
foundational models has emerged from these llms high
lighting the interest of the academic community and comput
ing industry  the foundational models have demonstrated
the ability to perform tasks for which they were not explic
itly trained this ability known as emergence is considered
an early spark of artificial general intelligence agi 
the emergence properties of the foundational models have
sparked a wide range of testing of these models for various
tasks such as sentiment analysis critical thinking skills low
resource language learning and translation sarcasm and joke
understanding classification and other affective computing
challenges
corresponding email siddiquelatifquteduau
speech emotion recognition ser is a fundamental prob
lem in affective computing the need for ser has evolved
rapidly with the rapid integration of modern technologies
in every aspect of our lives ser systems are designed to
understand the wide range of human emotions from the given
input data audio video text or physiological signal using
traditional and modern machine learning ml techniques 
 however the availability of larger annotated data remains
a challenging aspect for speech emotion recognition ser
systems which prompts the need for further investigation and
exploration of new methods
the use of crowdsourced and expert intelligence for data
annotation is a common practice the annotated data serves
as the ground truth for ml models to learn and generate
predictions this annotation policy is mostly opted in com
putational social science sentiment analysis bot detection
stance detection emotion classification etc human emotion
understanding and image classification   however
these strategies are prone to a variety of biases ranging from
human biases to situational biases   these annotation
techniques also necessitate a big pool of human annotators
clear and straightforward annotator instructions and a veri
fication rationale that is not always available or dependable
 although there are a few unsupervised techniques for
data annotations these techniques necessitate a high sample
size of the data unfortunately the generated annotations do
not embed the context 
annotating speech emotion data is a doubly challenging
process the annotators listen to a speech recording and assign
an annotation to a data sample using the predefined criteria
human emotions are highly contextdependent and annotating
emotions based on a brief recording in a specific controlled
situation might restrict the annotations accuracy though the
stateoftheart on humanannotated emotion classification is
strong the generalisability of the learning for unseen data
with slightly different circumstances might stymie the ser
systems effectiveness the recent availability of several llms
chatgpt google bard etc has unearthed the possibility
of replacing or assisting human annotators llms are trained
on enormous text corpora allowing them to learn and grasp
complicated language patterns their emergence property 
makes them wellsuited for data annotations and various
studies e g   explored llms for annotations of
various natural language processing nlp tasks however
none of the studies explores them to annotate speech emotion
data based on the transcripts
in this paper we present an evaluation of the effectiveness
arxivv  cssd   jul 
of large language models llms in annotating speech data
for ser we performed a series of experiments to show
the effectiveness of chatgpt for data annotation however
we observed that annotations solely based on text lacked
generalisation to speech emotion data due to the absence
of audio context to address this limitation we propose a
novel pipeline that incorporates audio features such as average
energy pitch and gender information to provide essential
audio context for accurate sample annotation furthermore
we introduce a method for encoding speech into a fixed
length discrete feature representation using a vector quantised
variational autoencoder vqvae  which serves as the
audio context in the annotation prompt to the best of our
knowledge this is the first endeavour to leverage llms for
annotating speech emotion data specifically for classification
purposes and evaluating their performance we conduct a
comparative analysis between llmbased data annotations
and human data annotations using publicly available datasets
including iemocap and mspimprov
in the following section we provide a brief literature review
on the use of llms for data annotation we highlight the
gap between conventional annotations and annotations made
with llms section iii covers the methodology used in this
study section iv presents the initial results and compares
the performance of various llms for speech emotion data
annotation section v provides a detailed discussion of the
results and limitations and section vi concludes the paper
with the potential to extend this work
ii related work
this section provides an overview of the research on lever
aging fundamental models such as llms for data annotation
 data annotations are critical for developing ml models
capable of uncovering complex patterns in large datasets and
pushing the stateoftheart in a particular domain human ex
pert annotators bulk annotations semisupervised annotations
and crowdsourced annotations are all widely used approaches
in practice  these strategies have their pros and cons
human annotators for example can provide highquality data
annotations but are susceptible to challenges such as fairness
bias subjectivity high cost and time label drifting annotation
fatigue and inconsistency dealing with data ambiguity and
scalability bulk annotations are a faster and less expensive
technique to create data annotations but they might result in
lowerquality annotations semisupervised annotations com
bine the benefits of humanexpert annotations with bulk anno
tations for data annotation but they are complex to implement
and have generalisability and robustness difficulties although
crowdsourcing human intelligence to annotate large datasets
is the quickest and most costeffective option it can create
lowerquality annotations and is more challenging to manage
the quality of the annotations
recently a few studies have investigated the efficacy of
llms i e chatgpt for data annotations the goal of these
experiments was to explore the potential of chatgpt for data
annotation and to find out whether chatgpt can achieve full
emergence in downstream tasks such as classification zhu
et al  tested the ability of chatgpt to reproduce the
humangenerated annotations for five seminal computational
social science datasets the datasets include stance detection
two datasets hate speech detection sentiment analysis and
bot detection their results indicate that chatgpt is capable
of annotating the data but its performance varies depending
on the nature of the tasks the version of chatgpt and the
prompts the average reannotation performance is 
across all five datasets for the sentiment analysis task the
accuracy of chatgpt reannotating the tweets is reported at
 and for the hate speech task the chatgpt performance
has gone down to  the authors also provided a prompt
template that was used for reannotating the data
factchecking is a wellknown way to deal with the misin
formation epidemic in computational social science hose et
al  evaluated the ability of llms specifically chatgpt
to assist factcheckers in expediting misinformation detection
they used chatgpt as a zeroshot classifier to reannotate
 humanannotated true claim false claim fact
checked statements chatgpt was able to correctly reannotate
 of the statements the study further suggests that chat
gpt performs well on recent factchecked statements with
true claim annotations despite the reasonable performance
of chatgpt on factchecking it is hard to suggest that it will
replace human factcheckers anytime soon yang et al 
explored the rating of news outlet credibility by formulating
the problem as a binary reannotation task for chatgpt chat
gpt achieved a reasonable performance in reannotating 
domains with a spearman correlation coefficient of ρ  
tornberg  also used chatgpt as a zeroshot classifier
for reannotating  political tweets he found that chatgpt
 outperformed experts and crowd annotators in terms of
accuracy reliability and bias gilardi et al  reported
that chatgpt used as a zeroshot classifier outperformed the
crowdworksbased text annotations for five textannotation
tasks around content moderation we have also observed
studies using llms chatgpt for annotatingreannotating
data for various computational social science tasks such as
election opinion mining tasks  intent classification 
genre identification  stance detection  and sentiment
analysis  several other prominent works that evaluate the
application of llms in the annotation of computational social
science datasets for various applications include 
amin et al  evaluated the capabilities of chatgpt
in three famous nlp classification tasks in affective com
puting personality recognition suicide tendency prediction
and sentiment analysis their results indicated that chatgpt
shows far better performance in the presence of the noisy
data than wordvec models  chatgpt further pro
duces comparable performance with bagofwords bow and
wordvec models without noisy data and was outperformed
by a roberta model  trained for a specific affective
computing task chatgpt scored an unweighted average recall
of  on the sentiment analysis outperforming bow and
wordvec models by nearly  roberta also scored
an unweighted average recall of  on this task for the
suicide tendency prediction task chatgpts performance was
the same as wordvec and bow with all three models achiev
ing an unweighted average recall of nearly  roberta
outperformed chatgpt on this task achieving an unweighted
average recall of  for the personality recognition task
roberta performed best scoring an unweighted average
recall of  chatgpt performed the worst on this task
getting an unweighted average recall of  interestingly
wordvec and bow models also performed marginally well
when compared to chatgpt for this task
wang et al  argued that gpt can be a lowcost
solution for the data annotations for downstream natural
language understanding and generation tasks this research
evaluated the efficacy of augmenting humanannotated data
with gpt annotated data for improving the performance
language understanding and generation in a constrained an
notation budget they tested their method on various language
understanding and generation tasks ranging from sentiment
analysis question answering summarisation text retrieval to
textual entailment they found that gpt based annotations
policy saved  to  cost in annotation tasks how
ever they also noted that gpt is not yet as reliable as
human annotators in annotating highstakes sensitive cases
more details on the evaluation of the comparison of chatgpt
with human experts on various nlp tasks are compared and
evaluated in  huang et al  explored the ability of
chatgpt to reproduce annotations and their corresponding
natural language explanation their results indicate that lay
people agreed with the results more when they were provided
with the chatgptgenerated natural language explanation of
the annotations than just the considered post itself along with
the annotation chatgpt agreed with the humanannotated
data points  of the time
in contrast to the aforementioned studies our research ex
plores the untapped potential of llms in annotating emotions
in speech data we present a novel approach that incorporates
audio context into llms to improve the precision of anno
tations to our knowledge no prior research has investigated
the utilisation of llms for annotating speech emotion data
iii methodology
in our exploration of emotional data annotation we conduct
a series of experiments firstly we annotate samples using
only text and then we incorporate audio features and gender
information alongside textual data for improved annotation to
incorporate audio context we utilise the average energy and
pitch of each utterance and pass it to chatgpt additionally
we propose the use of vqvae to generate a dimensional
discrete representation of audio which is also provided to
chatgpt as the audio context for speechemotion classifi
cation we train a bidirectional longshort term memory
blstmbased classifier the following section provides
further details on our proposed method
a vqvae for speech code generation
we propose to use a vectorquantised variational autoen
coder vqvae  to learn a discrete representation from
the speech data unlike traditional vaes where the discrete
space is continuous vqvaes express the latent space as a
set of discrete latent codes and the prior is learnt rather than
being fixed as illustrated in figure  the model is comprised
of three main parts the encoder the vector quantiser and the
decoder
the encoder takes in the input in the form of mel
spectrograms and passes it through a series of convolutional
layers having a shape of n h w d where n is the batch size
h is the height w is the width and d represents the total number
of filters after convolutions let us denote the output from the
encoder as ze the vector quantiser component contains an
embedding space with k total vectors each with dimension
d the main goal of this component is to output a series of
embedding vectors that we call zq to accomplish this we
first reshape ze in the form of n h w d and calculate
the distance for each of these vectors with the vectors in the
embedding dictionary for each of the n h w vectors we
find the closest of the k vectors from the embedding space
and index the closest vector from the embedding space for
each n h w vector the discrete indices of each of the
vectors in the embedding space are called codes and we get
a unique series of codes for each input to the model the
selected vectors are then reshaped back to match the shape of
ze finally the reshaped vector embeddings are passed through
a series of transpose convolutions to reconstruct the original
input melspectrogram one problem with this approach is that
the process of selecting vectors is not differentiable to tackle
this problem the authors simply copy the gradients from zq
to ze
the total loss is composed of three loss elements the
reconstruction loss the code book loss and the commitment
loss the reconstruction loss is responsible for optimising the
encoder and decoder and is represented by
reconstruction loss  logpxzq
we use a code book loss which forces the vector embeddings
to move closer to the encoder output ze
code book loss  sgzex e
where sg is the stop gradient operator this essentially freezes
all gradient flows e are the vector embeddings and x is the
input to the encoder and finally for making sure that the
encoder commits to an embedding we add a commitment loss
commitment loss  βzex sge
here β is a hyperparameter that controls the weight we want
to assign to the commitment loss
overall we train the vqvae model to represent the audio
representation in the form of a discrete list of integers or
codes these audio representations can be used in addition
to the transcriptions and fed to chatgpt for annotation in
the following section we will delve into the details of the
annotation procedure
b emotion label annotation using llms
we evaluated the data annotation ability of chatgpt with
different experiments we start our experiments by annotat
ing the training data of iemocap by passing the textual
fig  model diagram of the vqvae
transcripts to chatgpt and annotating the data both in zero
shot and fewshot settings for a few shots we randomly
selected  samples from the training data and passed them
to chatgpt as context we trained the classifier using the
training samples annotated with chatgpt and unweighted
average recall uar is computed we repeat this procedure
of annotation by passing the audio features along with the
textual information first of all we use average pitch and
energy for a given utterance and reannotated the data both
in a zeroshot and a fewshots setting and classification uar
is measured using a blstm based classifier as the female
voice usually has a high pitch and energy therefore we
also annotated the data by providing the gender information
finally we propose to use an audio representation by vq
vae section iiia and pass it to chatgpt as audio context
we then used the openai api with the chatgpt pro
version to annotate the data in our approach we meticulously
designed and curated multiple prompts for annotating the data
leveraging chatgpt for the annotation process we trained the
classifier on the annotated dataset and computed the uar
considering it as a benchmark for evaluating the classification
performance to improve upon this benchmark we conducted
additional experiments exploring various prompts to enhance
the classification results beyond the established performance
level
c speech emotion classifier
in this work we implement convolutional neural network
cnnblstmbased classifiers due to their popularity in
ser research  it has been found that the performance of
blstm can be improved by feeding it with a good emotional
representation  therefore we use cnn as emotional fea
ture extractor from the given input data  a cnn layer acts
like datadriven filter banks and can model emotionally salient
features we pass these emotional features to the blstm layer
to learn contextual information emotions in speech are in
the temporal dimension therefore the blstm layer helps
model these temporal relationships  we pass the outputs
of blstm to an attention layer to aggregate the emotional
salient attributes distributed over the given utterance for a
given output sequence hi utterance level salient attributes are
aggregated as follows
rattentive 
x
i
αihi
where αi represents the attention weights that can be computed
as follows
αi 
expw t hi
p
j expw t hj
where w is a trainable parameter the attentive representation
rattentive computed by the attention layer is passed to the fully
connected layer for emotion classification overall our classi
fier is jointly empowered by the cnn layers to capture an ab
stract representation the blstm layer for context capturing
the attention layer for emotional salient attributes aggregation
and the fully connected layer emotion classification
iv experimental setup
a datasets
to evaluate the effectiveness of annotations by chatgpt
we use three datasets iemocap mspimprov and meld
which are commonly used for speech emotion classification
research   both the iemocap and the msp
improv datasets are collected by simulating naturalistic
dyadic interactions among professional actors and have similar
labelling schemes meld contains utterances from the friends
tv series
 iemocap the interactive emotional dyadic motion
capture iemocap database is a multimodal database that
contains  hours of recorded data  the recordings were
captured during dyadic interactions between five male and five
female speakers the dyadic interactions enabled the speakers
to converse in unrehearsed emotions as opposed to reading
from a text the interactions are almost five minutes long
and are segregated into smaller utterances based on sentences
where each utterance is then assigned a label according to the
emotion overall the dataset contains nine different emotions
to be consistent with previous studies we use four emotions
including sad  happy  angry  and neutral
 mspimprov this corpus is a multimodal emotional
database recorded from  actors performing dyadic inter
actions  similar to iemocap  the utterances in
mspimprov are grouped into six sessions and each session
has recordings of one male and one female actor the sce
narios were carefully designed to promote naturalness while
maintaining control over lexical and emotional contents the
emotional labels were collected through perceptual evaluations
using crowdsourcing  the utterances in this corpus are
annotated in four categorical emotions angry happy neutral
and sad to be consistent with previous studies   we
use all utterances with four emotions anger  sad 
neutral  and happy 
 meld
multimodal emotionlines dataset  or
meld contains over  dialogues and  utterances
and multiple speakers from the popular tv series friends
the utterances have been labelled from a total of seven
emotions anger disgust sadness joy neutral surprise and
fear furthermore meld also contains sentiment annotations
for each utterance to stay consistent with the other datasets
we choose four emotions including sadness  samples
neutral  samples joy and anger  samples with
this configuration we get a total of  utterances from the
dataset
b speech features
for utterances across all datasets we use a consistent
sampling rate of  khz for extracting the audio features
we then convert the audio into mel spectrograms the mel
spectrograms are computed with a shorttime fourier trans
form of size  a hop size of  and a window size
of  we specify a total of  melbands for the output
and cutoff frequency of  khz we set a cutoff length of 
for each mel spectrogram to have a final shape of x
where smaller samples are zeropadded finally the mel
spectrograms are normalised in the range of  
c hyperparameters
the vqvae was trained using the following parameters
we chose a batch size of  and trained for a total of 
epochs with a learning rate of e the convolution layers
each had a stride and kernel size of  and  respectively
a total of  token embeddings were selected where each
had a dimensionality of  with our particular configuration
we got a total of  codes for each given utterance we pass
these codes to chatgpt along with textual data for annotation
based on these annotations we trained over the classifier
our classifier consists of convolutional layers and a bidi
rectional lstm blstmbased classification network to
generate highlevel abstract feature representations we employ
two cnn layers in line with previous studies   we
utilise a larger kernel size for the first convolutional layer and
a smaller kernel size for the second layer the cnn layers
learn feature representations which are then passed to the
blstm layer with  lstm units for contextual repre
sentation learning following the blstm layer an attention
layer is applied to aggregate the emotional content spread
across different parts of the given utterance the resulting
attentive features are then fed into a dense layer with 
hidden units to extract emotionally discriminative features for
a softmax layer the softmax layer employs the crossentropy
loss function to calculate posterior class probabilities enabling
the network to learn distinct features and perform accurate
emotion classification
in our experiments we utilise the adam optimiser with its
default parameters the training of our models starts with a
learning rate of  and at the end of each epoch we assess
the validation accuracy if the validation accuracy fails to
improve for five consecutive epochs we decrease the learning
rate by half and revert the model to the bestperforming
previous epoch this process continues until the learning rate
drops below  as for the choice of nonlinear activation
function we use the rectified linear unit relu due to its
superior performance compared to leaky relu and hyperbolic
tangent during the validation phase
v experiments and results
all experiments are conducted in a speakerindependent
manner to ensure the generalisability of our findings specif
ically we adopt an easily reproducible and widely used
leaveonespeakerout crossvalidation scheme as commonly
employed in related literature  for crosscorpus
ser we follow   and use iemocap for training
and mspimprov is used for validation and testing for
the experiments we repeat each experiment ten times and
calculate the mean and standard deviation of the results
the performance is presented in terms of the unweighted
average recall rate uar a widely accepted metric in the field
that more accurately reflects the classification accuracy across
multiple emotion categories when the data is in imbalance
across these
a within corpus experiments
for the withincorpus experiments we select the iemo
cap data and compare the results with the baseline uar
achieved using actual true labels we trained the classifier
for different settings  true label settings  zeroshot
chatgpt labels and  fewshots chatgpt labels in the
first experiment we trained the cnnbstmbased classifier
on true labels using the wellknown above mentioned leave
onespeakerout scheme   in the second and third
experiments the classifier is trained in the same leaveone
speakerout scheme however we annotated samples using
chatgpt with our proposed approach we repeat the second
and third experiments using text only and text plus audio
context results are presented in figure  overall results
on data annotated using few shots achieve improved results
compared to the zeroshot scenario it is important to note
fig  comparing the classification performance uar  using
training data annotated by chatgpt and original iemocap labels
that the emotion classification performance using training data
annotated with only text is poor compared to the baseline
here baseline results represent when the classifier is trained
using the original annotations of iemocap this observation
underscores the insufficiency of textual information alone
to provide the necessary context for accurate annotation by
chatgpt consequently additional context becomes essential
to enable chatgpt in effectively annotating the data as previ
ously found for example happy and angry voice samples often
have high energy and pitch compared to a sad and neutral voice
 building upon this insight we incorporated the average
energy and pitch values of a given utterance as additional
contextual information for chatgpt during the reannotation
process both in zeroshot and fewshot settings however the
performance improvement was not considerable primarily due
to the confounding factor of gender as female voices typically
exhibit higher pitch and energy compared to male voices 
to address this limitation we extended the experiment by
providing gender labels to chatgpt resulting in improved
classification accuracy as illustrated in  in addition to average
energy pitch and gender information we further proposed the
utilisation of audio patterns to provide enhanced audio context
for annotation to achieve this we employed a vqvae model
to encode the given utterance into discrete representations
these representations along with the textual and other feature
inputs were employed in various experiments for annotation
refer to figure  notably in the zeroshot scenario no
substantial improvements were observed however significant
advancements were achieved by incorporating the discrete
codes generated by vqvae in conjunction with average
energy pitch and gender information
b crosscorpus evaluations
in this experiment we perform a crosscorpus analysis
to assess the generalisability of annotations performed using
our proposed approach here we trained models on iemo
cap and testing is performed on the mspimprov data
iemocap is more blanched data therefore we select it
for training by following previous studies
  
we randomly select   of the mspimprov data for
parameter tuning and   of data as testing data we
report results using the fewshots annotation by chatgpt as it
consistently demonstrated superior performance compared to
the zeroshot setting
table i crosscorpus evaluation results for speech emotion recog
nition
model
uar 
attentive cnn 
cnnblstmbaseline
textenergyfgender
textenergyfgendervqvae
we compare our results with different studies in table i in
 the authors use the cnnlstm model for crosscorpus
evaluation they show that cnnlstm can learn emotional
contexts and help achieve improved results for crosscorpus
ser in  the authors utilise the representations learnt
from unlabelled data and feed it to an attentionbased cnn
classifier they show that the classifiers performance can
be improved by augmenting the classifier with information
from unlabelled data we compare our results using the cnn
blstmbased classifier by using the iemocap annotated by
the chatgpt model this experiment demonstrates the gen
eralisability of annotations performed by chatgpt in cross
corpus settings however it is worth noting that our results
did not surpass those of previous studies in the subsequent
experiment we aim to showcase the potential for enhancing
the performance of ser using data annotations generated by
chatgpt both withincorpus and crosscorpus settings
c augmentating the training data
in the previous two experiments we showed how we can
annotate new speechemotional data using a large language
model like chatgpt however the performance does not
surpass the uar achieved using actual labels in this ex
periment we aim to address this limitation by showcasing
the potential of improving ser performance through data
augmentation using our proposed approach for this we can
utilise abundantly available audio data by annotating with our
proposed approach for instance data from youtube can be
annotated and used to augment the ser system to validate
this concept we select the meld dataset which consists of
dialogue samples from the friends tv series we employ
the fewshot approach using samples from the iemocap
dataset for fewshots and annotate the meld data with four
emotions happy anger neutral and sad we used samples
from iemocap data for the fewshots and annotated meld
data in four emotions including happy anger neutral and
sad results are presented in figure  where we compare
the results with the cnnblstm classifier using the actual
iecmoap labels and when data is augmented using the
samples with chatgpt labels this analysis provides insights
into the effectiveness of data augmentation for enhancing the
performance of the ser system
fig  comparing the classier performance uar  with data
augmentation
table ii comparison of results with previous studies
model
uar 
within corpus
dialoguernn  
cnnattention  
cnnblstm  augmentation  
our work  augmentations 
 
crosscorpus
cyclegandnn   augmentations 
cnnblstm  augmentations  
  
our work  augmentations 
 
furthermore we provide a comprehensive comparison of
our results with previous studies in both withincorpus and
crosscorpus settings as presented in table ii in   the
authors utilise dialoguernn for speech emotion recognition
using iemocap data peng et al  use an attentionbased
cnn network for emotion classification we achieve better
results compared to these studies by augmenting the classifier
with additional data annotated by chatgpt one possible
reason can be that these studies did not train the models
with augmentation however we also compared the results
with  where the authors use different data augmentation
techniques to augment the classifier and achieve improved
results in contrast we use chatgpt to annotate the publicly
available data and use it for augmentation of the training set
we are achieving considerably improved results compared to
 one possible reason is that we are adding new data in
the classifiers training set however authors in  employed
perturbed versions of the same data which can potentially lead
to overfitting of the system similarly we achieve considerably
improved results for crosscorpus settings compared to the
precious studies   where the authors augmented their
classification models with either synthetic data or perturbed
samples using audiobased data augmentation techniques like
speed perturbation specaugmet and mixup
overall our results showcase the effectiveness of our ap
proach in achieving superior performance compared to previ
ous studies both in withincorpus and crosscorpus settings
the utilisation of chatgpt for data annotation and augmen
tation proves to be a promising strategy for enhancing ser
systems
d limitations
in this section we highlight the potential limitations of our
work and in general the limitations of llms for data an
notation during our experiments we observed the following
limitations
 we obtained promising results by augmenting the training
data with samples annotated using chatgpt however
this approach proved ineffective when applied to corpora
such as librispeech  where the recordings lack
emotional variations although we attempted to utilise
librispeech data results are not shown here the results
were not as promising as those achieved with meld
 chatgpt is known to be sensitive to prompt variability
which can lead to ambiguous and erroneous results if
even slight changes are made to the prompt content in
order to address this issue we suggest conducting exper
iments using different prompts to generate annotations
as presented in section iiib the inclusion of more
context in the prompts has been shown to improve the
quality of results however for ser annotation prompts
this can be particularly challenging due to the significant
variability of human emotions within short time frames
this limitation stems from llms reliance on training
data
 chatgpt has not been trained particularly to annotate
speech emotion data while the emergent nature of chat
gpt has aided with annotation relying exclusively on
chatgpt annotation is insufficient through our research
we have found that incorporating chatgptbased annota
tions alongside the training data leads to enhanced classi
fication performance notably when utilising multishot
chatgpt annotations instead of zeroshot annotations we
observe a substantial performance improvement
 chatgpt offers a significant cost reduction in data an
notation for instance in our experiments we were able
to annotate iemocap data examples using chatgpt for
approximately  usd which is significantly lower than
human annotations cost however it is paramount to note
that the accuracy of chatgptbased annotations is not
as good as human annotations because chatgpt is not
specifically trained for annotating speech emotion data
as a result it is a tradeoff situation therefore it be
comes a tradeoff between cost and accuracy striking the
right balance is crucial when utilising chatgpt for data
annotation to avoid potential inaccuracies in classification
performance
despite the mentioned limitations we have found chatgpt
to be an invaluable tool for speechemotion data annotation
we believe that its capabilities will continue to evolve cur
rently generating annotations using chatgpt and incorporat
ing them to augment humanannotated data has demonstrated
improved performance in speech emotion classification this
highlights the potential of chatgpt as a valuable asset in
advancing research in this field
vi conclusions and outlook
in this paper we conducted a comprehensive evaluation of
chatgpts effectiveness in annotating speech emotion data
to the best of our knowledge this study is the first of its
kind to explore the capabilities of chatgpt in the domain of
speech emotion recognition the results of our investigation
have been encouraging and we have discovered promising
outcomes below are the key findings of our study
 based on our findings we observed that textbased emo
tional annotations do not generalise effectively to speech
data to address this limitation we introduced a novel
approach that harnesses the audio context in annotating
speech data leveraging the capabilities of a large lan
guage model by incorporating the audio context we
successfully enhanced the performance of ser yielding
improved results compared to the textbased approach
 we observed that the quality of annotations by chatgpt
considerably improved when using a fewshot approach
compared to a zeroshot one by incorporating a small
number of annotated samples we were able to achieve
improved results in our evaluation
 we introduced an effective technique to utilise large
language models llms to augment the speech emotion
recognition ser system with the annotated data by
chatgpt the augmented system yielded improved re
sults compared to the current stateoftheart ser systems
that utilise conventional augmentation techniques
in our future work we aim to expand our experimentation
by applying our approach to new datasets and diverse contexts
this will allow us to further validate the effectiveness and gen
eralisability of our proposed technique additionally we plan
to explore and compare the annotation abilities of different
llms for speech emotion data enabling us to gain insights
into their respective strengths and weaknesses we also intend
to use llms in the training pipeline of the ser system

sparks of large audio models
a survey and outlook
siddique latif moazzam shoukat fahad shamshad muhammad usama yi ren heriberto cuay
ahuitl
wenwu wang xulong zhang roberto togneri erik cambria and bj
orn w schuller
abstractthis survey paper provides a comprehensive overview of the recent advancements and challenges in applying large language
models to the field of audio signal processing audio processing with its diverse signal representations and a wide range of sources 
from human voices to musical instruments and environmental sounds  poses challenges distinct from those found in traditional natural
language processing scenarios nevertheless large audio models epitomised by transformerbased architectures have shown marked
efficacy in this sphere by leveraging massive amount of data these models have demonstrated prowess in a variety of audio tasks
spanning from automatic speech recognition and texttospeech to music generation among others notably recently these
foundational audio models like seamlessmt have started showing abilities to act as universal translators supporting multiple speech
tasks for up to  languages without any reliance on separate taskspecific systems this paper presents an indepth analysis of
stateoftheart methodologies regarding foundational large audio models their performance benchmarks and their applicability to
realworld scenarios we also highlight current limitations and provide insights into potential future research directions in the realm of
large audio models with the intent to spark further discussion thereby fostering innovation in the next generation of audioprocessing
systems furthermore to cope with the rapid development in this area we will consistently update the relevant repository with relevant
recent articles and their opensource implementations at httpsgithubcomemulationaiawesomelargeaudiomodels
index termslarge language models foundation models large audio models audio processing speech processing music signal
processing multimodality
introduction
a
udio processing encompassing the broad categories of
speech music and environmental sounds is a vibrant
research area that has a myriad of realworld applications
these applications range from voiceactivated assistants like
siri and alexa   to transcription services  and extend
to telecommunication systems  and hearing aids  tradi
tional audio processing systems were built on meticulously
handcrafted features and extensive linguistic knowledge 
despite their effectiveness these handcrafted approaches
often lacked scalability and struggled with the variability and
complexity inherent in audio signals  however in the past
decade the field has experienced a significant paradigm shift
with the emergence of datadriven methodologies 
this progression towards datacentric techniques paves the
way for systems that can learn to understand and interpret
complex audio patterns directly from raw data  
however
these
datadriven
models
despite
their
siddique latif is with queensland university of technology qut australia
email siddiquelatifusqeduau
moazzam shoukat is with emulation ai australia
fahad shamshad is with mohamed bin zayed university of artificial
intelligence abu dhabi uae
muhammad usama is with nuces pakistan
yi ren is with the speech and audio team bytedance ai lab singapore
heriberto cuay
ahuitl is with the university of lincoln uk
wenwu wang is with the university of surrey uk
xulong zhang is with lab of large audio models ping an technology china
roberto togneri is with the university of western australia australia
erik cambria is with nanyang technological university singapore
bj
orn w schuller is with glam  the group on language audio  music
imperial college london uk and is also with the chair eihw university of
augsburg germany
prowess typically perform well only for the specific tasks
they are trained on and generally struggle with situations
that deviate from their training environments meanwhile
large ai models particularly large language models llms
have demonstrated outstanding accomplishments in almost
every ai domain reshaping how humans interact with
machines  these large models characterised by their
billions of parameters and training on massive datasets
have manifested emergent abilities to tackle a multitude of
intricate tasks across various fields  such capabilities
have elevated ai algorithms to unprecedented levels of
power and efficacy in particular the emergence of models
such as chatgpt and gpt has rekindled discussions about
the potential of artificial general intelligence   unlike
earlier learningbased models that were tailored for specific
tasks these large models boast versatility in addressing
diverse tasks   given their immense potential these
expansive ai models signify a new technological wave that
promises a rich ecosystem of realworld applications and
have already found extensive applications in various sectors
such as vision   language health education robotics
and governance among others
while large ai models have made remarkable advance
ments in the domains of language  images  and
videos  the audio arena has followed a more gradual
trajectory nevertheless recently these large models have
made significant strides in a variety of audio processing tasks
characterised by techniques that adeptly integrate audio
data representations with traditional text token embeddings
equipping these large models with the capacity to interpret
and manage a wide range of audio content  despite
arxivv  cssd   sep 
table  comparison between this paper and other review articles concerning foundation models fmslarge language
models llms andor audio signal processing
authors
year
fm
audio
domain
focus
karita et al 
speech
comprehensive study to compare the performance of transformer and recurrent
neural networks in numerous speech applications
latif et al 
speech
first survey paper of applications of transformer models in speech processing
mehrish et al 
speech
comprehensive survey covering applications of deep learning in speech processing
latif et al 
speech
first survey paper of applications of reinforcement learning in audio processing
bommasani et al 
general
a comprehensive survey paper on the applications and risks of foundation models
in diverse fields including language vision health among others
zhao et al 
general
first comprehensive survey paper on llms including their background key findings
in the literature and mainstream techniques
chang et al 
general
comprehensive review of these evaluation methods for llms focusing on three key
dimensions what to evaluate where to evaluate and how to evaluate
kaddour et al 
general
identify several unsolved challenges of llms provide an overview of their current
applications and discuss how the former constrain the latter
wang et al 
general
first survey to provide an uptodate review on the alignment process of llms
gan et al 
vision
this survey categorises visionlanguage pretraining frameworks covering various
architectures objectives and downstream tasks
zhang et al 
vision
comprehensive review of the visually prompted foundation segmentation model
segment anything sam and discusses potential downstream tasks
zhang et al 
vision
survey of different visionlanguage pretraining network architectures objectives
and downstream tasks and categorises visionlanguage pretraining frameworks
awais et al 
vision
reviews vision and language foundational models focusing on their architecture
types training objectives downstream task adaption and their prompting designs
with a broad coverage of their applications in a variety of visual tasks
kasneci et al 
education
emphasise the potential of large models models to enhance educational content boost
student engagement and tailor individual learning experiences
kung et al 
education
assess chatgpts performance on the united states medical licensing exam
usmle where it impressively achieved scores near the passing threshold without
any dedicated specialised training
qadir et al 
education
review regarding promise and pitfalls of chatgpt in engineering education
rudoph et al 
education
examine the implications of technology for higher education focusing on the future
of learning teaching and assessment in the context of ai chatbots like chatgpt
moor et al 
health
identify potential applications for medical foundation models and outline specific
technical capabilities and training data needed to enable them
qiu et al 
health
comprehensive review of large ai models in health informatics including drug
discovery medical diagnosis and decisionmaking medical imaging medical
informatics medical education public health and medical robotics
wornow et al 
health
reviews  foundation models using nonimaging emr data categorising their
architectures training sources and applications
zhang et al 
health
survey of medical foundation models from general vision to modality and task
specific ones emphasising their challenges opportunities and uses
hu et al 
comp bio
review the latest developments in large models and protein large models focusing on
their architectures pretraining methods and prevalent protein databases
tran et al 
comp bio
survey a number of representative embedding models for execution time memory
needs and their ability to perform various tasks related to global properties for
different protein sets
cyphert et al 
law
article delves into the ethical implications of integrating gpt into legal practices
sun et al 
law
survey of llms in legal tasks like judgement prediction and document analysis also
highlights related legal challenges including privacy bias and transparency
nay et al 
law
examines llms proficiency in tax law application noting improvements in newer
models compared to older ones
yang et al 
robotics
explore applications of foundation models in practical decisionmaking using
prompting generative modeling planning and reinforcement learning
this paper
audio
first survey paper of applications of large ai models in audio signal processing
substantial progress and promising potential the integration
of large models into audio processing presents unique chal
lenges and requires dedicated exploration this highlights
the imperative for an allencompassing survey centred on the
application of these large models within the audio domain
encompassing speech music and other auditory facets this
paper aims to fulfil this requirement providing an exhaustive
overview of the methods limitations and future directions
in this emerging field specifically our key contributions are
as follows
this is the first survey paper that comprehensively
covers applications of large ai models in the domain
of audio signal processing thereby covering the recent
progress in this emerging area
we also shed light on how large ai models handle
the distinct characteristics of audio processing and
how they can be further enhanced to handle the
complexities of spoken language in particular we
cover the applications of these large models in the
broad categories of speech and music
fig  paper outline
we discuss challenges limitations and potential
directions for future research through this survey
we aim to provide a comprehensive understanding
of the current landscape of large models in the realm
of audio processing thus paving the way for future
innovations in this exciting area
paper organisation the organisation of this paper is
shown in figure  section  provides insights into the
applications of sequential models and transformers within
the audio processing sphere while also briefly discussing
large language models and the pivotal role of datasets
in training expansive audio models section  provides a
comprehensive overview of the applications of large ai
models in the speech and music domains section  discusses
open problems and charts potential avenues for future
research finally in section  we summarise and conclude
the paper
related surveys and differences
while several com
prehensive surveys delve into the applications of deep
learning for audio processing     including
speech   music  and other categories  
none concentrate on the advent and deployment of llms
in this field numerous surveys exist that cover the vast
landscape of llms each focusing on specific aspects or
applications among these the work by zhao et al 
closely parallels ours as it provides a broad overview of
llms and related topics similarly mialon et al  turn
their attention towards augmented language models those
with advanced reasoning capabilities and tool usage skills
on a similar vein tornede et al  explore llms in the con
text of automated machine learning automl techniques
discussing existing methodologies and the challenges of
using them to enhance llm performance tang et al 
focus on techniques for detecting text generated by llms
while chang et al  have examined the various ways to
evaluate llms additionally there are a number of surveys
dedicated to investigating the specialised applications of
large models in various fields such as vision    
education   healthcare   computational
biology   computer programming   law 
  or robotics    among others on the other
hand our survey stands apart in its exclusive focus on
the applications of large ai models in the realm of audio
signal processing and fills an existing gap in the current
body of research to round off our review we provide a brief
summary of the contributions of existing surveys in table 
background
in this section we provide an overview of llms begin
ning with a brief overview of sequential models and the
difficulties they encounter while processing sequential data
subsequently we will probe the principal ideas that underpin
the operation of large language models emphasising the dis
tinctive traits that equip these models to surpass traditional
recurrent neural networks ultimately we will examine the
widely used large language models in the domain of audio
processing
sequential models for audio processing
initial applications of deep learning in the field of audio
processing primarily utilised versions of convolutional neu
ral networks cnns  however the inability of these
cnnbased methodologies to encapsulate the sequential
essence of speech data was a substantial disadvantage this
shortcoming led to the inception of sequencetosequence
seqseq architectures such as recurrent neural networks
rnns  and long shortterm memory networks
lstms  specifically engineered for handling sequential
data rnns proved to be a suitable fit for sequential data
given their ability to process extensive sequences incre
mentally maintaining a constrained memory of preceding
sequence components a recent trend in research merges the
unique strengths of both cnns and rnns this involves
using cnns to derive audio features which are then fed as
input for rnn training however rnns are known to suffer
from the challenges of vanishing or exploding gradients
to combat this lstms implement a gating mechanism
alongside memory cells to regulate the information flow and
mitigate issues related to gradients   there have been
fig  architecture of standard transformer a fundamental building block of large ai models adapted from vaswani
et al  and tay et al  it consists of encoder and decoder layers both equipped with stacked selfattention and
feedforward components the encoder derives hidden states from an input token sequence and the decoder utilises these
states alongside its own output token sequence to produce predictions
various adaptations of lstms such as frequencylstm
timefrequency lstms bidirectional lstms convlstms
and stacked lstms each proposed to cater to specific speech
processing tasks despite their potency seqseq models have
certain restrictions for instance they struggle to leverage
parallel computing hardware efficiently and have difficulty
in modelling longterm contexts due to their inherently
sequential nature
transformers for audio processing
transformers utilise selfattention mechanisms to capture
temporal correlations from sequential data  this equips
transformers with the ability to capture extensive temporal
contexts while maintaining reduced computational complex
ity transformers employ selfattention layers to effectively
capture distant relationships within input sequences unlike
traditional rnns which struggle with such interactions self
attention also enables greater parallelisation compared to
rnns allowing transformers to process speech sequences
holistically without relying on past states vaswani et al 
introduced two types of attention scaled dotproduct at
tention and multihead attention additionally positional
encoding conveys information about token positions see
figure  these benefits have spurred significant interest
in transformers across various ai domains  notably
the audio community this has given rise to diverse archi
tectures such as wavvec  whisper  fastpitch 
musicbert  and others   
furthermore transformers have not only revolutionised
natural language processing and audio processing but have
also paved the way for the development of llms that can
understand generate and interact with human language
and its underlying contexts in increasingly nuanced and
sophisticated ways their remarkable ability to efficiently
capture contextual dependencies and relationships within
sequences has been instrumental in the creation of llms with
billions of parameters such as gpt this breakthrough
in capturing contextual information has extended beyond
text generation to various modalities like speech and audio
giving rise to the emergence of large audio models that
have transformed tasks such as speech recognition emotion
detection and music generation we discuss the large audio
model in the next subsection
overview of large language models
investigations reveal that the act of scaling pretrained lan
guage models plms either through enhancing the model
size or expanding the data size typically yields superior
model performance on subsequent tasks adhering to what is
known as the scaling law  numerous investigations have
probed the limits of performance by training increasingly
larger plms such as the gpt model with  billion
parameters and the palm model with  billion parameters
while the majority of scaling endeavours primarily focus on
model size preserving similar architectures and pretraining
tasks these expanded plms exhibit distinct characteristics
compared to their smaller counterparts such as bert with
 million parameters and gpt with  billion parameters
they exhibit unexpected proficiency referred to as emergent
abilities in tackling a variety of intricate tasks for example
gpt has demonstrated the ability to address fewshot tasks
via incontext learning a feat that gpt struggles with
hence the term large language models llms has been
coined by the research community to describe these enlarged
plms and these models have garnered increasing interest
a notable example of an llm application is chatgpt which
adapts the gpt series llms for dialogue showcasing excep
tional conversational capabilities with humans a significant
surge in arxiv papers pertaining to llms can be observed
following the launch of chatgpt
fig  overview of foundational audio models a foundational audio model aggregates information from diverse data
modalities once trained this model can be tailored to various downstream audio tasks
recently gpt  has been developed which is a large
scale multimodal model that can accept image and text as
input and produce text outputs gpt is capable of achieving
humanlevel performance on some professional and aca
demic benchmarks including achieving a score around the
top  of testtakers in a simulated bar exam various other
multimodal large language models are proposed by utilising
multimodal information including visual audio and text
these llms are considered a crucial step towards artificial
general intelligence agi most importantly large audio
models see figure  attract significant interest from the
research community to build llms that have intrinsic cross
modal conversational abilities and are capable of perceiving
and generating audio or multimodal content we also show
a brief timeline for large audio models in figure  in the next
section we cover popular large audio models and a summary
of these models is presented in table 
popular large audio models
in this section we provide a brief overview of popular large
audio models
speechgpt
zhang et al  proposed speechgpt a large language
model that has intrinsic crossmodal conversational abilities
that allow it to generate multimodal content the model is
based on three significant elements a discrete unit extractor
a large language modal and a unit vocoder they utilised
hiddenunit bert hubert  as a discrete unit extractor
for the transformation of continuous speech to discrete units
the meta ai llama  model as llm and hifigan as
a unit vocoder the low availability of publicly available
speech data compelled them to construct the speechinstruct
a speechtext crossmodal instructionfollowing dataset com
prised of two parts crossmodal instructions and chainof
modality instruction the training process of this model
is broken down into three steps modality adaptation pre
training on unpaired speech data crossmodal instruction
finetuning and chainofmodality instruction finetuning
they employ an unlabelled speech corpus to train the llm
in a nexttoken prediction task which empowers the large
language model llm to effectively handle discrete units
of modality in the crossmodal instruction finetuning
they utilised the paired data to align speech and text
subsequently they applied the parameterefficient lowrank
adaptation lora technique  to perform finetuning
consequently they found the model to perform various
tasks with correct output on different instructions although
this model has shown remarkable crossmodal instruction
recognition and speech dialogue abilities it also has some
limitations that can be listed as paralinguistic information
sequential response generation and context length limitation
audiopalm
rubenstein et al  introduce a multimodal generative
model called audiopalm see figure  for speech and
text capable of both understanding and generating speech
the model is built upon the foundation of palm  and
palm  initially devised for textonly pretraining
the models training encompasses three primary stages
tokenisation of text and audio modification of pretrained
text decoders and transformation of the models output
into audio they adopt token extraction techniques from
raw audio   following token processing the tokens
are fed into a transformer decoder which subsequently
passes through an audio decoding process they employ
autoregressive techniques as in audiolm  as well as
nonautoregressive approaches similar to  to translate
decoding tokens into audio their findings demonstrate
fig  timeline of large audio models
improved asrast performance with llm size and a
single model is effectively trained across multiple tasks
audiolm
borsos et al  present the audiolm framework designed
to facilitate highquality audio synthesis while prioritising
the preservation of longterm consistency coherence and
uniformity across extended time spans this framework
is composed of three integral components a tokeniser
model a decoderonly transformer and a detokeniser model
drawing from soundstream  wvbert  the k
means quantiser for wvbert embeddings and decoder
only transformers all of which have been trained on the
extensive librilight  english dataset encompassing
 hours of speech data the authors assembled these
components this amalgamation incorporates adversarial
neural audio compression selfsupervised representation
learning and language modelling techniques they have
shown a comparison between the acoustic tokens from
soundstream and the semantic tokens extracted from a pre
trained wvbert model on a speech dataset to show that
these two types of tokens complement each other regarding
enhancing phonetic discriminability and attaining high
quality rebuilding of the audio content through training
on comprehensive raw audio waveform datasets audiolm
acquires the proficiency to generate highquality and logically
coherent audio extensions from concise prompts converting
input audio into a series of tokens audiolm approaches
audio generation as a language modelling task
audiogen
meta recently introduced audiocraft an extensive frame
work designed to facilitate a diverse range of generative
audio tasks encompassing music generation sound effects
creation and posttraining compression using raw audio sig
nals this comprehensive framework consists of three essen
tial components musicgen  audiogen and encodec
both musicgen and audiogen incorporate independent
autoregressive language models lms tailored to operate
with discrete audio representations in the form of tokens in
contrast encodec is built upon neural networks
audiogen  a critical component of this framework
is an autoregressive model that effectively addresses the
challenge of generating audio while incorporating textual
inputs this model adopts a transformerbased architecture
functioning with discrete audio representations the oper
ational mechanism of this model can be distilled into two
primary steps firstly an autoencoding method  
is employed to comprehend the discrete representation of
raw unprocessed audio subsequently these acquired repre
sentations are employed to train the transformer language
model the transformer decoder language model is extended
from the gptlike model imbuing the entire system with
an encoderdecoder configuration empirical evaluations un
derscore the models commendable performance across both
objective and subjective evaluation metrics positioning it
favourably in comparison to assessed baselines notably the
proposed methodology excels in generating audio continua
tions adeptly navigating both conditional and unconditional
scenarios
audioldm and audioldm 
audioldm  is a texttoaudio generation framework
with an encoder built on a contrastive language audio
pretrained clap model and the latent diffusion model
ldm for sound generation with audio embedding as input
and text embedding as conditions the clap model is
pretrained with datasets including laionaudiok
audioset audiocaps and clotho with the clap encoder
the training of the ldm does not require audiotext pairs
any more which is substantially different from the previous
method such as audiogen  and diffsound  as a
result a large number of audio clips without the paired texts
could be used to train the ldm model and this leads to a
generation model capable of generating more diverse sounds
with potentially better quality as compared with audiogen
and diffsound in addition due to the operation in the latent
space the training of audioldm is much more efficient
fig  overview of the audiopalm model  designed for speechtospeech translation and automatic speech recognition
a pretrained textonly model denoted by dashed lines is modified to incorporate an extended embedding matrix for
new audio tokens the overall structure remains consistent accepting a combined sequence of text and audio tokens and
decoding either type the subsequent stages of audiolm or soundstorm then revert audio tokens back to raw audio figure
taken from 
as compared with audiogen and diffsound and only one
gpu is required for training on the audiocaps dataset in
addition the audioldm model enables a number of other
audiorelated tasks to be performed in zeroshot fashion such
as textguided superresolution inpainting and style transfer
built on the success of audioldm the authors have created a
more advanced model called audioldm   which aims
to develop a general audio representation method called
language of audio loa for speech music and general
sound effects with this method a single foundation model
is learned with the same method and is able to generate
highquality speech music and sound effects the self
supervised learning method audiomae is used to convert
any audio modality into the language of audio with the
loa representation the audio signal can be generated with
a selfsupervised learning process with a ldm with loa
as conditions this technique leverages the strengths of in
context learning the pretrained audiomae and ldm this
method is shown to give stateoftheart performance in
texttosound generation
ltu
gong et al  present an audio model known as ltu
listen think and understand designed to perform audio
classification and captioning tasks based on the openaqa
m dataset which comprises  million diverse audio
samples the training of ltu involves the creation of a novel
dataset openaqam by amalgamating eight datasets
containing audio questions and answers the architec
ture of the ltu model draws from various components
including an audio spectrogram transformer ast 
as the audio encoder llama  as the large language
model llm enhanced with vicuna  instructions low
rank adapter  and specific generation settings to align
the embedding dimensions with llama a pretrained
audio spectrogram transformer is used alongside the cav
mae  and finetuned on audiosetm  for audio
encoding
during training the authors maintained the llama
unchanged to minimise catastrophic forgetting  they
focused solely on training the ast audio encoder the audio
projection layer and the lora adapters llama underwent
selfsupervised pretraining on both natural language and
programming language datasets while vicuna was fine
tuned using instructions generated by gpt models the
arbitrary initialisation of the audio projection layer led to
training this component in conjunction with closedended
classification and acoustic feature description tasks while
keeping ast and lora adapters unaltered evaluation of
ltu against a stateoftheart model clap showcased its
significant performance in audiototext tasks achieving an
average relative improvement of  across classification
eight benchmarks
viola
wang et al  introduce viola a codec language model
encompassing a multilingual multimodal autoregressive
transformer decoderonly network this model exhibits
proficiency in speech recognition speech synthesis and
translation covering speechtotext stt texttospeech
tts and machine translation mt tasks viola is built
upon valle  and valle x  which share tts
capabilities akin to gpt the authors utilise an offline neural
model encodec to convert speech waveforms into discrete
tokens this transformation enables speech representations
to be treated as textual tokens effectively leveraging a
decoderonly model for adept optimisation of multimodal
tasks viola is trained using multitask learning strategies
encompassing asr mt and tts tasks the results under
score violas effectiveness in addressing both singlemodal
and crossmodal tasks despite its versatility in numerous
speech tasks viola is not without limitations its training
relies solely on supervised data neglecting the untapped
potential of unsupervised data including unlabelled speech
and diverse text corpora the models scope encompasses
incontext learning for speech synthesis tasks but it does
not encompass other speech processing sp tasks addi
tionally viola currently lacks endtoend capabilities in
comprehensive speechprocessing tasks
musicgen
musicgen a part of the audiocraft framework  is a
texttomusic generation language model lm that oper
ates on discrete audio representations to generate music
from provided text descriptions this study introduces a
model for generating coherent music based on text and
melody conditions with extensive objective and subjective
evaluations the architecture relies on an autoregressive
transformerbased decoder  conditioned on textual and
musical representations enodec  is employed to encode
audio into a continuous tensor the model is trained on
 instances of licensed music data and evaluated against
musiccaps benchmarks  surpassing evaluated baselines
in subjective assessments
musiclm
musiclm  has the main idea of generating music from
the textual description and it can generate highquality
music at  khz that has consistency over several minutes
it leverages the multistage autoregressive modelling of
audiolm  as the generative component and extends it to
include text conditioning it also uses mulan  a joint
musictext model to address the main challenge of paired
data scarcity the authors created a new handcurated dataset
musiccaps which contains the k examples prepared by
expert musicians they trained the musiclm to generate long
and coherent music for textual descriptions of significant
complexity based on the results they showed that the musi
clm can generate up to minute long clips and outperforms
previous research in music quality as well as it adheres to
the textual description musiclm inherits the limitations
from mulan which makes the model misunderstand the
negations which causes the model to not adhere to the
temporal ordering described in the text
wavjourney
wavjourney see figure  is a method that uses llms to
analyse text instructions and then connects a variety of
audio models for compositional sound generation  first
structured audio scripts are generated based on the text
instruct using llms and these scripts are organised in terms
of their spatiotemporal relations a script compiler is then
used to convert the audio scripts into computer programs
which then calls for various acoustic models and operation
functions in order to synthesise the audio content this
method offers a powerful creative tool for audio content
generation for a number of potential applications including
storytelling science fiction radio play and education
seamlessmt
seamlessmt  short for massively multilingual 
multimodal machine translation see figure   offers a
comprehensive solution for a wide range of translation tasks
spanning  languages this model operates on the multi
task unity architecture  facilitating the direct generation
of translated text and speech as well as supporting asr and
various translation modes the architecture encompasses
text and speech encoders a text decoder and a textto
unit model further strengthened by the selfsupervised
encoder speechtotext texttotext translation and textto
unit model pretraining these components contribute to the
conversion of decoded discrete units into speech through
a multilingual hifigan unit vocoder  notably the
selfsupervised speech encoder wvbert  demonstrates
fig  overview of the seamlessmt model  illustrates
the pretrained models employed during the finetuning
of multitasking unity   depicts the multitasking
unity structure including its dual encoders text decoder
tu encoderdecoder and accompanying vocoders for sst
speech synthesis figure taken from 
improved training stability and representation quality en
abling the extraction of structural and semantic insights
from multilingual speech alongside this a text encoder
trained across nearly  languages captures valuable text
representations enhancing the efficiency of multilingual
translation tasks
literature review
in this section we extensively provide the literature review
of large audio models in various tasks including speech
processing and music signal processing for the evaluation
of these tasks various datasets are available and being used
in audio processing research in table  we provide details
of various public datasets used in the development of large
audio models for a comprehensive list of datasets readers
are referred to the github page below we cover various
audiorelated tasks using large audio models or llms
automatic speech recognition asr
automatic speech recognition asr empowers machines
to convert the spoken language into corresponding text
sequences comprising words or even subwords in asr
research recurrent neural networks rnns embedded with
long shortterm memory lstm  units are considered
as core architecture until the transformers have been pro
posed  in contrast to rnns transformers can model
temporal correlations within sequential data by utilising
selfattention mechanisms  in addition transformers
offer the advantage of parallelising computations enabling
faster training of deeper models on larger datasets recently
language models have shown their power in capturing high
level longterm patterns across different data types including
text   and image   and speech  this
has also opened avenues for developing large audio models
in the speech and audio domain
 httpsgithubcomemulationaiawesomelargeaudiomodels
table  some recent large audio models asr automatic speech recognition ss speech synthesis tts text to speech st
speech translation sp speech paralinguistics sd spoken dialogue system code official code release  will be released
later
llmpaper
train data
tasks
asr
tts
st
sp
sd
others
code
speechgpt 
gigaspeech
common voice
librispeech
speechinstruct
audiopalm 
covost cvss
voxpopuli asr
common voice
conversational esen
librispeech
youtube asr
wmtted tts
palm mt tts
machine translation
audiolm 
librilight
piano continuation
speech continuation
ltu 
openaqam
audio classification
audio captioning
summarisation
viola 
wenetspeech
librilight
librispeech
ai challenger
wmt
emime
machine translation
speechx 
librilight
dns challenge corpus
noise suppression
speech removal
target speaker extraction
clean speech editing
noisy speech editing
valle 
librilight
muslam 
mc dataset
voxpopuli mls
babel covost
fleurs
machine translation
soundstorm 
librilight
audiogpt 
libritts
mustc
chime
audioset
audiocaption
and others
style transfer
speech enhancement
speech separation
monotobinaural
audio inpainting
sound extraction
imagetoaudio
singing synthesis
and others
pengi 
clotho
audiocaps
urbansoundk
tut 
cremad
fsdk
and others
audio captioning
audio question answering
sound sence classification
music analysis
instrument classification
vocal sound classification
and others
seamlessmt 
 million hours
of open speech
audio data
machine translation
speechtexttotext
translation
nextgpt 
tm
mosit
texttoimage
texttovideo
texttoimage
for instance wu et al  introduced the concept of
speechllama a technique that involves seamlessly inte
grating acoustic embeddings into a textbased large language
model to enhance translation capabilities this integration
empowers the language model to base its translation on
acoustic cues this model comprises three fundamental
elements a pretrained text neural lm an audio encoder and
a connectionist temporal classification ctc compressor
they utilise llamab  as their text neural lm due to
its flexibility the ctc compressor a pretrained component
ensures the alignment of text and speech lengths simulta
neously an audio encoder facilitates the transformation of
continuous speech vectors notably the approach bypasses
the conversion of speech into discrete tokens instead directly
mapping continuous speech representation into the lms
semantic space this tailored architecture effectively accom
table  list of audio datasets asr automatic speech
recognition st speech translation mt machine translation
ac audio classification sed sound event detection amg
affective music generation mag music analysis and gen
eration mu music understanding sc sound classification
sg symphony generation ttm text to music mt music
tagging mag music arrangement generation mgr music
genre recognition
title
application
size
multi
lingual
public
access
commonvoice  
asr
 hours
librilight 
asr
 hours
wenetspeech 
asr
 hours
gigaspeech 
asr
 hours
mustc 
asr mt
and slt
 hours
voxpopuli 
asr sst
k hours
covost 
st
 hours
cvss 
st
 hours
emime 
st
audiocaps 
ac
k audios
clotho 
ac
 audios
 captions
audio set 
sed
k hours
emopia 
amg
 piano
solo sounds
metamidi 
mca
 midi
files
dali 
mu
 songs
million midi 
mu
k songs
vggsound 
sc
k videos
fsdk 
sed
 sound
clips
symphony 
sg
 midi
files
musiccaps 
ttm
 music
text pairs
jamendo 
mt
 tracks
pop 
mag
 songs
multiple piano
arrangements
fma 
mgr
 clips
modates acoustic embeddings within textbased language
models proficiently processing both acoustic embeddings
and text cues to generate outputs that seamlessly integrate
textual and acoustic insights kubo et al  present a
strategy to tackle this challenge through knowledge transfer
from a neural network language model initially pretrained
on textonly data the core focus lies in transferring the
inherent semantic understanding embedded within large
scale language model vectors these vectors serve as implicit
representations of linguistic aspects like partofspeech and
intent holding potential as valuable cues for asr decoders
the proposed approachs effectiveness manifests in the form
of reduced error rates achieved without introducing extra
computational complexities during the decoding phase
ling et al  explore a methodology involving the
use of pretrained llm for fully formatted endtoend ee
asr transcriptions their model architecture demonstrates
flexibility in integrating a speech decoder with a pretrained
llm offering both encoderdecoder and decoderonly con
figurations drawing from a rich dataset of  hours of
diverse formatted audio data spanning multiple domains
their approach remains highly adaptable the composability
of their model allows for the seamless integration of a
speech encoder into a pretrained llm featuring either an
encoderdecoder or decoderonly structure in the encoder
decoderbased llm approach a pretrained llm is har
nessed utilising its text tokeniser for speech recognition
their training strategy encompasses three loss functions
ctc crossentropy ce and masked language modeling
mlm facilitating the acquisition of transcription knowl
edge from both textual and speechtext data in the case
of the decoderonly llm approach for speech recognition
ling et al leverage the lora adapter to integrate it with
the pretrained llm this adaptation effectively minimises
trainable parameters by updating pairs of decomposition
matrices while preserving the original weights unaltered for
the encoderdecoderbased llm the zcode model 
serves as the text encoder and decoder conversely the
decoderonly llm approach employs the gpt model 
as the decoderbased llm for performance comparison the
authors conduct thorough evaluations on a range of datasets
analysing the outcomes of five distinct models in their study
in written text meaningful sentence boundaries are often
indicated by punctuation marks however this clear demar
cation is lacking in spoken realworld utterances to tackle
this issue huang et al  devised a strategy to extract
punctuation insights from a bidirectional teacher language
model lm trained on written and punctuated text their
approach involves a comparison between their segmenter
distilled from the lm teacher and another segmenter derived
from an acousticpausebased teacher utilised in previous
research the evaluation of both segmenters took place
within a streaming asr pipeline the incorporation of their
segmenter led to a  relative reduction in word error
rate wer and a significant  ms reduction in median
endofsegment latency during a youtube captioning task
in the previous section we discussed audiopalm 
a substantial large audio models designed to encompass
both speech comprehension and generation with a unified
vocabulary bridging text and speech through a limited set of
discrete tokens and a basic markup description of tasks this
model facilitates training a single decoderonly model for
various tasks including asr evaluation efforts delved into
asr performance across multiple datasets including cvss
voxpopuli asr commonvoice  conversational esen and
youtube asr datasets the results highlight the models
competitive performance across these diverse datasets in
a different study huang  introduces strategies for
curating language modelling data to enhance the recognition
of rare words without compromising overall performance
these strategies demonstrate substantial impact leading to
an enhanced language model achieving a noteworthy up
to  relative reduction in wer for sentences containing
rare words importantly this enhancement in rare word
recognition is achieved without causing any adverse impact
on the overall wer
fathullah et al  delve into extending the practicality
of llms by directly incorporating a compact audio encoder
thus enabling them to perform speech recognition tasks
this approach for constructing multilingual speech recogni
tion systems relies on decoderonly llms conditioned on
audio sequences the underlying concept revolves around
utilising large language models to capture sequences of
embeddings irrespective of their modality by utilising
a conformerbased audio encoder to generate embedding
sequences and validating them through simple ctc loss
training this study leverages the llamab  model
with lora  adaptation the multilingual librispeech
mls dataset derived from librivox  encompassing
 hours of speech recordings in  different languages
serves as the basis for evaluation the studys observations
emphasise the alignment between audio embeddings and
text as well as the significance of audio encoder strides and
size zhuo et al  introduce lyricwhiz a multilingual
automatic lyrics transcription alt method designed
for zeroshot scenarios across diverse lyrics transcription
datasets including unique genres like rock and metal gpt
 a large language model serves as the annotator while
the whisper speech recognition model  assists in audio
transcription leveraging the mtgjamendo dataset with
 audio songs in various languages the model requires
no training and undergoes direct testing on multiple datasets
including jamendo  hansen  musdb  and
dsing  this combined approach not only transcribes
lyrics in multiple languages but also contributes to reducing
the wer in english furthermore the model generates an
extensive multilingual publicly available lyrics dataset based
on mtgjamendo offering a humanannotated subset for
noise level estimation and evaluation
table  average normalised wer comparison on fleurs
dataset for asr where n is the number of languages
model
size
wer
fleurs
n
fleurs
n
whisperlargev
b
mmsl
b
mmsl
b
seamlessmtmedium
b
seamlessmtlarge
b
in summary recent advancements in leveraging llms
or designing large audio models for speechrelated tasks
demonstrate the growing potential of combining linguistic
and acoustic insights table  provides a concise overview
of the various studies and their contributions these studies
highlight diverse strategies from incorporating audio en
coders to enhancing rareword recognition and multilingual
transcription table  compares the performance of seam
lessmt with stateoftheart asr models including whisper
and mms which shows that large audio model considerably
improves the asr performance as the field continues
to evolve these innovations underscore the capacity of
language models to bridge the gap between speech and
text opening up new avenues for more efficient and effective
solutions in speech processing and understanding
neural speech synthesis
neural speech synthesis also referred to as neural textto
speech tts is considered an important area of research
with the aim of generating humanlike speech from the
text traditional tts systems have complex architecture
by encompasses intricate components including acoustic
frontends duration models acoustic prediction models
and vocoder models this complexity of tts systems has
recently been overcome with the advent of deep endtoend
tts architectures these systems possess the capacity to
generate convincingly realistic speech by being trained on
pairs of text and audio popular tts models include tacotron
 deep voice model  and clarinet  and many
other  these models produce melspectrograms from
textual inputs which are subsequently employed for speech
synthesis by vocoders like griffinlim  wavenet 
and waveglow  lately transformers become popular
structures in tts by showing improved performance and
accelerated training 
more recently large audio models have become popular
in solving problems in tts research various studies either
utilise llms or develop large audio models to show their
effectiveness in the tts domain for example kakouros et
al  explore the concept of word surprisal as a potential
factor enhancing prosody in speech synthesis word surprisal
a linguistic and nlp concept quantifies the information
conveyed by a word within a sentence or language model
context their primary focus was investigating the interplay
between word surprisal derived from llms and their
capacity to capture prosodic prominence in both human and
synthesised speech their study employed gpt models and
gptj an opensource and openaccess alternative to gpt
 utilising the lj speech corpus as their dataset to assess
surprisal rates in the textual content the authors identified
tokens and common sequences within the text serving not
only to satisfy the models dictionary requirements but also
to reduce the models dictionary size and manage outof
vocabulary oov words hassid et al  introduced
twist an innovative approach to training speechlms that
employs a warmstart strategy with a pretrained textual
llm this method capitalises on the shared characteristics be
tween text and semantic tokens by initialising a decoderonly
audio generator with the pretrained weights of a textbased
language model through a comprehensive combination
of automated and human evaluations twist consistently
showcases superior performance compared to a coldstart
speechlm across various aspects based on the results the
authors emphasise the importance of both model and dataset
scale in enhancing the effectiveness of speechlms
wang et al  trained a neural codec language model
called valle using discrete codes obtained from a readily
available neural audio codec model they approached tts as
a conditional language modelling task differing from prior
methods that treated it as a continuous signal regression in
the pretraining phase they significantly expanded the tts
training dataset to  hours of english speech a several
hundredfold increase over existing systems experimental
results show that valle outperforms the leading zeroshot
tts system particularly in terms of speech naturalness and
speaker similarity additionally results indicate that vall
e effectively maintains emotional nuances and acoustic
characteristics from the provided acoustic prompt during
synthesis valle x introduced in  is designed for
crosslingual speech synthesis it builds upon the foundation
of valle  and is trained to predict acoustic token
sequences in the target language speech using both source
language speech and target language text as cues valle x
inherits robust incontext learning capabilities enabling its
application in zeroshot crosslingual texttospeech synthesis
and speechtospeech translation tasks experimental results
showcase its ability to generate highquality speech in the
target language using just a single speech utterance in the
source language as input this preservation of the unseen
speakers voice emotion and acoustic context is a prominent
aspect of valle xs performance
kharitonov et al  presented a multispeaker tts
speartts with two features of minimum data requirement
for training and speech synthesis maintaining voice charac
teristics of a previously unseen speaker using a second
long voice example in particular they integrate bartt
style pertaining   with back translation  to
substantially decrease the quantity of parallel supervision
necessary for training speartts to control the voice
employed by speartts during utterance generation they
utilise an illustrative prompting mechanism similar to textual
language models  they utilise librilight data as a source
of training data and show that speartts attains a character
error rate cer that is comparable with stateoftheart tech
niques by only using  minutes of parallel data moreover it
matches the naturalness and acoustic quality of groundtruth
speech as assessed through subjective tests viola 
discussed in section  is a multilingual multimodal auto
regressive transformer decoderonly network that presents
promising results in tts their findings showcase a notable
enhancement of  in speaker similarity a reduction of
 in wer and an improvement in speech naturalness
by 
maiti et al  introduced an autonomous evaluation
approach known as speechlmscore aimed at assessing
generated speech samples using speechlanguage models
this unsupervised speech evaluation metric leverages a pre
trained language model to gauge the similarity between
synthesised speech and natural human speech the authors
harnessed pretrained models from gslm  through
fairseq  and employed the voicemos challenge dataset 
which encompasses speech from diverse sources encoding
was accomplished using the pretrained tokeniser hubert
baselsh  complemented by a kmeans cluster
ing model for quantisation this combination of hubert
features and corresponding clustering models facilitated
the development of ulm within gslm with heightened
efficiency the model was exclusively trained with a dataset
eliminating the need for extensive humanevaluated data
in the context of an extensive dataset and larger model the
system was configured into four layers speechlmscore pre
speechlmscore lstm speechlmscore lstmrep and
speechlmscore large
wang et al  presented an lmbased approach named
lmvc for zeroshot voice transformation this model
draws inspiration from audiolm and hubert lmvc is
structured in two stages  coarse acoustic modelling and 
fine acoustic modelling within the lmvc architecture three
distinct lms are employed a masked prefix lm mplm an
external lm elm and a prefix lm plm leveraging the
benefits of hubert and soundstream the model capitalises
on separate sequences of semantic tokens and acoustic tokens
for training the authors utilised libritts and an internal
dataset for both their model and soundstream testing
was conducted on a selection of  pairs from emime
vctk and cmu arctic datasets the model demonstrated
efficiency in terms of the proximity of generated speech to
natural speech and its similarity with the original speaker
 httpsgithubcomfacebookresearchfairseq
wang  proposed a method to assess phrase breaks util
ising pretrained language models and llms the approach
encompasses two key components evaluating phrase breaks
within speech and conducting a comprehensive analysis of
each pause or break position bert was chosen for pre
training due to its vast training data and contextual under
standing of word relationships additionally the authors
investigated the potential of chatgpt for zeroshot and few
shot phrase break assessments the authors used lj speech
data for pretraining and curated a dataset comprising 
samples from diverse chinese esl learners categorised as
poor fair great and humanly validated they demonstrate
that the dependency of pretrained language models has
significantly decreased leading to improved performance
based on the results
table  neural speech synthesis comparison using lib
rispeech dataset
model
wer 
spk
smos
speechtospeech systems
gslm 
audiolm
tts systems
yourtts 
valle
vallecontinual
groundtruth
we cover various recent papers on large audio models
or llms for neural speech synthesis table  presents the
benchmark results on the librispeech dataset here wer is
calculated on the generated speech and speaker similarity
score spk is calculated using the speech pairs from the
same speaker in the test set human evaluation is performed
to calculate smos on  speakers on librispeech testclean
with a second enrolled recording results show that vall
e considerably outperforms other stateoftheart models
in summary speech synthesis has greatly benefited from
complementing large audio models with acousticphonetic
linguistic models as shown by the systems deployed in table
 summarise recently proposed large audio models evaluated
on speech synthesis tasks
table  summary of recent large audio models evaluated
on text to speech tts task
modelpaper
dataset
evaluations
mosp
mosq
moss
mos
megatts
vctk
  
  
  
librispeech
  
  
megatts 
librispeech
  
  
  
prompttts 
multilingual
librispeech
  
foundationtts
combined libritts
vctk and internal
  
speech translation st
speech translation st involves the conversion of spoken
speech from the source language into the target language
st systems are typically categorised into two main groups
cascaded systems and endtoend systems cascaded st
systems comprise an automatic speech recognition asr
component and a machine translation mt component in
contrast endtoend st systems aim to optimise a single
model that directly translates the spoken utterance into the
target language various studies have explored methods
and techniques to improve both cascaded st systems 
and endtoend st systems  in endtoend st systems
transformerbased models  have played a significant role
in addressing various challenges recently the use of large
audio models is becoming increasingly popular in speech
translation and showing promising results
in the landscape of recent advancements the introduction
of seamlessmt  as outlined in section   stands
out as a groundbreaking multimodal translation model
denoted as massively multilingual  multimodal machine
translation seamlessmt the scope of this model is all
encompassing spanning a multitude of translation tasks such
as speechtospeech speechtotext texttospeech textto
text and asr its capabilities extend across a wide linguistic
panorama spanning up to  languages seamlessmt
utilises the seamlessalign corpus a monumental multimodal
translation dataset totalling k hours facilitated by the
sonar sentence embedding space adept at capturing both
speech and text nuances notably seamlessmt sets a new
translation benchmark exhibiting a  bleu improvement
over prior direct speechtotext methods on the fleurs
dataset
dong et al  introduced the innovative poly voice
framework which hinges upon a versatile language model
lm proficient in speechtotranslation sst capabilities
this framework comprises two pivotal components a transla
tion language model and a speech synthesis language model
the former operates as a decoderonly model while the
latter involves discrete units the translation model further
delves into speechtounit translation sut effectively
converting audio into languagespecific units while the
speech synthesis model identified as unittospeech us
undertakes the task of generating translated speech while
preserving the original speakers style the authors use
hubert for semantic unit extraction sut while the
us component employs the valle x approach to execute
speech synthesis additionally soundstream is enlisted to
acquire embeddings of audio tokens the training process
involves multiple datasets spanning various domains encom
passing asr librilighten inhouse zh mt inhouse
and ss gigaspeech wenet speech in the evaluation phase
two established benchmarks namely emime and cvss are
utilised to gauge speech and translation quality providing
comprehensive insights into the frameworks performance
as outlined in models rubenstein et al  proposed a
multimodal generative model called audiopalm for speech
based on the foundation of palm  and palm 
the model can perform multiple tasks including speech to
speech translation sst to build palm mt tts they
employed palm for translating youtube commonvoice
and babel  consequently after the training described
earlier their model outperformed the baselines in ast
and sst building upon the previous discussion wang et
al  proposed viola a language model encompassing a
decoderonly transformer network which is multilingual
and multimodal based on an autoregressive approach
that exhibits proficiency in speechrelated tasks with the
capability of speech translation the model is based on vall
e  and valle x  an offline neural model and
encodec the training procedure of the model has been
previously outlined in the model section  as a result they
found the model achieving improvement in blue scores
the integration of speech and language training is
confronted by challenges stemming from data and gpu
requirements as well as the inherent distinctions between
spoken and textual information le et al  introduce
comsl a novel speechlanguage model formulated through
a composite architecture that harnesses the power of pre
trained speech and language models this strategy opti
mises data utilisation for tasks involving spoken language
specifically comsl incorporates crossmodality learning into
transfer learning and concurrently applies these mechanisms
within a multitask learning framework for downstream
tasks notably comsl demonstrates efficacy in endtoend
speechtotext translation assignments it achieves a remark
able new stateoftheart average bleu score of  on the
multilingual speechtoenglish text translation task across
 languages as assessed on the publicly available covost
dataset wu et al  conducted pioneering research that
explores the application of prompt tuning to enhance speech
language models for a wide array of generation tasks this
innovative approach is implemented within a unified frame
work known as speechgen characterised by its capacity
to harness around  million trainable parameters this
cohesive framework holds significant promise delivering
increased efficiency and efficacy the authors evaluated
speechgen across three speechrelated tasks including
speech translation and demonstrated promising results
in summary the landscape of speech translation is
evolving rapidly with a growing focus on bridging the
gap through innovative large audio models the studies
discussed in this section as outlined in  underscore the
progress in this field from leveraging large language models
like audiopalm to tackle multilingual speech translation
to the development of viola a versatile language model
proficient in speechrelated tasks these advancements hold
the potential to revolutionise the accuracy and naturalness
of translated speech as the demand for seamless communi
cation across languages continues to rise these models offer
a promising path forward in achieving enhanced speech
translation capabilities
spoken dialogue systems
spoken dialogue systems sdss have garnered significant
attention in the audio processing community due to their
versatile applications in customer service and goaloriented
humancomputer interactions these systems encompass key
components such as speech recognition intent recognition
a knowledge base andor database backend a dialogue
manager language generation and speech synthesis 
within the architecture of sdss the dialogue manager plays
a pivotal role in making action selections based on observed
events  researchers have effectively demonstrated how
rnns and transformers can be employed to optimise action
selection adeptly modelling the dynamic nature of spoken
dialogue using fully or partially observable markov decision
processes however transformers have recently emerged
as a superior alternative to rnns to optimise the action
selection process within sdss   by leveraging their
selfattention mechanism transformers have demonstrated
exceptional capabilities in modelling dynamic dialogue
system scenarios 
this evolution has led to numerous studies that harness
the power of transformers to enhance spoken dialogue
systems while textbased dialogue systems can be trained
directly on extensive text data   a large number
of sdss have relied on user simulations for training due
to the scarcity of real training dialogues available for both
training and evaluation purposes
 the integration
of transformers into sdss presents a promising avenue for
improving dialogue management offering the potential to
better comprehend user inputs context and pselfdn  august   budapest hungary
yaqoob et al
on analyzing selfdriving networks
a systems thinking approach
touseef yaqoob
information technology university lahore pakistan
mseeituedupk
muhammad usama
information technology university lahore pakistan
muhammadusamaituedupk
junaid qadir
information technology university lahore pakistan
junaidqadirituedupk
gareth tyson
queen mary university of london united kingdom
gtysonqmulacuk
abstract
along with recent networking advances such as softwaredefined
networks network functions virtualization and programmable
data planes the networking field in a bid to construct highly op
timized selfdriving and selforganizing networks is increasingly
embracing artificial intelligence and machine learning it is worth
remembering that the modern internet that interconnects millions
of networks is a complex adaptive social system in which interven
tions not only cause effects but the effects have further knockon
consequences not all of which are desirable or anticipated we be
lieve that selfdriving networks will likely raise new unanticipated
challenges particularly in the humanfacing domains of ethics
privacy and security in this paper we propose the use of insights
and tools from the field of systems thinkinga rich discipline
developing for more than half a century which encompasses more
realistic models of complex social systemsand highlight their rel
evance for studying the longterm effects of network architectural
interventions particularly for selfdriving networks we show that
these tools complement existing simulation and modeling tools and
provide new insights and capabilities to the best of our knowledge
this is the first study that has considered the relevance of formal
systems thinking tools for the analysis of selfdriving networks
ccs concepts
 networks network design principles network dynamics
acm reference format
touseef yaqoob muhammad usama junaid qadir and gareth tyson 
on analyzing selfdriving networks a systems thinking approach in
proceedings of acm sigcomm  afternoon workshop on selfdriving
networks budapest hungary august   selfdn   pages
httpsdoiorg
introduction
the exponential growth in the number of connected devices and
users in networks is placing significant stress on current humanin
theloop network management architectures there is now interest
permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page copyrights for components of this work owned by others than acm
must be honored abstracting with credit is permitted to copy otherwise or republish
to post on servers or to redistribute to lists requires prior specific permission andor a
fee request permissions from permissionsacmorg
selfdn  august   budapest hungary
  association for computing machinery
acm isbn 
httpsdoiorg
in equipping networks with autonomous runtime decisionmaking
capability through the incorporation of artificial intelligence ai
machine learning ml big data network analytics and network
telemetry to allow networks to configure manage and heal them
selves the idea that networks should learn to drive themselves is
gaining traction and there is a lot of interest in the networking com
munity to develop selfdriving networks  the idea itself is not
entirely new and reflects a recurring motif seen in various guises
such as cognitive networking  selforganized networks 
knowledge defined networks  and most recently datadriven
networking  and selfdriving networks  
the vision of selfdriving networks is promising and finds much
encouragement from recent advances in ml such as deep learning
and networking such as softwaredefined networks programmable
data planes and edge computing however there are many chal
lenges that remain most notably modern networks and their in
tegration into the global internet yields a complex adaptive social
system that encompasses the interaction of a vast diversity of au
tonomous devices human users applications and service providers
complex adaptive systems are characterized by their dynamic com
plexity and nonlinearity due to which the act of playing the game
has a way of changing the rules  any selfdriving network
must acknowledge and address this complexity hence the real
concern is not to only see the potential benefits of the approach to
the optimizing entity itself but to also critically understand poten
tial downsides and unintended consequences on other subsystems
in this work we seek to investigate the pros and cons of selfdriving
networks using systems thinking techniques
what is systems thinking
although many different definitions of systems thinking have been
proposed  all of them share an emphasis on interconnected
ness and interdependency they focus on understanding how vari
ous system entities influence each other and in turn themselves
through feedback loops the goal is to facilitate users in seeing
the proverbial forest for the trees  systems thinking is char
acterized by three important features firstly the ability to think
dynamically secondly to think causally through feedback loops
thirdly to think more deeply about endogenous influences where
the system itself is the cause of the observed problems  sys
tems thinking is different from conventional thinking in many ways
see table  but most prominently in modeling complex systems
nonlinear closedlooped and multicausal with delayed feedback
rather than linear openlooped causal with immediate feedback
systems thinking has made a big impact in research on complex
adaptive systems in such systems researchers have noted that
on analyzing selfdriving networks
a systems thinking approach
selfdn  august   budapest hungary
table  comparing conventional vs systems thinking details 
conventional thinking
systems thinking
model of thinking
linear causal openlooped immediate feedback
nonlinear multicausal closedlooped with delayed feedback
determining a problems cause
obvious and easy to trace
indirect and nonobvious
cause of problems
external to the system
internal systemasacause thinking
how to optimize
by optimizing the parts
by optimizing relationships among the parts
where to intervene
aggressive use of obvious solutions
careful change applied at the leverage points
how to resolve problems
cure the symptoms
fix the systemic causes
hardly anything is influenced linearly in just one direction and the
presence of multiple intertwined nonlinear feedback loops have
made social systems notorious for being counterintuitive  in
terms of selfdriving networks this implies that it is not sufficient
to optimize only a protocol an architecture or a network without
reasoning about how this will influence the other parts technical as
well as sociocultural aspects of the larger internet system systems
thinking the right tool for understanding complex adaptive social
systems since it is considered axiom in systems thinking that every
influence is both a cause and an effect   and that interactions
between subsystems are modeled by circular loops rather than
directed arrows
we can define a system as an interconnected set of elements
that is coherently organized in a way that achieves something  a
definition given by donella meadows a highly influential system
thinker and the lead author of the bestselling limits to growth
 the something in the definition may however be quite dif
ferent from what the designer intended if we find some stubborn
problems with a system that refuse to go away despite efforts and
best intentions some authors call these wicked problems  it is
likely that these problems are systemic ie the problems follow
from how the system is built and from its architectural choices
goals and constraints systems thinking opens us up to the fact
that wicked problems may not be resolvable through further in
terventions and that using more advanced technology is not always
good or neutral  thus systems thinking may be defined as
the ability to understand the systemic interconnections in such a way
as to achieve a desired purpose  for more information about
systems thinking we refer to various primers  and books
  on this topic
contributions of this paper
in this paper we aim to highlight that the internet and selfdriving
networks should be envisioned as complex adaptive systems in
which we should be wary of easy solutions and quick fixes as
pointed out by h l mencken theres always an easy solution to
every problem that is neat plausible but wrong in a similar vein
systems thinking research informs us that most wellintentioned
solutions fail to sustainably solve their addressed problems and
may actually create more problems than they solve however not
all solutions are doomed in this mannersome highleverage
solutions exist that can provide sustainable longrun benefits with
minimum effort and these can be uncovered by systems thinking
we propose the use of tools and insights from systems thinking in
selfdriving networks for managing the unintended consequences
of policies and for devising highleverage effective solutions to
the best of our knowledge this is the first proposal to use systems
thinking insights and tools for the study of selfdriving networks
and possibly also for the internet
why use systems thinking for
selfdriving networks
leveraging a rich set of theory and tools
systems thinking has been successfully used as a management tool
to study policymaking in domains such as healthcare education
management  and looks promising for selfdriving networks as
well the field of systems science is a highlydeveloped discipline
with many schools of thought including system dynamics com
plexity theory general systems theory human system dynamics
   we can leverage tools from a vast library of qualita
tive as well as quantitative tools eg visualisations domain specific
languages developed by the systems thinking community which
has been active since its genesis at mit in the s  
as an example of a qualitative system thinking tool consider
causal loop diagram cld which is an aid to visualize and easily
communicate how different system entities connect to each other
and influence each other possibly with a delay through reinforcing
positive or balancing negative feedback loops this could be
used to capture various aspects of decision making within modern
networks for instance content delivery networks cdns exert
significant influence on the traffic generated within isps by dynam
ically setting the destinations of a large fraction of flows this has
longterm impacts on isp decision making as well as transient ef
fects on relevant content producers transit providers and exchange
points it has been hypothesized that integrating the control loops
of these parties could have significant mutual benefits  self
driving networks offers a means to attain this but a vital precursor
would be formalizing the influences and dependencies between
these stakeholders clds offer a perfect tool
in contrast to clds the stock and flow diagram is a quantitative
system thinking tool for understanding systemic structure stocks
or accumulators are things that accumulate and can be measured
eg population bits transferred energy spent while flows or
rates represents things that change over time eg transmission
rate unlike clds stock and flow diagrams can provide informa
tion about rates of change due to the lack of space we limit our
discussion to these two tools only but highlight that the field has a
number of other tools details of which can be seen in  
support for rigorous big picture thinking
systems thinking also affords us the ability to see the big picture by
expanding our time and thought horizons using system thinking
tools we can take better policy decisions regarding selfdriving
networks and avoid an exclusive reliance on implicit mental mod
els which are illsuited for this task since they are simplistic since
they inadvertently substitute a higherorder nonlinear system for a
in this paper we consider systems thinking to be synonymous with system dynamics
 and to encompass it  although not everyone agrees 
selfdn  august   budapest hungary
yaqoob et al
linear causal one narrow ie not broad enough to see the big pic
ture and myopic since they tend to discount the future and focus
predominantly on the shortterm  systems thinking can also
be used to better understand the connections between the various
subsystems in particular it helps us identify nonobvious connec
tions between effects and causes and also find missing connections
which if they had existed would have improved the system perfor
mance of our selfdriving networks
finding highleverage interventions
in systems thinking systems respond to interventions according to
the principle of leverage  previous research in system dynam
ics has shown that most intuitively obvious policy interventions
in complex social systems are lowleverage ie they do not pro
duce significant longrun change and will likely also create other
problems and only a few policy interventions are highleverage
ie capable of producing substantial longrun change system
dynamics research has consistently highlighted the counterintu
itive nature of complex social systems in that the highleverage
points are not where most people expect and if even these points
are identified they are prone to be altered in the wrong direction
by people  in an influential essay on leverage  donella
meadows stated that interventions that rely only on parameter
optimization are typically low leverage and higher leverage can be
attained through deeper interventions that for example optimize
information flows eg by minimizing information sharing delays
or change the system rules ie the incentives and the constraints
the most powerful way to change a system meadows notes is to
change the system goals and paradigm out of which its goals rules
and culture emerge although these ideas are abstract we can use
insights about leverage points to unearth the few sensitive influ
ence points in selfdriving networks thereby avoiding some of the
problems that have plagued traditional networks
facilitating systemascause thinking
in systems thinking it is considered an axiom that every influence
is both a cause and an effectie it is possible that when a causes b
b also causes a through a feedback loopin such doubly looped sys
tem the systems are said to cause their own behavior endogenously
we can use the systems thinking concept of systemasacause to
explain how the perennial internet nuisances such as spam and
lack of privacy security and qos are not isolated problems but
as noted by keshav  follow endogenously as the byproducts of
the internets design pspectragan spectrum based generation of city scale
spatiotemporal mobile network traffic data
kai xu rajkarn singh marco fiore mahesh k marina hakan bilen muhammad usama
howard benn cezary ziemlicki
the university of edinburgh imdea networks institute samsung orange
abstract
cityscale spatiotemporal mobile network traffic data can support
numerous applications in and beyond networking however op
erators are very reluctant to share their data which is curbing
innovation and research reproducibility to remedy this status quo
we propose spectragan a novel deep generative model that upon
training with realworld network traffic measurements can produce
highfidelity synthetic mobile traffic data for new arbitrary sized
geographical regions over long periods to this end the model only
requires publicly available context information about the target
region such as population census data spectragan is an original
conditional gan design with the defining feature of generating
spectra of mobile traffic at all locations of the target region based on
their contextual features evaluations with mobile traffic measure
ment datasets collected by different operators in  cities across two
european countries demonstrate that spectragan can synthesize
more dependable traffic than a range of representative baselines
from the literature we also show that synthetic data generated
with spectragan yield similar results to that with real data when
used in applications like radio access network infrastructure power
savings and resource allocation or dynamic population mapping
ccs concepts
 networks mobile networks  computing methodologies
neural networks
keywords
mobile network traffic data synthetic data generation deep
generative modeling conditional gans
acm reference format
kai xu rajkarn singh marco fiore mahesh k marina hakan bilen
muhammad usama howard benn cezary ziemlicki  spectra
gan spectrum based generation of city scale spatiotemporal mobile
network traffic data in the th international conference on emerging
networking experiments and technologies conext  december 
 virtual event germany acm new york ny usa  pages https
doiorg
permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page copyrights for components of this work owned by others than acm
must be honored abstracting with credit is permitted to copy otherwise or republish
to post on servers or to redistribute to lists requires prior specific permission andor a
fee request permissions from permissionsacmorg
conext  december   virtual event germany
  association for computing machinery
acm isbn 
httpsdoiorg
introduction
datadriven analysis and optimization enable rich insights to design
efficient automated systems and to create new valueadded services
and the availability of large datasets is a key contributor to these
developments   in the networking context spatiotemporal
mobile traffic is arguably a highly valuable form of data it consists
of information about the timevarying traffic load observed at all
locations in a target geographical region a data sample is illustrated
in figure  plot a shows the time averaged spatial distribution
of mobile traffic across a city whereas plot c portrays the space
averaged temporal fluctuations of the same traffic over one week
additional time series in plot c highlight the diversity of traffic
volumes and patterns at different locations
information on cityscale mobile traffic has numerous appli
cations within and beyond networking prominent examples of
network problems that benefit from mobile traffic data include
resource management      mobile network infrastruc
ture planning  network energy efficiency optimization  
or network monitoring  beyond networking usages for spa
tiotemporal mobile traffic emerge eg in urban sensing and com
puting    inference of commuting patterns and segrega
tion     monitoring of demographic patterns  
   detection of land use and its dynamics  transporta
tion engineering and urban planning  or road traffic surveil
lance  
limited access to mobile traffic data all aforementioned ap
plications are enabled by mobile traffic data that is inherently de
personalized as shown in figure  the data is aggregated over space
eg across all users associated to a same base station or within
a same spatial area and time eg during intervals of minutes to
hours although its nature poses reduced privacy risks eg as
corroborated by the european unions general data protection
regulation spatiotemporal mobile traffic data is deemed sensitive
by network operators in terms of industrial and commercial se
crecy hence access to this data is not uniform and generally scant
in the research community and often occurs behind restrictive non
disclosure agreements ndas the result is that 𝑖 the potential
of mobile traffic data to feed innovation is curbed and 𝑖𝑖 current
research based on mobile traffic is not reproducible or verifiable
synthesis as a solution to data access motivated by the above
and to overcome the mobile traffic data access barrier we aim at
generating dependable synthetic cityscale spatiotemporal mobile
traffic data our goal is to design a model trained on a limited
amount of realworld measurement data which can then be used
to generate large amounts of highfidelity synthetic traffic from
publicly available data about arbitrary geographical regions
such a model primarily benefits researchers but also data holders
such as network operators by using the trained model researchers
conext  december   virtual event germany
kai xu et al
would be finally able to independently generate dependable mobile
traffic data to support their studies ideally this could lead to the
adoption of a reference ensemble of synthetic datasets of spatiotem
poral mobile traffic by the community ensuring the comparability
of results across works based on such type of data in addition data
holders can leverage the model to synthesize and share realistic mo
bile traffic data from their measurements with third parties without
concerns on leakage of commercially sensitive information
challenges of mobile traffic generation however meeting
the goal above entails a number of significant and unique challenges
firstly generation requires synthesizing spatiotemporal data like
that in figure  without prior knowledge of the historical traffic
in the target area it is thus a different and more complex problem
than eg mobile traffic prediction secondly ours is a controllable
generation problem the model is required to capture nontrivial
correlations between the urban context and the corresponding mo
bile traffic so as to generate traffic for a previously unseen urban
region solely based on its local contextual conditions thirdly as
cities have diverse geographical span the model should be capable
of generating traffic over arbitrary spatial dimensions fourthly
mobile traffic information must cover long time periods to be useful
in many applications therefore the model should allow generating
traffic time series of any specified and potentially long duration
without compromising dependability meeting these last two re
quirements entails capturing complex spatiotemporal dynamics
seen in realworld mobile traffic    so as to preserve eg
traffic peaks and flows across space and time that are rooted in
mobile user movements and digital usages
our contributions to attain the goal outlined above and ad
dress the associated challenges we propose spectragan a novel
generative model based on a tailored deep neural network architec
ture in essence spectragan is a conditional neural sampler with
two main components an encoder and a generator the role of the
encoder is to transform contextual information that is readily avail
able via public repositories broadly falling into three categories
ie census land use and points of interest pois so that it can be
used to control of the generation process an example of context
used by our approach is the inhabitant density from population
census portrayed in figure b for the same city of figure a
the generator receives the hidden representation of the context
produced by the encoder and outputs spatiotemporal synthetic traf
fic to this end it leverages the insight that mobile traffic at any
given location exhibits repeating variations over time as observed
in the literature    and in figure c this manifests in the
form of small number of dominant components when traffic is
viewed in the frequency domain as illustrated in figure d our
generator directly generates the significant frequency components
based on the input context then turns them into a time series via an
inverse fourier transform as shown in figure e this already well
approximates the actual traffic variations finally the generator
adds a separately produced contextdriven residual temporal signal
to model smaller fluctuations in traffic as in figure f the pro
cess above is run concurrently and independently on small spatial
patches which are then sewed together to obtain traffic data over
the whole target region spectragan is adversarially trained à la
gan the key contributions of our work are as follows
a averaged traffic map
b census context
c weekly traffic averaged over space grey and at two loca
tions with maximum blue and median red loads whose po
sition is annotated in figure a and figure b
d frequency domain representation of the mobile traffic in all
cities in our study orange spectra refer to single locations and
gray spectra to their average per city significant frequencies
are labelled along the xaxis
e
data
and
reconstruction
lines are almost overlaid
f residual signal data minus
reconstruction
figure  data for city a see  for details
 we introduce spectragan a novel conditional gan model that
leverages a frequency representation of localized traffic to gener
ate mobile traffic for any desired region and temporal duration
given the relevant contextual data  this is the first solution to
the important and hard problem of synthesizing spatiotemporal
mobile traffic from only publicly available information 
 we evaluate spectragan with multicity mobile traffic mea
surement datasets collected in two european countries  our
results not only justify the design choices for the different com
ponents of spectragan but also show its superior ability in
generating highfidelity longterm traffic for previously unseen
cities relative to representative baseline approaches 
 we further evaluate spectragan with practical use cases in
networking and beyond and show that using synthetic traffic
data generated with our model yields results comparable to those
obtained with real traffic data 
upon publication of this work we will make a synthetic spatiotem
poral mobile traffic dataset generated using spectragan available
spectragan
conext  december   virtual event germany
to the research community specifically this dataset will consist of
traffic data for five diverse sized cities in germany obtained with
context data for those cities retrieved from public sources as input
to a pretrained spectragan model
spectragan
we first formalize the problem of synthesizing cityscale spatiotem
poral mobile traffic data then outline our spectragan approach
before presenting the detailed design of its generative model
overview
we start by elaborating on the requirements and challenges that
the target model needs to meet and address
requirements and challenges
generation versus prediction note that traffic generation
task is different from traffic prediction the latter is an active re
search direction in the context of mobile traffic on its own see
eg    given a sequence of citylevel traffic data snap
shots x     x𝑇over 𝑇timesteps and the corresponding context
information c eg population pois as input training data the
goal of generation is to model the joint conditional probability
𝑝x     x𝑇 c whereas the goal of prediction is to model the con
ditional probability 𝑝x𝑡 x𝑡 c while seemingly similar the
former is relatively a much harder task as the distribution is more
complex as apparent when factorizing the joint distribution as
𝑝x     x𝑇 c  𝑝x  c𝑝x  x c    𝑝x𝑇 x     x𝑇 c
compared to 𝑝x𝑡 x𝑡 c the joint modeling requires to estimate
multiple such conditional probabilities and an extra term 𝑝x  c
which is complex as it is in other words while the prediction in
volves only estimating the local changes from 𝑡 to 𝑡 generation
demands synthesizing the first point x for a given context c and
also estimating multiple consecutive changes towards x𝑇
controllability an ideal generation method should let users
modify the output synthetic data by specifying certain properties
of the target urban region as context input such as cartography
of urbanization levels and layout of the different city infrastruc
tures such a controllable generation calls for conditional generative
models rather than just the more common freeform generation
approaches such as those based on vanilla generative adversarial
networks gans
modeling arbitrary spatial sizes in order to work with dif
ferent cities the model should be able to condition generation on
context with arbitrary spatial size this is a known nontrivial task
in machine learning as popular multilayer perceptron mlp or
convolutional neural network cnn architectures only operate on
input with fixed dimensions recent works try to tackle the problem
in a principled way   yet no ultimate solution is available
modeling temporal correlations mobile network traffic ex
hibits a consistent longterm behavior that the generated data should
faithfully reproduce learning longterm correlations is challeng
ing for recurrent neural networks rnns where gradients tend
to either vanish or explode in the long term during training 
although we mention a onestep prediction with a firstorder markov property here
the argument can be generalized to any horizon and order
figure  traffic flow illustrated the peak traffic area shown
in the red circle shifts from one region to a neighboring re
gion over a hour period
while long shortterm memory lstm  can alleviate this is
sue solving it fully via a pure recurrent model requires additional
constraints on the model resulting in a higher complexity  
modeling spatiotemporal correlations mobile network traf
fic correlations are not only spatial and temporal but also spa
tiotemporal specifically mobile network traffic features significant
activity peaks that occur at different times in different locations
these traffic flows are due to the mobility and activity of users and
are illustrated in figure  where the traffic peak shifts from one
location to another nearby within a twohour period therefore the
spatial and temporal dimensions of the generation problem cannot
be addressed in isolation but complex spatiotemporal correlations
must be fully captured
problem statement the task of conditional spatiotemporal
mobile network traffic generation is to synthesize traffic data x con
ditioned on context c formally let us consider a city 𝑚whose geo
graphical surface is tessellated according to a regular spatial grid
we term each grid element a pixel and assume that 𝑚is covered by
𝐻𝑚𝑊𝑚pixels the cityscale traffic over 𝑇timesteps denoted
as x𝑚
𝑇 x𝑚
      x𝑚
𝑇 is a dimensional tensor in r𝑇𝐻𝑚𝑊𝑚
the generation of x𝑚
𝑇is conditioned on ie controlled by the
context for that city denoted as c𝑚r𝐶𝐻𝑚𝑊𝑚 where 𝐶is the
number of different types of contextual attributes note that c𝑚is a
pure spatial context the conditional generation task is to draw
samples 
x𝑚
𝑇 for a given length of time 𝑇 from the conditional
distribution 𝑝x     x𝑇  c𝑚
although the true conditional distribution for city 𝑚is not
accessible we can leverage available data from other urban ar
eas accordingly we take a datadriven approach and design a
parametric probabilistic model with parameters 𝜃 representing
𝑝𝜃x     x𝑇
 c and fit the model on training data in par
ticular given groundtruth traffic and context data for 𝑁cities
d  x
𝑇 c     x𝑁
𝑇 c𝑁 we fit 𝜃on d by finding 𝜃that
minimizes the divergence d between data distribution 𝑝d and
model 𝑝𝜃 ie 𝜃 arg min𝜃d𝑝d 𝑝𝜃 depending on the specific
training methods different divergence criteria d can be consid
ered once trained the model can draw samples based on city 𝑚
context c𝑚to synthesize 
x𝑚
𝑇
implicit to this formulation is the assumption that the conditional
distribution 𝑝x     x𝑇 c relating spatiotemporal traffic pat
terns with context information holds across the 𝑁cities employed
the contextual attributes we consider ie census land use pois vary over timescales
of months or years which are much longer than those of traffic variations in the
order of minutes in that sense the contextual attributes in our problem setting can be
viewed as static in time
conext  december   virtual event germany
kai xu et al
for training and the target city 𝑚for which mobile traffic needs to
be generated this assumption is key to the ability of the model
to generalize to unseen cities and is common to most conditional
generation tasks eg   we verify that the assumption holds
in our mobile traffic datasets through evaluations in  also note
that the above problem and our proposed model outlined below
are general enough that they can support arbitrary units and types
of mobile network traffic these are determined by the nature of
the training data which the synthetic data inherently mimics
outline of proposed solution at a high level our proposed
solution is to represent 𝑝𝜃as a conditional neural sampler ie model
𝑝𝜃as a deep neural network specifically our conditional neural
sampler consists of two major components an encoder eg
𝜃that
processes c into a hidden representation and a generator g𝜃that
takes the output of the encoder along with a noise vector z to
output samples 
x𝑇 we follow the common approach to train
such generative models in an adversarial manner following the
framework of generative adversarial networks gans  gans
essentially provide a practical way to match the data and model
distribution as per the jensenshannon divergence  and have
been found to be empirically successful for this purpose
our proposed design of 𝑝𝜃is guided by the specific requirements
of spatiotemporal mobile traffic data generation as set out in 
specifically the neural network model we devise named spectra
gan takes the spatial context for a target city and noise as inputs
and directly outputs the frequency components of the signal rep
resenting traffic across the target city over time along with the
residual timeseries signal the rationale for this approach is best
explained by means of an example illustrated in figure  which
refers to the mobile traffic observed over one week in a represen
tative city from our dataset the temporal patterns in the mobile
network traffic in figure c stand out because of the regularity
in the underlying network usage reflecting weekdayweekend di
chotomies circadian rhythms and routines at work commuting or
other daily activities
such periodicities make a frequencydomain representation via
fourier transformation a compact yet effective way to capture
the usagedependent temporal dynamics indeed figure d which
shows the traffic timeseries data from each pixel in all cities of
our dataset in the frequency domain highlights how only a few
frequency components appear to be significant across the whole
dataset consistent with observations in prior work eg   
the effectiveness of a spectrum based design is further proven by
figure e which portrays the mean traffic reconstructed from the
 significant frequency components the overlap with the original
traffic confirms that the time variation in traffic can be well ap
proximated by considering the significant frequency components
the residual traffic in figure f shows the small part of difference
between original and generated traffic which is separately modeled
in spectragan in the time domain
in the light of these considerations a neural sampler that outputs
frequency components can be expected to be especially effective at
modeling mobile traffic dynamics moreover there are two impor
tant additional advantages with a spectrum based generation first
the approach lends itself to learning relation between context and
traffic data on a perpixel basis this allows capturing the differences
in significance of various frequency components at the pixel level
shown in orange in figure d second decomposing traffic into
periodic and nonperiodic parts and modeling the former in the
frequency domain and the latter in the temporal domain allows
overcoming the limitations of rnns mentioned earlier in 
indeed a spectrum representation naturally adds patterns with
identical periodicity in the same bin and enables a more effective
learning of traffic time series over long time periods the follow
ing subsection details the spectragan architecture while also
explaining how it addresses the other challenges from  such
as handling arbitrary spatial sizes
detailed design
input specification as directly working on data for arbi
trary city sizes poses challenges to neural network design instead
of modeling the entire city traffic map and its dynamics as a whole
our model operates on smaller sized fixed dimensional subregions
of the map which we call traffic patches for every time step specif
ically each traffic patch x has the spatial dimensions of 𝐻𝑡 𝑊𝑡
and each context patch c has the spatial dimensions of 𝐻𝑐𝑊𝑐 we
specifically choose 𝐻𝑐 𝐻𝑡and 𝑊𝑐 𝑊𝑡 as we experimentally
found that not only the context within the target patch but also that
surrounding the patch correlates with hence allows conditioning
its mobile traffic dynamics
generator as illustrated in figure a our conditional neu
ral sampler 𝑝𝜃has three components an encoder eg
𝜃 a spectrum
generator g𝑠
𝜃and a timeseries generator g𝑡
𝜃 all of which operate
at the patch level
 eg
𝜃 r𝐶𝐻𝑐𝑊𝑐r𝐶ℎ𝐻ℎ𝑊ℎis a cnn that takes the context
conditions c as input and and outputs a hidden representation
of the context h where 𝐶ℎis the number of channels and 𝐻ℎ𝑊ℎ
are height and width of each channel
 g𝑠
𝜃 r𝐶ℎ𝐻ℎ𝑊ℎ r𝑍𝐻ℎ𝑊ℎr𝐹𝐻𝑡𝑊𝑡is also a cnn that
takes h and noise z as inputs and outputs the traffic in the fre
quency domain denoted as 
y𝑠 here 𝑍is the dimension of the
noise vector z and 𝐹is the dimension of frequency components
here 
y𝑠is further passed to an inverse fourier transformation
to convert it to the time domain 
x𝑠 specifically the inverse fast
fourier transformation ifft note that ifft is differentiable
so is the overall generator making gradientbased optimization
possible
 g𝑡
𝜃 r𝐶ℎ𝐻ℎ𝑊ℎ r𝑍𝐻ℎ𝑊ℎr𝑇𝐻𝑡𝑊𝑡is a batched lstm
it takes h and z as inputs and outputs the residual traffic in the
time domain 
x𝑡
finally the outputs of two generators are summed to obtain the
generated traffic patch ie 
x  
x𝑠 
x𝑡
training following standard gan formulations  we
train the model by minimizing the jensenshannon divergence ie
𝜃 arg min𝜃js 𝑝d 𝑝𝜃 and with the aid of discriminators as in
the gan framework we denote such discriminators as r due to
their role as density ratio estimators  specifically the corre
sponding adversarial loss between the data 𝑝d x  c distribution
and the model 𝑝𝜃x  c distribution is defined as
lr
js𝑝d 𝑝𝜃  e𝑝d log rx c  e𝑝𝜃log r 
x c
spectragan
conext  december   virtual event germany
c
eg
𝜃
g𝑠
𝜃
z
hg
g𝑡
𝜃
y
x𝑡
x𝑠
x
a the conditional neural sampler 𝑝𝜃
c
er
𝜃
r𝑠
𝜃
hr
x
y
r𝑡
𝜃
y
x
b discriminators for adversarial training
figure  schematic of spectragan model architecture
where variables in are shared nodes between two figures
note that we use separate encoders in top and bottom
in our case as illustrated in figure b the adversarial training
contains one encoder er
𝜃and two discriminators r𝑠
𝜃acting on the
intermediate spectrum output 
y𝑠and r𝑡
𝜃acting on the final time
series output 
x the discriminator r𝑠
𝜃for the spectrum patch is a
mlp the discriminator r𝑡
𝜃for the time domain is a batched lstm
besides we found the addition of extra explicit loss helpful in
particular 𝐿 loss as in  we thus add a 𝐿 loss to 
y𝑠and 
x the
target of 
x is the real traffic x whereas the target of 
y𝑠is the real
masked fourier transformed traffic y𝑞 defined as
y𝑞 m𝑞y  m fftx
m  i fftx  𝑦𝑞 
where i is the elementwise indicator function is the element
wise multiplication and𝑦𝑞is the 𝑞percent quantile of fftx such
masking operation m on the target encourages the spectrum gen
erator to only attain significant components as motivated in 
denoting the data distribution in the frequency domain as 𝑝
d and
the distribution by the spectrum generator as 𝑝
𝜃 the 𝐿 loss is
l𝑞
 𝑝d 𝑝𝜃 𝑝
d 𝑝
𝜃  ec
n
ex𝑝d x e
x𝑝𝜃
x
o
 ec
n
ey𝑝
d m𝑞y e
y𝑠𝑝
𝜃 
y𝑠
o
jointly with gan components the overall loss to fit 𝜃is
l  l
r𝑡
𝜃
js 𝑝d 𝑝𝜃  l
r𝑠
𝜃
js 𝑝
d 𝑝
𝜃  𝜆l𝑞
 𝑝d 𝑝𝜃 𝑝
d 𝑝
𝜃
where 𝜆is a tuning parameter to balance the contribution of the
explicit loss and 𝑞controls the extent to which g𝑠
𝜃has direct su
pervision of significant frequencies we use 𝜆 𝑞  by
default the final loss l is then used to update the discriminator
and the generator in turn
spatiotemporal mobile traffic data generation our goal is
to generate citylevel mobile traffic data of arbitrary length 𝑇 for
a target city given its context we now fill the gap between the
patched fixedlength training and this goal
traffic maps of variable spatial sizes at each timestep we out
put a set of patches that cover the whole city map and sew them
into a complete map generating a nonoverlapping set of patches
note that we omit the time index in the notation throughout this paragraph as the
discussion refers to the procedure for a single timestep
f
f
𝑓
𝑓
𝑓
𝑓
𝑓
𝑓
𝑓
𝑓
𝑓
𝑓
figure  example of multiple approximation
to make up the city map has the downside of leaving undesirable
artifacts at the edge of each patch so we instead take a sliding win
dow approach over space to generate partially overlapping patches
for each timestep as such each pixel in the target city map for a
timestep is generated multiple times as part of different patches
the final value of a pixel is taken as the average over all values
generated for it more formally for the pixel 
x𝑖 𝑗 at location 𝑖 𝑗
that appears in a set of patches p  
x𝑝𝑃
𝑝 with 𝑃patches the
selected traffic value is
x𝑖 𝑗  
𝑃
õ
x𝑝p 
x𝑝𝑖
𝑝 𝑗
𝑝
where 𝑖
𝑝 𝑗
𝑝 is the corresponding local index of the pixel in each
patch investigation of more sophisticated methods for aggregating
different estimates for each pixel beyond the average is left for
future work note that the above averaging step in spectragan
is very different from that in kriging  the core task in kriging
is spatial interpolation ie estimating the value of a pixel from its
neighbors for which there are measurement observations in con
trast we have multiple values generated for each pixel in different
patches where it is part of
in addition it is worth emphasizing that the randomness should
be shared across spatial dimension when generating patches oth
erwise the randomness together with the averaging operation in
equation  essentially outputs the expected traffic per pixel lead
ing to oversmoothed traffic maps so we use same noise vector
which models stochasticity and also represents unobserved context
attributes across all patches for the target city
traffic patch timeseries beyond the training length we can easily
generate arbitrary length signal using g𝑡
𝜃by recurrently running a
rnn for the desired number of timesteps within each patch do
ing the same is not as straightforward for g𝑠
𝜃 which outputs fixed
length frequency components these components are essentially a
discretization of the underlying continuous frequency distribution
the latter is needed to generate time series of any given length we
therefore perform an approximation in the frequency domain in
order to generate longer time series more concretely since the
duration of the time signal obtained via ifft is linearly propor
tional to the number of frequency components 𝐹 we can act on the
latter to obtain a time series with target duration 𝑇 specifically
for a frequency vector f of length 𝐹 we first expand f to a desired
length 𝐹  𝑇   if 𝐹 is a 𝑘multiple of 𝐹 our approximation
initializes the newly expanded vector f with zeroes and then fills
every 𝑘𝑡ℎlocation in this vector using values from the old one f
scaled by 𝑘so that the total energy is 𝑘times see figure  for
an example with 𝑘  this procedure gives f with the desired
length 𝐹 and ensures the total energy is also correctly multiplied
we omit the spatial index in this paragraph as it refers to a single patch
conext  december   virtual event germany
kai xu et al
this produces an approximation of the signal in the time domain
as ifftf ifftf where fis the ground truth discretized
frequency domain representation of the targeted length see ap
pendix c for a justification such a procedure can be more involved
if 𝐹 is not a multiple of 𝐹as it would require careful smoothing
to avoid potential aliasing with total energy preservation we do
not explore a general approximation in this paper as we are mainly
interested in outputting traffic for multiple weeks
evaluation methodology
we evaluate spectragan in  using a wide range of fidelity met
rics in comparison with multiple alternative baseline approaches
that reflect the state of the art in  we also evaluate the effec
tiveness of synthetic traffic data generated with spectragan to
support diverse application use cases in the rest of this section we
elaborate on the reference datasets metrics and baselines
reference datasets
in order to assess the performance of spectragan and baselines
we employ realworld mobile traffic data measured in the networks
of operators in two european countries we also gather a variety
of contextual data for the same regions from public sources
mobile traffic data as our interest is with the generation of
synthetic traffic at urban scale we focus on  major cities and
refer to them as city acity i  cities and city city  
cities in the two countries respectively the data was collected
by the operators using passive measurement probes deployed in
their infrastructure under the control of the local data protection
officers dpos and in compliance with applicable regulations the
data was aggregated in secure servers at the operators premises
and we only had access to the depersonalized aggregates
the aggregates report the total mobile data traffic generated
by the whole subscriber base of the operators in the target cities
which accounts for around  of the mobile user population in
both countries the data have a homogeneous format across all
cities as the traffic load is represented over a regular grid tessella
tion of space with each grid element ie pixel covering   
m in all cities the data covers a continuous period of  weeks with
a temporal granularity of  minutes these settings are aligned
with those of the most popular mobile traffic dataset that is cur
rently publicly available  clearly as the target cities have a
dissimilar geographical extent the size of their grids is uneven and
spans from    to    pixels traffic volumes in each city
are expressed in bits per pixel and refers to the total uplink plus
downlink demand they are anonymized via normalization by the
pixellevel peak traffic observed in that city details on character
istics of mobile traffic datasets are presented in appendix a
context data our conditional generation model takes advantage
of contextual attributes to produce credible synthetic traffic we
gather a wide range of context data from easily accessible open
sources so that the method is applicable as widely as possible all
attributes are mapped via spatial interpolation or counting to the
regular grid tessellation employed by the mobile traffic data
census the number of inhabitants residing in each grid ele
ment as reported in the relevant national census
cont urban
high dense
industrial
traffic signals
primary roads
figure  sample
context data
table  context attributes and the
mean and standard deviation std of
their pccs with traffic across all cities
contextual attribute
mean
std
census
continuous urban
high dense urban
medium dense urban
low dense urban
verylow dense urban
isolated structures
green urban
industrialcommercial
airsea ports
leisure facilities
barren lands
sea
tourism
cafe
parking
restaurant
postpolice
traffic signals
office
public transport
shop
secondary roads
primary roads
motorways
railway stations
tram stops
land use the different utilization of the territory in each grid
element obtained from the copernicus urban atlas repository 
we only retain land uses that yield nonnearzero pearsons correla
tion coefficient pcc with respect to the mobile traffic ultimately
 land use attributes are considered as listed in table 
points of interest pois the number of landmarks of a spe
cific class within each grid element extracted from the open
streetmap osm repository  we filter out a large fraction of
insignificant poi categories using a correlation analysis with traffic
and retain  poi categories in table 
in summary we use  different context conditions a subset of
which are exemplified in figure  for one of the cities in our dataset
it is worth noting that no single attribute is strongly correlated
with the mobile traffic as shown in table  this suggests that a
naive univariate statistical model based on any attribute would not
be effective and motivates considering them together as we do in
spectragan as a final consideration we stress that additional
relevant context such as base station locations or radiofrequency
signal propagation maps is not considered since it is typically not
publicly available and difficult to access  which would impair our
intended design of relying solely on easily retrieved context
metrics
we use a combination of qualitative and quantitative metrics to
assess fidelity of spectragan relative to the baselines qualita
tive metrics allow visual inspection of the generated data to check
its unacceptability hence complementing quantitative metrics
specifically we consider three forms of qualitative assessments 𝑖
spectragan
conext  december   virtual event germany
timeaveraged city traffic maps 𝑖𝑖 timeseries of average citywide
traffic and 𝑖𝑖𝑖 traffic videos showing spatiotemporal variations
we also consider five different quantitative metrics outlined
below that cover a wide range of aspects of interest
marginal by total variation mtv this metric quantifies
how well the traffic distribution of generated data matches that of
the real data to compute it we first obtain the empirical marginal
distributions of traffic volume across all locations pixels and time
steps for both real and synthetic data then the metric is calculated
as the total variation tv distance  between the two marginal
distributions  lower the value of this metric better is the match
between real and synthetic data
ssim on average traffic ssim ssim  is a standard image
fidelity metric which compares two images as a function of their
respective mean and variance across pixels as well as covariance
between the images ssim lies between  and  closer to the latter
is desirable we use this metric to quantify the spatial fidelity of the
generated data by a model and compute it using the timeaveraged
traffic maps for real and synthetic data
autocorrelation by 𝐿 ac𝐿 this metric also considered
in previous work  is aimed at quantifying the temporal fidelity
of the synthetic data with respect to the real data we compute it
by taking the 𝐿 norm between the corresponding points of the
autocorrelations of real and synthetic timeseries data at the pixel
level lower values imply better performance as per this metric
trainsynthetictestreal tstr this metric aims to capture
the quality of generated data through the lens of a generic down
stream use case as done in previous works  we use synthesized
citywide traffic timeseries to train a linear regression model to
predict city traffic snapshot for a future timestep the performance
of the trained model is then evaluated on real data in terms of 𝑅
fréchet video distance fvd  this metric originally de
signed for video data aims at evaluating the quality of spatiotempo
ral data generation by treating cityscale mobile traffic over time
as video data we obtain embeddings of real and synthetic videos
and then compute the fréchet distance between these embeddings
 lower this distance better the quality in the video generation set
ting the embeddings are obtained via a pretrained neural network
however using a neural network in our case entails a risk to intro
duce a bias that may artificially favor our model instead we devise
a strategy tailored to our spatiotemporal mobile traffic generation
setting specifically we first spatially flatten the spatiotemporal
traffic data into a multivariate timeseries we then use a signature
transformation   to convert the multivariate timeseries into
a vector which we use as the embedding and employ vectors of
the real and synthetic traffic data to compute fvd
baselines
to evaluate spectragan we consider the following baselines that
represent the stateoftheart on mobile traffic generation as well
as generic spatial temporal and spatiotemporal data generation
fit distribution and sample fdas as later discussed in 
the current stateoftheart on mobile traffic generation essentially
involve fitting an empirical distribution to model the traffic data
using maximum likelihood estimation of parameters and then sam
ple it afterwards to generate synthetic data while previous works
focus on just the peak hour  or peak and offpeak hours 
a weekly traffic generated with fdas for city a averaged
across the city grey and at two locations with maximum
blue and median red traffic volume as per figure c
b city c
c city d
d city h
figure  qualitative results for fdas synthetic data
we fit a separate distribution to the fit the pixellevel traffic for
every hour of the day and sample from those different distributions
to generate citywide spatiotemporal mobile traffic data like in
 we find lognormal distribution best fits the data but with
different parameters across distributions as expected
pixpix from a spatial data generation perspective the pixpix
model  from the computer vision domain is a representative
prior work it uses a unet  based conditional gan architecture
for imagetoimage translation we adapt pixpix to mobile traffic
generation by conditioning it on spatial context attributes as in
spectragan note that pixpix does not have a notion of time
doppelganger  this is a stateoftheart work on con
ditional timeseries data generation and is based on an rnnbased
conditional gan architecture as doppelganger itself does not
have a spatial dimension we use an independent instance of dop
pelganger for each pixel conditioning it on the context attributes
corresponding to that pixel
convdlstm as a representative of the start of the art on
spatiotemporal data generation we use a conditional gan model
combining d convolution convd with convolutional lstm
convlstm  this combination is seen to be an effective choice
for spatiotemporal data generation in the literature   for tasks
like road traffic flows with convd capturing local spatial dynamics
and convlstm for longterm correlations to realize this model
for our mobile traffic generation task we use the same encoder as
in spectragan to transform the context data to an intermediate
representation that is then fed to the generator
in addition to the above baselines we also consider an ideal case
for reference which we refer to as data metrics for this case are
computed by comparing two distinct week periods of real data
against each other and as such is an approximation of the best
achievable values for the different quantitative metrics
evaluation results
in this section we first evaluate the fidelity and generalizability of
citywide spatiotemporal traffic data generated with spectragan
relative to baselines  then we examine the effect of design
choices underlying our approach through an ablation study
conext  december   virtual event germany
kai xu et al
overall generation quality
we first present the results considering country  dataset and
then for country  dataset note that the two datasets used are not
mixed in our evaluations rather they are explored in isolation since
they are collected by different operators in different countries
as we are concerned with cityscale spatiotemporal mobile traffic
data generation we adopt a leaveonecityout evaluation approach
essentially we choose one city as a test city each time and train
each model spectragan and baselines with traffic and associ
ated context data for the remaining cities and repeat this process
with a different test city for all cities we conduct this evaluation
separately for country  dataset with  cities and country 
dataset with  cities this not only allows us to study the relative
fidelity of different models with respect to the metrics described
in  but also lets us assess the generalization ability of different
models to synthesizing mobile traffic for unseen cities this testing
approach is also well aligned with the intended use of spectragan
to generate traffic data for new regions solely from publicly avail
able context for those regions finally it is worth recalling that the
considered cities have various sizes ranging from    to   
pixels therefore the leaveonecityout strategy allows assessing
the capability of the model to generate traffic for arbitrarily sized
areas since the dimension of the training cities and test city may
not be the same
unless otherwise specified in the following the traffic data is
generated at an hourly granularity to be consistent across all the
methods compared but we remark that spectragan is by de
sign potentially capable of generating more granular traffic data if
equivalently accurate data is available for training as we show later
in appendix b concerning the temporal duration of the synthetic
data all models are trained on week long data and then made
to generate data for weeks different from that in training data
this lets us evaluate the capability of different models to generate
data for a long period
country  we start with discussing the fidelity perfor
mance of fdas baseline recall that the fdas method relies on
sampling empirically fitted traffic data distributions at every time
step figure a shows citywide average temporal traffic pattern
generated by fdas for city a as test city data generated for two
representative pixels reflecting the maximum and median traffic
pixels in the ground truth are also shown the corresponding real
timeseries traffic pattern is shown in figure c the fdas gen
erated data fails to preserve the diurnal pattern seen in the real
data it is also unable to capture the absolute differences in traffic
volumes across different locations
we can make the same observation about spatial traffic patterns
with fdas the timeaveraged traffic maps for city c city d
and city h generated with fdas are respectively shown in fig
ures b c d which are in stark contrast to the corresponding
real traffic maps shown in figure  in the row labeled data the
seemingly random traffic timeseries and maps generated by fdas
can be attributed to the inherent limitation with this approach to
treat spatial locations and time steps independently thus unable
to capture strong correlations that exist across these dimensions
while we find that fdas can capture the overall citywide traffic
data distributions well as reflected by its mtv results not shown
table  average testing performance in country 
method
mtv 
ssim 
ac𝐿 
tstr 
fvd 
spectragan
pixpix
doppelganger
convdlstm
data
and expected given its nature the spatiotemporal data generated
is clearly unacceptable from its qualitative results so we do not
consider this method further in our evaluations the above results
with fdas also support mobile traffic data generation via machine
learning models generally and deep generative models in particular
as we do with spectragan
we now consider the quality of generated data with the rest of
the methods including spectragan starting with a visual inspec
tion of the timeaveraged traffic map results in figure  for the
same subset of cities highlighted above we observe that spectra
gan shows a good match with real data in capturing the spatial
traffic patterns pixpix captures traffic hotspot areas well but also
shows a strong blur effect highlighting that the image generation
approach is not readily applicable for the mobile traffic generation
case calling for a tailored approach for the latter setting doppel
ganger shows clear artifacts due to independently generating
traffic timeseries per pixel without regard to correlations among
nearby pixels convdlstm tends to also generate traffic where
there should be none leading to unsatisfactory spatial quality
we now switch our attention to examine the temporal aspect
of generated data with the different methods here we only high
light the generated citywide traffic timeseries results for one city
city b in figure  for a week long period spectragan yields
temporal traffic pattern that is in close alignment with the real
data for the whole period figure a while pixpix as expected
completely fails to model any temporal aspects figure b the
traffic timeseries generated with both doppelganger figure c
and convdlstm figure d exhibit deviations from real data
to different degrees we discuss the potential root causes below
table  summarizes the fidelity performance of different methods
in terms of quantitative metrics when considering each city in
country  as a test city and averaging the resulting metric values
across all test cities here we mark the best worst performing
methods for each metric with green red colors we make the
following observations spectragan yields the best performance
in almost all metrics even for tstr it is almost similar to the best
performing method convdlstm and best possible data
case these results also demonstrate the generalization ability of
spectragan to new unseen cities pixpix performs the worst
among metrics involving temporal aspects hence also in the traffic
data distribution quantified by mtv but it does well on the
spatial fidelity metric ssim which is expected
both doppelganger and convdlstm yield intermedi
ate results with doppelganger performing particularly worse in
terms of spatial fidelity ssim metric the independent pixellevel
timeseries generation approach of doppelganger also limits its
we make the full set of results including the traffic videos generated with different
methods accessible via an anonymous repository at httpsbitlyptenk
spectragan
conext  december   virtual event germany
data
spectragan
pixpix
doppelganger
convdlstm
a city c
b city d
c city h
figure  timeaveraged traffic maps all models
model
data
a spectragan
model
data
b pixpix
model
data
c doppelganger
model
data
d convdlstm
figure  mean citywide traffic timeseries for city b
ability to accurately capture traffic peak behaviors or flow phenom
ena a key spatiotemporal mobile traffic aspect this is highlighted
in figure a for city b where distribution of the hour of day when
the traffic peak occurs in the generated data with doppelganger
deviates markedly from the real data the distribution with spec
tragan on the other hand matches better the real data figure b
note the difference in yaxis scale between the two subfigures
relatively convdlstm exhibits slightly better spatial qual
ity ssim but with suboptimal temporal patterns ac𝐿 and also
poorly captures spatiotemporal correlations eg the flow phenom
ena clearer in the videos this ultimately results in its overall inter
mediate performance all of these can be attributed to its blackbox
architecture in which all computation is correlated agnostic to
the data characteristics spectragan overcomes the issues with
convdlstm through its traffic generation via spectratime
decomposition while accounting for spatiotemporal correlations
model
data
a doppelganger
model
data
b spectragan
figure  peak distributions with doppelganger fig
ure a and spectragan figure b for city b
table  average testing performance in country 
method
mtv 
ssim 
ac𝐿 
tstr 
spectragan
pixpix
doppelganger
convdlstm
data
table  importance of wider spatial contexts spectragan
is a variant that only uses pixellevel contexts
method
mtv 
ssim 
ac𝐿 
tstr 
fvd 
spectragan
spectragan
country  as a datadriven approach spectragan is ag
nostic to the target country or mobile operator to demonstrate
such a wide applicability we conduct similar leaveonecityout
evaluation experiments as above on country  table  summa
rizes the testing performance of different methods in terms of the
quantitative metrics averaged over the  cities in country  note
that we omit fvd in the table due to relatively less amount of
data in country  dataset to get a reliable embedding we also
do not include qualitative results for country  due to space con
straints the relative performance among the methods is broadly
consistent with what is observed with country  dataset spec
tragan still emerges as the most reliable model while pixpix is
the least performing one the performance of doppelganger and
convdlstm is in between as before
ablation study
here we perform ablation study on some key components of spec
tragan to justify their choice
importance of rich contexts we study the importance of using
a wider context scope to generate each traffic pixel via comparing
spectragan to a variant with only pixellevel context as is the
case naturally for doppelganger when applied to spatiotemporal
data generation table  shows the average performance in terms
of quantitative metrics for country  dataset results show that
not conditioning on a wide context worsens performance on several
of the metrics with the effect more pronounced for spatial fidelity
ssim metric overall these results confirm our choice to use a
wider context to condition spatiotemporal traffic generation
importance of spectrum generator we study the relevance of spec
trum generation by comparing three spectragan variants
 speconly without residual timeseries generator
 timeonly without spectrum generator
conext  december   virtual event germany
kai xu et al
table  importance of spectrum generator
method
mtv 
ssim 
ac𝐿 
tstr 
fvd 
spectragan
speconly
timeonly
timeonly
 timeonly timeonly with an extra minmax generator
table  shows quantitative metrics for these alternatives results
show that spectragan needs both the spectrum generator and
the residual timeseries generator in order to perform well across
all metrics especially reflected by the degraded fvd for all variants
the noticeably degraded performance of timeonly which is
essentially doppelganger with a wider context and explicit loss
in time domain in  of the  metrics highlights the benefit of our
hybrid spectratimeseries traffic generation
application use cases
to complement the previous evaluation we assess the utility of
spectragan through multiple downstream application use cases
for spatiotemporal mobile traffic specifically we employ synthetic
data generated by spectragan to feed models for 𝑖 energy
efficient micro base station bs sleeping  and 𝑖𝑖 resource
allocation in virtualized rans vrans  we also demonstrate
the benefits of spectragan beyond mobile networking via 𝑖𝑖𝑖
trafficdriven dynamic urban population tracking 
it is worth noting that problems 𝑖 𝑖𝑖 and 𝑖𝑖𝑖 above can all
be solved effectively only using spatiotemporal mobile traffic data
as shown by recent methods proposed in the literature  
 they are thus clear examples of situations where researchers
could benefit from the spectragangenerated data to evaluate
models and algorithms that build on such typically hardtoaccess
data while these three use cases cannot cover the full spectrum of
possible problems where mobile traffic data may support a technical
solution they offer a reasonable set of cases that span different
research domains and aspects of mobile network operation
datadriven micro bs sleeping
the substantial operating expense opex due to energy consump
tion at bss has led to the proposal of a number of solutions for saving
power in the ran we consider a recent approach for trafficaware
bs onoffswitching  and examine how it performs when in
formed with synthetic data generated by spectragan as opposed
to real data we assume a heterogeneous ran deployment where
each pixel of our spatial tessellation is served by a separate micro
bs whereas macro bss provide umbrella coverage to a larger area
of  grid cells micro bs provide localized high capacity at added
energy cost and are dynamically switched on and off according to
traffic fluctuations in their associated grid cell
the power needed for the operation of a bs at time 𝑡is 
𝑃𝑡  𝑁trx
𝑃  δ𝑝𝑃max𝜌𝑡 
 𝜌𝑡 
where 𝑁trx is the number of radio transceivers 𝑃 is the static
power consumption at zero traffic load δ𝑝is the scaling of power
consumption per traffic unit 𝜌𝑡 is the relative traffic load at the
considered time 𝑡 and 𝑃max is the power consumed at the maximum
traffic load the parameter values for micro and macro bss are those
table  settings of the bs power consumption model
bs type
𝑁trx
𝑃max
𝑃
δ𝑝
macro
bs type
𝑁trx
𝑃max
𝑃
δ𝑝
micro
figure  average power consumption per unit area in cities
of country  when micro bss are always active and when
a cell sleeping strategy is used based on realworld traffic or
synthetic traffic generated by spectragan
provided in the original study in table  then if 𝜌𝑡 𝜌min the
micro bs offloads its local traffic to the macro bs and goes into sleep
mode where it consumes negligible power we set 𝜌min to  as
recommended by previous works  figure  shows that a micro
bs sleeping strategy based on spectragangenerated traffic yields
equivalent energy savings as a model fed with realworld traffic
in both cases power consumption reductions due to sleeping are
in the  range with similar variations across the test cities
resource allocation in vrans
emerging vran paradigms foster the creation of edge datacenters
where central units cus execute software part of the function
alities traditionally performed by bss which are then replaced
by simpler radio units rus the rutocu association can be
adapted to the fluctuations of the traffic load at rus so as to best
use cu resources we investigate the effectiveness of the synthetic
data produced by spectragan in driving a rutocu association
model that ensures load balancing across a given set of cus 
we assume that each grid cell pixel is covered by one ru and
that all rus in a city are served by a single edge datacenter hosting
a set of cus 𝑐c the model employs a graph representation
r e of the radio network deployment where each node 𝑟r
maps to one ru and each edge 𝑒𝑟𝑟 e only exists if rus 𝑟and 𝑟
serve spatially adjacent pixels it then formulates the timevarying
rutocu deployment as the following optimization problem
min
õ
𝑒𝑟𝑟 e𝑥𝑒𝑟𝑟𝑡
subject to
 𝜖
õ
𝑟r
𝑦𝑟𝑐𝑡ℓ𝑟𝑡
 õ
𝑟r
ℓ𝑟𝑡
c
  𝜖 𝑐c
õ
𝑐c𝑦𝑟𝑐𝑡   𝑟r
𝑥𝑒𝑟𝑟𝑡 𝑦𝑟𝑐𝑡 𝑦𝑟𝑐𝑡 𝑒𝑟𝑟 e 𝑐c
𝑥𝑒𝑟𝑟𝑡 𝑦𝑟𝑐𝑡 𝑦𝑟𝑐𝑡 𝑒𝑟𝑟 e 𝑐c
the solution of the problem in  yields a partitioning of the
graph at time 𝑡into c subsets of rus each associated to one cu
as the sum of the ru traffic loads ℓ𝑟𝑡 within a same partition is
equivalent by a tolerance margin 𝜖 the rutocu association is
load balanced in addition it exhibits desirable features in terms of
spatial adjacency and comparable latency across all rus served by
the same cu  formally𝑦𝑟𝑐𝑡 are decision variables that take
a value one if ru 𝑟is associated with cu 𝑐at time 𝑡 and zero oth
erwise they constrain in  and  the variables 𝑥𝑒𝑟𝑟𝑡 which
indicate whether an edge 𝑒𝑟𝑟 is cut by the partitioning and ensure
that each ru is associated to a single cu in  the expressions in
 enforce the load balancing policy
we solve the above problem via an efficient heuristic  using
synthetic or realworld traffic for a day we then assess the quality of
spectragan
conext  december   virtual event germany
table  performance of load balancing in rutocu associations informed by synthetic data generated by spectragan com
pared against realworld data mean and standard deviation of jains fairness index on cu loads over time
cus
method
city a
city b
city c
city d
city e
city f
city g
city h
city i
spectragan
  
  
  
  
  
  
  
  
  
real data
  
  
  
  
  
  
  
  
  
spectragan
  
  
  
  
  
  
  
  
  
real data
  
  
  
  
  
  
  
  
  
spectragan
  
  
  
  
  
  
  
  
  
real data
  
  
  
  
  
  
  
  
  
associations by computing jains fairness index on the timevarying
load experienced by cus during a different day table  reports
the mean and standard deviation of the index at different times
for each city in country  and a different number of cus the
spectragangenerated traffic allows for comparable performance
relative to real data with average difference in fairness of 
dynamic urban population tracking
the tracking of population density in realtime is a key functional
ity to support adaptive urban and transport planning and mobile
networks are an effective data source for that purpose we stress
that such tracking is completely different from surveying dwelling
units as done in the population census tracking aims at follow
ing orderofminute population density variations whereas census
data only captures home locations therefore there is no direct
link between the static population data we use as a condition for
generation and the dynamic density we aim at estimating here
we consider a recent multivariate regression model for the track
ing of population presence 𝑝𝑖𝑡 at grid cell 𝑖and time 𝑡from the
mobile network traffic 𝑥𝑖𝑡 measured at 𝑖in 𝑡 formally
𝑝𝑖𝑡  e𝑘𝜆𝑖𝑡𝑘𝑥𝑖𝑡𝑘𝜆𝑖𝑡𝑘
where 𝜆𝑖𝑡 is an activity level computed as the mean number of
network events eg established data sessions per subscriber while
𝑘 𝑘 𝑘 and 𝑘 are constant model parameters we set the time
varying 𝜆𝑖𝑡 according to the empirical values in figure  of the
original paper and parametrize the constants as per table  in
that same study we generate hourly cartographies of the people
presence in all cities of country  by separately applying  to
𝑖 the synthetic traffic generated by spectragan on previously
unseen cities and 𝑖𝑖 the actual traffic recorded by the operator
in these cities we then compare the resulting dynamic population
tracking maps in terms of peak signaltonoise ratio psnr 
which is a standard metric for image fidelity table  summarizes
the results which highlight the dependability of the synthetic data
for the task at hand across all cities indeed values of psnr above
 are considered acceptable for quality loss 
figure  shows the dynamic people presence estimated at five
different times of the day by using spectragan output and orig
inal traffic a visual inspection of the plots reveals the closeness of
the population dynamics in the two cases
summary
minimum discrepancy is observed between models informed with
realworld or spectragangenerated traffic in all three use cases
above in other words evaluations of the methods based on spectra
gangenerated data are as dependable as similar assessments with
synthetic
real
a 
b 
c 
d 
e 
figure  dynamic people presence estimated at five differ
ent times of the day for a sample city city h
actual measurement data this proves our point that researchers
could use synthetic data generated by our model to demonstrate
the performance of the solutions considered in sections  in
a way that is both credible due to the similar performance just
mentioned and reproducible as synthetic data can be more easily
shared than realworld data these results pave the way for fur
ther studies considering additional application use cases towards a
complete assessment of the suitability of spectragan as a tool for
the creation of dependable reference spatiotemporal mobile traffic
datasets for the research community
discussion
as the first model of its kind spectragan has limitations that
we deem important to discuss so as to also foster further studies
towards open data synthesis for networking research
first there is no universal spatiotemporal granularity of the
mobile traffic data that is relevant and appropriate for all down
stream applications some studies have indicated that analyses
of several digital human activities are adequately supported by
data with a spatiotemporal resolution of  km  and  min
utes  which is largely satisfied in our case also many previous
works eg     have designed and evaluated solutions
based on mobile network traffic using datasets with resolutions of
   square meters in space and  minutes in time which
are comparable to granularity of real and synthetic data in our
work examples such as those above or in section  show that
spectragandata can support studies on such concrete use cases
however the suitability of spectragan data for additional applica
tions needs to be assessed case by case and remains a shortcoming
of our study and in the literature in general
a setting where the synthetic data currently generated by spec
tragan would clearly be illsuited is for studies requiring a higher
spatial or temporal resolution than that considered in this paper
this may be the case of eg network resource management tasks
that operate at fast timescales in the order of seconds in theory
conext  december   virtual event germany
kai xu et al
table  fidelity of estimated hourly population tracking maps using a model informed by synthetic data generated by spec
tragan relative to realworld data mean and standard deviation of psnr over time
method
city a
city b
city c
city d
city e
city f
city g
city h
city i
spectragan
  
  
  
  
  
  
  
  
  
spectragan could also generate synthetic data at higher spatial
and temporal resolutions which may meet more stringent require
ments such as those above however we do not presently have
groundtruth data that can be used to verify this hypothesis
as another limitation we would like to clarify that it is not the
purpose of spectragan to model the deeper causes that under
pin the spatiotemporal fluctuations of mobile network traffic such
as the activity or mobility of the users while these phenomena
obviously play a big role in determining the spatial and temporal
dynamics of mobile traffic in the network explicitly including them
in the generative process is not needed to attain our data synthesis
objective indeed the spectragan deep neural network architec
ture learns a complex function that translates static context into
realistic spatiotemporal traffic by abstracting various causal pro
cesses in a nonobservable way therefore if the explicit generation
of the underlying user activity or mobility is required our model
is not an appropriate tool
related work
network traffic modeling has received substantial attention in the
literature but largely focused on packet level traffic generation via
packet sizes interpacket arrival times number of traffic gener
ation tools exist for this purpose eg iperf  ditg  os
tinato  and such traffic generation capability is embedded in
network simulators like ns  and omnet  some of these
tools merely focus on the capability to generate arbitrary packet
level workloads with no constraint on realism eg iperf  while
others such as ditg include statistical models for packetbased
traffic generation with empirically derived parameters this ap
proach has also been applied to flowlevel traffic generation for
network intrusion detection type applications see  for a good
survey and for social network traffic generation based on session
durations intersession times etc 
our focus is on spatiotemporal mobile network traffic generation
which is an entirely different problem from the ones above closest
works from the literature to ours by domain are di francesco et al
 oliveira et al  which consider the synthesis of mobile
network traffic at macroscopic ie urban scales the approach in
di francesco et al  requires information on bs locations and
on the distribution of traffic on a peruser basis which are typically
very difficult to obtain and the latter also poses privacy concerns
even so the essence of synthetic mobile traffic generation in di
francesco et al  and also that in oliveira et al  can be
described as fitting the traffic statistics to an empirical probability
distribution and then sampling from it broadly similar to that from
earlier works in the general networking context eg vishwanath
and vahdat  we consider this approach in our evaluations
and show that it fails to capture traffic correlations in space and
time as also acknowledged in di francesco et al  unlike these
prior works our spectragan is a conditional deep generative
model that is designed to account for these correlations only needs
publicly available contextual data to generate traffic in previously
unseen urban regions and is validated extensively with realworld
mobile traffic measurement datasets
more recently lin et al  with a similar overall motivation to
ours have proposed doppelganger a conditional deep generative
model aimed at network timeseries data which relies on batched
rnn for capturing longterm temporal correlations in data as
doppelganger does not have a spatial dimension applying it our
cityscale spatiotemporal mobile network traffic data generation
leads to treating each spatial location independently as a result
doppelganger is unable to capture spatial and spatiotemporal
correlations well as we demonstrate in our evaluations
beyond the networking domain neural networks have been
extensively used for modeling spatiotemporal data existing archi
tectures focus on next frame prediction in videos by condition
ing them on an image or text sample  videotovideo synthe
sis   and texttovideo generation  inflow and outflow
crowd forecasting    or learning spatiotemporal feature
representations for prediction problems  while these meth
ods share a similar highlevel goal we target they are not well
suited for mobile network traffic generation reasons include that
such previous approaches are limited to the estimation of a few
future frames  are conditioned on previous frames  cap
ture only shortterm temporal correlations    and can
be only conditioned on nonspatial contexts such as weather or
weekdaysweekends    in contrast spectragan is de
signed to model spatiotemporal relations over long periods of time
and to condition the generated data on spatial contexts we also
show through our evaluations that a representative model from
this body of literature is not effective for our traffic generation
task highlighting the need for domain appropriate data generation
methods like spectragan
conclusions
we have presented spectragan a new conditional gan model
spectragan is the first synthetic generation method for cityscale
spatiotemporal mobile network traffic data it embeds a number of
innovative aspects including the defining approach to generate the
significant frequency components of the traffic spectrum for each
spatial location based on local contextual attributes importantly
the spectragan generation process is conditioned on context data
that is typically publicly available for a city of interest so as to fos
ter its usability we evaluate spectragan using multicity mobile
traffic datasets for two european countries augmented with con
textual data for each city our results show that spectragan not
only significantly outperforms existing approaches that could be
used for spatiotemporal data generation but is also able to generate
highfidelity longterm mobile traffic data for completely unseen
cities solely based on contextual input we also demonstrate the
efficacy of spectragan through multiple application use cases in
mobile networking and beyond
spectragan
conext  december   virtual event germany
acknowledgments
we thank the anonymous shepherd and reviewers for their helpful
comments
oj logo
 revised 
affective computing and the road to
an emotionally intelligent metaverse
farrukh pervez
 moazzam shoukat
 muhammad usama
 moid sandhu
siddique latif
 junaid qadir
college of aeronautical engineering national university of sciences  technology nust pakistan
emulationai
national university of computer and emerging sciences nuces pakistan
australian ehealth research centre aehrc csiro australia
queensland university of technology qut australia
qatar university qatar
corresponding author junaid qadir email jqadirqueduqa
abstract the metaverse is currently undergoing a profound transformation fundamentally reshaping
our perception of reality it has transcended its origins to become an expansion of human consciousness
seamlessly blending the physical and virtual worlds amidst this transformative evolution numerous
applications are striving to mould the metaverse into a digital counterpart capable of delivering immersive
humanlike experiences these applications envisage a future where users effortlessly traverse between
physical and digital dimensions taking a step forward affective computing technologies can be utilised to
identify users emotional cues and convey authentic emotions enhancing genuine meaningful and context
aware interactions in the digital world in this paper we explore how integrating emotional intelligence
can enhance the traditional metaverse birthing an emotionally intelligent metaverse eim our work
illuminates the multifaceted potential of eim across diverse sectors including healthcare education gaming
automotive customer service human resources marketing and urban metaverse cyberspace through our
examination of these sectors we uncover how infusing emotional intelligence enriches user interactions
and experiences within the metaverse nonetheless this transformative journey is riddled with challenges
and we address the obstacles hindering the realisation of eims full potential by doing so we lay the
groundwork for future research endeavours aimed at further enhancing and refining the captivating journey
into the world of eim
index terms metaverse affective computing arvr technologies artificial intelligence speech
emotion recognition emotionally intelligent metaverse
i introduction
the concept of the metaverse is a captivating vision
that combines a fully immersive and interconnected digital
realm  through the convergence of virtual reality vr
augmented reality ar and other digital technologies such
as spatial computing in an expansive ecosystem that allows
seamless transition between physical and digital domains 
the metaverse concept goes beyond the traditional boundaries
of vr forging a comprehensive virtual universe where
individuals can interact collaborate and engage with digital
environments and entities in ways that mirror aspects of
the physical world   as technology advances the
metaverse holds the potential to redefine social interactions
entertainment education commerce and more offering a
new dimension of interconnectedness and experience  
the success of metaverse technology relies heavily on
its humancentric and social dimensions considering the
fundamental role of affect and emotions in human interactions
it becomes imperative to incorporate insights and technologies
from affective computing  into the metaverse  to enable
a virtual world possessing the capability to simulate interpret
and respond to human emotions in realtime in this paper
we posit the idea of an emotionally intelligent metaverse
eim the envisaged future of traditional metaverse that
leverages affective computing technologies to recognise users
emotional cues and express realistic emotions thus fostering
genuine meaningful and contextaware interactions within
the digital realm eim offers multifaceted benefits including
but not limited to humanlike social virtual interactions en
hanced users emotional immersion personalised therapeutic
interventions adaptive emotional designs and creationbased
learning elevating the overall quality of user experience
metaverse designers use various elements like materials
lighting layouts and cultural nuances to craft virtual spaces
this work is licensed under a creative commons attribution  license for more information see httpscreativecommonsorglicensesby
volume 
this article has been accepted for publication in ieee open journal of the computer society this is the authors version which has not been fully edited and 
content may change prior to final publication citation information doi ojcs
this work is licensed under a creative commons attributionnoncommercialnoderivatives  license for more information see httpscreativecommonsorglicensesbyncnd
figure  affective computing can transform the traditional metaverse
into an emotionally intelligent metaverse
that boost social interaction learning healing and most
importantly emotional connections within such eim 
the concept of an eim holds immense potential but
introduces intricate challenges demanding thoughtful con
sideration eim can be used to support practical activities
like meditation personalised healthcare gaming content
creation emotiondriven education and refining products
with feedback as depicted in figure 
translating human emotions into the digital realm however
requires meticulous precision due to the complexity of emo
tional expressions spanning facial features vocal intonations
gestures body language and physiological responses
to capture and transmit emotional nuances accurately
avatars and digital entities require advanced algorithms that
decode realtime contextdependent cues adapting affective
computing models to accommodate this variability necessi
tates technological sophistication and deep comprehension of
the interplay between emotions and human behaviour within
the eim
this paper embarks on a thorough exploration envisioning
the creation of an eim empowered by affective computing
our primary focus centres on delineating potential features
and applications of eim illustrating how affective computing
can enhance the traditional metaverse in various ways as
demonstrated in figure  however amidst these opportuni
ties we engage in an open discussion regarding the challenges
that might hinder seamless integration these challenges en
compass intricacies in accurately translating human emotions
ethical considerations regarding privacy and data security and
the need to adapt to the everevolving emotional landscape
of the metaverse hence this paper orchestrates a scholarly
discourse navigating both the promises and complexities
involved in harnessing affective computing to propel the
metaverse towards heightened engagement and authenticity
the key contributions of this paper are appended below
 metaverse overview the paper introduces the meta
verse covering its history enabling technologies and
limitations
 exploration of eim it explores how affective com
puting transforms the metaverse with a focus on its
impact in healthcare education gaming and business
 challenges outlined the paper highlights challenges
in designing eim systems including ethical considera
tions responsible ai practices and security
 future research directions this paper also identifies
promising research avenues for advancing emotional
intelligence integration in the metaverse fostering
innovation and ethical use
numerous surveys   elucidating latest advance
ments in the metaverse have been published in the recent
years various others   focus on metaverse potential
with regards to a particular applicationarea such as healthcare
similarly existing affective computing surveys  
focus on specific aspects of emotion recognition we present
the contributions of our paper in contrast to the existing
metaverse surveys in table 
a methodology
for the literature search in our survey we curated ref
erences from wellestablished databases including ieee
xplore google scholar scopus and web of science using
search terms related to healthcare metaverse and artificial
intelligence to ensure comprehensive coverage we also
examined the bibliographies of relevant papers identifying
additional sources that extend the breadth and depth of our
discussion on affective computing within the metaverse this
layered search strategy allowed us to incorporate seminal
works and contemporary studies fostering a rich dialogue on
the evolution and future of emotionally intelligent interactions
in eim we selectively gathered papers pivotal to advancing
the conversation at the nexus of these fields ensuring that
each selected work significantly enriched our understanding of
eim after thoroughly reading each paper we made informed
decisions on whether to include or exclude it from our survey
based on its relevance alignment with our papers scope
and publication date selecting papers not earlier than 
our narrative synthesis informed by an extensive array of
academic contributions captures the historical evolution and
the anticipated forward momentum of eim presenting a
nuanced and comprehensive perspective shaped by a wealth
of academic discourse
b organisation
the paper is structured as follows section ii explores the
metaverses history and core technologies noting limitations
section iii covers affective computing in eim its impact
on user immersion and uses in healthcare education and
gaming section iv addresses eim development challenges
like performance adversarial robustness realtime processing
and privacy section v looks at future eim research directions
including methodological and ethical aspects the conclusion
volume 
this article has been accepted for publication in ieee open journal of the computer society this is the authors version which has not been fully edited and 
content may change prior to final publication citation information doi ojcs
this work is licensed under a creative commons attributionnoncommercialnoderivatives  license for more information see httpscreativecommonsorglicensesbyncnd
oj logo
table  comparison of our paper with existing papers
research paper
year
metaverse
emotionally intelligent metaverse
history
enabling
technologies
limitations
literature
review
features
applications
challenges
future
directions
lee et al 
sun et al 
wang et al 
ning et al 
coutinho et al 
very limited
very few
this work
detailed
comprehensive
table  organisation of this paper
sections
subsections
i introduction
ia methodology
ib organisation
ii background of metaverse
history enabling
technologies and limitations
iia the timeline of metaverse
iib metaverses enabling technologies
iic limitations
iii affective computing
for eim
iiia authentic humanai interaction
iiib enhanced user immersion
iiic emotionaware resource dimensioning
iiid meditation and adaptive
health surgeries
iiie personalised gameplay and content
iiif emotiondriven virtual education
iiig product refinement and feedback
iiih impact and practicality of eim in
diverse industries
iv challenges in developing
eim
iva performance considerations of emotion
recognition
ivb securing eim against
adversarial attacks
ivc privacy and security considerations
in eim
ivd addressing the uncanny valley
phenomenon in eim
ive modelling dynamic and evolving
emotional states in eim
ivf challenges of realtime emotion
processing in eim
v future prospects for eim
research
va foundational models and eim
vb cultural and contextual sensitivity in
eim using deep reinforcement learning
vc improving transparency and
explainability in eim
vd ethical and social considerations in
developing applications for eim
vi conclusions
summarises key findings and their significance for eims
future the papers structure is summarised in table  for
reference
ii background of metaverse history enabling
technologies and limitations
the metaverse combines meta beyond and verse
universe to describe a threedimensional spacetime internet
it aims to create a virtual world parallel to the real one
with its own societal and economic systems the metaverses
evolution technological underpinnings and challenges have
been extensively discussed in research   next we
outline its historical progress key technologies and inherent
constraints
a a timeline of metaverse
the metaverse has evolved notably since the introduction
of the first headmounted vr and ar displays in the s
nasas utilisation of vr for astronaut training followed
by ars application in theatre by  demonstrates these
technologies versatile use cases the term metaverse was
table  the timeline of the emergence of arvr technologies and the
metaverse  
year
event
first vr headmounted display
first headmounted ar display
nasa used vr simulator to train astronauts
a nasa engineer developed a vr system that lets you
pilot a mars rover
snow crash the first novel to introduce the metaverse
and avatar
vr in the gaming sector
ar used in theatre and entertainment
artoolkit an opensource computer tracking library for
creating strong ar applications
second life d personalised virtual space
roblox a rudimentary form of the metaverse
google brings its maps service with streetlevel degree
images
ar emerged in print media
emergence of unique cryptographic tokens nft
wearable ar technology google glass
ar headset microsoft hololens
ar applications in retail
two standalone vr systems oculus go and oculus quest
that need no computer or phone to work
the critical point of virtual social
the birth of metaverse
popularised by neil stephensons  novel snow crash
 gaming applications of vr began in  and by
 roblox introduced an early version of the metaverse
integrating usergenerated content googles vrsupported
street view in  and the emergence of nfts in 
marked significant milestones in virtual technologies the
covid pandemics influence expedited the transition
towards virtual social interaction boosting the metaverses
development as outlined in table 
in  robloxs public offering and googles starline
project underscored the growing focus on metaverse technolo
gies facebooks rebranding to meta signified its commitment
to developing a metaverse ecosystem microsofts mesh
for teams and nvidias omniverse platform reflected the
corporate worlds increasing investment in the metaverse
disneys venture into the metaverse with its ip imagery and
microsofts acquisition of activision blizzard in january 
for  billion have both been pivotal to the metaverses
rapid progression  these developments illustrate a
sustained trend towards immersive digital environments
supported by advanced technology
b metaverses enabling technologies
the metaverse characterised by spatiotemporal extensibil
ity virtualreal interaction and humancomputer symbiosis
leverages advanced technologies for its existence and growth
volume 
this article has been accepted for publication in ieee open journal of the computer society this is the authors version which has not been fully edited and 
content may change prior to final publication citation information doi ojcs
this work is licensed under a creative commons attributionnoncommercialnoderivatives  license for more information see httpscreativecommonsorglicensesbyncnd
figure  metaverse enabling technologies
as shown in figure  spatiotemporal extensibility allows it
to extend beyond physical limitations offering endless virtual
dimensions while the virtualreal interaction integrates digital
and physical realities humancomputer symbiosis in the
metaverse indicates a cooperative relationship transcending
traditional internet capabilities   
 ai plays a critical role with ml nlp and computer
vision driving content diversity and enhancing user
interaction within the metaverse
 telecommunications enable realtime virtualphysical
synchronicity the advent of g and the anticipated
transition to g is key to minimizing latency in the
metaverse 
 xr comprising ar vr and mr serves as a pillar
for the metaverse merging the physical and virtual
through varied immersive experiences 
 blockchain a part of decentralised ledger technologies
ensures secure decentralised metaverse transactions
fundamental to its widespread adoption and functional
ity 
 digital twins provide digital replicas of physical enti
ties underpinned by distributed computing and ledger
technologies enabling realtime authentic metaverse
interactions  
 distributed computing along with cloud and edge
computing optimises data processing for the metaverse
essential for delivering a realtime experience 
c limitations
despite its potential the metaverse encounters challenges
in emulating the complex dynamics of human communication
that are intrinsic to the physical world  avatars and virtual
characters the metaverses inhabitants are often limited in
their capacity to interpret and react to human emotions
social cues and the subtleties of context  as a result
metaverse interactions can lack the depth authenticity and
richness that characterise facetoface encounters leading
to experiences that may feel superficial and disconnected
when users engage in the metaverse for specific activities
like business negotiations or personal conversations the
virtual entities insufficient emotional intelligence can lead
to inaccurate perceptions of the users emotional states this
could prevent avatars from providing empathetic responses
to emotions like joy or sadness frustration or anger making
interactions within the metaverse less compelling authentic
and satisfying
the traditional metaverse is constrained by several limita
tions particularly in terms of personalisation options as
identified in  these constraints inhibit the systems
ability to tailor experiences to individual user needs leading
to possible frustration and diminished engagement this is
of significant concern in domains such as healthcare and
mental health therapy where customisation is vital table 
delineates these limitations in contrast to the capabilities of
eim in virtual environments fostering meaningful human
interactions which are fundamental depends on the ability to
establish deep emotional connections which is a challenging
task without emotional intelligence traditional metaverses
limited by poor content moderation and marketing from
lacking emotional intelligence face negative impacts on user
experience and revenue this issue also perpetuates problems
like hate speech and cyberbullying further damaging user
experience and platform standing to overcome these hurdles
incorporating emotional intelligence into the metaverse and
creating an eim is imperative the following section delves
into how affective computing can revolutionise the metaverse
addressing the aforementioned limitations to realise the full
potential of the metaverse
iii affective computing for eim
affective computing an interdisciplinary field focuses
on understanding and utilizing human emotions it inte
grates engineering psychology education cognitive science
and sociology to explore how technology can enhance
our comprehension of emotions this field examines the
complex relationship between emotions humantechnology
interactions and system design for leveraging affective states
it provides numerous solutions to challenges in the traditional
metaverse aiding the shift to an emotionally intelligent
metaverse eim the key emotional indicators that eim
systems aim to interpret include facial expressions  body
language  and voice tones  etc that are captured via
advanced metaverse technologies and further processed by
sophisticated ai algorithms
eim is defined as a novel iteration of the metaverse that
integrates affective computing distinguishing itself from
volume 
this article has been accepted for publication in ieee open journal of the computer society this is the authors version which has not been fully edited and 
content may change prior to final publication citation information doi ojcs
this work is licensed under a creative commons attributionnoncommercialnoderivatives  license for more information see httpscreativecommonsorglicensesbyncnd
oj logo
table  comparison of feature limitations in the traditional metaverse versus enhancements in eim
features
traditional
metaverse
eim
adaptive interaction to user emotions
x
dynamic emotionaware content personalization
x
advanced emotional communication tools
x
personalized user experience based on emotional data
x
emotionally responsive healthcare solutions
x
learning modules tailored to emotional and psychological state
x
deep emotional data analysis and insights
x
enhanced privacy measures for sensitive emotional data
x
affective humanai interaction
x
figure  presenting the eim framework showcasing the incorporation of emotional intelligence into the traditional metaverse the conventional
metaverse applications are depicted in shades of pink while the eim applications are represented in blue users affective states are incorporated in
traditional metaverse through sophisticated stateoftheart metaverse technologies as presented in table  this integration of the traditional metaverse and
affective computing unlocks a broad range of possibilities enriching interactions and immersing users in the eim experience
table  features of emotionally intelligent metaverse
feature
description
 ieeeacm international conference on advances in social networks analysis and mining asonam
a first look at cqvid messages on whatsapp
in pakistan
r tallal javed mirza elaaf shuja muhammad usama junaid qadir waleed iqbalt gareth tysonl  ignacio
castrotand kiran garirnellai
inforrnation technology university punjab pakistan
tqueen mary university of london
lmit
email tallaljavedmsdsmuhammadusamajunaidqadirituedupk iwiqbal gtyson
icastroqmulacuk arimellmitedu
abstractthe
worldwide
spread
of
covid
has
prompted extensive online discussions creating an infodemic
on social media platforms such as whatsapp and twitter
however the information shared on these platforms is prone
to be unreliable andor misleading in this paper we present
the first analysis of covid discourse on public whatsapp
groups from pakistan building on a large scale annotation of
thousands of messages containing text and images we identify
the main categories of discussion we focus on covid
messages and understand the different types of imagestext
messages being propagated by exploring user behavior related
to covid messages we inspect how misinformation is spread
finally by quantifying the flow of information across what
sapp and twitter we show how information spreads across
platforms and how whatsapp acts as a source for much of
the information shared on twitter
keywordscovid misinformation whatsapp twitter
i
introduction
social media apps like facebook whatsapp and twitter
have changed the way we communicate the information
disseminated through these apps has influenced our social
and cultural norms in an unprecedented way whatsapp is
one of the most frequently used and rapidly growing social
media apps in the world with more than  billion users
whatsapp is also ranked  for the average number of active
users in the world per month 
whatsapp has therefore become important for under
standing social behavior and opinion formation in many
cases the scope of the information shared in whatsapp
groups is limited to a community or a country  recent
studies  have shown that whatsapp like other social
media platforms is also used for the dissemination of
misinformation we argue that it is important to under
stand how this false information either spread knowingly
disinforrnation or naively misinformation influences
opinion formation in different societies this is particularly
important in the global south where despite users having
low digital literacy whatsapp is the de facto mode through
which users obtain and share information 
with this in mind we perform a comprehensive analysis
of covid messages being propagated through whatsapp
in pakistan pakistan is a major developing country with
approximately  million active social media users build
httpsdatareportalcomlreportsdigitalpakistan
ieeelacm asonam  december  
   ieee
ing on the idea of how political parties around the world 
are using public whatsapp groups to reach their audience
we start by monitoring a large sample of public whatsapp
groups related to politics in pakistan meanwhile a major
world event occurred on march   the world health
organization who declared covid a pandemic 
our data also holds unique value as it encompasses non
covid groups and gives us insight into how covid related
content organically gets propagated across public what
sapp groups specifically we explore the following research
questions
rql what kinds of messages about the pandemic are being
shared on the publicly accessible whatsapp groups of
pakistan
rq is there misinformation related to covid and if
so to what extent and of which type
rq what is the general user behavior and can we detect
disinformation from it
rq what is the interplay between misinformation related
to covid shared on whatsapp and twitter
to explore these questions we have collected data from
 public whatsapp groups starting january  
to the best of our knowledge this is the first dataset and
analysis of covid related conversations from a country
in the global south involving multiple modalities text and
images and multiple platforms whatsapp and twitter
we begin our investigation by analyzing the content shared
in the whatsapp groups and filtering out the covid
related content the filtered content is then further divided
into text images videos and other related categories
using this data we make the following contributions
 we offer the first whatsapp dataset consisting of
discussions related to covid from pakistan the
dataset includes texts images and videos originating
from  groups the anonymized dataset will be
made publicly available to the community
 we show using
extensive
manual
annotation that
around  of the messages related to covid had
misinformation about the pandemic
 we perform a temporal analysis of misinformation
related to covid propagation across whatsapp
and twitter exploring how content is copied across
in this study we focus on text and images leaving video analysis for
future work
 ieeeacm international conference on advances in social networks analysis and mining asonam    ieee  doi asonam
 ieee  this article is free to access and download along with rights for full text and data mining reuse and analysis
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ii related w ork
a misnjormation on vhatsapp
wh atsapp has been a source of major political misinfor
mation and propaganda campaigns   political parties
have invested heavily in social media strategies by creating
whatsapp groups to reach whatsapp users  surveys
done in india and brazil show that at least one m six users
are part of one such public political whatsapp group 
garimella et al   provide tools to collect and an
alyze public whatsapp group data at scale making use
of these tools various studies have shown the extent of
misinformation and manipulation on whatsapp i i 
  particularly resende et al  analyze doctored
images to fuel smear campaigns against political rivals
and the dissemination of misinformation through whatsapp
groups in brazil garim ella et al  provide an analysis
of imagebased misinformation spread during the 
indian elections and show that over  of the images
contained misinform ation melo et al  provide a system
for gathering analyzing and visualizing whatsapp public
group data for identification of misinformation propagated
in three countries india brazil and indonesia maros et
al  analyze audio messages shared on whatsapp and
char acterize their propagation dynamics the analysis is
performed on k audio messages from  whatsapp
publi c groups and the results suggest that the audio messages
with misinformation spread further more than the bemgn or
unchecked audio messages
b health misnjo rmation
a major focus of this paper is understanding the spread
of health misinformation related to covid whatsapp
has been a major source of health misinformation especially
during the pandemic   this misinformation ranges from
highlighting wrong symptoms to ineffective treatm ents  in
et al  reported a massive wave of misinformation
on social media especially on twitter during the ebola
pandemic in africa more
comprehensie
detai s
n ho
fake news about ebola on social media applications
is
explored in 
with the ongoing surge in the covid pandemic a
wealth of misinformati on has already been documented
sharma et al  provide a dashboard for analyzing
misinformation about covid  on twitter they analyze
 million tweets and provide a countrywise sentiment
analysis of how people are reacting to covid singh
et al  analyze twitterbased
misinformation about
covid and provide insights on how the propagation
of misinformation on social media is connected to the rise
in the number of covid positive cases kouzy et al
 analyze twitterbased misinform ation about covid
 and report that tweets having the keyword covid
 contains less misinformation and tweets with keywords
ncov and corona cinelli et al  provide a
comprehensive analysis of the use of different social media
platforms in the covid pandemic they analyze twitter
instagram youtube reddit and gab providing a review
of how the discou rse on these applications is evolving
they also explore the propagation of misinformation from
different questionable sources in social media
c our vorks novelty
to the best of our knowledge there does not exist any
work analyzing covid related discussions on wh atsapp
since whatsapp is arguably the most frequently used ap
plication in the world it is important to study it to see
how people are using the platform during the pandemic
and how the platform facilitates the spread of covid
 misinformation although prior work has focused on
misinformation spread via whatsapp in brazil and india
we are the first one to study misinformation on wh atsapp
during
a major pandemic
furthermore our analysis is
focused on pakistan which has a thriving muslim relig ious
identity which allows us to see how religion plays a role
in the context of public health in contrast to the majority
of prior work on misinformation which focuses on textual
analysis we also provide a detailed analysis of images
related to covid and study the information spread
across whatsapp and twitter both for text messages as well
as images
iii methodology
in this section we delineate our data collection  anno
tation methodology and discuss the related ethical issues
a daza collection
whatsapp allows its users to create public and private
groups the public groups can be joined by any user of
the platform typically through an invite url of the form
chatwhatsappcom  these urls are frequently shared via
other social web platforms eg facebook twitter to invite
third parties to join
selection of groups to compi le a list of relevant public
groups we looked for chatwhatsappcom links on facebook
and google to find group invite urls we specifically
targeted the popular political parties of pakistan as these
groups tend to be more active and give an idea of the
political sphere hence whatsapp along with political
parties names and slogans were used to search for public
groups 
based on the above parameters we compiled a list of
 public wh atsapp groups in order to ensure the quality
of groups we manually discarded groups that were ume
lated for instance if a groups profile picture group name
or bio did not contain any relevant information political
aimsmotivations then it was removed we further removed
groups which were buying and selling thins  and did not
have any organic interactionsmessages this left us w
ith
 public groups on which the analysis was done 
in order to find these groups a set of queries search
engines and filters were used these queries can be found
at httpsllcuttlyyxhxbd we also plan to release our
anonymised dataset once the paper is accepted to encourage
further research on wh atsapp data from pakistan
whatsapp data collection to join and get data from the
groups we used tools provided by garimella et al  
which uses the selenium web driver to automate the jommg
of the groups whatsapp stores all message data on the
users device in an encrypted sqlite database we used
a rooted android device to obtain the decryption key and
for brevity we refer to covid simply as covid and use these
terms interchangably
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
and extracted the decrypted database every week the media
content which is stored as encrypted urls was downloaded
locally and decrypted using a public tool slightly modified
for our convenience whatsapp deletes media content from
their servers after a certain amount of time as a result
when decrypting media files we missed a small subset of
the content shared  the joining of the groups took
place over a  month period as new groups were being
identified the data collection started from  january 
onward and continued until  february  we have
complete data from all groups from the end of february
until the second week of april the details of the dataset
are summarized in table 
table i overview of our whatsapp dataset
liroups
u
adrrnns
sers
ruque users
m
otal messages
uu
 ext messages
 mages
video
u
au io
lthers
uk s
twitter data to compare the data we obtained from the
whatsapp groups to other open well studied social media
platforms
we also gathered data from twitter specifi
cally we obtained historical twitter data on an extensive
list of hashtags specific to covid in pakistan such
as covidpakistan coronafreepakistan and other local
twitter trend variations this gave us  tweets
ethics note
the groups joined had been openly propa
gated on facebook twitter and other mediums and can
be joined by anyone the profile bio of our whatsapp
account declares that we are collecting information for
research purposes we also anonymized the user data before
analyzing it
b identifying covid text messages
we extract covid related text messages using a
keywordfiltering approach we utilize  which offers
a dictionary of covid english keywords we added
small variations and multiple spellings to the dictionary to
capture a wide variety of content related to the pandemic
we translated these keywords into urdu and used both
the english and urdu keywords to search our dataset the
final list includes keywords such as corona coronavirus
covidiv covid covidlv and corona virus among
others this keyword based approach results in a high
precision yet low recall method to identify covid related
messages using this approach we obtained  covid
related text messages between march   and april
  figure  compares the number of daily covid
 related and noncovid related text messages in our
dataset
hu
psgithubcomddzwhatsappmediadecrypt
httpscutt
ynyxrvyp
figure  covid vs noncovid texts timeline of num
ber of messages and messages containing covid related
keywords in our whatsapp dataset
c identifying covid images
as we see in table i around  of the content is
images hence solely evaluating text would give a distorted
view of the overall information landscape naturally image
content is far harder to automatically categorize therefore
to extract images discussing covid manual tagging was
performed
two armotators tagged a total of  images ranging
from  march to  april  an image was declared as
covid related if it had any of the following attributes
 contained coronavirus covid or any other re
lated terminology in urdu or english
 information relating to a lockdown or any restrictions
being imposedrelaxed by the government on business
or publicprivate institutions
 sharing of any precautionary measures like prayers
for protection from disease herbal medications etc
 contained any blackbox adversarial machine learning attack on
network trafﬁc classiﬁcation
muhammad usama adnan qayyum junaid qadir ala alfuqaha
information technology university punjab pakistan
hamad bin khalifa university doha qatar
email muhammadusama adnanqayyum junaidqadirituedupk aalfuqahahbkueduqa
abstractdeep machine learning techniques have shown
promising results in network trafﬁc classiﬁcation however the
robustness of these techniques under adversarial threats is still
in question deep machine learning models are found vulnerable
to small carefully crafted adversarial perturbations posing a
major question on the performance of deep machine learning
techniques in this paper we propose a blackbox adversarial
attack on network trafﬁc classiﬁcation the proposed attack
successfully evades deep machine learningbased classiﬁers which
highlights the potential security threat of using deep machine
learning techniques to realize autonomous networks
index termsadversarial machine learning blackbox adver
sarial attack network trafﬁc classiﬁcation
i introduction
network trafﬁc classiﬁcation is an important task in network
engineering it provides a method for monitoring understand
ing and quantifying network trafﬁc with the emergence of
g internet of things iot and other related technologies
network trafﬁc volume is expected to grow up to  zettabyte
zb per year or  gigabyte gb per capita per month
by   with this exponential growth in network trafﬁc
volume and inception of many datahungry communication
applications network trafﬁc classiﬁcation becomes a very
challenging problem for users and service providers classical
network trafﬁc classiﬁcation techniques are based on port and
payload inspection but these schemes have their shortcomings
in terms of dealing with a large amount of data and different
types of network trafﬁc
recent advances in machine learning ml such as deep
learning dl techniques have produced exceptional results
in many application domains including computer vision
natural language processing speech recognition and system
control dl is a branch of mltechniques where a hierarchical
structure of neural network layers is used to autonomously
learn the features and then those learned features are used
for classiﬁcation or prediction the success of mldl in
multiple application domains has motivated the networking
community to explore the potential beneﬁts of these techniques
for building an autonomous control for improving the per
formance of networking applications such as network trafﬁc
classiﬁcation anomaly and intrusion detection in the last few
years many mldl based networking solutions have been
proposed highlighting the applications and challenges of using
ml techniques in the networking domain    
recently mldl techniques were found to be vulnerable
to carefully crafted perturbations in the test examples these
examples are known as adversarial ml examples adversarial
examples force the mldl algorithm to malfunction and
produce incorrect results dl schemes especially deep neural
networks dnn are function approximators that have an
associated generalization error which makes them vulnerable
to adversarial ml attacks adversarial ml attacks can be
divided into two broader categories based on the adversarys
knowledge namely whitebox adversarial attacks ie per
fect knowledge and blackbox adversarial attacks ie real
world settings
in this paper we take network trafﬁc classiﬁcation as a
functional proxy for mldl based autonomous networking
applications and propose a blackbox adversarial ml attack on
network trafﬁc classiﬁcation although the focus of our paper
is on network trafﬁc classiﬁcation our ﬁndings are broadly
applicable to similar settings that involve other applications of
mldl to realize autonomous networks the purpose of our
proposed attack is to compromise the integrity of network traf
ﬁc classiﬁcation to shed light on the risks involved in utilizing
mldl techniques in support of networking applications
our results indicate that the current state of the art mldl
based network trafﬁc classiﬁcation algorithms do not pro
vide substantial deterrence against adversarial ml attacks
our experiments utilize the highly cited tornontor dataset
provided by habibi et al  to perform the proposed black
box adversarial ml attack on tornontor trafﬁc classiﬁer to
demonstrate that using current mldl techniques to realize
autonomous networks can be a potential security risk
contributions the contributions of this work are twofold
 propose and validate a blackbox adversarial ml attack
on network trafﬁc classiﬁcation tornontor classiﬁca
tion
 to the best of our knowledge this is the ﬁrst blackbox
adversarial ml attack on network trafﬁc classiﬁcation to
highlight that network trafﬁc classiﬁers utilizing mldl
techniques are very vulnerable to adversarial ml attacks
the rest of the paper is organized as follows in the next
section we review related research that focuses on network
trafﬁc classiﬁcation speciﬁcally tor nontor classiﬁcation
and adversarial attacks on networking applications section
iii describes our research methodology particularly with
reference to the dataset the mldl model threat model as
sumptions and blackbox attack procedure in section iv we
present our performance evaluations and discuss the outcomes
of out experiments finally section v concludes our study
  ieee
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
and provides directions for future research extensions
ii related work
a tor trafﬁc classiﬁcation
tor  is a low latency anonymity preserving system that is
based on overlay network that anonymizes the trafﬁc of tcp
based applications it is also known as onion routing tech
nique for trafﬁc anonymization in tor messages are encrypted
and transmitted through distributed onion routers where each
router uses a symmetric key to decrypt the messages and learn
the routing details ie next onion router the same process
goes on in each router and this process obscures the actual
transmitter from the users perspective tor provides security
and privacy whereas from service providers perspective
detection and classiﬁcation of the tor trafﬁc becomes a very
difﬁcult challenge 
tor trafﬁc classiﬁcation is a key component of networking
architecture it is expected and experimentally validated that
deep ml techniques outperform classical tor trafﬁc classi
ﬁcation algorithms alsabah et al  used a decision tree
bayesian networks and naive bayes techniques for classifying
tor network trafﬁc into two classes namely interactive trafﬁc
eg browsing and bulk trafﬁc eg torrent downloading
the purpose of their classiﬁcation was to improve the quality
of service qos of the tor network in their twoway classi
ﬁcation experiments they managed to achieve  accuracy
and  improvement in tor responsiveness ling et al
 proposed torward a malware detection and classiﬁcation
technique for tor trafﬁc which improves the tor performance
he et al  described a hidden markov model based on tor
trafﬁc classiﬁcation schemes their presented model classiﬁes
the tor trafﬁc into four categories namely pp ftp im and
web with  accuracy
unsupervised ml learning schemes such as gravitational
clustering have been used for tor trafﬁc classiﬁcation and
the results were compared with classic clustering schemes in
 hodo et al  used artiﬁcial neural networks anns
and support vector machines svms for binary classiﬁcation
of the tornontor dataset and demonstrated  accuracy
habibi et al  used decision trees knn and random forest
techniques to perform binary classiﬁcation on the tornontor
dataset pescape et al  proposed a trafﬁc classiﬁcation
technique using multinomial naive bayes and random forest
techniques
b adversarial ml attacks
since adversarial ml attacks have not yet been thoroughly
explored in the networking domain we ﬁrst review their
applications and effects in other domains deep ml tech
niques especially dnns were demonstrated to produce the
best classiﬁcation results in many application domains but
they also learn counterintuitive and uninterpretable properties
due to discontinuity in the learning process and generalization
error  these counterintuitive properties can be exploited
to form adversarial attacks that deteriorate the performance of
dnn based classiﬁers
goodfellow et al  proposed an adversarial perturbation
generation method to fool dnn based classiﬁers called fast
gradient sign method fgsm in fgsm an adversarial
perturbation is calculated by computing the gradient of the cost
function with respect to the input itself an extension of fgsm
is proposed in  where fgsm was iteratively applied with a
smaller step size to fool the dnn this method is known as the
basic iterative method papernot et al  proposed a forward
derivative based approach for crafting adversarial perturbations
known as jacobian saliency map based attack jsma carlini
et al  proposed three adversarial perturbation crafting
methods for evading robust ml classiﬁers by exploiting three
different distance matrices l l and l moosavi et
al  proposed deepfool to evade ml classiﬁers where
adversarial perturbations were generated through the iterative
linearization of the classiﬁer transferability of adversarial
ml examples such as logistic regression and svm has been
studied in  where it is highlighted that svm is less
prone to adversarial perturbation due to its training speciﬁcity
and decision boundary learning process more details about
adversarial ml attacks are described in   
adversarial attacks on network trafﬁc classiﬁcation have not
yet been covered duly in literature we will cover some general
networking applications where basic adversarial ml research
has been conducted in our previous work we have used
fgsm bim and jsma based attacks to highlight the vulnera
bility of using ml in cognitive selforganizing networks under
whitebox settings ie the adversary knows details about
training data training process and model architecture 
corona et al  highlighted challenges an research opportu
nities of adversarial attacks for network intrusion detection
grosse et al  used the jsma attack to evade malware
classiﬁcation generative adversarial networks ganbased
blackbox adversarial ml attacks on malware classiﬁcation
are presented in  where the condition of preserving the
functional behavior was not ensured in this paper we propose
an adversarial ml attack on network trafﬁc classiﬁcation
considering blackbox settings ie the adversary does not
have any knowledge about dnn training or architecture the
adversary can only query the deployed model for labels in
the next section we will provide the details of adversarial ml
attack on tor trafﬁc classiﬁcation
table i
notation used
symbol
meaning
f
function learned by dnn
x
input trafﬁc sample
y
input trafﬁc sample label
s
substitute dnn model architecture
sapprox
trained substitute dnn model
q
synthetic trafﬁc samples
y
synthetic trafﬁc labels
d
synthetic dataset dictionary
mi
mutual information
iii methodology
in this section we describe the approach that we followed
to design a blackbox adversarial ml attack on deep ml
based tor trafﬁc classiﬁcation which is used as a proxy
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
to represent other network functional areas to the best of
our knowledge no standardized deep mlbased tor trafﬁc
classiﬁcation method has been proposed yet although as
mentioned in section ii neural networks have outperformed
other mldl techniques for tor trafﬁc classiﬁcation we
utilize both dnns and svm for tortrafﬁc classiﬁcation we
utilize the mutual information mi for crafting adversarial
perturbations and substitute model training to perform the
blackbox adversarial attack before discussing the design of
the deep ml classiﬁer and the adversarial attack we describe
the threat model and related assumptions
a threat model
in this subsection we delineate the threat model assump
tions table i provides a summary of the notation used in our
blackbox attack procedure
 adversary knowledge the proposed attack in this paper
only considers blackbox adversarial ml attack model where
the adversary has no knowledge of training data number of
layers in the model training hyperparameters type of layers
and training data the adversary can only access the output
of the deep ml model ie dnn in this case in a query
response manner the adversary can send an input to the model
and collect the label as a response these queryresponse pairs
are later used for crafting an adversarial attack we assume that
the adversary can only perform an adversarial attack during
the test time other attacks such as poisoning attacks are not
within the scope of this study
 adversarial goals the goal of the adversary is to
compromise the integrity and availability of the tor trafﬁc
classiﬁer by minimally altering the test examples in adver
sarial attacks on computer vision and natural language pro
cessing applications the fundamental restriction on adversarial
examples is to preserve the visual representation or semantic
meaning of the image or text respectively this restriction is
replaced with a more difﬁcult one in the context of networking
where the adversary has to ensure that the applied adversarial
perturbation does not affect the functional behavior of the
network trafﬁc
b tor classiﬁcation model
in this work we use dnn and svm for tor trafﬁc
classiﬁcation svm is a well known ml technique used for
classiﬁcation and regression whereas dnns are wellknown
for being capable of solving complex classiﬁcation tasks by
extracting hierarchical representation from their input dnn
consists of multiple layers of neurons smallest computational
unit each layers output is the input of the next layer the
nonlinear activation function is used to ensure that each
neuron also learns nonlinear information the output layer of
the dnn uses softmax as activation function to produce the
classiﬁcation probability vector
we use the dnn and svm classiﬁers for binary and multi
class classiﬁcation where binary classiﬁcation is performed
between tor and nontor trafﬁc and multiclass classiﬁcation
is performed between different tor trafﬁc classes we used
stochastic gradient descent with a batch size of  for
training the classiﬁer we used a  ratio of the data
figure  steps for designing a blackbox adversarial attack on network trafﬁc
classiﬁcation processes through synthetic data generation substitute model
generation and adversarial sample crafting
for training and validation purposes we achieved  and
 accuracy for binary class classiﬁcation using dnn and
svm respectively for multiclass classiﬁcation we achieved
 and  accuracy using dnn and svm respec
tively classiﬁcation accuracy of both models can be improved
by carefully choosing hyperparameters for dnn training
c blackbox attack procedure
in this subsection we delineate the procedure used to per
form the blackbox adversarial ml attack on tor trafﬁc classi
ﬁcation models the proposed adversarial attack is performed
in two steps namely substitute model training and adversarial
sample crafting figure  provides a detailed description of the
process used to perform a blackbox adversarial attack on tor
trafﬁc classiﬁcation
 substitute model training according to the assump
tions provided in iiia the adversary can only query the
deployed mldl model f with synthetic input data q to
get a label as a response y  these queryresponse pairs are
then used for training a substitute model architecture s the
goal in training s is to mimic the decision boundary of
the deployed classiﬁer f this process is divided into two
components namely substitute model architecture design 
synthetic dataset collection and substitute dnn training on
synthetic dataset
substitute model architecture design and synthetic dataset
collection are very challenging tasks since the adversary has
no information about fs architecture and training process
selection of appropriate architecture for s and training pro
cedures are performed heuristically in our experiments we
selected dnn as our substitute architecture the adversarial
attack proposed in this paper is also applicable to other mldl
architectures with some modiﬁcations to the training process
the adversary can also train multiple mldl models to ﬁnd
the besttrained substitute model sapprox substitute model s is
trained using synthetic data samples q prepared by querying
f for labels y  we used a moderate number of queries to
develop synthetic data for training s initially the adversary
sends queries to f from a set q of synthetic trafﬁc samples
obtained by using tor and a regular browser to get labels y 
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
each query along with its response label is stored as a synthetic
data pair in synthetic dataset dictionary d
once we obtain a moderate amount of synthetic datain
our case  queryresponse pairsthe substitute dnn is
trained on this synthetic dataset binary cross entropy and
categorical cross entropy loss functions are used in binary and
multiclass classiﬁcation we utilized the stochastic gradient
descent algorithm for training the substitute model s the
complete training process is described in algorithm 
algorithm  substitute dnn training
input f s and q
output sapprox and d
initialize y  
for all x q do
y fx
y y
end for
d  q y 
sapprox  min
s
ld s
return sapprox d
d adversarial sample crafting
once the substitute classiﬁer s is trained it is used to
generate the adversarial attack since the adversary knows
every detail about the trained substitute model sapprox it is
very easy to generate an adversarial perturbation for sapprox
to perturb sapprox an adversary needs to ﬁnd the most dis
criminant feature and to slightly perturb it formally speaking
an adversarial perturbation for network trafﬁc is an input that
when added to the actual input does not lose its functional
behavior but gets classiﬁed in a different class in our binary
class classiﬁcation case a small perturbation in the tor sample
will force the classiﬁer to classify tor sample in the nontor
category
we use mi mathematical notation ix y  for most
discriminative feature detection for adversarial sample craft
ing the mi ix y  is deﬁned as the measure of statistical
dependence between two random variables the mi between
two random variables x and y is given as
ix y  
x
xy
px ylogpx ypxpy
to select the most discriminative feature from synthetic data
d we calculate mi between each feature and label pair the
top n n can vary between  to any moderate number of
features while maintaining the functional behavior features
having the highest values of mi are selected as the most
discriminant features mi value of any feature also depicts
its inﬂuence on the classiﬁcation procedure once the most
discriminative features are selected they are perturbed sparsely
using l norm minimization the perturbation is always kept
less than  the adversarial sample crafting algorithm is
provided in algorithm 
once the adversarial examples crafted using the algorithm
 have successfully evaded sapprox according to the adversarial
ml transferability property  the adversarial examples
evading the integrity of sapprox are highly likely to compromise
the integrity of f in our experiments we evaluated the
adversarial examples on f and the corresponding results are
provided in section iv where for both binary and multiclass
classiﬁcation the crafted blackbox adversarial examples have
successfully evaded the deployed mlbased network tor
trafﬁc classiﬁcation system
for an adversarial attack to be practical in cognitive net
working it is important that the original packets functionality
is preserved even though the attacker is perturbing the packet
with the intention of tricking the classiﬁer we assume that the
perturbations can be reversed through a middlebox employed
by the adversary or that the adversary uses the portions of
packets for the perturbation that are otherwise unrelated to
the packets functionality eg through extra padding or using
unused control ﬁelds
algorithm  adversarial sample crafting algorithm
input sapprox dq y 
output x
initialize x  p   q   i  
while arg maxsx  y st y y x q do
mi compute ixi yi
a p select topn mi values of target class
b q select topn mi values of other class
p compute arg min
p p q
δ  
p 
p
for l   l do
xal  xal  δl
end for
xx
end while
iv performance evaluation
we conducted systematic experiments to evaluate the tor
trafﬁc classiﬁer against proposed our proposed blackbox
adversarial attack through our experiments we want to afﬁrm
the hypothesis that the blackbox adversarial example crafting
algorithm proposed in this paper allows us to successfully
fool the mlbased tor trafﬁc classiﬁcation model in our
experiments we consider dnn and svm based binary class
and multiclass tor trafﬁc classiﬁers drop in accuracy is
considered as a measure of success for the proposed black
box adversarial sample crafting algorithm before discussing
our experimental results we provide a brief description of the
dataset used in our experiments
a dataset
we use the unbcic tor network trafﬁc dataset  to
validate the proposed blackbox adversarial ml attack the
dataset consists of two classiﬁcation categories namely a
binary tornontor classiﬁcation and multiclass tor trafﬁc
classiﬁcation for the binary tornontor classiﬁcation tor
and nontor trafﬁc data samples are provided while for the
multiclass classiﬁcation tor trafﬁc of  different applications
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
a dnnbased binary classiﬁer performance before and after
attack
b svmbased binary classiﬁer performance before and after
attack
c dnnbased multiclass classiﬁer performance before and
after attack
d svmbased multiclass classiﬁer performance before and
after attack
figure  performance of dnn and svm based binary and multiclass tor trafﬁc classiﬁers clearly highlighting the drop in the classifers accuracy due to
the proposed blackbox attack
namely
browsing chat audio streaming videostreaming
mail ﬁle transfer voip and pp is provided the trafﬁc
samples were curated using wireshark and tcpdump all
necessary information from the trafﬁc data has been extracted
using iscxflowmeter  more details about the dataset
used in this study can be found in 
b results
we conducted systematic experiments to evaluate the per
formance of our adversarial attack on network trafﬁc clas
siﬁcation using tor trafﬁc classiﬁcation as a proxy in our
experiments we considered binary tornontor and multi
class  different tor applications classes for the network
trafﬁc only the top two most discriminant features were
perturbed using l norm minimization and the perturbation
was limited to being less than 
in the binary classiﬁcation case tor vs nontor we
achieved  and  classiﬁcation accuracy on the legit
imate samples using dnn and svm classiﬁers respectively
when the proposed blackbox adversarial attack was applied
we observed a signiﬁcant drop in classiﬁcation performance
we created  adversarial samples of tor trafﬁc when these
adversarial samples were subjected to the binary classiﬁers
we observed that the classiﬁcation accuracy of the dnn
based classiﬁer has dropped from  to  and the
svmbased classiﬁers accuracy has dropped from to
 table ii presents the performance of the proposed
blackbox adversarial sample crafting algorithm in the binary
class classiﬁcation task highlighting the number of successful
tor class adversarial samples figures a and b also
depict the fscore recall and precision performance of the
binary classiﬁers before and after the adversarial attack
in the multiclass classiﬁcation case we employed the
proposed blackbox attack to target the integrity of a single
class ie chat for adversarial sample crafting algorithm
we have considered chat vs nonchat classiﬁcation once
the adversarial sample is crafted for chat class it is sub
jected to a dnn and svm based multiclass classiﬁer this
process also proves the transferability of adversarial examples
in networking domain this experiment was performed to
highlight that the proposed blackbox attack can also perform
targeted attacks legitimate chat samples were classiﬁed
with  and  accuracy by dnn and svm based
classiﬁers respectively after the adversarial attack the clas
siﬁcation accuracy of the same class has suffered a signiﬁcant
drop for the dnnbased multiclass classiﬁer the accuracy
dropped from  to  which is a drop of nearly 
in performance conﬁrming our hypothesis that dnnbased
network trafﬁc classiﬁers are very vulnerable to adversarial
perturbations for the svmbased multiclass classiﬁer we
observed a performance drop from  to  which
is nearly a  drop in accuracy by only perturbing 
trafﬁc features table iii provides the performance of proposed
blackbox adversarial sample crafting algorithm in multiclass
classiﬁcation highlighting the number of successful chat
class adversarial samples figures c and d also depict
the fscore recall and precision performance of the multi
class classiﬁers before and after the adversarial attack
our results highlight that the use of ml to realize net
work functions comes with potential adversarial attack threats
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
table ii
performance of proposed blackbox adversarial sample
crafting algorithm in binary class tor traffic classification
ml techniques
number of adversarial
samples crafted
successfully misclassiﬁed
adversarial samples
dnn
svm
table iii
performance of proposed blackbox adversarial sample
crafting algorithm in multiclass classification chat class
adversarial samples
ml techniques
number of adversarial
samples crafted
successfully misclassiﬁed
adversarial samples
dnn
svm
these adversarial attacks can cause serious damage to the
performance of networked applications the design of more
sophisticated blackbox adversarial attacks on network trafﬁc
classiﬁcation using advanced statistical schemes is left for
future work similarly the design of defense mechanisms
against adversarial ml attacks to ensure robust mlbased
network trafﬁc classiﬁcation is also left for future work
v conclusions
in this paper we proposed a method for performing a black
box adversarial ml attack on network trafﬁc classiﬁcation we
take the tor trafﬁc classiﬁcation as a proxy for network trafﬁc
classiﬁcation and demonstrated that deep neural network based
network trafﬁc classiﬁcation schemes are very vulnerable to
small carefully crafted perturbations in the test inputs our
results also indicate that deep machine learning techniques
especially deep neural networks do not provide any deterrence
against adversarial perturbations and utilizing such techniques
in networked applications can introduce new security risks to
networking applications and infrastructure
breaking barriers can multilingual foundation
models bridge the gap in crosslanguage speech
emotion recognition
moazzam shoukat
emulationai
pakistan
moazzamshoukatemulationaicom
muhammad usama
national university of computer  emerging
sciences faisalabad pakistan
musamanuedupk
hafiz shehbaz ali
emulationai
pakistan
shehbazaliemulationaicom
siddique latif
university of southern queensland unisq
queensland university of technology qut
australia
abstractspeech emotion recognition ser faces challenges
in crosslanguage scenarios due to differences in linguistic and
cultural expression of emotions across languages recently large
multilingual foundation models pretrained on massive corpora
have achieved performance on natural language understanding
tasks by learning crosslingual representations their ability
to understand relationships between languages without direct
translation opens up possibilities for more applicable multilingual
models in this paper we evaluate the capabilities of foundation
models wavvec xlsr whisper and mms to bridge the
gap in crosslanguage ser specifically we analyse their per
formance on benchmark crosslanguage ser datasets involving
four languages for emotion classification our experiments show
that the foundation model outperforms cnnlstm baselines
establishing their superiority in crosslingual transfer learning
for emotion recognition however selfsupervised pretraining
plays a key role and inductive biases alone are insufficient
for high crosslingual generalisability foundation models also
demonstrate gains over baselines with limited target data and
better performance on noisy data our findings indicate that
while foundation models hold promise pretraining remains vital
for handling linguistic variations across languages for ser
index termscrosslanguage speech emotion recognition
foundation models transformers multilingual data and self
supervised learning
i introduction
speech emotion recognition ser is a technique for un
derstanding human communication both interpersonal and
between people and machines  with the potential to be a
technology in forthcoming artificial general intelligence new
applications of ser are emerging at a pace ranging from
healthcare to transportation forensics to education entertain
ment to social media ser classifies emotional categories by
analysing audio signals such as pitch intensity and spectro
grams  however dealing with crosslingual inputs makes
the job difficult since slight cultural and linguistic variances
cast suspicion on the performance of the ser systems 
though emotional expressions are universal across languages
the peculiarities of each language present an impediment to
emotional interpretation therefore advancing the capabilities
of ser necessitates an understanding of the interactions be
tween language culture and affective expression  machine
learning mlenabled ser systems have outperformed legacy
emotion recognition systems and are now gaining traction in
industry and academia  as ser systems are now capable
of solving the riddle of understanding and modelling human
emotion with the aid of various context variables such as
gender age dialect and culture it is now imperative to
incorporate foundation modellike abilities into ser systems
   it would allow ser systems to understand cross
lingual emotion and act as a bridge towards the revolution in
humanmachine interaction hci by enabling effective service
delivery in a wider range of realworld applications
the performance of mlbased ser in crosslanguage sce
narios faces limitations due to several factors a key factor is
the language and cultural barrier  while human emotions
are universal their expression differs based on ones language
speech patterns and culture as a result the same emotion
manifests with diverse cues and syntax across languages
posing a challenge   another complication arises from
culturalspecific linguistic nuances affecting emotional cues
datasets used to train mlbased ser capture the nuances of a
single languageculture while performance may be adequate
in that language understanding other speech patterns faces
issues  additionally overlapping phonemes can cause
misclassification exacerbated by phonetic relatedness between
languages ser requires extensive annotated data to learn
emotion patterns but datasets are limited for many languages
without sufficient data classification accuracy is restricted
 current ser is also influenced by a single language
addressing biases through multilanguage training with fair
ness could help however variability in emotion expression
and data scarcity present hurdles 
 tenth international conference on social networks analysis management and security snams    ieee  doi snams
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
recently large foundation models pretrained on massive
corpora using selfsupervised techniques have achieved re
sults across natural language understanding tasks by learning
robust crosslingual representations   their ability
to understand relationships between languages without direct
translation opens up possibilities for more universally appli
cable multilingual models  their scale of training allows
them to discover deeper mappings between languages than was
previously possible where traditional models focus narrowly
on attributes of a single language foundation models can learn
shared semantic structures underlying emotional expressions
across diverse cultures and tongues  this expanded scope
of understanding makes them suited to bridge gaps faced
by traditional crosslanguage ser systems by leveraging
relationships between languages at both semantic and phonetic
levels foundation models hold the promise of speech emotion
classifiers that generalise more effectively across linguistic
barriers  foundation models enabling cheaper annotation
may help generate annotated datasets to tackle the lack of data
and aid effective crosslanguage ser design 
in this paper we evaluate multiple multilingual foundation
models  wavvec  xlsr  whisper  and
mms   on benchmark crosslanguage ser datasets
specifically we analyse their ability to bridge the language
and cultural gap when classifying emotions from speech data
in multiple source and target languages to the best of our
knowledge this represents the first study that assesses the
capabilities of these foundation models for advancing the field
of crosslanguage ser the results from our experiments aim
to provide insights into whether and how these models are able
to learn crosslingual speech representations that generalise
better for emotion classification across languages compared to
traditional approaches
the major contributions of this work include
 we experimentally investigated the possibility of using
foundation models wavvec  xlsr  whisper
 and mms  to bridge the gap in crosslanguage
ser
 we used four different language corpora for speech
emotion detection and evaluated the performance of pre
trained foundation models here we also note that the
proposed method is scalable to many languages
 we also provided the generalisation and robustness per
formance of crosslanguage ser under noisy data con
ditions we also evaluated the fewshots adaptation per
formance of the crosslanguage ser we further reported
the performance of crosslanguage ser with the language
information available at the pretraining of the foundation
models
the next section covers the related work ii section iii
describes the models and datasets utilised in the research
section iv focuses on the experiments and their results
section v closes the paper and provides a way forward
ii related work
this section provides a concise review of related work
including crosslingual emotion recognition multimodal emo
tion recognition transformerbased emotion recognition ap
proaches and foundation models for ser
a crosslanguage ser
crosslanguage emotion recognition aims to identify emo
tions in speech data across different languages and domains
   a key challenge is the limited availability of
labelled data for lowresource languages like urdu  persian
 or marathi  additionally using emotion recognition
models trained on a single language or corpus limits gen
eralizability due to domain mismatch between datasets 
prior work has proposed various techniques to address these
issues feature selection methods identify relevant features
to represent emotions across modalities   domain
adaptation reduces distribution discrepancies between source
and target domains via adversarial learning  data aug
mentation expands training data through transformations like
speech synthesis and pitch shifting  multimodal
fusion combines speech and text using attention tensors or
graph networks  evaluation on benchmark datasets
demonstrates the effectiveness of these approaches  
    this prior work lays the ground
work for developing more generalised crosslanguage emotion
recognition
b transformers in emotion recognition
transformers have advantages over rnns and cnns for
emotion recognition tasks due to their ability to model long
range dependencies and perform parallel computation 
 they can effectively harness semantic and acoustic
information from speech data to capture interactions between
modalities such as audio and text  several studies have
applied transformers for emotion recognition chen et al 
developed a keysparse transformer for multimodal emotion
classification focusing on emotionrelated information wag
ner et al  analysed the impact of model size and pretraining
data on transformer performance finding larger models pre
trained on more diverse data improved emotion prediction
zenkov et al  integrated cnns with a transformer encoder
to classify emotions from the ravdess dataset li et al
 proposed a multihead selfattentionbased transformer
achieving results on iemocap  msppodcast  and
mosi  datasets triantafyllopoulos et al  demon
strated transformers are sensitive to sentiment and negation
through probing emotion recognition models
c pretrained models for ser
multimodal emotion recognition involves identifying human
affective states from multiple sources of information includ
ing audio text visual etc this approach has demonstrated
superior accuracy compared to singlemodality methods 
nevertheless there are several challenges associated with
multimodal emotion recognition such as feature extraction
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
difficulties  feature alignment complexities  fusion
techniques  dealing with missing or noisy data 
therefore more advanced methods are needed to effectively
exploit information from multimodal data and provide a richer
understanding of human emotions
several methods have been proposed for multimodal emo
tion recognition to improve performance using pretrained
models for feature extraction makiuchi et al  proposed a
crossrepresentation speech model combining selfsupervised
features from audio and text features extracted with trans
former models achieving stateoftheart results on iemocap
using score fusion tang et al  propose a feature fusion
method for facial expression and speech using attention mech
anisms showing improved accuracy on ravdess yoon et
al  proposed a deep dual recurrent encoder model using
text and audio simultaneously to better understand speech
data outperforming previous methods on iemocap emotion
classification few recent works have proposed novel fusion
techniques using hybrid transformer models   the
hybrid transformer models combine transformer architectures
such as encoderdecoder or encoderonly for better multi
modal performance  for example chen et al  propose
a keysparse attention model fusing data efficiently using an
encoderdecoder transformer wagner et al  proposed a
progressive fusion model using an encoderonly transformer
to fuse data through refined iterations preserving modality
information while enhancing crossmodality interactions
d foundation models for ser
foundation models have shown potential for speech emotion
recognition by learning representations from large unlabeled
speech datasets for example von neumann et al  pre
trained a foundation model called speechbert on 
hours of unlabeled speech data from podcasts achieving
strong zeroshot transfer capabilities for ser tasks bender
et al  analyzed foundation models trained on speech
to understand what linguistic patterns they learn and how
robust their representations are in our previous work 
recent advances in audio foundation models were covered
by leveraging large amounts of audio data these models
have demonstrated abilities in various audio tasks including
automatic speech recognition asr texttospeech and music
generation notably foundation models like wavvec 
xlsr  whisper  mms  seamlessmt 
have started showing capabilities as universal translators for
multiple speech tasks across up to  languages without
taskspecific systems latif et al  also presented an
analysis of stateoftheart methodologies regarding foundation
large audio models their performance benchmarks and their
applicability to realworld scenarios current limitations are
also highlighted and insights are provided into potential future
research directions for large audio models with the intent
to spark discussion and foster innovation in nextgeneration
audio processing systems careful analysis of biases is also
needed as foundation models are deployed for realworld
ser systems  while audio foundation models show
abilities this research area remains in the early development
stages further exploration and advancements are needed to
fully realise the capabilities of these large language models
for audio and speechrelated applications including potential
pathways such as improving ser systems
iii model architectures and datasets
in this section we describe the foundation models and
datasets used for finetuning we have selected various foun
dation models for comparison to gauge their performance
against the baseline cnnlstm model below we provide
an overview of these models and datasets
a baseline model
our baseline model incorporates a convolutional encoder
structure coupled with a bidirectional lstm blstm for
classification tasks the convolutional layers within the en
coder are designed to capture highlevel emotional features in
line with past research  we use a larger kernel size
for the initial convolutional layer and subsequently a smaller
kernel for the subsequent layers the encoders features are
then passed to the blstm layer housing  lstm units
to capture emotional contexts these outputs from blstm
are fed into a dense layer consisting of  units generat
ing discriminative features for the subsequent softmax layer
overall the model is trained using the crossentropy loss for
categorical ser
b pretrained foundation models
we employ a simple head architecture and build it on top of
established foundational models among the chosen founda
tion models for pretraining we opt for esteemed models such
as wavvec  xlsr  whisper  and mms 
these models gain recognition for their training on vast multi
lingual datasets a comprehensive overview of these models
focusing on their scale the datasets they train on and the range
of languages encompassed in their training data is provided in
table i we employ multilingual foundational models and fine
tune them for crosslanguage ser by doing so we contrast
their capabilities against a conventional cnnlstm baseline
aiming to discern the effectiveness of these models in bridging
the gap in crosslanguage emotion detection in speech
wavvec  a selfsupervised model that learns by
masking speech input in the latent space and tackling a
contrastive task based on quantized latent representations
it was pretrained using the librispeech ls dataset
which lacks transcriptions and consists of  hours of audio
additionally they incorporated speech data from librivox
lvk notably on the clear hour segment of the
librispeech dataset wavvec outperformed previous bench
marks by only using  of the typically required labelled
data
xlsr as introduced by conneau et al  stands as a
pivotal model in the domain of crosslingual speech repre
sentation learning the foundation of xlsr is its pretraining
on raw speech waveforms from a diverse array of languages
this approach is an extension of wavvec but with a specific
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
table i details on pretrained foundation models dataset and a number of languages
model
alias
dataset
hours
languages
wavvecbase
wavvec
librispeech
english
xlsr
xlsr
common voice
babel
multilingual librispeech mls
k
massively multilingual speech
mms
mmslabk hours
mmsunlabk
mmslabuk hours
k
whisper
whisper
multitask training data k hours
k
fig  architecture build on top of wvxlsrwhipermms
focus on crosslingual settings the pretraining phase involves
solving a contrastive task that matches masked feature encoder
outputs the datasets that provided the bedrock for this expan
sive pretraining are common voice babel and multilingual
librispeech mls this comprehensive pretraining strategy
not only boosts the models ability to recognize and understand
different languages but also sets the stage for effective fine
tuning when subsequently tuned for specific tasks xlsr
demonstrates the ability to rival models that are individually
optimized for each language
whisper  is trained through weakly supervised learning
objectives these objectives include tasks like voice activity
detection vad language detection and automatic speech
recognition asr among others the innovative facet of
whisper lies in its training methodology by employing a
colossal supervised dataset that spans over  hours
of labelled audio data it pushes the boundaries of weakly
supervised speech recognition furthermore the model un
derscores the potency of zeroshot transfer as a mechanism
to significantly bolster the robustness of speech detection
systems
massively multilingual speech mms was introduced by
pratap et al  this initiative aimed to significantly expand
the range of supported languages in speech technology by a
notable x depending on specific speech tasks central
to their approach was the effective use of selfsupervised
learning they curated a labelled dataset mmslab encom
passing speech audio from  languages totalling k
hours in parallel they assembled an unlabelled dataset mms
unlab with audio recordings without associated text from
 languages amounting to k hours additionally an
unlabelled variant of mmslab designed for pretraining and
language identification named mmslabu spanned 
languages and contributed k hours with these resources
they developed a speech system capable of supporting a
language count ranging from  to a vast 
for finetuning these models we follow   and the
parameterefficient finetuning peft technique regardless
of the finetuning method employed we also make sure of
the consistency in our downstream crosslanguage ser archi
tecture to encapsulate our efforts spanned from maintaining
the original state of foundation models adapter tuning and
modifying the embedding prompt to using lowrank approx
imation lora  we implement average pooling on the
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
table ii results uar  of crosslanguage experiments evaluating the performance of various pretrained foundation
models
source
target
models performance uar 
cnnlstm
wavvec
xlsr
whisper
mms
iemocap
emodb
emovo
urdu
emodb
iempcap
emovo
urdu
urdu
iempcap
emodb
emovo
emovo
iempcap
emodb
urdu
hidden states from the final transformer layer followed by
processing through a hidden and then an output layer for
the downstream task finetuning the adam optimiser is used
alongside the crossentropy loss a commonly utilised loss
function for classification our chosen learning rate is set at
e the training lasts for  epochs with a batch size of 
and we retain the model checkpoint that showcases the best
results on the development set
c datasets
to broaden the scope of our findings we chose pub
licly accessible datasets representing four different languages
these corpora were selected due to their availability and to
incorporate linguistic variety into our evaluations an overview
of each data collection is provided below
 iemocap english
the iemocap corpus cited in  is a widelyused
public collection of multimodal emotional data in english
different annotators labelled the utterances in categorical and
dimensional labelling schemes based on previous research
  we focused on four emotions angry sad happy
and neutral these emotions represented  samples in the
iemocap dataset
 emodb german
the emodb corpus  is a wellknown german emo
tional speech dataset it features ten professional speakers con
veying seven varied emotions through ten german sentences
in our research we utilise  utterances  angry  sad
 neutral and  happy expressions this selection supported
our detailed evaluation of crosslanguage emotion recognition
 emovo italian
the emovo corpus  is an italian emotional speech
dataset it includes  sentences each delivered by six ac
torsthree males and three femalesexpressing seven dis
tinct emotions anger disgust fear joy sadness surprise and
neutral in our research we focused on  utterances that
fit into four emotions angry happy neutral and sad with
each emotion having  utterances this dataset is used in
conducting a thorough crosslanguage ser evaluation
 urdu urdu
the urdu dataset  is an emotional speech collection in
the urdu language it encompasses a total of  utterances
each reflecting one of the four fundamental emotions angry
happy neutral and sad this dataset features recordings from
 distinct speakers with  males and  females all of
whom were sourced from various urdu talk shows available on
youtube for our study weve incorporated all  utterances
ensuring an equal representation of each emotion with 
utterances each
iv experiments and results
in this section we evaluate and display the outcomes
using various models we employ these models to categorize
emotions and gauge their effectiveness using the unweighted
average recall uar uar is a popular metric in emotion
recognition as it provides a balanced score especially when
the data for certain emotions might be imbalanced compared to
others we conducted each experiment five times and presented
the average uar for all results throughout our tests we
adhere to a speakerindependent ser approach
a benchmarking results
in this study we conduct crosslanguage ser training our
model on source data and then evaluating its performance on
unseen target data in a different language we utilise datasets
from four different languages including english german
italian and urdu our focus narrows to four primary emotional
states happy sad neutral and angry for experiments we
set out to see how these multilingual foundation models
stack up against models like wavvec which is solely pre
trained on english data as well as the baseline cnnlstm
model starting our experiment we finetuned models using
the iemocap dataset and evaluated them on other lan
guage datasets those models that have been pretrained with
considerable data volume stand out surpassing conventional
architectures baseline cnnlstm to make our observations
generalisable we perform multiple evaluation strategies across
the selected four datasets and the results are presented in table
ii results show the dominant position of foundation models
over the conventional cnnlstm methods in the field of
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
a iemocap to emodb
b iemocap to emovo
c iemocap to urdu
fig  crosslanguage ser performance comparison of cnn
lstm and various pretrained foundation models across three
datasets emodb emovo urdu for varying sample sizes
as measured by uar the models are finetuned on
iemocap and evaluated on the target datasets
crosslanguage ser this shows that the models with a diverse
linguistic background tend to perform better in crosslanguage
a iemocap to emodb
b iemocap to emovo
c iemocap to urdu
fig  crosslanguage ser performance uar comparison
of cnnlstm and pretrained foundation models on clean
speech vs noisy data db snr from the target datasets
the models are finetuned on iemocap and evaluated on
clean and noisy versions of emodb emovo and urdu
datasets
ser tasks compared to ones like wavvec which is pre
trained on english data our findings in crosslanguage ser
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
underscore the advantages of foundation models pretrained on
rich and varied linguistic datasets such extensive pretraining
evidently positions these models favourably for crosslanguage
ser tasks as illustrated in table ii
b fewshots adaptation
in this experiment we delve into the impact of fewshot
adaptation for crosslanguage settings essentially we combine
a subset of samples from a target language with our main
training data to observe the outcomes the iemocap dataset
serves as our primary training resource in this experiment and
we use other datasets as test data we finetuned foundation
models and the results of our findings are illustrated in figure
 to cover a wide spectrum we alter the sample size
beginning with zero and ramping up to  we initiate our
tests with  samples for each individual emotion from there
we methodically increase the sample count examining results
at   and  sample thresholds as depicted in figure
 a clear pattern emerges employing fewshot adaptation
while finetuning the pretrained foundation model notably
boosts crosslanguage ser surpassing the conventional mod
els like the cnnlstm model importantly this experiment
also highlights the elevated efficiency of foundation models
pretrained on datasets comprising multiple language data
such as xlsr whiper and mms these models outperform
wavvec which is only trained on english language data
this result highlights how using varied language data for
training can make a difference especially in recognising emo
tions across languages incorporating a few samples from the
target data into the training set can notably boost performance
paving the way for realworld applications of ser
c robustness of pretrained models
in this experiment we delve into the robustness of various
architectures especially contrasting traditional models like
cnnlstm with transformerbased models pretrained on
vast and diverse datasets the test conditions involve the intro
duction of ambient noisespecifically kitchen park station
traffic and cafeteria sounds from the demand dataset 
this noise is interspersed randomly within the test dataset
performance assessments are then made on the data with a
signaltonoise snr ratio of  db against clean speech
and the findings are captured in figure  several observations
emerge from this analysis pretrained foundation model given
their extensive training on a large corpus of data seemingly
display an innate ability to handle noisy disruptions better
it is plausible that their expansive training data encompassed
various noisy environments furnishing them with the capabil
ity to better adapt to and process distorted auditory signals
their ser performance in the context of noise tolerance
distinctively eclipses that of the conventional cnnlstm
model
furthermore it becomes evident that sheer volume and
diversity in training data play pivotal roles in noise resilience
models like xlsr whiper and mms pretrained on sub
stantial multilingual datasets illustrate superior performance
metrics compared to the wavvec base this differential is
not just attributable to the advanced transformer architecture
but also the breadth of their training data specifically the
wavvec base model constrained by its training solely on
english data struggles to match the versatility and adaptability
of its more extensively trained counterparts this reaffirms the
notion that diversity in trainingboth in terms of language
and acoustic conditionsequips models with a more holistic
noiseresistant capability
v conclusions and outlook
in this paper we evaluated the performance of different
foundation models for crosslanguage speech emotion recog
nition based on our experiments and analysis we conclude
the following
 foundation models like xlsr whisper and mms sig
nificantly outperform traditional cnnlstm approaches
for crosslanguage ser achieving higher uar scores
across different language pairs this establishes the su
periority of foundation models in handling crosslingual
learning for emotion recognition
 as found previously  wavvec when initialised
randomly showed performance comparable to cnn
lstm however models like xlsr whisper and mms
which are pretrained on massive multilanguage datasets
demonstrate improved performance in crosslanguage
ser compared to wavvec trained on singlelanguage
data the distinct advantage underscores the significance
of diverse pretraining datasets in elevating the capabili
ties of speech models for finetuning tasks
 adapting the foundation models with a few target lan
guage samples resulted in substantial gains over the base
line demonstrating their ability to effectively leverage
limited target data
 the foundation models also exhibited better robustness
over cnnlstm when evaluated on noisy target data
maintaining higher uar scores
in conclusion while foundation models hold promise for
crosslanguage tasks selfsupervised pretraining currently
plays a vital complementary role in equipping them with the
necessary skills for handling linguistic and cultural variations
across languages further research can explore inductive bi
ases that facilitate improved crosslingual transfer ability of
foundation models

ieee
ieee technology and society magazine         s e p t e m b e r     
digital object identifier mts 
date of publication  august 
siddique latif adnan qayyum muhammad usama junaid qadir  
andrej zwitter and muhammad shahzad
caveat emptor
istocklagartofilm
b
ig data has the potential to facilitate sustainable development in many 
sectors of life such as education health agriculture and in combating hu
manitarian crises and violent conflicts however lurking beneath the im
mense promises of big data are some significant risks such as  the po
tential use of big data for unethical ends  its ability to mislead through 
reliance on unrepresentative and biased data and  the various privacy 
and security challenges associated with data including the danger of an 
adversary tampering with the data to harm people these risks can have severe conse
quences and a better understanding of these risks is the first step towards their mitigation 
the risks of using big data for human development
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
s e p t e m b e r               ieee technology and society magazine
of these risks in this article we highlight the poten
tial dangers associated with using big data particu
larly for human development
data deluge
over the last decades widespread adoption of digital 
applications has moved all aspects of human lives 
into the digital sphere the commoditization of the 
data collection process due to increased digitization 
has resulted in a data deluge that continues to inten
sify with a number of internet companies dealing with 
petabytes of data on a daily basis the term big 
data has been coined to refer to our emerging ability 
to collect process and analyze the massive amount 
of data being generated from multiple sources in 
order to obtain previously inaccessible insights big 
data can equip policy and decision makers with evi
dencebased actionable insights that can help in 
enhancing social systems tracking development prog
ress and in developing a nuanced understanding of 
the effects of policies without being swayed by intu
ition ideologies or emotions
in particular the recent advances in machine learn
ing ml and artificial intelligence ai techniques have 
revolutionized intelligent data analytics resulting in 
enhanced interest in using big data for sustainable 
human and social development bdd many organiza
tions and government institutions are exploring such 
solutions in diverse fields such as healthcare educa
tion intelligence fraud and crime prevention 
although big data technology offers great promise 
 it is worth remembering that big data is not a silver 
bullet and we may ignore the hardearned statistical les
sons on measurement bias data quality and inference 
variation that have been earned through a hard toil and 
sometimes bitter experience only at our own peril 
while most writing on data is enthusiastic new work 
has started emerging that has begun to show how big 
data can mislead and be used detrimentally   
 more than  years of research into artificial intelli
gence and statistical learning has shown that there is no 
free lunch  ie there are no universally applicable 
solutions  and that there are always tradeoffs 
involved 
the use of bdd is transforming society in various 
domains from education to prevention diagnosis and 
treatment of illness  it has improved the efficiency 
and effectiveness of disaster management systems by 
utilizing realtime community information  in these 
applications data is emerging as a new economic 
resource and used by companies governments and 
even individuals to optimize everything  the ulti
mate goal of the development sector seems to be what 
is referred to as forecastbased financing  a 
predictionbased and automatized funding and logistical 
system based on big data analytics and smart contracts 
that automatizes everything from funding to action in 
the field 
despite the great excitement around the big data 
trend big data is also pegged with criticism the dark 
side of big data is that data invariably contains some 
biases and there is a fear that big data could erode pri
vacy and threaten freedom when deployed for human 
and social development these issues become particu
larly serious when big data is deployed for human sub
jects in the case of bdd for example consider the 
case where big data predictions about individuals are 
used to punish people on their propensities rather than 
on their actions this denies human free will and their 
capability to improve over time and effectively reinforc
es existing stereotypes 
various studies have articulated common issues that 
concern big data analytics interdisciplinary research 
    but a critical analysis of bdd is 
missing in the literature therefore in this paper we 
discuss the caveats of big data analytics when it is 
used for human development purposes the purpose of 
this article is to present a critical synthesis of the 
diverse literature and put together various underlying 
issues that affect bdd significantly in addition to criti
cally evaluating bdd risks this paper also explores 
potential remedies that can help mitigate the problems 
of bdd
general issues in using data for decisions
today big corporations are investing their resources in 
utilizing big data technology to uncover important cor
relations customer p
ieee transactions on artificial intelligence vol  no  april 
challenges and countermeasures for adversarial
attacks on deep reinforcement learning
inaam ilahi
 muhammad usama
 junaid qadir
 senior member ieee muhammad umar janjua
ala alfuqaha
 senior member ieee dinh thai hoang
 member ieee and dusit niyato
 fellow ieee
abstractdeep reinforcement learning drl has numerous
applications in the real world thanks to its ability to achieve
high performance in a range of environments with little man
ual oversight despite its great advantages drl is susceptible
to adversarial attacks which precludes its use in reallife critical
systems and applications eg smart grids trafﬁc controls and
autonomous vehicles unless its vulnerabilities are addressed and
mitigated to address this problem we provide a comprehensive
survey that discusses emerging attacks on drlbased systems and
the potential countermeasures to defend against these attacks we
ﬁrst review the fundamental background on drl and present
emerging adversarial attacks on machine learning techniques we
then investigate the vulnerabilities that an adversary can exploit to
attack drl along with stateoftheart countermeasures to prevent
such attacks finally we highlight open issues and research chal
lenges for developing solutions to deal with attacks on drlbased
intelligent systems
impact statementdeep reinforcement learning drl has nu
merous reallife applications ranging from autonomous driving
to healthcare it has demonstrated superhuman performance in
playing complex games like go however in recent years many
researchers have identiﬁed various vulnerabilities of drl keeping
this critical aspect in mind in this article we present a comprehen
sive survey of different attacks on drl and various countermea
sures that can be used for robustifying drl to the best of our
knowledge this survey is the ﬁrst attempt at classifying the attacks
based on the different components of the drl pipeline this article
will provide a roadmap for the researchers and practitioners to
develop robust drl systems
index termsadversarial machine learning cybersecurity
deepreinforcementlearningdrlmachinelearningmlrobust
machine learning
manuscript received may   revised july   and august 
 accepted september   date of publication september  
date of current version march   this work was supported by the qatar
national research fund a member of qatar foundation through the national
priorities research program under grant s this article was
recommended for publication by associate editor prof pablo estevez inaam
ilahi and muhammad usama contributed equally to this work corresponding
author inaam ilahi
inaam ilahi muhammad usama and muhammad umar janjua are
with the information technology university lahore  pakistan e
mail mscsituedupk muhammadusamaituedupk umarjanjua
ituedupk
junaid qadir is with the information technology university lahore
 pakistan and also with qatar university doha  qatar email
junaidqadirituedupk
ala alfuqaha is with the hamad bin khalifa university doha  qatar
email aalfuqahahbkueduqa
dinh thai hoang is with the university of technology sydney ultimo nsw
 australia email hoangdinhutseduau
dusit niyato is with the nanyang technological university
singapore
 email dniyatontuedusg
digital object identiﬁer tai
nomenclature
ac
asynchronous advantage actorcritic
ac
advantage actorcritic
asa
adversarialstrategic agent
age
adversarially guided exploration
ai
artiﬁcial intelligence
arpl
adversarially robust policy learning
atn
adversarial transformation networks
carrl
certiﬁed adversarial robustness for rl
cw
carlini and wagner
cdg
common dominant adversarial example genera
tion
cmarl
cooperative multiagent reinforcement learning
drl
deep reinforcement learning
ddpg
deep deterministic policy gradient
ddqns
double deep qnetworks
djsma
dynamic budget jsma
dl
deep learning
dqn
deep qnetworks
fgsm
fast gradient sign method
frarl
falsiﬁcationbased rarl
gb
gradient based
gps
graded policy search
ia
imagination augmented agents
irl
inverse reinforcement learning
itfgsm
iterative targetbased fgsm method
jsma
jacobianbased saliency map attack
kl
kullbackleibler
las
lookahead action space
mad
maximal action difference
mas
myopic action space
mbmfrl
modelbased priors for modelfree reinforcement
learning
mdp
markov decision process
metrpo
model ensemble trust region policy optimization
ml
machine learning
mlah
metalearned advantage hierarchy
mpc
modelpredictive control
mujoco
multijoint dynamics with contact
mve
modelbased value expansion
naf
normalized advantage function
nrmdp
noisy action robust mdp
pca
principal component analysis
pepg
parameter exploring policy gradients
pomdp
partially observable markov decision process
   ieee personal use is permitted but republicationredistribution requires ieee permission
see httpswwwieeeorgpublicationsrightsindexhtml for more information
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
ppo
proximal policy optimization
prmdp
probabilistic mdp
rararl
riskaverse rarl
rarl
robust adversarial rl
rbfq
radialbasisfunctionbased qlearning
rnn
recurrent neural network
sarsa
stateactionrewardstateaction algorithm
samdp
stateadversarial mdp
sdn
softwaredeﬁned networking
sfd
samplingbased ﬁnite difference
sgd
stochastic gradient descent
spg
stochastic policy gradient
steve
stochastic ensemble value expansion
tmdps
threatened markov decision processes
trpo
trust region policy optimization
wma
weighted majority algorithm
i introduction
t
he ultimate goal of research in ai is to develop artiﬁ
cial general intelligence agi agents that can perform
similar activities as humans in a more efﬁcient manner this
longstanding challenge for developing such agents is no longer
a pipe dream thanks to rapid growth in computational ai and
ml technologies in the last decade ml and especially dl
have revolutionized ﬁelds such as computer vision language
processing etc ml is divided into three categories  namely
supervised unsupervised and reinforcement learning rl in
supervised learning training data along with the corresponding
labels are available for decision making supervised learning is
by far the most wellstudied branch of ml for problems with
labeled data which has a lot of applications in practice such as
object recognition speech recognition spam detection pattern
recognition and many more in unsupervised learning the target
is to infer the underlying patterns and structures from unlabeled
data rl is deﬁned as a learning process that focuses on ﬁnding
the best strategies for agents based on the interactions with the
surrounding environment unlike supervised and unsupervised
learning processes which need training data to learn rl agents
can learn in an online manner based on observations obtained
through realtime interactions with the environment
rl utilizes a trialanderror process to solve sequential
decisionmaking problems in robotics control and many other
realworld problems rl algorithms also have some limitations
tobeutilizedinpracticemainlyduetotheirslowlearningprocess
and inability to learn in complex environments recently a new
technique combining the advancement of dl called drl has
been introduced  drl has shown great results in many
complex decisionmaking processes such as designated task
completion in robotics  navigating driverless autonomous
vehicles   healthcare  ﬁnancial trading  smart grid
management  automated transportation management 
wireless and data network management  and for playing
games such as pong  go  etc in  drl beat the
human champions in the game of go  and most recently
a team of ﬁve drl agents has beaten the world champion
human team in dota matches  this shows that drl is
promising and can address highly complex and timesensitive
decisionmaking problems in real time
with the rapid adoption of drl in critical realworld
applications the security of drl has become a very important
area of research   recently drl has been vulnerable
to adversarial attacks where an imperceptible perturbation
is added to the input to the drl schemes with a predeﬁned
goal of causing a malfunction in the working of drl 
thus it is crucial to understand the types and nature of these
vulnerabilities and their potential mitigation procedures before
deploying drlbased reallife critical systems eg smart
grids and autonomous vehicles here we want to note that the
securityofsupervisedandunsupervisedmliswellstudiedinthe
literature  but the security of drl has not yet received sim
ilar attention in  behzadan and munir  reviewed the
security vulnerabilities and open challenges in drl although
it provides a decent initial review of the security concerns it
does not properly cover the security issues associated with four
major components of the drl pipeline state action model
and reward and related robustness mechanisms furthermore
the survey does not cover the recent studies we aim to fulﬁll
these requirements by providing a more comprehensive survey
on attacks and defense techniques together with a discussion of
the future research directions on drl
contributions of this article in this article we build upon the
existing literature available on security vulnerabilities of drl
and their countermeasures and provide a comprehensive and
extensive review of the related work the major contributions
of this article are as follows
 we provide the drl fundamentals along with a nonex
haustive taxonomy of advanced drl algorithms
 we present a comprehensive survey of adversarial attacks
on drl and their potential countermeasures
 we discuss the available benchmarks and metrics for the
robustness of drl
 finally we highlight the open issues and research chal
lenges in the robustness of drl and introduce some
potential research directions
organization of this article the organization of this article
is depicted in fig  an overview of the challenges faced by ml
and drl schemes has been provided in section ii section iii
presents a comprehensive review of adversarial ml attacks
on the drl pipeline a detailed overview of countermeasures
proposed in the literature to ensure robustness against adver
sarial attacks is presented in section iv section v presents
the available benchmarking tools and metrics along with open
research problems in drl section vi describes the open issues
and research challenges in designing adversarial attacks and ro
bustness mechanisms for drl finally we conclude this article
in section vii for the convenience of the reader a summary
of the salient acronyms used in this article is presented in the
nomenclature
ii background
in this section we discuss the fundamentals of the drl
process then we provide a summary of the shortcomings of
the ml and drl techniques
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee transactions on artificial intelligence vol  no  april 
fig 
organization of this article
fig 
basic process of the mdp in rl
a fundamentals of drl
the important concepts used in drl are described as follows
 markov decision process a generic rl problem is
described as an mdp in terms of the state action reward
and dynamics of the system in an mdp at each time step
the agent observes the current state st and performs an
action at based on its current policy π after the action is
executed the agent observes its reward rt and next state
st the objective of an mdp is to ﬁnd the best actions
which maximize its longterm expected reward fig 
illustrates a typical mdp setup with an agent interacting
with its surrounding environment
 environment is a simulator or a realworld scenario in
which the agent interacts and learns at each time step
the agent governed by the policy interacts with the
environment and in return receives a reward environ
ment is divided into two categories namely partially
observable and fully observable in the case of a partially
observableenvironmenttheagentisonlyabletopartially
observe the environment for these partially observable
environments pomdps are used in a fully observable
environment the agent can observe all the states and we
use mdps for this mdps are a special case of pomdps
where the observation function is identity
 action is a stimulus used by the agent for interactions
with the environment the actions can be discrete or
continuous based on the environment and drl problem
formulation
 reward is an incentive expressed by a numerical value
that the agent receives after making an action the goal
of an agent is to maximize the accumulated reward to
reduce the impact of the reward r which the agent might
get in a later state due to taking a speciﬁc action a in the
current state st the notion of discounted rewards was
introduced it is usually denoted by γ and can take any
valuerangingfromtomathematicallythediscounted
reward rt given as
rt 
t
tt
γttrst
where t denotes the time step t is the ﬁnal time step r
denotes the reward for the time step and st denotes the
current state
 value function speciﬁes the value of a state value is
deﬁned as the maximum expected discounted reward of
a certain state mathematically it is determined as
vπs  eπrts  st
where π is the policy rt is the discounted reward and
st is the current state
 qfunction speciﬁes the qvalue of a state qvalue is
deﬁned as the maximum expected discounted reward an
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
fig 
nonexhaustive taxonomy of major drl schemes as proposed in 
agent may get by taking a speciﬁc action at a speciﬁc
state mathematically it can be calculated as follows
qπs  eπrts  st a  at
where π is the policy rt is the discounted reward st is
the current state and at is the current action
 advantage function is the difference of the qvalue of a
speciﬁc action at a state qs a from the value of that
state v s ie as a  qs a v s
 policy deﬁnes how the agent will behave in the envi
ronment at a particular time in other words it is a
mapping from the perceived states of the environment
to the actions taken in those conditions a policy is said
to be optimal if it achieves the maximum possible reward
at each state policies are further divided into two types
deterministic policy and stochastic policy when actions
taken by the agent are deterministic the policy is termed
as deterministic on the other hand when the actions
are sampled from the conditional probability distribution
of actions given the states the policy is called to be
stochastic
 onpolicy algorithms enable an agent to learn and update
its policy in an online manner through realtime interac
tion with the environment samples generated from the
current policy are used to train the algorithm to estimate
the policy in advance
 offpolicy algorithms use an online policy and a target
policy the target policy is used to estimate the action val
ues while the online policy is being learned hence the
agent can estimate the target policy without its complete
knowledge
 model mimics the behavior of the environment hence
allowing inferences to be made about the behavior of
the environment based on the availability of the system
models the drl schemes are divided into further two
categories namely modelbased and modelfree rl
 exploration and exploitation exploration is the process
when the agent tries to explore the surrounding environ
ment by taking different actions available at a given state
exploitation occurs after exploration the agent exploits
the optimal actions to achieve the maximum cumulative
reward an ϵgreedy policy is used to balance exploration
and exploitation the agent chooses a random action
with a certain probability otherwise it takes the action
followed by the policy the probability of the random
action being taken keeps decreasing with each time step
this change factor is usually denoted by λ
a taxonomy of major drl algorithms as proposed in  has
been provided in fig  we refer the interested readers to 
and  for further details on variations of drl schemes
b security of ml
although the utilization of ml techniques has revolutionized
many areas including vision language speech and control
it has also introduced new security challenges that are very
threatening in designing and developing new dynamic intelli
gent systems security attacks in ml can be divided into two
categories training phase attacks and inference phase attacks
for the training phase attacks the adversary tries to force the
learning process to learn faulty modelpolicy by introducing
small imperceptible perturbations to the input data inference
phaseattacksareperformedbytheadversaryattheinferencetest
time of the ml pipeline to fool the modelpolicy in providing
malfunctioned resultsactions
the malicious input generated by adding adversarial perturba
tions into the original input is known as an adversarial example
adversarial examples are classiﬁed into four major categories
based on the objective knowledge frequency and speciﬁcity
formally an adversarial example xis created by adding a
small imperceptible carefully crafted perturbation δ to the cor
rectly classiﬁed example x the perturbation δ is calculated
by approximating the optimization problem iteratively until the
crafted adversarial example gets classiﬁed by ml classiﬁer f
in targeted class t as follows
x x  arg min
δx δ fx  δ  t
where t is the targeted class fig  shows a basic taxonomy of
attacks on ml
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee transactions on artificial intelligence vol  no  april 
fig 
taxonomy of adversarial ml attacks classiﬁed according to the adversarys objective knowledge speciﬁcity and attack frequency
 attacks based on adversarys knowledge depending on
the adversarys knowledge about the targeted ml model adver
sarial attacks are divided into further three categories whitebox
attacks graybox attacks and blackbox attacks in the case of
whitebox attacks the adversary has perfect knowledge of the
target mldl algorithm ie the adversary knows the training
and testing data parameters of the model etc these attacks
are used for the worstcase security malfunction analysis of an
mldl system in the case of graybox attacks the adversary is
supposed to have limited knowledge knowledge about feature
representation and optimization algorithms only about the tar
geted mldl model the adversary designs a surrogate model
on the limited knowledge available and uses transferability
property  of the adversarial examples where an adversarial
example evading a classiﬁer will evade other similar classiﬁers
even if they are trained on another dataset to evade the mldl
based system the attacker may also have limited test access to
the model ie it may be able to ask the model the output on some
inputs in the case of blackbox attacks the adversary does not
know the model or any of its attributes the adversary can only
query the systems for labels or conﬁdence scores and develop
an adversarial perturbation based on the feedback provided by
the deployed mldl model
 attacks based on adversarys goals based on the adver
sarys objective adversarial attacks are divided into four types
 conﬁdence reduction attacks in which adversarial attacks
are launched to compromise the conﬁdence levels of the
predictions of the deployed mldlbased system
 misclassiﬁcation attacks in which adversarial attacks are
launched for disturbing the classiﬁcation boundary of any
class to cause misclassiﬁcation
 targeted misclassiﬁcation attacks in which adversarial
attacks are launched to misclassify only a targeted class
and
 sourcetarget misclassiﬁcation attacks in which adversar
ial attacks are launched to force misclassiﬁcation of a
speciﬁc source class into a speciﬁcally targeted class
 attacks based on adversarys speciﬁcity based on speci
ﬁcity adversarial examples can be classiﬁed into two types ie
targeted and nontargeted these concepts are similar to the ones
as in the case of the adversarys objective in the case of targeted
attacks the attackers target speciﬁc classes in the output while
in the case of nontargeted attacks the goal is to misclassify the
maximum number of samples
although adversarial examples are transferable from one
ml model to another in many cases the performance of the
transferred examples is not enough to further improve the
performance of blackbox attacks while reducing the number
of queries needed for the attack queryefﬁcient blackbox at
tacks are required different queryefﬁcient blackbox attack
methods are available in the literature cheng et al  use
randomized gradientfree methods for the creation of adversarial
examples and show their algorithm to require three to four
times fewer queries to achieve the same performance as the
stateoftheart attacks chen et al  uses the zerothorder
optimization technique for adversarial perturbation generation
and shows their blackbox attack to demonstrate the same
performance as stateoftheart whitebox attacks the queries
required by their technique  are less than those required
by that of  tu et al  propose a more queryefﬁcient
attack they propose autoencoderbased zerothorder optimiza
tion for adversarial image generation in blackbox attacks they
show a reduction of more than  in the mean query count
while maintaining the same performance as the stateofthe
art attacks more details on adversarial ml can be found in
 and 
c security of drl
the increasing use of drl in practical applications has led
to an investigation of the security risks it faces however the
security challenges faced by drl are different from those ex
perienced by other ml algorithms the major difference is that
a drl process is trained to solve sequential decisionmaking
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
fig 
taxonomy of adversarial attacks on drl classiﬁed according to the major parts of drl
problems in contrast to most other ml schemes that are trained
to solve singlestep prediction problems the independence of
the current actions from the previous ones increases the degrees
of freedom of adversarial attacks raising new challenges that
must be addressed this makes the adversarial attacks more
challenging to be recognized as we cannot discriminate between
the action intentionally taken by the agent and the action the
adversary forceslures the agent to take also the training is
done on a dataset from a ﬁxed distribution in the case of
ml in contrast to the drl where the agent begins with a
deterministic or stochastic policy and starts exploring for best
actions
usually rl problems are formulated as an mdp consisting
of four parts s a r p where s is the state space a is the
action space r is the reward function and p is the transition
matrix between states hence an adversary has more choices
to attack if the adversary targets the state space impercepti
ble perturbations can be added to the environment directly by
perturbing the sensors  similarly an adversary can target
any of the four major components of the mdp adversarial
attacks on drl are classiﬁed into inferencetime and training
time attacks  an adversary may compromise one or more
than one dimension of conﬁdentiality integrity and availability
based on the goal of the adversary the adversarial attacks
on drl can be classiﬁed into active or passive  for active
attacks the adversary desires to change the behavior of the agent
while for passive attacks the adversary desires to infer details
about the model reward function or other parts of drl an
adversary can use these details to either create a copy of the
model or use them to perform an attack on the model the
adversary may be limited by the part of the environment where
an adversary is only capable of making changes to a certain area
of the environment adding a lot of perturbation in a single time
instance may make the attack perceptible which is not preferred
by the adversary distinguishing the adversarial samples and
behavior from the normal ones in the case of drl is not as
easy as in supervised learning because of the increased possible
attack dimensions
iii adversarial attacks on drl
in this section we discuss the adversarial attacks on drl
we divide the attacks on drl into four categories based on the
functional components of the drl process a major portion
of the attacks involve the addition of adversarial perturbations
to the state space and a small portion of the proposed attacks
involve perturbing the reward and action space fig  shows a
basic taxonomy of the adversarial attacks on drl algorithms
a attacks perturbing the state space
we divide this subsection based on the access of the adversary
 manipulating the observations since dnns are vulner
able to adversarial attacks in supervised learning we would
expect dnns trained via drl to also be vulnerable indeed
behzadan and munir  show this vulnerability and verify
the transferability of adversarial examples across different dqn
models they consider a maninthemiddle adversary between
the environment and the drl agent where the adversary
perturbs the states from the environment and forwards these
perturbed states to the drl agent to take the desired action to
ensure the imperceptibility of the perturbation the amplitude
of the adversarial examples crafting algorithms fgsm and
jsma  is controlled the attack procedure is divided into
two phases initialization and exploitation the initialization
phase includes the training of a dqn on adversarial reward
function to generate an adversarial policy then a replica of the
targets dqn is created and initialized from random parameters
the exploitation phase includes generating adversarial inputs
such that the target dqn can be made to follow actions governed
by the adversarial policy furthermore they propose an attack
method to manipulate the policy of the dqn by exploiting the
transferability of adversarial samples they use a blackbox set
ting and show a success rate of  when adversarial examples
are transferred from one model to another the cycle of the
proposed policy induction attack is shown in fig  huang
et al  use the attack proposed in  and show a signiﬁcant
drop in the performance of dqn trpo and ac methods in
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee transactions on artificial intelligence vol  no  april 
fig 
process of policy induction attack  performed on the game of pong
both white and blackbox settings they show the dqn to be
more susceptible to adversarial attacks than the trpo and ac
lin et al  argue that the uniform attack schemes may
not be practically feasible and are easy to detect they con
sider a different approach and propose two adversarial attack
techniques on drl schemes strategically timed attack and
enchanting attacks for the former they propose to minimize
the reward of the drl schemes by using adversarial examples
on a subset of time steps in an episode of the drl operation
for the latter they propose a novel method of luring the drl
agent to a predeﬁned targeted state by using a generative model
and a sophisticated planning algorithm the generative model is
used to predict the next state in the space and the planning
algorithm is used to generate actions required for luring the
agent to the targeted state performance of the strategically
timed attack and the enchanting attack is reported on dqn and
ac agents playing atari games where  of the success
rate of the adversarial attacks is reported they use the cw
attack  for generating adversarial inputs it is also shown that
perturbing only  of the inputs using the proposed method
produces the same results as the previously proposed attacks
based on the fgsm the workﬂow of the enchanting attack is
shown in fig 
tretschk et al  propose a similar approach to the en
chanting attacks proposed by lin et al  where they use the
adversarial transformer network atn  to impose adver
sarial reward on the policy network of drl the atn makes
the agent maximize the adversarial reward through a sequence
of adversarial inputs complete information regarding the agent
and the target environment is required hence making the attack
white box it is shown that given a large enough threshold for
perturbation the agent can be made to follow the adversarial
policy at the test time
pattanaik et al  prove that fgsmbased attacks on
drl  do not use an optimal cost function for crafting the
adversarial inputs and propose a loss function that is guaranteed
to maximize the probability of taking the worst possible action
they propose three types of gb adversarial attacks on dqn and
ddpg techniques for reducing the expected reward by adding
perturbations to the observations the ﬁrst attack is based on
a naive approach of adding random noise to the drl states
to mislead the drl agent in selecting a suboptimal action
that decays the performance of the drl scheme the second
attack is a gb attack where a new cost function is introduced
for creating adversarial actions that outperforms the fgsm
in determining the worst possible discrete action to limit the
performance of drl schemes the third attack is an improved
version of the second attack instead of using a simple gb
approach for generating adversarial perturbation the authors
use sgd for adversarial action generation which ultimately
misleads the drl agent to end up in a predeﬁned adversarial
state
kos and song  discuss that the previous attacks require
perturbing several states to be successful which may not be
practically feasible they propose to use a value function to
guide the adversarial perturbation injection hence reducing the
number of adversarial perturbations needed for introducing a
malfunction in drl policies they propose three types of attack
situations  the addition of noise at a ﬁxed frequency  the
addition of specially designed perturbed inputs after n samples
and  the recalculation of the perturbation after n samples and
adding the previously calculated perturbation to the intermediate
steps the results show that their last approach performs as well
as the one in which all states are perturbed furthermore they
use the generated samples for retraining the model and show
that resilience can be improved against both fgsm and random
adversarial perturbations
a similar issue has been raised by sun et al  further
more they discuss that the previously proposed attacks are
not generalpurpose and have limitations eg  cannot be
used for continuous action spaces they propose two sample
efﬁcient generalpurpose attacks that can be used to attack any
drl algorithm while considering longterm damage impacts
namely critical point attack and antagonist attack the ﬁrst one
involves the building of a model by the adversary to predict
future environmental states and the agents actions the damage
of each possible attack strategy is then assessed and the optimal
one is chosen the antagonist attack involves automatic learn
ing of a domainagnostic model by the adversary to discover
the critical moments of attacking the agent in an episode to
be successful the critical point technique only requires one
torcs or two atari pong and breakout steps and the
antagonist technique needs fewer than ﬁve steps four mujoco
tasks
hussenot et al  discuss that the previously proposed
approaches are either practically infeasible or computationally
extensive they propose two types of adversarial attacks to take
full control of the drl agents policy the ﬁrst one called per
observation attack includes the generation of a new adversarial
perturbation for every observation of the agent and adding that
perturbationtotheenvironmentthesecondonecalleduniversal
mask attack includes the addition of one universal perturbation
created at the start of the attack to all the observations these
attacks are discussed in both targeted and nontargeted situations
it is also reported that the proposed attacks are more successful if
the fgsm is used for generating the perturbations in untargeted
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
fig 
illustration of enchanting attack on pacman is depicted which is highlighting all four components  action sequence planning  crafting an adversarial
example with a target action  the agent takes an action and  environment generates the next state st
attack situations whereas in the case of targeted attacks the
fgsm is not able to generate imperceptible adversarial samples
chan et al  take a different approach from other articles
and propose static reward impact maps which can be used to
quantify the inﬂuence on the reward of each feature in the state
space by the use of such a map the adversary can choose to
perturb only those features which have a large impact on the
cumulative reward the time complexity of the generation of
these static maps is posed as a limitation
cmarl algorithms are gaining attention in a wide range of
applications such as cellular base station control  trafﬁc
light control  and autonomous driving  the target of
the agent in cmarl is to learn to take action cooperatively
as a team to maximize a total team reward lin et al 
show the vulnerability of cmarl agents to adversarial attacks
by proposing a mechanism of adding perturbations to the state
space difﬁculty to estimate team rewards difﬁculty to measure
the effect of misprediction of an agent on the team reward
nondifferentiability of models and lowdimensionality of the
feature space make attacking such environments challenging
they hypothesize that the cooperative aspects of cmarl
agents make these agents more vulnerable to adversarial attacks
as compared to singleagent rl as the failure of a single agent
may cause the failure of the whole team they extend the fgsm
attack and propose two new approaches to decrease the team
reward more effectively itfgsm and djsma attack these
attacks involve training an adversarial policy network to search
for a suboptimal action from which the adversarial examples
are then introduced in the observations of one of the agents to
force it to take the targeted action they test their attack on the
startcraft ii multiagent benchmark they show that their attack
can decrease the reward from  to  by attacking only a single
agent out of the multiple possible agents when the perturbations
are added with an average of  l norm as a reaction to this
drop in reward the winning rate of the multiagent drops from
 to  furthermore they discuss the applicability of the
proposed attack in real environments as an adversary can gain
access to a single agent and use it to attack the whole system
despite the success of drl there is little research that
studies the impact of adversarial attacks in drl algorithms
that do not use images as inputs wang et al  propose
techniques that can degrade the performance of a welltrained
drlbased energy management system of an electric vehicle
causing them to either use much fuel or lead it into running
out of battery before the end of the trip they show their
adversarial inputs to be imperceptible for whitebox settings
theyusethefgsmastheadversarywhileforblackboxsettings
attack transferability and the ﬁnitedifference method  are
used they test their attacks on a dqn trained for energy
management of an electric vehicle and show the degradation of
performance
 manipulating the environment adversarial attacks on
the state space can also be carried out by adding perturbations
in the environment of the agent in turn this causes the agent
to consider the environment as the adversary desires chen et
al  propose cdg method for crafting adversarial examples
with high conﬁdence for the environment of drl the core
idea of their attack is the addition of confusing obstacles to the
original clean map for the case of pathﬁnding to confuse the
robot by messing with its local information for a perturbation
to be successful it should either stop the agent from reaching the
destination or otherwise delay the agent the proposed attack is
tested on ac and is shown to be successful at least  of
the time
bai et al  take a different approach than  and propose
a method of ﬁnding adversarial examples for dqns trained for
automatic pathﬁnding the proposed attack analyzes a trained
dqn for the task and identiﬁes the weaknesses present in the
qvalue curves especially designed perturbations are added to
these weaknesses in the environment to effectively refrain the
agent from learning an optimal solution to the maze
xiao et al  introduce online sequential attacks on the
environment of the drl agent by exploiting the temporal con
sistency of the states this attack performs faster than the fgsm
algorithm as no backpropagation is needed and is based on
model querying the authors provide two methods for model
querying adaptive dimension sfd method and optimal frame
selection method in addition to these sequential attacks they
also propose other attacks on the observations action selection
and environment dynamics
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee transactions on artificial intelligence vol  no  april 
gleave et al  propose to introduce an adversarial agent in
the same environment as the legitimate agent the adversary is
not able to manipulate the observations of the legitimate agent
but can create natural observations that can act as adversarial
inputs and make the agent follow the target policy this leads to a
zerosum game between the adversarial agent and the legitimate
agent both the adversarial and the victim agent are based on
ppo after showing the existence of such adversarial policies
they suggest that the learning of the deployed model must
be frozen to save them from undesired behaviors enforced by
adversaries such adversarial agents can also be used in making
the models better by constantly attacking and retraining
although the drl techniques work better in navigation tasks
they are more vulnerable to adversarial attacks than the classic
methods yang et al  introduce timingbased adaptive adver
sarialperturbationsforlearningbasedsystemsinrealworldsce
narios they introduce two attacks namely wma whitebox
setting and asa via a populationbased training method based
on pepg blackbox setting the ﬁrst one is based on online
learning while the other is based on evolutionary learning
through experiments they show that out of the two proposed
attacks the wma shows a better performance
 manipulating the training data the adversary can also
choose to perturb the training data to indirectly having the agent
follow a targeted policy an adversary may create and hide some
deﬁciencies in the policy to use them later for his beneﬁt kiourti
etalshowthisvulnerabilityofdrlmodelstotrojanattack
with adversary having access to the training phase of the model
it is reported that by only modifying  of the training data
an adversary can induce such hidden behaviors in the policy that
the models perform perfectly well until the trojan is triggered
the proposed attack is shown to be resistant against current
defense techniques for trojans
a similar approach has been proposed by behzadan and
hsu  to secure drl models from model extraction at
tacks but can be used for adversarial purposes this involves
the integration of a unique response to a speciﬁc sequence of
states while keeping its impact on performance minimum hence
saving from the unauthorized replication of policies it is also
shown that the unwatermarked policies are not able to follow
the identiﬁed trajectory which is speciﬁed during the training
as already discussed this can be used by adversaries to hide
speciﬁc patterns in the policy and use them to their beneﬁt later
 manipulating the sensors the research on realtime at
tacks on robotic systems in a dynamic environment has not
been much explored clark et al  evaluate a whitebox
adversarial attack on the drl policy of an autonomous robot in
a dynamic environment the goal of the drl robot is to reach
the destination by routing through the environment while the
goal of the adversary is to mislead the agent into the wrong
routes the adversary misleads the agent into following false
routes by tampering with sensory data they also observe that
once the adversarial input is removed the robot automatically
reverts to taking the correct route hence an attacker can modify
the behavior of the model temporarily and leave behind zero or
very little evidence their attack requires access to the trained
policy but not the hyperparameters used during training
a similar observation has been shown by usama et al 
theyarguethatalotofresearchisbeingdoneforcreatingaiml
solutions to problems in future networks such as internet of
things and g they show these ml systems to be vulnerable
by highlighting the adversarial dimension of these systems they
prove their point by attacking a drlbased channel autoencoder
framework and showing its drop in performance noise is added
to the feedback channel for a certain time interval furthermore
they show that when this noise is removed the drl system
automatically can regain its original performance leaving no
footsteps by the adversary
b attacks perturbing the reward function
han et al  discuss the reaction of the drl agent in sdn
to different adversarial attacks the adversary adopts whitebox
and blackbox settings for both inference and poisoning attacks
in an online setting they propose two types of attacks ﬂipping
reward signals and manipulating states for ﬂipping reward
signals the adversary can manipulate the binary reward signal
of the model by ﬂipping it a certain number of times for state
manipulation the attacker makes two changes in the ﬁrst few
steps of the training ie an adversary can change the binary
reward of two states from  to  and  to  respectively hence
the adversary can change the label of one compromised node to
be uncompromised and vice versa
a similar falsiﬁcation approach has been followed by huang
and zhu  leading the agent into taking targeted decisions
they characterize a robust region for policy in which the ad
versary can never achieve the desired policy while keeping the
cost in this region they use four terms to specify different types
of attackers  omniscient attacker who has all the information
before a certain time t  peer attacker who does not know about
the transition probabilities but has access to the knowledge the
agent has before a time t  ignorant attacker who only knows
the cost signals before a time t and  blind attacker that has no
information at time t all these attackers may be limited by the
budget of the attack and other constraints it is shown that by the
falsiﬁcation of the cost at each state all of these adversaries can
mislead the agent into learning a policy desired by the adversary
rakhsha et al  propose a trainingtime attack involving
the poisoning of the learning environment to force the agent into
executing a target policy chosen by the adversary they con
sider rl agents that maximize average reward in undiscounted
inﬁnitehorizon settings and argue this to be a more suitable
objective for many realworld applications that have cyclic tasks
or tasks without absorbing states eg a scheduling task and
an obstacleavoidance robot they suppose that the adversary
can manipulate the rewards and the transition dynamics in the
learning environment at training time in a stealthy manner they
test their attack in both ofﬂine and online settings in the former
the agent is planning in a poisoned environment while in the
latter the agent is learning a policy using a regretminimization
framework with poisoned feedback they show that the adver
sary can easily succeed in teaching an adversarial policy to the
rl agent
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
c attacks perturbing the action space
the adversary can have access to the actuators and might try
to perturb the actions taken yeow et al  propose two attacks
on the action space of the drl algorithms the ﬁrst one is an
optimization problem for minimizing the cumulative reward of
the drl agent with decoupled constraints called mas attack
the second one has the same objective as the ﬁrst one but with
temporally coupled constraints called las attack the results
show that las is more lethal in deteriorating the performance
of the drl algorithm as it can attack the dynamic information
of the agent this attack is also shown to perform well in the
case of limited resources such attacks can be used to gain
insights into the potential vulnerabilities of the drl model
they also speculate that their proposed attacks on reward signals
by perturbing the action space cannot be defended as the action
space is independent of the policy however it can be detected
by having a look at the decay in the reward
due to the difﬁculty of obtaining the complex models for
cyberphysical systems for traditional control they are being
shifted to drl lee et al  argue that before transferring
these systems to drl the security limitations of drl must be
understood they propose a querybased attack for perturbing
the action space of drl in such systems furthermore they
show that by the use of adversarial training the attack success
can be reduced to half
d attacks perturbing the model space
the adversary can have access to the model during or af
ter training based on this access the adversary might try to
manipulate the model into learning the adversarial behavior or
might also try to extract the learned model and use it later for
attack purposes behzadan and hsu  propose an adversarial
attack for targeting the conﬁdentiality of the drl policy the
proposed attack performs a model extraction attack by using
imitation learning while querying the original model iteratively
they show that the adversarial examples generated for the model
extractedaretransferredsuccessfullytotheoriginalmodelhence
affecting its performance in a blackbox setting they use the
fgsm for generating adversarial examples for the imitated
model it is also shown that by providing the attack a sufﬁcient
number of observations adversarial examples can be crafted
with high efﬁciency they use adversarial regret ie the differ
ence between maximum return achievable by the trained policy
π and return achieved from actions of adversarial policy as a
metric to measure the performance of their attacks they show
an increase in adversarial regret in case of an adversarial policy
chen et al  argue that the techniques used for model
extraction in supervised ml cannot be applied to rl due to high
complexity and limited observable information and propose a
technique for model extraction in drl at ﬁrst they use an
rnn classiﬁer to reveal the training algorithm of the target
blackbox drl model based on the predicted actions then
they use imitation learning to replicate the victim model from
the extracted algorithm a ppo is used for imitation learning
the extraction of models can be used by adversaries to generate
successful adversarial examples making deployed models even
more vulnerable to adversarial attacks
huai et al  propose an optimization framework for de
riving optimal adversarial attack strategy for model poisoning
attacks they propose two attacks one in which adversarial
perturbations are added to the observations of the agent and the
other in which the attacker modiﬁes the parameters of trained
models in such a way that their performance is not affected the
ﬁrst one is termed as universal adversarial attack against drl
interpretations uadrli while the latter is termed as a model
poisoning attack against drl interpretations mpdrli for
uadrli they assume that the adversary has access to a certain
area of the images states and cannot perturb pixels outside this
certainareatheperturbationsareonlyaddedatsometimesteps
e discussion
in this section we discuss the attacks on drl by categorizing
them based on the targeted part of the mdp the adversary
can target the state space action space reward function or the
modelspacebasedontheaccessavailabletotheadversarywhen
targeting the state space the adversary can add perturbations to
the environment training data observations and sensory data
in the case of perturbing the action space the adversary can
target the actuators in the case of perturbing the reward function
the adversary can perturb the reward signal or might ﬂip it in
the case of modelspace attacks the adversary can perturb the
learned parameters of the model or might attempt to extract
the learned model which might be proprietary ie owned and
copyrighted by some organization
in real environments the attacks that generate imperceptible
and natural perturbations are more practical than the attacks
that involve adding specially designed perturbations to states in
applications like autonomous driving getting direct access to the
sensors might not be possible for the adversary the only option
is to perturb the environment hence indirectly affecting the ob
servations actions rewards and policies the real environments
are often blackbox where the adversary has no knowledge of
the system being attacked and the number of queries is limited
the adversary has to improvise to attack the system where the
target of the adversary can be to cause a drop in performance
of the system or to evade the system this puts forward a need
for queryefﬁcient attacks similar to those proposed in  for
supervised ml to be proposed for drl
table i shows a summary of the adversarial attacks on drl
iv defenses against adversarial attacks on drl
in this section we provide a detailed review of the counter
measures proposed to deal with adversarial attacks on drl
fig  shows a basic taxonomy of the defenses that can be used
for securing drl algorithms
a adversarial training
adversarial training includes retraining of the ml model
using the adversarial examples along with the legitimate ex
amples this increases the robustness of the ml model against
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee transactions on artificial intelligence vol  no  april 
table i
summary of the adversarial attacks on drl pipeline highlighting the threat model and attack location in the drl pipeline
adversarial examples as the model is now able to learn a better
distribution although adversarial retraining can help improve
the robustness of the ml model the ml model can still be com
promised through adversarial examples generated through some
other methods the goal of adversarial training is to improve
the generalization outside of the training manifold kos and
song  proposed using adversarial training for robustifying
drl algorithms they retrain their agent on perturbations gen
erated using the fgsm and random noise and show performance
retention against similar attacks furthermore they observe that
the retrained agent is also resilient against fgsm perturbations
having magnitudes different than the one used for retraining
pattanaik et al  also adopt adversarial training as a
measure to make the algorithms robust against gb attacks they
show its equivalence to robust control they train the drl model
by using the adversarial samples generated from the gb attacks
this helps the algorithm to model uncertainties in the system
making them robust to similar adversarial attacks they show
that the addition of noise to the training samples while training
increases the resilience of the drl models against adversarial
attacks han et al  also propose adversarial training as a
method of robustifying the drl algorithms against adversarial
attacks they show that this technique is effective when coun
tering attacks such as node corruption and node falsifying in
sdn
behzadan and munir  ﬁnd the adversarially trained poli
cies to be more robust to testtime attacks they investigate the
robustness of drl algorithms to both training and testtime
attacks and ﬁnd out that under the trainingtime attack the dqn
can learn and become robust by changing the policy they
propose that for an agent to recover from adversarial attacks
the number of the adversarial samples in the memory needs to
reach a critical limit in this way when the agent samples a
random batch from the memory it can learn the perturbation
statistics they also compare the performance of ϵgreedy and
parameterspace noise exploration methods in case of adversar
ial attacks they show the ϵgreedy methods to be more robust to
trainingtime attacks than the noisy exploration technique they
also ﬁnd noisy exploration techniques to be able to recover faster
from attacks when compared to the ϵgreedy methods
later on behzadan and munir  compare the resilience
to adversarial attacks of two dqns one based on ϵgreedy
policy learning and another employed noisynets  which
is a parameterspace noise exploration technique their results
show the noisynets to be more resilient to trainingtime attacks
than that of the ϵgreedy policy they argue that this resilience is
due to the enhanced generalizability and reduced transferability
in noisynets they propose that by using parameterspace noise
exploration the drl algorithms can be made robust to attack
techniques like fgsm chen et al  propose a gb adversarial
training technique they use adversarial perturbations gener
ated using their proposed attacking algorithm ie cdg for
retraining the rl agent this approach can achieve a precision
of  in detecting adversarial samples they prove that
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
fig 
taxonomy of the major defense schemes used in drl
adversarial training using only a single adversarial example
generated using cdg can realize the generalized cdgattack
immunity of ac pathﬁnding with high conﬁdence behzadan
and hsu  propose age after considering the sample inef
ﬁciency of current adversarial training techniques their tech
niqueisbasedonamodiﬁedhybridoftheϵgreedyalgorithmand
the boltzmann exploration exploring probabilistically relative
to expected rewards the new adversarial training procedure
is tested on dqn trained for the cartpole environment with
different perturbation probabilities they show that for small
perturbationsprobabilitiesieandtheagentcanrecover
fromtheattackwhileinthecaseoflargeprobabilitiessuchas
or  the agent is not able to recover they compare the efﬁciency
of their proposed technique with ϵgreedy and parameterspace
noise exploration algorithms and prove its feasibility
tanetalarguethatalthoughthedrlalgorithmsusedfor
decision and control tasks are vulnerable to adversarial attacks
little research has been done to make them robust after showing
the vulnerability of welltrained drl agents to action space
attacks they use adversarial training to increase the robustness
oftheattackedmodelfurthermoreaperformanceimprovement
of the adversarially trained agent over the normal agent in
nonadversarial scenarios is also shown lee et al  also show
that the use of adversarial training with their proposed attack
decreases the attack success rate to half
vinitsky et al  argue that the existing literature on robust
learning in drl focuses on training a single rl agent against a
single adversary and these systems are bound to fail in the case
of a different adversary they propose a populationbased aug
mentation to the robust rl formulation in which a population
of adversaries is randomly initialized and samples are drawn
uniformly from the population during training
b gametheoretic approach
pinto et al  propose rarl as a method of robust policy
learning in the presence of an adversary they formulate policy
learning as a zerosum minimax objective function to ensure
robustness to differences in test and train conditions even in the
presence of an adversary they use a selfproposed adversarial
agent with an especially designed reward targeted at ﬁnding
the statespace trajectories that lead to the worst rewards they
call these trajectories hard examples an adversary is introduced
in the environment whose goal is to destabilize the rl agent
abdullah et al  propose a robust rl using a novel minmax
game with a wasserstein constraint for a correct and convergent
solver this technique shows a signiﬁcant increase in robustness
inthecaseofbothlowandhighdimensionalcontroltasks they
also discuss that by using their technique the ddpg algorithms
are not able to achieve signiﬁcant performance improvement
in robustness even in the case of inverted pendulum while
the other two drl schemes ie trpo and ppo demonstrate
acceptable performance and hence are reported in their results
bravo and mertikopoulos  examine a game approach
where the players adjust their actions based on past payoff
observations that are subject to adversarial perturbations in
the singleplayer case containing an agent trying to adapt to
an arbitrarily changing environment they show that irrespective
of the level of noise in the players observations the stochastic
dynamics under study leads to no regret almost surely in the
case of multiple players they show that the dominated strategies
become extinct and the strict nash equilibrium is stochastically
stable and attractive conversely a stable or attractive state
with better probability is the nash equilibrium finally they
provide an averaging principle and show that in the case of
twoplayer zerosum games with an interior equilibrium the
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee transactions on artificial intelligence vol  no  april 
time averages converge to nash equilibrium for any noise level
ogunmolu et al  propose an iterative minimax dynamic
game framework that helps in designing robust policies in the
presence of adversarial inputs they also propose a method of
quantifying the robustness capacity of a policy they evaluate
their proposed framework on a mecanumwheeled robot the
goal of this agent is to ﬁnd a locally robust optimal multistage
policy that achieves a given goalreaching task
c robust learning
robust learning is a training mechanism to ensure robust
ness against trainingtime adversarial attacks behzadan and
munir  propose adding noise to the parameter state while
training this technique is found very effective in mitigating the
effects of both training and testtime attacks for both blackbox
and whitebox settings the results of the proposed method are
tested on dqn trained for three atari games namely enduro
assault and blackout in particular the authors use the fgsm
for crafting adversarial samples then they show the perfor
mance of the normal agents to deteriorate signiﬁcantly while
the ones that were retrained using the parameter noise show
great performance even in the presence of adversarial inputs
mandlekar et al  show superior resilience to adversarial
attacks by introducing an arpl algorithm this involves the use
of adversarial examples during training to enable robust policy
learning they consider the addition of adversarial perturbations
not only to the image space but also to the whole state of the
system which in their case also included the parameters such
as friction mass and inertia they use the gb fgsm technique
for the generation of adversarial samples they show that in the
case of agents that do not follow their learning technique the
performance deteriorates drastically while their agent can retain
the training performance it is important to note that the agent
trained using the arpl algorithm does not perform as well as
the normal one in case of no perturbations
wang et al  point out that the reward function is suscep
tible to three kinds of noise namely inherent noise application
speciﬁc noise and adversarial noise as a remedy they propose a
rewardconfusionmatrixtogeneraterewardstohelptherlagent
to learn in cases of perturbednoisy inputs such rewards are
called to be perturbed rewards using these perturbed rewards
they can develop an unbiased reward estimatoraided robust rl
framework their algorithm not only achieves higher expected
rewards but also converges faster they experiment with their
technique extensively using several drl algorithms which are
trained for different classic atari gaming environments their
proposed technique can achieve  and  improve
ments in average reward when the error rate is  and 
respectively in the case of ppo they discuss both the cases
of the perturbations added to some samples and perturbations
being added to all samples
policies that can retain the performance in nonstationary
environments are also robust to adversarial attacks that involve
adding noise to the state space smirnova et al  propose
a distributionally robust policy iteration scheme to restrict the
agent from learning suboptimal policy while exploring in cases
of highdimensional stateaction space this induces a dynamic
level of risk to stop the agent from taking suboptimal actions
their scheme is based on robust bellman operators which
provide a lower bound guarantee on the policystate values
they also present a distributionally robust soft actorcritic
based on mixed exploration acting conservatively in the short
term and exploring optimistically in a long run leading to an
optimal policy the direct target in  is adversarial robust
ness while in  the direct target is distributional robust
ness hence the target of adversarial robustness was achieved
indirectly
tessler et al  propose prmdp and nrmdp as two
new criteria for robustness they modify the ddpg to form
arddpg for solving these mdps the proposed techniques
are evaluated in various mujoco environments and the results
prove that the learning of actionrobust policies can help in
making the proposed algorithms secure and perform better even
in the absence of these perturbations the adversarial robustness
was achieved here by making the agent action robust
kumar et al  present a technique to make the drl
algorithm learn in the presence of noisy rewards the proposed
scheme is based on using a neural network as a noise ﬁlter
targeted at estimating the true reward of the environment these
estimates are then compared with the reward the agent gets at
each state to ﬁlter out the noisy samples they show that beyond
the perturbation probability of  their agent starts to learn
based on adversarial samples rather than the normal ones
fisher et al  propose the idea of robust student dqn
rsdqntheyproposetosplitthestandarddqnintotwonet
works namely a student policy network s and a qnetwork
this s network is robustly trained and used for exploration
while the qnetwork is trained normally this permits online
robust training while keeping the competitive performance of
the qnetworks they show that in the case of no attacks the
dqn and the rsdqn show the same performance while
in the case of adversarial attacks the dqn fails while the
rsdqn remains robust furthermore they show that the rs
dqn when combined with stateoftheart adversarial training
provides resilience to strong adversarial attacks during training
and evaluation
pan et al  argue that training rl on physical hardware
is dangerous due to exploration and can also be slow due to
high sample complexity this puts forward a need for a robust
learning algorithm that can make sure that the policy performs
well in catastrophic situations they propose rararl using
a riskaverse agent and a riskseeking adversary they point
out that the rarl technique proposed by pinto et al 
has no explicit modeling and optimization of risk as they only
optimizetheexpectedcontrolobjectiveanensembleofqvalue
networks is used to model risk as to the variance of value
functions their technique is similar to bootstrapped dqns 
proposed to assist exploration but in this case the purpose of the
ensemble is to estimate variance they test their approach on a
selfdriving environment using the torcs simulator and show
that a riskaverse agent handles the risk better and leads to fewer
crashesthananormalagenttrainedinasimilarenvironment the
attacker and the victim agent are made to work independently in
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
the same environment this gives more options to the attacker
to perturb the environment hence serving as a strong adversary
the overﬁtting of rl policies to the training environments
cause them to fail to generalize to safetycritical scenarios
wang et al  argue that the rarl technique proposed
by pinto et al  requires handcrafting sophisticated reward
signals which is a difﬁcult task they say that safety falsiﬁcation
methodscanbeusedtoﬁndasetofinitialconditionsaswellasan
input sequence to make a system violate a given property formu
lated in temporal logic they propose an frarl technique for
integrating temporallogic falsiﬁcation in adversarial learning to
improve policy robustness this removes the requirement of the
construction of an extra reward function for the adversary their
experiments show that the policies trained with frarl gener
alize better and show less violation of the safety speciﬁcations
in test scenarios when compared to techniques similar to rarl
lütjens et al  argue that adversarial detection detecting
adversarial samples using specialized models can only detect
a perturbed input but they cannot propose an alternate action
in case of an attack they leverage the research on certiﬁed
adversarial robustness to develop an online certiﬁed defense for
drl algorithms called carrl carrl involves computing
lower bounds on the stateaction pairs and choosing a robust
action in case of an adversarial attack they make their tech
nique certiﬁable robust by using robust optimization to consider
worstcase uncertainties and to provide certiﬁcates on solution
quality they show the effectiveness of their technique on a
dqn trained for a collisionavoidance system and a classic
control task cartpole and using the targeted fgsm as an
adversary their experiments show that carrl can  recover
and avoid the obstacles in case of an adversarial attack on col
lision avoidance system and  recover and achieve a sufﬁcient
reward in cartpole environment furthermore they prove that
although their technique reduces the computational efﬁciency
of the dqn it increases the robustness
zhang et al  point out that the robustness for continuous
action space drl has not got any attention and existing ap
proaches lack proper theoretical justiﬁcation they prove that
the classiﬁcation techniques like that of adversarial training
prove to be inefﬁcient for many rl problems they develop
a theoretically principled policy regularization and propose an
samdp their technique improves robustness under strong
whitebox attacks on state observations including the two new
attacks that they have proposed the robust sarsa attack rs
attack and mad attack furthermore they show performance
improvement in nonadversarial scenarios they assume the ad
versary to  be stationary deterministic and markovian ie
the adversary does not change with time and  have bounded
adversary power ie the adversary can only perturb a speciﬁc
number of states
oikarinen et al  propose a method of training drl
agents robust to lpbounded attacks they termed their tech
nique radialrl furthermore they propose a new metric
greedy worstcase reward for evaluating the performance of
drl algorithms against adversarial attacks they show their
technique to outperform the stateoftheart robust learning tech
niques   under pgd attack
zhang et al  propose a technique to enhance the robust
ness of drl agents against learned adversary attacks ie at
tacks in which the adversary is continuously learning they term
their technique as alternating training with learned adversaries
atla their technique involves the training of an adversarial
agent online together with the victim agent using policy gradient
following the optimal adversarial attack framework
d adversarial detection
adversarial detection involves the detection of adversarial
samples using a model especially trained to segregate the true
samples from the adversarial ones in this way we can disregard
the adversarial inputs without modifying the original model lin
et al  propose a method of protecting the drl algorithms
from adversarial attacks by leveraging an actionconditioned
frame prediction module by using this technique they can
detect the presence of adversarial attacks and make the model
robust by using the predicted frame instead of the adversarial
frame they also compare their results with other ml defense
approaches to show the effectiveness of this technique the
techniques used for adversarial example generation are fgsm
cw  and basic iterative method  the present results
indicate that their proposed technique can detect adversarial
attacks with accuracy from  to 
havens et al  detect the presence of adversarial attacks
via a supervisory agent by learning separate subpolicies using
the mlah framework because this technique can handle the
attacks in the decision space it can mitigate the learned bias
introduced by the adversary they consider a policy learning
problem that is being attacked at speciﬁc periods the goal of
the adversary is the corruption of state space while the agent
is being trained they assume that while training the agent
learns subpolicies before learning the ultimate policy thus
the supervisory agent can detect the presence of the adversarial
examples due to them being unexpected they use a selfdeﬁned
adversarial agent having the ability to perturb the states before
they reach the agent for training the perturbations generated
by this agent are bounded by lnorm
xiang et al  propose an advanced qlearning algorithm
for automatic pathﬁnding in robots that is robust to adversarial
attacks by detecting the adversarial inputs speciﬁcally they
propose a model to predict the adversarial inputs based on a
calculation determined by ﬁve factors energy point gravitation
key point gravitation path gravitation included angle and the
placid point the weights for these ﬁve factors are calculated
based on the pca using these factors they train a model able
to achieve a precision of  in segregating adversarial inputs
from the normal ones
gallego et al  introduce tmdps a variant of mdp
this framework supports the decisionmaking process in the
drl setting against adversaries that affect the reward generating
process they propose a levelk thinking scheme resulting in a
new framework for dealing with tmdps they show that while
a normal qlearning algorithm is exploited by an adversary
a level learner can approximately estimate the adversarial
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee transactions on artificial intelligence vol  no  april 
behavior and achieve a positive reward integrating dqns to
tmdps is discussed as a future research path
e defensive distillation
papernot et al  propose the idea of using defensive dis
tillation to deal with adversarial attacks on ml schemes in this
techniqueonemodelistrainedtopredicttheoutputprobabilities
of another model that was trained with an emphasis on accuracy
using this technique dl models can be made less susceptible to
exploitation by adding ﬂexibility to an algorithms classiﬁcation
process using adversarial training carlini and wagner 
show that defensive distillation gives a false sense of robustness
against adversarial examples rusu et al  present a method
of extracting the policy of a dense network to train another
comparatively less dense network this new network can take
expertlevel decisions while being smaller in size this method
can also be used to merge multiple taskspeciﬁc policies into a
single policy they show that the distilled agents which were
four times smaller than dqns were able to achieve better
performance than the dqn they also show that the agents
having  times fewer parameters than the dqn were able to
achieve a performance of  as compared to  of the
dqn such networks are proved to be more stable and robust
to adversarial noise and attacks as they have fewer parameters
than their denser counterparts and hence decreasing the count
of attackable parameters
recently czarnecki et al  analyzed empirically and the
oretically each variant of distillation and reported the strengths
and weaknesses of each variant furthermore they propose ex
pected entropy regularized distillation which makes the training
much faster while guaranteeing convergence this technique can
be used in making the drl models robust to adversarial attacks
by leveraging learning information from a complex model into
a simpler one hence making the models robust to adversarial
attacks however as discussed by carlini and wagner 
using this technique alone may not be effective it needs to
be combined with other approaches like adversarial training
adversarial detection etc to be successful
qu et al  propose robust policy distillation ie a policy
distillation paradigm capable of achieving an adversarially ro
bust student policy without relying on any adversarial example
during student policy training they propose a policy distillation
loss consisting of a prescription gap maximization loss and a
jacobian regularization loss they perform a theoretical analysis
and show that their proposed mechanism ensures the learning of
robust policies during the distillation process they show their
technique to outperform the one proposed in 
f discussion
we discuss the stateoftheart defenses in this section by
categorizing them into adversarial training robust learning
adversarial detection defensive distillation and gametheoretic
approaches it can be seen that most of these techniques are only
effective against the speciﬁed type of adversarial attacks and
do not provide any guarantees against other types of attacks
most of these techniques focus on making the drl agent
learn a robust policy by use of different mechanisms such as
training using adversarial examples simulating minmax games
with adversaries using robust alternatives of mdps etc these
techniques are more practical than the ones involving adversarial
detection due to the advent of new attacking strategies by the
day one can never be sure that a detection mechanism will be
able to detect the attack furthermore it is worth noting that there
are very few defenses for drl algorithms that do not involve
images as the observations
table ii summarizes key information of the proposed defenses
for drl algorithms
v metrics tools and platforms for benchmarking
drl
as we have previously discussed drl is different from other
ml schemes and only reporting the accuracy is not sufﬁcient
to cover security aspects of the drl schemes in particular we
need to consider the temporaldomain aspect of the drl while
designing the drlbased attack or defense benchmarking the
drl performance in attacks and defenses is very important
the need for an applicable solution to evaluate the robustness
and resilience of drl policies is not fulﬁlled by the current
literature there is also a need for a quantitative approach to
measure and benchmark the resilience and robustness of drl
policies in a reusable and generalizable manner
therearefewbenchmarksproposedbuttheyarenotsufﬁcient
to cover the security aspects needed to measure the robustness
and resilience of drl algorithms the few proposed approaches
are discussed in this section behzadan and hsu  introduce
the terms of adversarial budget and adversarial regret as a
measure to quantify the robustness and resilience of drl algo
rithms adversarial budget is deﬁned as the maximum number
of features that can be perturbed in the observation and the prob
ability of perturbing each observation the adversarial regret is
the difference between the reward obtained by the unperturbed
agent and the reward obtained by the perturbed agent after an
episode based on these two terms behzadan and hsu 
deﬁne testtime resilience and testtime robustness
a testtime resilience and robustness
testtime resilience is described as the minimum number of
perturbations required to incur the maximum reduction to return
at time t while testtime robustness is described as the maximum
achievable adversarial regret
the following procedure is proposed to measure testtime
resilience for drl algorithms
 approximate the stateaction value function using policy
imitation in case it is not already given
 report the optimal adversarial return and maximum ad
versarial regret by training the adversarial agent against
the targets policy
 apply the obtained adversarial policy to the target for sev
eral episodes while recording the return for each episode
 report the average adversarial return over these episodes
as the mean testtime resilience of the target policy
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
table ii
summary of defenses against adversarial attacks on drl
the method of measuring the testtime robustness is the same
as testtime resilience the only difference is that in the testtime
case we measure the average adversarial regret in place of the
average adversarial reward
behzadan and munir  propose a novel framework for
benchmarking the behavior of drlbased collision avoidance
mechanisms under the worstcase scenario of dealing with an
adversarial agent which is trained to drive the system into unsafe
states they prove the practical applicability of the technique
by comparing the reliability of two collision avoidance systems
against intentional collision attempts more recently behzadan
and hsu  have presented a technique for watermarking
drl policies for robustness against model extraction attacks
this involves the integration of a unique response to a speciﬁc
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee transactions on artificial intelligence vol  no  april 
sequence of states while keeping its impact on performance
minimum hence saving from the unauthorized replication of
policies it is shown that unwatermarked policies are not able
to follow the identiﬁed trajectory
b metrics for attack performance
kiourti et al  introduce three metrics for measuring the
performanceofthedrlattacksperformancegappercentageof
target action and time to failure as the name suggests the per
formance gap is the difference between the performance of the
normal and the victim model for the second metric percentage
of target action they measure the number of times the adversar
ialtargeted action is performed by the victim policy the third
metric time to failure is the number of consecutive states that
need to be perturbed to trigger a complete failure of the model
as observed these proposed measurement techniques can
only cover a part of the drl algorithms and hence are not
sufﬁcient for measuring the performance of the drl algorithms
under the wide range of adversarial attacks and defenses there
is therefore a need for the development of benchmarks that can
be used as standards for drl algorithms as a measure of their
resilience and robustness to adversarial attacks
c attacking drl tools and platforms
drl can be implemented using several available toolkits or
by using a combination of these toolkits some of the ways to
implement drl are the following
 openai gym  is a toolkit for testing the rl al
gorithms which provides with multiple gaming environ
ments such as pong space invaders and lunar lander this
toolkit is combined with tensorﬂow  to test the drl
algorithms the dnn part can be implemented on the later
one and then the choice of actions based on the states is
done by the neural network
 openai baselines  provide a set of highquality
implementations of rl algorithms
 rlcoach  provides with integrated mechanisms of
implementing the dnn and testing drl algorithms
 horizon  is an opensource project now known as
reagent  that also provides integrated mechanisms
for testing multiple drl algorithms
 nsgym platform  provides with network environ
ments to test rl algorithms this again can be combined
with tensorﬂow  to test drl algorithms
all of these toolkits can be further combined with the toolkits
available for attacking dl  and drl  to test dif
ferent attacks and defenses on drl algorithms in simulated
environments
vi open issues and research challenges
we identify the following major open issues and research
challenges in drl techniques at the end of this section we
have also provided a roadmap to secure and robustify drl
a universally robust algorithms
despite the presence of the various defenses that have been
proposed the security of drl algorithms remains an open
challenge the proposed defenses are only able to defend from
attacks they are designed for hence they are still vulnerable
to attacks led by proactive adversaries moosavidezfooli et
al  point out that no matter how many adversarial examples
are added to the training data there are new adversarial examples
that can be generated to cheat those newly trained networks
moreover if the adversary is only targeting conﬁdence levels
then we may never be able to detect the attack until the adversary
uses his created deﬁciency for his beneﬁt we may not be even
able to trace the attacks as shown by clark et al  thus
methods to make the drl algorithms more robust are an urgent
need
b multitask learning
one of the major challenges for drl is learning to do
multiple tasks at a single time it requires a lot of samples
for this currently proposed drl algorithms can only learn to
perform one task perfectly they can be trained to play multiple
games like cartpole inverted pendulum etc but they need
to be trained from scratch for each game the algorithms are
expected to be scalable and be more generalizable so that their
learning can be transferred from one game to another multitask
learning can help in making robust models that can grip the
true essence of the tasks and hence become difﬁcult to be
fooled
c metrics for robustness and resilience
we need to study why vulnerabilities exist in drl models
and how we can mitigate them and train robust models a major
reason for the existence of these vulnerabilities is the use of drl
models without the proper knowledge of the domain there is a
need to properly deﬁne the benchmarks of drl in terms of the
robustness of drl against adversarial attacks behzadan and
hsu  have proposed techniques for quantifying the robust
ness and resilience of the rl algorithms some benchmarks are
also proposed by kiourti et al  but as previously discussed
these benchmarks are inadequate to measure the robustness and
resilience of an algorithm even though they can be used as
stepping stones to lead to a ﬁnal goal
d system design and transferability
system design remains an open challenge for the case of drl
there is a need to deﬁne standards for system design for drl
problems as in this case the learning process is not supervised
so the agent may not focus on the features that it needs to
learn this can introduce the error by mistake of the intermediary
and also even induce his behavior on the model we need to
have proper standards for designing the reward functions the
system design needs to be robust and resilient to adversarial
attacks
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ilahi et al challenges and countermeasures for adversarial attacks on deep reinforcement learning
e ensemble of defenses
various ensemble defenses have been proposed for the case
of dl however they may not be appropriate to apply in the
case of drl as it can lead to an exponential increase in the
complexity of the model which results in a signiﬁcant decrease
in performance in the case of drl the model is making a
realtime prediction so a small reduction in the computation
capabilities may cause a great loss to the agent this remains
a challenge to defend drl models using an ensemble with a
minimum loss of computations
f model privacy
privacy has become a leading issue these days and model
extraction attacks pose a serious threat to the integrity of the
learned models through illegal duplication a mitigation for this
suggested by behzadan and hsu  is to increase the cost of
such attacks or to watermark the policies we may experience
some randomness in the agent to save from such attacks but
that will incur an unacceptable loss of decreased performance
developing techniques that can incur constrained randomization
in the model to save from such attacks is a promising ﬁeld of
research
g explainable and transparent drl
fordeployingaisystemsinrealworldscenariostrustisakey
componentthedeveloperneedstobeconﬁdentoftheemployed
models decisions transparency ensures that the model is fair
and ethical while explainability helps to explain and justify the
models decisions there are a few articles that discuss explain
ability for drl   current techniques for explaining
drl do not speciﬁcally focus on targeting speciﬁc audiences
ie tester developer and the general public and there is a need
for the development of such techniques  only through
their development we might be able to make drl responsible
trustworthy and applicable in critical applications
h transfer learning for drl
transfer learning  is a ﬁeld of ml that does not require
the training data and test data to be independent and identically
distributed the model is not needed to be trained from scratch
in case of a different domain hence signiﬁcantly reducing the
demand of training data and training time of the target model
the research on transfer learning in the context of drl has been
limited and there are a few papers that test and discuss transfer
learning for only some speciﬁc drl algorithms  transfer
learning can help with saving training time for these models
hence making drl more applicable to realworld scenarios
i roadmap toward secure and robust drl
the ultimate goal of research in ai is to develop agi which
can perform similar activities as humans in a more efﬁcient
mannerinadditiontothealgorithmbeingabletolearnthetaskat
hand efﬁciently it also has to be computationally efﬁcient while
being robust to adversarial attacks furthermore algorithms
need to be sample efﬁcient to be able to learn quickly in real
environments as there might not always be enough time to wait
for the algorithm to converge meeting all these requirements
at the same time is a challenging task and one has to strike
intelligent tradeoffs between them
in this regard the ﬁrst task to achieve is the development
of sampleefﬁcient and inherently robust drl algorithms the
second task is the development of explainability techniques
whichcanexplainthebehaviorofthesealgorithmsinaccordance
with human perception the ﬁnal task will be the development of
metrics that can be used to quantify the robustness and resilience
of these drl algorithms based on these metrics and the sample
and computational efﬁciency one can then choose the most
suitable algorithm for the task at hand
vii conclusion
the broadening applicability of drl in the real world has
directed our concern to the security of these algorithms against
adversarial attacks this article has provided a comprehensive
survey of the latest techniques proposed for attacking drl
algorithms and the defenses proposed for defending against
these attacks we have also discussed the open research issues
and provided the list of available benchmarks for measuring the
resilience and robustness of drl algorithms
acknowledgment
the statements made herein are solely the responsibility of
the authors
see discussions stats and author profiles for this publication at httpswwwresearchgatenetpublication
design challenges in wireless  data networks security as case study course
report
technical report  april 
citations
reads
 author
muhammad usama
 publications    citations   
see profile
all content following this page was uploaded by muhammad usama on  april 
the user has requested enhancement of the downloaded file
design challenges in wireless  data networks
security as case study course report
muhammad usama
information technology university itupunjab lahore pakistan
abstract
this report covers the design evolution shortcomings and future design challenges in wireless and data networks
security is considered as a use case to describe current architectural and design issues in wireless and data networks
this report also covers the technical and socioeconomic tussles in the current design i have also purposed a new
cognition cycle to improve the current state of the art in the wireless cognitive network which involves radio sensing
state of the art machine learning knowledge base estimation and decision making this new cognition cycle will
ensure systems thinking based security architecture by incorporating knowledge base
i
introduction
an inexpensive instrument not bigger than a watch will enable its bearer to hear anywhere on sea
or land music or song the speech of a political leader the address of an eminent man of science or the
sermon of an eloquent clergyman delivered in some other place however distant in the same manner any
picture character drawing or print can be transferred from one to another place  nicola tesla
modern wireless and data communication systems are a combination of different distributed architectures
which involves many underlying applications technologies and networking policies the ﬁfth generation
of communication technology is expected by the year  with this new networking generation different
allied networking and computational regimes such as the internet of things pervasive computing ubiquitous
computing approximates computing and approximate networking is expected to contribute in building
towards the network of everything cost of computing and networking hardware is expected to decay
exponentially and with that networking cost also decays rapidly this massive transition and new networking
regimes have got research community to think of new alternative networking designs for wireless and data
communication in this section we will brieﬂy introduce and discuss the issues in previous and current
networking architecture we will also provide a list of problems in current networking architecture this
section will also include the social and economic challenges for next generation networking architecture
a design evolution of wireless  data communication networks
 legacy wireless communication network legacy networking architecture lacks the ability of cog
nition they usually follow a strict rulebased policy in determining the allocation of spectrum resources
identiﬁcation of transmission channel interference temperature and many other network related information
these rulebased systems initially work ﬁne for a small set of users with limited quality of service qos
requirements but as the wireless network grows in the number of users and their service requirements
these strict rulebased systems with no cognition ability were not able to deliver the optimal performance
the major reason for this failure lies in the ossiﬁcation of the network design which did not allow the
transmitter and receiver to learn from the dynamic environment and results in bad network performance
poor qos and wastage of network resources
 crosslayer wireless networking communication systems were designed in a strict layered approach
where each layer performed prespeciﬁed tasks and follows strict layering principals to perform these
prespeciﬁed tasks the major shortcoming of this design was the lack of the operational information
dissemination to other layers which is a major hindrance in fulﬁlling the necessary architectural design
requirements of wireless communication system another reason for this failure was the timevarying nature
of the wireless channel to overcome these issues a crosslayer designing approach for wireless network was
used where joint optimization of networking protocols across different layers and improved coordination
among different layers was introduced fundamentally crosslayer wireless network architectures are based
on sharing the knowledge of physical and media access control mac layer of the wireless channel with the
layers above them this information sharing solves the critical problem of resource allocation in wireless
networking the major problem with this design approach is its lack of dynamic behavior adaption of
the wireless network user diversity and different qos demands of users and this lack of adaption has a
negative effect on the tradeoff between performance and interoperability
 cognition based networking the rapid expansion of the wireless communication and the internet
has resulted in a complex heterogeneous design which requires the network to be capable of dynamically
adapting from the surroundings for intelligent resource allocation and interoperability the ossiﬁed legacy
layered network design and the stringently bounded crosslayer architecture are not able to meet the diverse
needs of the new era of wireless communication systems to meet these challenges the idea of cognition
is taken from psychology and implemented in wireless communication network design this new paradigm
was named as cognitive radios
a spectrum access  utilization before moving ahead with cognitive radios we need to mention
another major issue which causes the diversion from crosslayer design to a more intelligent cognition based
design this issue is known as spectrum access and utilization the electromagnetic spectrum is a scarce
natural resource regulated by governments the expected exponential growth in connected devices and
proposed small densely connected topologies for upcoming communication systems will have a disruptive
effect on spectrum allocation and utilization similarly rapid growth in the adaption of new communication
technologies and reduced cost of access for personal and corporate use has raised serious questions about
the availability and utilization of electromagnetic spectrum federal communications commission fcc
published a report in  which is considered to be a very ﬁrst document reviewing the  years of
spectrum allocation and usage this report characterized the potential issues in electromagnetic spectrum
allocation and usage  utilization of electromagnetic spectrum is biased in terms of occupancy of
frequency bands in the spectrum when we sweep the whole frequency spectrum few frequency bands
are vacant most of the time few are partially loaded and rest of them are heavily loaded this uneven
distribution of frequency bands usage causes underutilization of the electromagnetic spectrum
according to the fcc report underutilization of the electromagnetic spectrum will be the most signiﬁcant
problem in future communication systems underutilization of electromagnetic spectrum occurs due to two
major causes namely traditional command and control procedures and ﬁxed spectrum assignment policy
this underutilization leads to a phenomenon known as spectrum holes a spectrum hole is caused when
the primary user a primary user is the one which buys the license form the regulatory body and regulatory
body assigns a frequency spectrum for a geographical area for a mutually decided time to which a certain
frequency band is assigned for a certain time does not utilize it completely
in  mitola et al  proposed a solution to this ﬁxed spectrum assignment policy by utilizing the
spectrum holes for secondary users users with no spectrum license opportunistically this policy is known as
dynamic spectrum access dsa opportunistic behavior involves sensing the surrounding environment and
adapting to the statistical variations to extract the best possible result this sensing reasoning and adapting
behavior is known as cognitive behavior by incorporating cognitive behavior mitola et al  in the
year  purposed a new paradigm of intelligent wireless communication systems called cognitive radios
which has the ability of sensing the statistical changes in incoming radio frequency signals and making
corresponding changes in certain network operating parameters this reasoning and adaptive behaviour
has two primary objectives highly reliable communication whenever and whereever needed and efﬁcient
utilization of frequency spectrum
cognitive radios introduced a sensing and reconﬁguring approach in networking but this design approach
has some serious issues like detection of weak signals from primary users before sharing the spectrum
with the secondary user it required a tighter control over the secondary user to avoid interference and
this control has killed the whole idea of opportunistic networking to solve this issue a new intelligent
sensing algorithm along with customized transceiver was required another major challenge is to manage
the tradeoff between the censored radius of the primary user and interference power to avoid the shadowing
similarly dynamic nature of wireless channel and diverse qos demands needed a revised rate and capacity
adaption algorithms for cognitive radios to work cognitive radios proved to be a much better design than
previous crosslayer or legacy wireless designs but due to aforementioned ﬂaws in cognitive radios design
it was not very successful but it paved a path towards intelligent wireless networking
b design challenges for next generation of wireless  data communication networks
now lets take a look on the issues in current wireless and data network designs heterogeneity com
plexity and dynamic nature are the three fundamental properties of next communication generation the
communication architecture and the internet were not designed to fulﬁll these properties with the emergence
of new technologies such as the internet of things multicore architectures and exponential social adaption
of these new technologies have rapidly increased the complexity of the wireless communication systems
this has also increased the qos bar for the applications to meet the qoe of the users with all these new
technologies wireless communication and the internet have become a bounded closed loop system with
multiple tradeoffs and restriction to avoid multiple performance issues but now these strict policies have
become a bottleneck in designing nextgeneration communication systems
 network management as mentioned earlier there is an exponential increase in new innovative ap
plications of the internet and wireless communication technologies but we are lagging behind in network
management and this is very alarming given the expected number of connected devices and their diverse
nature network management has lagged behind in innovation curve because of fundamental strict bounded
internet and wireless communication system design to meet the challenges of nextgeneration communi
cation systems and connectivity requirements we need to think a new selforganized network management
systems
 field of view of protocols wireless networks and the internet employs multiple protocols to make
communication between transmitter and receiver possible these protocols are limited in their ﬁeld of view
and information sharing abilities with the complete network whenever we need to integrate a new system
we introduce a protocol in the software and then keep on updating the protocols to ﬁx the raised issues due
to variable network conditions users qoe and security reasons although we employee all these ﬁxes still
we are lagging behind in user qoe applications qos security etc this is because the problem does not
lie in protocols it lies in the protocols limited ﬁeld of view and their inability to model holistic network
systems due to shortcomings the operators are not able to have a complete picture of what is happening
in the network this causes multiple technical issues at the operator which also reﬂects on consumers qoe
although network function virtualization softwaredeﬁned networking and centralized control have offered
a solution of the protocol problem but apple does not the apple doesnt fall far from the tree these schemes
have their shortcomings and these shortcomings have their basis in rule based switching of sdn and closed
form of networking so in order to design nextgeneration networks we need to increase the ﬁeld of view
of a network protocol and rethink the restriction on the coordination among the networking protocols
 measurement  quantiﬁcation measurement and quantiﬁcation process of the wireless communi
cation systems and the internet is of critical importance it is used for network planning and resource
allocation this process is usually decoupled from network control and performed ofﬂine and this is a
major shortcoming in current network design since most of the next generation networks are considered
to be selforganized they need measurement and quantiﬁcation process to be realtime and distributed to
get a better view of network statistics to make an intelligent decision
 knowledge base current wireless communication and data network architectures mostly use rule
based or threshold based decisionmaking strategies for their operation automation recommendation and
troubleshooting process very few applications such as sdn employees artiﬁcial intelligence ai for
decision making when we consider designing a nextgeneration communication network this lack of
adaption of intelligent machine learning techniques in current wireless and data communication networks
is a very alarming problem the adaption of ai in networking along with centralized control and strong
network analytics forms a knowledge base and provides the ability of realtime inference which is a
fundamental property of selfdriven future networks
 tussles current networking architecture has a distinctive perhop behavior for example routing
there are many parties involved in how to perhop behavior should look like these parties have their own
agenda or function that they need to fulﬁll these agenda can be aligned to the network overall function or
these agenda have an adverse nature to optimize the network behavior to its own advantage without caring
much about the overall system this property is termed as tussle  tussles have its basis in different
social political conﬂicting interests biased users ptheme article aipowered g services
examining machine learning for g and
beyond through an adversarial lens
muhammad usama
 inaam ilahi and junaid qadir
 information technology university lahore 
pakistan
rupendra nath mitra and mahesh k marina the university of edinburgh edinburgh eh yl uk
spurred by the recent advances in deep learning to harness rich information hidden
in large volumes of data and to tackle problems that are hard to modelsolve eg
resource allocation problems there is currently tremendous excitement in the
mobile networks domain around the transformative potential of datadriven
artiﬁcial intelligencemachine learning aiml based network automation control
and analytics for g and beyond in this article we present a cautionary perspective
on the use of aiml in the g context by highlighting the adversarial dimension
spanning multiple types of ml supervisedunsupervisedreinforcement learning
and support this through three case studies we also discuss approaches to
mitigate this adversarial ml risk offer guidelines for evaluating the robustness of
ml models and call attention to issues surrounding ml oriented research in g
more generally
a
considerable amount of industry and aca
demic rd endeavors are currently paving
the way toward g and beyond g bg
networks g networks unlike their g counter
parts are foreseen to be the underpinning infra
structure
for
a
diverse
set
of
future
cellular
services well beyond mobile broadband to span
multiple vertical industries to ﬂexibly and cost
effectively support diverse usecases and to enable
complex network functions at scale g network
design espouses several innovations and technolo
gies such as artiﬁcial intelligence ai along with
softwaredeﬁned networking network function vir
tualization
nfv
multiaccess
edge
computing
mec and cloudnative architecture that are new
to the domain of mobile telecommunications
technical developments toward g and bg of
mobile networks are quickly embracing a variety of
deep learning dl algorithms as a de facto approach
to help tackle the growing complexities of the network
problems however the wellknown vulnerability of the
dl models to the adversarial machine learning ml
attacks can signiﬁcantly contribute to broadening the
overall attack surface for g and beyond networks
this observation motivates us to deviate from the on
going trend of developing a newer ml model to
address a g network problem and instead examine
the robustness of the existing ml models in relation
to the g networks under adversarial ml attacks in
particular we focus on representative use cases for
deep neural network dnn driven supervised learning
sl unsupervised learning ul and reinforcement
learning rl techniques in the g setting and high
light their brittleness when subject to adversarial ml
attacks
through this article we would like to draw the
attention of the research community and all stake
holders of g and beyond mobile networks to seri
ously consider the security risks that emerge from the
rapid unvetted adoption of dl algorithms across the
wide spectrum of network operations control and
automation and urge to make robustness of the ml
models a criterion before they are integrated into
deployed systems overall we make the following two
contributions
 we highlight that despite the wellknown vulner
ability of dl models to adversarial ml attacks
there is a dearth of critical scrutiny on the
impact
of
the
widescale
adoption
of
ml
   ieee
digital object identiﬁer mic
date of publication  january  date of current version
 april 
ieee internet computing
published by the ieee computer society
marchapril 
 authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
techniques on security attack surface of g and
bg networks
 we bridge the aforementioned gap through a
vulnerability study of the dl models in all its
major incarnations sl ul and deep rl drl
from an adversarial ml perspective in the con
text of g and bg networks
background
primer on g architecture
a schematic diagram of the g network architecture
is depicted in figure  apart from the user equipment
the g system features a cloudnative core network a
ﬂexible
and
disaggregated
radio
access
network
ran and a provision for mec cloud for reduced
latency the ran comprises gnodeb gnb access
nodes split into du and cu to efﬁciently handle
evolved network requirements the gnb connects to
the mec to signiﬁcantly reduce the network latency
for selected applications by availing edge server com
puting at the mec cloud which is close to the radio
service cells for instance to cater to the ultrareliable
lowlatency
communication
urllc
usecase
of
industry automation the ran radio unit along with
the du cu and the mec can be installed onsite
thus g network architecture enables applications to
be deployed remotely app  and app  or near the
edge app  and app  latter when low latency is a
requirement the provision of mec also reduces the
aggregated trafﬁc load on the transport networks
responsible for connecting ran to the core network
the g core network is a cloudnative network that
stores subscriber databases and hosts essential vir
tualized network functions for network operations
and management although the network management
and control functions are shown to be colocated with
the core in the ﬁgure they can be ﬂexibly deployed at
the edge as needed
ml in g and bg networks
a wide spectrum of dl algorithms is being developed
for the broad context of wireless communications and
g networking to deal with problems that are either
hard to solve or hard to model for instance optimal
physical network resource allocation for nfv is an np
hard problem and so require exponential computa
tional power with increasing system size drlbased
solutions are proposed to efﬁciently address resource
allocation problems network channel estimation for
efﬁcient beamforming is a hard to model problem for
which dnnbased sl solution offers an effective way
to tackle it moreover in certain usecases conven
tional expert systems become inappropriate due to
realworld constraints such as limited availability of
power where ai can perform effectively for instance
deep autoencoder based systems can replace the
powerhungry rf chain hardware with small embed
ded sensor systems enabling them to sustain longer
on onboard power supplies dl algorithms generally
outperform the conventional approaches in solving
mobile network prediction problems such as physical
layer channel prediction by sl signal detection prob
lems such as recovering transmitted signals from
figure  schematic diagram of g network architecture illustrating the disaggregated ran architecture with distributed unit
du and centralized unit cu components the mec for improved latency and the cloudnative core network and system
orchestration components
marchapril 
ieee internet computing
aipowered g services
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
noisy received signals by ul and optimization prob
lems like resource allocation by rl
widened attack surface in
mldriven g and bg
networks
the security of the g networks is receiving great deal
of attention eg but there is very limited focus on
the security of g and bg networks in the face of
adversarial ml threat in this section we brieﬂy intro
duce the adversarial ml in general and subsequently
outline the adversarial ml risks in g and bg
networks
overview of security attacks on ml
the vulnerability of the ml algorithms especially the
dl models to the adversarial attacks is now well
established where adversarial inputs are small care
fully crafted perturbations in the test data built for
fooling the underlying ml model into making wrong
decisions an adversary can often successfully target
an ml model with no knowledge of the model black
box attack or some knowledge graybox attack or
full knowledge whitebox attack of the target model
an adversary can attack the model during its training
phase and in its testing phase as well the training
phase attacks are known as poisoning attacks and
the test time attacks are known as evasion attacks
evasion attacks are commonly known as adversarial
attacks in the literature
more
formally an
adversarial
example x
is
crafted by adding a small indistinguishable pertur
bation d to the test example x of a trained ml clas
siﬁer fðþ where d is approximated by the nonlinear
optimization
problem
provided
in
equation
where t is the class label
x ¼ x þ arg min
dx fkdk  fðx þ dþ ¼ tg
in  szegedy et al observed the discontinuity
in the dnns inputoutput mapping and reported that
dnn is not resilient to the small changes in the input
following on this discontinuity goodfellow et al pro
pose a gradientbased optimization method for craft
ing adversarial examples this technique is known as
fast gradient sign method papernot et al craft adver
sarial
perturbation
using
a
saliency
mapbased
approach on the forward derivatives of dnn this
approach is known as jacobian saliency map based
attack carlini and wagner crafted three different
adversarial attacks using three different distance
matrices l l and l more details about adversar
ial ml attacks are described in
it is important however to note that the adversary
does not need to have access to training or test data
sets instead adversarial examples can also be gener
ated using query efﬁcient gradientbased techniques
zerothorder optimization techniques and generative
models in such methods the adversary uses query
response pairs to craft such adversarial examples
inputs and mislead the ml model such pairs are not
figure  applicability of ml across the g network architecture and a depiction of how ml models contribute to signiﬁcantly
enhance the attack vectors beyond the traditional security risks with new adversarial ml risks
ieee internet computing
marchapril 
aipowered g services
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
necessarily part of either training or testing datasets
therefore adversarial examples are not just the result
of an input data security issue
added threat from adversarial ml for
g and beyond
figure  illustrates network problems from different
network segments of g namely user devices ran
mec core networks and the network management
and control layer that have recently attracted ml
based solutions from all the three categories of ml
however in light of the above discussion in the sec
tion titled overview of security attacks on ml the
dlpowered ml models gaining popularity for g and
bg
networks
are
vulnerable
to
the
adversarial
attacks thereby further aggravating the security risks
of future generations of mobile networks
to show the feasibility of adversarial ml attacks on
g systems we take three wellknown ml modelsone
from each of the three ml families of algorithms ul sl
and drlfrom wireless physical layer operations rele
vant to g and bg context and show the vulnerability
that naive use of ml brings to future mobile networks
we choose all the three ml models for our case studies
from the physical layer network operations because of
the maturity of mlresearch in the context of aidriven
g networking and the availability of opensourced ml
models backed up with accessible datasets https
mlccommitteescomsocorgresearchlibrary
three case studies
highlighting adversarial ml
risk for g and beyond
attacking supervised mlbased g
applications
automatic modulation classiﬁcation is a critical task
for intelligent radio receivers where the signal ampli
tude carrier frequency phase offsets and distribution
of noise power are unknown variables to the receivers
subjected to realworld frequencyselective timevary
ing channels perturbed by multipath fading and shad
owing
the conventional
maximumlikelihood
and
featurebased solutions are often infeasible due to the
high computational overhead and domain expertise
that is required to make modulation classiﬁers more
common in modern g and bg networked devices
current approaches deploy dl to build an endtoend
modulation classiﬁcation systems capable of auto
matic extraction of signal features in the wild
we pick a convolutional neural network cnn
driven slbased modulation classiﬁcation model in
this case study to illustrate the added dimension of
vulnerability introduced in the networks by it we use
the wellknown gnu radio ml rmla dataset
that consists of  input examples of  digital
and analog modulation schemes amdsb amssb
wbfm pam bpsk qpsk psk qam qam
cpfsk and gfsk on the signaltonoise ratio snr
ranging from  to  db however we exclude the
analog modulation schemes from our study and con
sider only the eight digital modulations from the data
set because from g onward all mobile wireless
standards are strictly digital communications figure 
depicts the classiﬁcation performance of the cnn
model in the multiclass modulation classiﬁcation for
the signals between  and  db of snr
to show the feasibility of an adversarial ml attack
on the cnnbased modulation classiﬁer we make the
following assumptions
 we consider the whitebox attack model where we
assume that the adversary has a complete knowl
edge about the deployed modulation classiﬁer
 goal of the adversary is to compromise the
integrity of the cnn classiﬁer leading to a signiﬁ
cant decay in the classiﬁcation accuracy which
is the measure of the success of the adversary
to craft the adversarial examples to fool the cnn
classiﬁer we use the carlini and wagner cw
attack for each modulation class by minimizing the
l norm on the perturbation d such that when the per
turbation d is added to the input x and sent to the
cnnbased modulation classiﬁer c it misclassiﬁes the
input x more details on the cw attack are available
figure  accuracy of the cnnbased automatic modulation
classiﬁer before and after the adversarial ml attack a clear
drop in the accuracy of the classiﬁer with the increasing snr
indicates the success of the adversary in compromising the
integrity of the modulation classiﬁer that is seen as viable in
the g and bg networks
marchapril 
ieee internet computing
aipowered g services
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
in the performance of the cnnbased modulation
classiﬁer before and during the adversarial attack is
depicted in figure  a distinct drop in the accuracy of
the modulation classiﬁcation after the adversarial
attacks indicates the brittleness of deep supervised
ml in g and bg applications moreover our results
show that the adoption of unsafe dl models in the
physical layer operations of the g and bg networks
can make the airinterface of the future networks vul
nerable to adversarial ml attacks
attacking unsupervised mlbased g
applications
in  oshea et al proposed the idea of channel
autoencoders which is an abstraction of how an end
toend radio communication module functions in real
world wireless systems such a deep autoencoder
based communication model is seen as a viable alter
native to the dedicated radio hardware in the future g
and beyond networks figure a depicts the concep
tual design of the channel autoencoder that we choose
as a deep ul model for this case study we assume the
model is subjected to an additive white gaussian noise
awgn channel and apply the parameter conﬁgura
tions provided in to perform the adversarial ml
attack on the channel autoencoder we consider the
following threat model and compare the performance
of the model with and without attack
 we assume a whitebox setting where the adver
sary has complete knowledge of the deployed
ml model we further assume that the autoen
coder learns a broadcast channel the proposed
adversarial attack on channel autoencoder can
be converted into a blackbox adversarial attack
where the adversary has zero knowledge of the
target ml model by following the surrogate
model approach provided in
 the goal of the adversary is to compromise the
integrity of channel autoencoder and the suc
cess of the adversary is measured by the ele
vated bler with improving snr per bit ebn
we take the following twostep dataindependent
approach to craft adversarial examples for the chan
nel autoencoder
 sample
the
gaussian
distribution
randomly
because the channel is awgn and use it as an
initial adversarial perturbation d
 maximize the mean activations of the decoder
model when the input of the decoder is the per
turbation d
this produces maximal spurious activations at
each decoder layer and results in the loss of the integ
rity of the channel autoencoder figure b shows the
performance of the model before and under the adver
sarial attack moreover the ﬁgure suggests that
adversarial ml attack often outperforms the tradi
tional jamming attacks
since the idea of channel autoencoder in a wire
less device is to model the onboard communica
tion
system
as
an
endtoend
optimizable
operation the adversarial ml attacks on channel
autoencoder show that the application of unsuper
vised ml in the g mobile networks increases its
vulnerability to adversarial examples hence we
figure  a architecture of channel autoencoder for g and future networks proposed in b performance of the channel
autoencoder before and under the adversarial ml attack and traditional jamming attack the block error rate bler versus
ebn curves indicates that adversarial ml attack does not only deteriorate the models performance but also leads to similar
or worse performance than with a known jamming attack
ieee internet computing
marchapril 
aipowered g services
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
argue that deep ulbased g networked systems
and applications need to be revisited for their
robustness before being integrated into the g iot
and related systems
attacking reinforcement mlbased g
applications
in the ﬁnal case study we performed the adversarial ml
attacks on an endtoend drl autoencoder with a noisy
channel feedback system goutay et al take the
same architecture we consider in the previous case
study see the section titled attacking unsupervised
mlbased g applications and add a noisy feedback
mechanism to it as shown in figure a the endto
end training procedure involves the following
 the rlbased transmitter training by a policy
gradient theorem to ensure that the intelligent
transmitter learns from the noisy feedback after
a round of communication
 sl modelbased receiver training to train the
receiver as a classiﬁer
more details on the design and training procedure
are available in the considered threat model for this
case study is given as follows
 we choose a realistic blackbox setting where
the adversary does not know the target model
we also assume that the adversary can perform
an adversarial ml attack for ntime steps
 the goal of the adversary is to compromise the
performance of the drl autoencoder with noisy
feedback for a speciﬁc time interval the success
of the adversary is measured by the degradation
in the decoders performance during the attack
interval
we exploit the transferability property of the adver
sarial examples which states that adversarial examples
compromising an ml model will compromise other ml
models with high probability if the underlying data dis
tribution is same between two victim models so we
transfer the adversarial examples crafted in case study
see the section titled attacking unsupervised ml
based g applications and measure the average accu
racy of the receiver we run the drl autoencoder with
a noisy feedback system for time steps one time
step is equal to one communication round and per
form the adversarial attack between  and time
step window we transfer  successful perturbations
from the previous case study see the section titled
attacking unsupervised mlbased g applications
figure b shows the performance of the receiver
decoder of the drl autoencoder it is evident that the
performance of the receiver degrades from  to
nearly  during the adversarial attack window
our results as presented in this section conﬁrm
the feasibility of adversarial ml attacks on dlbased
applications from all the three types of ml algorithms
that are prevalent in the g network systems and
highlight the additional threat landscape emerges due
to the integration of vulnerable dl models to the g
and bg networks
discussion
toward robust mldriven g and
beyond networks
robustness against adversarial ml attacks is a very
challenging problem we ﬁrst note that there does not
exist much work on the recommendations and guide
lines for evaluating the robustness of ml in g appli
cations moreover to date there does not exist a
defense that ensures complete protection against
figure  a architecture of the drlbased channel autoencoder with noisy feedback for g and bg networks proposed in
b performance of the drl autoencoder with noisy feedback before during and after the adversarial ml attack a clear drop in
the performance of the receiver during the attack indicates the success of the adversary in compromising the drl autoen
coderbased endtoend communication system in future mobile networks
marchapril 
ieee internet computing
aipowered g services
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
adversarial ml attacks in our previous works we
have performed an extensive survey of the adversarial
ml literature on robustness against adversarial exam
ples and showed that nearly all defense mechanisms
proposed in the literature take one of the following
three approaches
 modifying data eg adversarial training feature
squeezing input masking
 auxiliary model addition eg generative model
addition ensemble defenses
 modifying
model
eg
defensive
distillation
model masking gradient regularization
although our results in g related usecases pre
sented in the section titled three case studies
highlighting adversarial ml risk for g and
beyond indicate that the representative mlbased
g applications from physical layers are vulnerable to
the adversarial ml attacks the threat models exploit
the underlying vulnerability inherent to known dl mod
els in general for instance we were able to attack the
drl autoencoder by exploiting the fact of transferabil
ity which is the rootcause that enables a same pertur
bation to fool multiple models thus we draw attention
to the security landscape of g and bg widening fur
ther from adoption of a plethora of dldriven compo
nents
substantiated
through
results
from
three
speciﬁc use cases related to g physical layer
recommendations for designing and
evaluating defenses against
adversarial ml attacks
designing a defense
designing a defense against adversarial examples is a
very challenging task many approaches for defending
against these attacks are available in the literature
but these techniques are shown ineffective against
newer variations of the attacks the following are a
few recommendations for designing a defensive inter
vention against adversarial examples
 a generic defense that can defend against any
type of adversarial attack is not possible so the
ﬁrst logical step is to understand the threat
model of the system for which the defensive
intervention is needed
 in many cases the adversarial examples are gen
eratedsampled from a distribution similar to the
legitimate data a preemptive data generation
process by using generative models and aggres
sive labeling labeling the preemptively generated
examples as false positives can improve the odds
of detecting many adversarial attacks in our previ
ous work we have shown that this procedure
can help in making a better defense
 deploy all known procedures from the literature
that is in line with the threat model
 always design defenses considering adaptive
adversaries
evaluating a defense
in the following we have provided a few important
evaluation guidelines for evaluating the mlbased g
applications against adversarial ml attacks these
insights are extracted from the carlini et al and our
previous works
 many defenses are available in the literature
against adversarial attacks but these defenses are
limited by the design of the application using them
without considering the threat model of mlbased
g applications can create a false sense of security
so for mlbased g applications threat models
must clearly state the assumptions taken type of
the adversary and the metrics used for evaluating
the defense
 always test the defense against the strongest
known attack and use it as a baseline evaluating
for an adaptive adversary is also necessary
 evaluate the defense procedure for gradient
based gradientfree and random noisebased
attacks httpswwwrobustmlorg
 clearly state the evaluation parameters accu
racy recall precision f score receiver operat
ing characteristic curve roc etc used in
evaluatingvalidating the defense and always
look for a change in the false positive and false
negative scores
 evaluation of the defense mechanism against
outofdistribution examples and transferability
based adversarial attacks is very important
although
these
recommendations
and
many
others in can help in designing a suitable
defense against adversarial examples but this is still
an open research problem in adversarial ml and ripe
for investigation for mlbased g applications
beyond vulnerability to adversarial ml
attacks
apart from the vulnerability of the ml models to the
adversarial ml attacks we underline the following
drawbacks that call into question the possibility of
ieee internet computing
marchapril 
aipowered g services
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
mldriven solutions getting integrated into the real
world g networks any time soon
lack of realworld datasets
due to the dearth of openly available real network
data from the telecom operators a large amount of
ml research in the telecom domain still largely
depends on simulatedexperimental data that often
falls short of truly representing realworld randomness
and variations thus current stateoftheart ml mod
els in telecommunication applications are not yet
ready to replace the domainknowledge based expert
systems currently in operation
lack of explainability
in ml studies the accuracy of a model comes at the
cost of explainability the dl models are highly accu
rate in providing output but lack an explanation of
why a particular output is achieved explanation of a
decision taken often would be a critical requirement
in the g and bg network settings especially
because many critical services such as transport sig
naling connected vehicles and urllc are expected
to be realized over the g infrastructure
lack of operational success of ml in real
world mobile networks
a plethora of ml models exist in the mobile network
ing literature but use of ml models in operational
mobile networks currently is still quite limited when
we perform attacks on the ml models running under
the ideal environment simulated or in favorable lab
conditions and still the victim models cannot with
stand
the
adversarial
attacks
as
demonstrated
through our case studies in realworld mobile net
works the ml models need to be deployed and stay
functional under unforeseen random environments
leaving them more vulnerable to adversarial attacks
that are beyond what they are designed to be robust
against
conclusion
security and privacy are uncompromising necessities
for modern and future global networks standards
such as g and bg and accordingly fortifying it to
thwart attacks and withstand the rapidly evolving
landscape of future security threats is of vital impor
tance this article speciﬁcally highlights that the
unvetted adoption of dldriven solutions in g and
bg networking gives rise to security concerns that
remain unattended by the g standardization bodies
such as the gpp we argue this is the right time for
crossdisciplinary research endeavors considering ml
and cybersecurity to gain momentum and enable
secure and trusted future g and bg mobile net
works for all future stakeholders we hope that our
work will motivate further research toward telecom
grade ml that is safe and trustworthy enough to be
incorporated into g and bg networks thereby
power intelligent and robust mobile networks sup
porting diverse services including missioncritical
systems
see discussions stats and author profiles for this publication at httpswwwresearchgatenetpublication
extremism on social media lynching of priyantha kumara diyawadana
poster  december 
citations
reads
 authors including
muhammad usama
 publications    citations   
see profile
all content following this page was uploaded by muhammad usama on  december 
the user has requested enhancement of the downloaded file
 ieeeacm international conference on advances in social networks analysis and mining asonam
extremism on social media lynching of priyantha
kumara diyawadana
muhammad musa muhammad usama and momin uppal
lahore university of management sciences lums pakistan
email  muhammadusama mominuppallumsedupk
abstractextremist content on social media platforms has
led to tragic acts of violence a contextaware extremist content
framework is the need of the hour to ensure the detection
and mitigation of this type of content this work provides
an outline of our recently launched initiative to develop a
contextaware framework we also present the rudimentary
results of the lynching of priyantha kumara diyawadana
to illustrate the impact of online extremist propaganda on
social media platforms our results indicate that nearly 
of the total population included in the gathered data have a
negative sentiment toward the lynching of priyantha kumara
diyawadana demonstrating how extreme hatemongering ex
tremist narratives are affecting social media users
keywordsextremism social media platforms twitter
lynching
i introduction
extremism is becoming a daunting problem in the modern
world the attacks on mosques in christchurch gun vio
lence in schools in the us the terrorism wave in canada and
the middle east religious and racial violence episodes in eu
rope riots and lynching in india and pakistan the genocide
in rohingya etc are a few of the horrific examples where
extremist ideologies on social media have resulted into real
world tragedies governments and social media giants are
trying to deal with this issue but unfortunately there hasnt
been any notable success extremism is a subjective term
identifying and quantifying it is an open area of research
because of its connections with various cultural religious
political and technological aspects extremist content is
an amalgamation of fake news misinterpreted religious
literature misdisinformation outofcontext videoaudio
clips hateful blogs search engine optimized hashtags pro
paganda videosliterature deepfakes and abuse all online
extremist ideas begin in the offline world schools theolog
ical seminaries literature ideas of revenge and supremacy
etc and the butterfly effect of social media and content
optimization algorithms makes it viral this availability and
virality of extremist content increase online extremism and
in many cases into realworld extremism episodes identify
ing and moderating social media content while preserving
free speech and privacy is a challenging task solving
this problem requires content moderation techniques and
platformlevel policies the lack of an extremism detection
and prevention framework notably in india and pakistan
is leading in the continual distribution of extremist content
via social media apps this work outlines a framework for
extremist content identification and mitigation the project
has only recently begun the complete summary of the
project is depicted in figure  and in this poster we discuss
preliminary results using the horrific lynching incident of
priyantha kumara diyawadana as a use case
ii related work
in recent years social media applications have emerged
as the most powerful tool for inciting extremism and
distributing hatefake news extremism hate speech and
fakemisinformation on social media are used to form
opinions cause controversies induce antagonism and so
cial divide curtail free speech troll opponents deteriorate
history namecalling killing and rape threats and violence
to achieve political religious or economic goals in third
world democracies pakistan india etc    
dash et al  studied the extremism and whataboutism
against the muslim population in bangalore india using
twitter data and showed how a derogatory facebook post by
an extremist turned the whole city into a war zone stahel
et al  stated that integrating online and behavioral data
can aid in capturing the relationship between online and
offline extremism biswas et al  used granger causality
test zscore sentiment analysis and other nlp techniques
to measure sinophobia on twitter niu et al  suggested
how a hate indicator can be developed for youtube simon
et al  shed light on the importance of making the
data and tools opensourced to help develop better content
moderation platforms to deal with online extremism to
date this effort can be seen in a few cherrypicked cases
but a larger consensus is still missing  in this poster we
intend to show the initial bits of the understanding of the
extremist content on twitter in the pakistani context through
a case study of the horrific lynching incident of priyantha
kumara diyawadana in pakistan
iii usecase lynching of priyantha kumara
diyawadana
on december   a mob killed and burnt priyantha
kumara diyawadana a srilankan citizen working as a
factory manager in sialkot pakistan on the allegation of
blasphemy the event is thought to be the work of the tlp
an extreme rightwing group in footage published on social
media the culprits can be seen yelling tlp slogans six
criminals were condemned to death when these allegations
were found to be false in court extremist information on
social media applications inspired the criminals we have
considered this horrible incident as a case study to demon
strate how extremist ideas had infiltrated pakistani twitter
we scraped twitter for december  and retrieved 
unique tweets using twinta twitter intelligence tool and
httpsgithubcomtwintprojecttwint
ieeeacm asonam  november  
   ieee
figure  outline of the proposed contextaware framework for studying extremism on social media and improving urban
sentiment
figure  polarity and subjectivity scores depicts that the
negative and subjective narrative about the lynching of
priyantha kumara diyawadana has taken over the pakistani
twitter feeds
conducted a rudimentary data analysisfew tweets retrieved
during the data collection process are also included below
 murders happen when emotions are high boys do
things in passion even i can get excited and do wrong
when it comes to religion dont blame the govt
 tlp flag witnessed on a cart outside rajco industries
in sialkot as the workers return to work after the
brutal murder of srilankanmanager priyanthakumara
on the pretence of blasphemy
the collected data was examined for polarity and sub
jectivity the polarity of a statement indicates how much
positive or negative commentary it includes if the message
is focused on ones emotions and ideas than on facts it is
deemed subjective polarity ranges between  with 
 indicating negative sentiment and  indicating positive
sentiment subjectivity spans from  figure  illustrates
the sentiment analysisassigned polarity and subjectivity
scores nearly  of the total population included in the
gathered data have a negative sentiment toward the lynch
ing of priyantha kumara diyawadana demonstrating how
extreme hatemongering extremist narratives are affecting
social media users
iv conclusions
online extremism is dividing communities and fault lines
are becoming more obvious by the day we have provided
an outline of a contextaware framework for identifying
and mitigating online extremism with the added benefit of
enhanced urban satisfaction according to our case study
negative sentiment is on the rise as a result of the propaga
tion of extremist content via social media apps
securing machine learning in the
cloud a systematic review of cloud
machine learning security
adnan qayyum  aneeqa ijaz  muhammad usama  waleed iqbal  junaid qadir 
yehia elkhatib  and ala alfuqaha 
information technology university itu lahore pakistan ainetworks research center university of oklahoma norman
ok united states social data science sds lab queen mary university of london london united kingdom school of
computing and communications lancaster university lancaster united kingdom hamad bin khalifa university hbku
doha qatar
with the advances in machine learning ml and deep learning dl techniques and the
potency of cloud computing in offering services efﬁciently and costeffectively machine
learning as a service mlaas cloud platforms have become popular in addition there is
increasing adoption of thirdparty cloud services for outsourcing training of dl models
which requires substantial costly computational resources eg highperformance
graphics processing units gpus such widespread usage of cloudhosted mldl
services opens a wide range of attack surfaces for adversaries to exploit the mldl
system to achieve malicious goals in this article we conduct a systematic evaluation of
literature of cloudhosted mldl models along both the important dimensionsattacks
and defensesrelated to their security our systematic review identiﬁed a total of 
related articles out of which  focused on attack six focused on defense and six focused
on both attack and defense our evaluation reveals that there is an increasing interest from
the research community on the perspective of attacking and defending different attacks on
machine learning as a service platforms in addition we identify the limitations and pitfalls
of the analyzed articles and highlight open research issues that require further investigation
keywords machine learning as a service cloudhosted machine learning models machine learning security cloud
machine learning security systematic review attacks defenses
 introduction
in recent years machine learning ml techniques have been successfully applied to a wide range of
applications signiﬁcantly outperforming previous stateoftheart methods in various domains for
example image classiﬁcation face recognition and object detection these ml techniquesin
particular deep learning dlbased ml techniquesare resource intensive and require a large
amount of training data to accomplish a speciﬁc task with good performance training dl models on
largescale datasets is usually performed using highperformance graphics processing units gpus
and tensor processing units however keeping in mind the cost of gpustensor processing units
and the fact that small businesses and individuals cannot afford such computational resources the
training of deep models is typically outsourced to clouds which is referred to in the literature as
machine learning as a service mlaas
mlaas refers to different ml services that are offered as a component of a cloud computing
services for example predictive analytics face recognition natural language services and data
edited by
bhavya kailkhura
united states department of energy
doe united states
reviewed by
giovanni apruzzese
university of liechtenstein
liechtenstein
cheng chen
the university of utah united states
correspondence
adnan qayyum
adnanqayyumituedupk
specialty section
this article was submitted to machine
learning and artiﬁcial intelligence
a section of the journal
frontiers in big data
received  july 
accepted  october 
published  november 
citation
qayyum a ijaz a usama m iqbal w
qadir j elkhatib y alfuqaha a 
securing machine learning in the
cloud a systematic review of cloud
machine learning security
front big data 
doi fdata
frontiers in big data  wwwfrontiersinorg
november   volume   article 
systematic review
published  november 
doi fdata
modeling apis mlaas allows users to upload their data and
model for training at the cloud in addition to training cloud
hosted ml services can also be used for inference purposes that
is models can be deployed on the cloud environments the system
architecture of a typical mlaas is shown in figure 
mlaas can help reduce the entry barrier to the use of ml and
dl through access to managed services of wide hardware
heterogeneity
and
incredible
horizontal
scale
mlaas
is
currently provided by several major organizations such as
google microsoft and amazon for example google offers
cloud ml engine that allows developers and data scientists
to upload training data and model which is trained on the cloud
in the tensorﬂow environment similarly microsoft offers
azure batch aia cloudbased service for training dl
models using different frameworks supported by both linux
and windows operating systems and amazon offers a cloud
service named deep learning ami dlami that provides
several prebuilt dl frameworks eg mxnet caffe theano
and tensorﬂow that are available in amazons ec cloud
computing infrastructure such cloud services are popular
among
researchers
as
evidenced
by
the
price
lifting
of
amazons
px
large
instance
to
the
maximum
possibletwo days before the deadline of neurips  the
largest research venue on mlindicating that a large number of
users request to reserve instances
in addition to mlaas services that allow users to upload
their model and data for training on the cloud transfer
learning is another strategy to reduce computational cost in
which a pretrained model is ﬁnetuned for a new task using a
new dataset transfer learning is widely applied for image
recognition tasks using a convolutional neural network
cnn a cnn model learns and encodes features like
edges
and
other
patterns
the
learned
weights
and
convolutional ﬁlters are useful for image recognition tasks
in other domains and stateoftheart results can be obtained
with a minimal amount of training even on a single gpu
moreover various popular pretrained models such as alexnet
krizhevsky et al  vgg simonyan and zisserman
 and inception szegedy et al  are available for
download and ﬁnetuning online both of the aforementioned
outsourcing strategies come with new security concerns in
addition the literature suggests that different types of attacks
can
be
realized
on
different
components
of
the
communication network as well usama et al a for
example intrusion detection han et al  usama et al
b network trafﬁc classiﬁcation usama et al  and
malware detection systems chen et al  moreover
adversarial ml attacks have also been devised for client
side ml classiﬁers that is googles phishing pages ﬁlter
liang et al 
contributions of the article in this article we analyze the
security of mlaas and other cloudhosted mldl models and
provide a systematic review of associated security challenges and
solutions to the best of our knowledge this article is the ﬁrst
effort on providing a systematic review of the security of cloud
hosted ml models and services the following are the major
contributions of this article
 we conducted a systematic evaluation of  articles related to
mlaas attacks and defenses
 we investigated ﬁve themes of approaches aiming to attack
mlaas and cloudhosted ml services
 we examined ﬁve themes of defense methods for securing
mlaas and cloudhosted ml services
 we identiﬁed the pitfalls and limitations of the examined
articles finally we have highlighted open research issues that
require further investigation
organization of the article the rest of the article is organized
as follows the methodology adopted for the systematic
review is presented in section  the results of the
systematic review are presented in section  section 
presents various security challenges associated with cloud
hosted ml models and potential solutions for securing cloud
hosted ml models are presented in section  the pitfalls and
limitations of the reviewed approaches are discussed in
section  we brieﬂy reﬂect on our methodology to
identify any threats to the validity in section  and various
open research issues that require further investigation are
highlighted in section  finally we conclude the article in
section 
 review methodology
in this section we present the research objectives and the adopted
methodology for the systematic review the purpose of this article
is to identify and systematically review the stateofthe art
research related to the security of the cloudbased mldl
techniques
the
methodology
followed
for
this
study
is
depicted in figure 
 research objectives
the following are the key objectives of this article
o to build upon the existing work around the security of
cloudbased mldl methods and present a broad overview of the
existing stateoftheart literature related to mlaas and cloud
hosted ml services
o to identify and present a taxonomy of different attack and
defense strategies for cloudhosted mldl models
o to identify the pitfalls and limitations of the existing
approaches in terms of research challenges and opportunities
 research questions
to achieve our objectives we consider answering two important
questions that are described below and conducted a systematic
analysis of  articles
we use mlaas to cover both ml and dl as a service cloud provisions
httpscloudgooglecommlengine
a popular python library for dl
httpsazuremicrosoftcomenusservicesmachinelearningservice
httpsdocsawsamazoncomdlamilatestdevguideaml_html
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
q what are the wellknown attacks on cloudhostedthird
party mldl models
q what are the countermeasures and defenses against such
attacks
 review protocol
we developed a review protocol to conduct the systematic review
the details are described below
 search strategy and searching phase
to build a knowledge base and extract the relevant articles eight
major publishers and online repositories were queried that
include acm digital library ieee xplore sciencedirect
international conference on machine learning international
conference on learning representations journal of machine
learning
research
neural
information
processing
systems
usenix and arxiv as we added nonpeerreviewed articles
from electric preprint archive arxiv we aq and ai performed
the critical appraisal using aacods checklist it is designed to
enable evaluation and appraisal of gray literature tyndall 
which is designed for the critical evaluation of gray literature
in the initial phase we queried main libraries using a set of
different search terms that evolved using an iterative process to
maximize the number of relevant articles to achieve optimal
sensitivity we used a combination of words attack poisoning
trojan attack contamination model inversion evasion backdoor
model stealing black box ml neural networks mlaas cloud
computing outsource third party secure robust and defense the
combinations of search keywords used are depicted in figure  we
then created search strategies with controlled or index terms given
in figure  please note that no lower limit for the publication date
was applied the last search date was june  the researchers wi
and ai searched additional articles through citations and by
snowballing
on
google
scholar
any
disagreement
was
adjudicated by the third reviewer aq finally articles focusing
on the attackdefense for cloudbased ml models were retrieved
 inclusion and exclusion criteria
the inclusion and exclusion criteria followed for this systematic
review are deﬁned below
 inclusion criteria
the following are the key points that we considered for screening
retrieved articles as relevant for conducting a systematic review
 we included all articles relevant to the research questions
and published in the english language that discusses the
attacks on cloudbased ml services for example offered by
cloud computing service providers
 we then assessed the eligibility of the relevant articles by
identifying whether they discussed either attack or defense
for cloudbased mldl models
 comparative
studies
that
compare
the
attacks
and
robustness against different wellknown attacks on cloud
hosted ml services poisoning attacks black box attacks
trojan attacks backdoor attacks contamination attacks
inversion stealing and invasion attacks
 finally we categorized the selected articles into three
categories that is articles on attacks articles on defenses
and articles on attacks and defenses
 exclusion criteria
the exclusion criteria are outlined below
 articles that are written in a language other than english
figure   taxonomy of different defenses proposed for defending attacks on the thirdparty cloudhosted machine learning ml or deep learning dl models
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
 articles not available in full text
 secondary studies eg systematic literature reviews
surveys editorials and abstracts or short papers are not
included
 articles that do not discuss attacks and defenses for cloud
basedthirdparty ml services that is we only consider
those articles which have proposed an attack or defense for a
cloudhosted ml or mlaas service
 screening phase
for the screening of articles we employ two phases based on the
content of the retrieved articles  title and abstract screening and
 full text of the publication please note that to avoid bias and to
ensure that the judgment about the relevancy of articles is entirely
based on the content of the publications we intentionally do not
consider authors publication type eg conference and journal
and publisher eg ieee and acm titles and abstracts might
not be true reﬂectors of the articles contents however we
concluded that our review protocol is sufﬁcient to avoid
provenancebased bias
it is very common that the same work got published in
multiple venues for example conference papers are usually
extended to journals in such cases we only consider the
original article in the screening phase every article was
screened by at least two authors of this article that were
tasked to annotate the articles as either relevant not relevant
or need further investigation which was ﬁnalized by the
discussion between the authors until any such article is either
marked relevant or not relevant only original technical articles
are selected while survey and review articles are ignored finally
all selected publications were thoroughly read by the authors for
categorization and thematic analysis
 review results
 overview of the search and selection
process outcome
the search using the aforementioned strategy identiﬁed a total of
 articles after removing duplicate articles title and abstract
screening the overall number of articles reduced to  a total
of  articles did not meet the inclusion criteria and were
therefore excluded from the remaining  articles 
articles did not discuss attackdefense for thirdparty cloud
hosted ml models and were excluded as well of the remaining
articles a total of  articles are identiﬁed as relevant reasons
for excluding articles were documented and reported in a
prisma ﬂow diagram depicted in figure  these articles
were categorized into three classes that is articles that are
speciﬁcally focused on attacks articles that are speciﬁcally
focused on defenses and articles that considered both
attacks and defenses containing   and  articles each
respectively
 overview of the selected studies
the systematic review eventually identiﬁed a set of  articles
related to cloudbased mldl models and mlaas which we
categorized into three classes as mentioned above and shown in
figure  as shown in figure  a signiﬁcant portion of the
selected articles were published in conferences 
comparatively a very smaller proportion of these articles
were published in journals or transactions  the
percentage of gray literature ie nonpeerreviewed articles
is  yet a very small proportion of publications are
published in symposia  and this percentage is the
same for workshop papers the distribution of selected
figure   an illustration of a typical cloudbased ml or machine learning as a service mlaas architecture
figure   the methodology for systematic review
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
publications by their types over the years is shown in figure 
the ﬁgure depicts that the interest in the security of cloud
hosted mldl models increased in the year  and was at a
peak in the year  and was slightly lower in the year  as
compared to  also the majority of the articles during these
years were published in conferences the distribution of selected
publications by their publishers over the years is depicted in
figure  the ﬁgure shows that the majority of the publications
have been published at ieee acm and arxiv there is a similar
trend in the number of articles in the year   and 
as discussed previously
 some partially related nonselected
studies a discussion
we have described our inclusion and exclusion criteria that help
us to identify relevant articles we note however that some
seemingly relevant articles failed to meet the inclusion criteria
here we brieﬂy describe few such articles for giving a rationale
why they were not included
 liang et al  investigated the security challenges for
the clientside classiﬁers via a case study on the googles
phishing pages ﬁlter a very widely used classiﬁer for
automatically detecting unknown phishing pages they
devised an attack that is not relevant to the cloudbased
service
 demetrio et al  presented wafamole a tool that
models the presence of an adversary this tool leverages a set
of mutation operators that alter the syntax of a payload
without affecting the original semantics using the results
the authors demonstrated that mlbased wafs are exposed
to a concrete risk of being bypassed however this attack is
not associated with any cloudbased services
 authors in apruzzese et al  discussed adversarial
attacks where the machine learning model is compromised
to induce an output favorable to the attacker these attacks
figure   distribution of selected publications according to their types
figure   search queries used to identify publications to include in the
systematic review
figure   flowchart of systematic review and categorization
figure   distribution of selected publications by types over years
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
are realized in a different setting as compared to the scope of
this systematic review as we only included the articles which
discuss the attack or defense when the cloud is outsourcing
its services as mlaas
 han et al  conducted the ﬁrst systematic study of the
practical trafﬁc space evasion attack on learningbased
network intrusion detection systems again it is out of the
inclusion criteria of our work
 chen et al  designed and evaluated three types of
attackers targeting the training phases to poison our
detection to address this threat the authors proposed
the
detection
system
kuafudet
and
showed
it
signiﬁcantly
reduces
false
negatives
and
boosts
the
detection accuracy
 song et al  presented a federated defense approach
for mitigating the effect of adversarial perturbations in a
federated
learning
environment
this article
can be
potentially relevant for our study as they address the
problem of defending cloudhosted ml models however
instead of using a thirdparty service the authors conducted
the experiments on a single computer system in a simulated
environment therefore this study is not included in the
analysis of this article
 in a similar study zhang et al  presented a defense
mechanism for defending adversarial attacks on cloudaided
automatic speech recognition asr however it is not
explicitly stated that the cloud is outsourcing ml services
and also which mldl model or mlaas was used in
experiments
 attacks on cloudhosted machine
learning models q
in this section we present the ﬁndings from the systematically
selected articles that aim at attacking cloudhostedthirdparty
mldl models
 attacks on cloudhosted machine
learning models thematic analysis
in ml practice it is very common to outsource the training of
mldl models to thirdparty services that provide high
computational resources on the cloud such services enable
ml practitioners to upload their models along with training
data which is then trained on the cloud although such
services have clear beneﬁts for reducing the training and
inference
time
however
these
services
can
easily
be
compromised and to this end different types of attacks against
these services have been proposed in the literature in this section
we present the thematic analysis of  articles that are focused on
attacking cloudhosted mldl models these articles are
classiﬁed into ﬁve major themes  attack type  threat
model  attack method  target models and  dataset
attack type a wide variety of attacks have been proposed in
the literature these are listed below with their descriptions
provided in the next section
 adversarial attacks brendel et al 
 backdoor attacks chen et al  gu et al 
 cyber kill chainbased attack nguyen 
 data manipulation attacks liao et al 
 evasion attacks hitaj et al 
 exploration attacks sethi and kantardzic 
 model extraction attacks correiasilva et al 
kesarwani et al  joshi and tammana  reith
et al 
 model inversion attacks yang et al 
 modelreuse attacks ji et al 
 trojan attacks liu et al 
threat model cloud ml attacks are based on different threat
models with the salient types with examples are listed below
 black box attacks no knowledge brendel et al  chen
et al  hosseini et al  correiasilva et al 
sethi and kantardzic  hitaj et al 
 white box attacks full knowledge liao et al  liu
et al  gu et al  reith et al 
 gray box attacks partial knowledge ji et al 
kesarwani et al 
attack method in each article a different type of method is
proposed for attacking cloudhosted mldl models a brief
description of these methods is presented in table  and is
discussed in detail in the next section
target models considered studies have used different
mlaas services eg google cloud ml services hosseini
et al  salem et al  sethi and kantardzic 
ml models of bigml platform kesarwani et al  ibms
visual recognition nguyen  and amazon prediction apis
reith et al  yang et al 
dataset these attacks have been realized using different
datasets ranging from small size datasets eg mnist gu
et al  and fashionmnist liu et al  to large
size datasets eg youtube aligned face dataset chen et al
 project wolf eye nguyen  and iris dataset joshi
and tammana  other datasets include california
housing boston house prices ujiindoorloc and ipin 
tutorial reith et al  facescrub celeba and cifar
yang et al  a summary of thematic analyses of these
attacks is presented in table  and brieﬂy described in the next
section
 taxonomy of attacks on cloudhosted
machine learning models
in this section we present a taxonomy and description of
different attacks described above in thematic analysis a
taxonomy of attacks on cloudhosted mldl models is
depicted in figure  and is described next
backdoor attacks on cloudhosted models can be further categorized into three
categories chen et al   complete modelbased attacks  partial
modelbased attacks and  modelfree attacks
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
table   summary of the stateofthe art attack types for cloudbasedthirdparty mldl models
authors
attack type
method
target model
s
threat model
data
brendel et al 
adversarial attack
presented a decisionbased attack ie the
boundary attack
two ml classiﬁers from clarifaicom ie brand
and celebrity recognition
black box
two datasets natural images and celebrities
saadatpanah et al
crafted adversarial examples for copyright
detection system
youtube content id and audiotag copyright
white box and
black box
na
hosseini et al 
proposed two targeted attacks for video
labeling and shot detection
google cloud video intelligence api
black box
kesarwani et al 
extraction attack
used information gain to measure model
learning rate
decision tree deployed on bigml platform
gray box
four bigml datasets irs tax pattern gss
survey email importance steak survey
correiasilva et al
knowledge extraction by querying the model
with unlabeled data samples and then used
responses to create fake dataset and model
three local cnn models for visual recognition
for facial expression object and crosswalk
classiﬁcation and microsoft azure emotion api
black box
used three datasets for facial expression
recognition object and satellite crosswalk
classiﬁcation
reith et al 
performed model extraction attacks on the
homomorphic encryptionbased protocol for
preserving svrbased indoor localization
support vector regressor svr and svm
white box
california housing boston house prices
ujiindoorloc and ipin  tutorial
joshi and tammana
proposed a variant of gradient driven adaptive
learning rate gdalr for stealing mlaas
models
used three different models
black box
iris liver disease and land satellite datasets
sethi and kantardzic
exploration attack
presented a seedexploreexploit framework for
generating adversarial samples
google cloud prediction platform
black box
 realworld datasets
gu et al 
backdoor attack
realized attack by poisoning training samples
and labels
mnist and a us street sign classiﬁer
ie fasterrcnn with outsourced training and
transfer learning
white box
mnist and us trafﬁc signs dataset
chen et al 
used poisoning strategies to realized a targeted
attack and proposed two types of backdoor
poisoning attacks
two face recognition models ie deepid and
vggface
black box
youtube aligned face dataset
liu et al 
trojan attack
proposed stealth infection on neural network
based trojan attack
cloudbased intelligent supply chain
ie mlaas
white box
fashionmnist
gong et al 
proposed realtime adversarial example crafting
procedure
voicespeech enabled devices and google
speech
gray box
voicecommand dataset
ji et al 
model reuse attack
presented empirical evaluation of modelreuse
attacks on primitive models and realizing attack
by generating semantically similar neighbors
and identifying salient features
pretrained primitive models for speech
recognition autonomous steering face
veriﬁcation and skin cancer screening
gray box
speech commands udacity selfdriving car
challenge vgg face and international skin
imaging collaboration isic datasets
liao et al 
data manipulation
attack
studied data manipulation attacks for stealthily
manipulating ml and dl models using transfer
learning and gradient descent
cloudhosted ml and dl models
white box
enron spam and minist
sehwag et al 
crafted outofdistribution exploratory
adversarial examples to compromise mldl
models of clarifais content moderation system
in the cloud
cloudhosted ml and dl models
white box and
black box
minist cifar and imagenet
continued on following page
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
 adversarial attacks
in recent years dl models have been found vulnerable to
carefully
crafted
imperceptible
adversarial
examples
goodfellow et al  for instance a decisionbased
adversarial attack namely the boundary attack against two
black box ml models trained for brand and celebrity
recognition hosted at clarifaicom are proposed in brendel
et al  the ﬁrst model identiﬁes brand names from natural
images for  distinct brands and the second model recognizes
over  celebrities to date a variety of adversarial examples
generation methods have been proposed in the literature so far
the interesting readers are referred to recent surveys articles for
detailed taxonomy of different types of adversarial attacks
ie akhtar and mian  yuan et al  qayyum
et al b demetrio et al 
 exploratory attacks
these attacks are inference time attacks in which adversary
attempts to evade the underlying mldl model for example
by forcing the classiﬁer ie mldl model to misclassify a
positive sample as a negative one exploratory attacks do not
harm the training data and only affects the model at test time
a
datadriven
exploratory
attack
using
the
seedexploreexploit strategy for evading googles cloud
prediction api considering black box settings is presented
in sethi and kantardzic  the performance evaluation
of the proposed framework was performed using  real
world datasets
 model extraction attacks
in model extraction attacks adversaries can query the deployed
ml model and can use queryresponse pair for compromising
future predictions and also they can potentially realize privacy
breaches of the training data and can steal the model by learning
extraction queries in kesarwani et al  the authors
presented a novel method for quantifying the extraction
status of models for users with an increasing number of
queries which aims to measure model learning rate using
information gain observed by query and response streams of
users the key objective of the authors was to design a cloud
based system for monitoring model extraction status and
warnings
the performance
evaluation
of
the proposed
method was performed using a decision tree model deployed
on the bigml mlaas platform for different adversarial attack
scenarios similarly a model extractionstealing strategy is
presented by correiasilva et al  the authors queried
the cloudhosted dl model with random unlabeled samples and
used their predictions for creating a fake dataset then they used
the fake dataset for building a fake model by training an oracle
copycat model in an attempt to achieve similar performance as
of the target model
 backdooring attacks
in backdooring attacks an adversary maliciously creates the
trained model which performs as good as expected on the users
training and validation data but it performs badly on attacker
table   continued summary of the stateofthe art attack types for cloudbasedthirdparty mldl models
authors
attack type
method
target model
s
threat model
data
nguyen 
cyber kill chain attack
proposed a highlevel threat model for ml cyber
kill chain and provided proof of concept
ibm visual recognition mlaas ie cognitive
classiﬁer for classiﬁcation cats and female lions
na
project wolf eye
hilprecht et al 
membership inference
attack
monte carlo based attack and membership
inference attack on gan
amazon web services p
black box
mnist fashionmnist and cifar
hitaj et al 
evasion attacks
realized evasion attacks using two ensemble
neural networks
watermarking detection models
black box
mnist
yang et al 
iversion attacks
constructed an auxiliary set for training the
inversion model
cnn
graybox
facescrub celeba and cifar
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
input samples the backdooring attacks on deep neural networks
dnns are explored and evaluated in gu et al  the
authors ﬁrst explored the properties of backdooring for a toy
example and created a backdoor model for handwritten digit
classiﬁer and then demonstrated that backdoors are powerful for
dnn by creating a backdoor model for a united states street sign
classiﬁer where two scenarios were considered that is
outsourced training of the model and transfer learning where
an attacker can acquire a backdoor pretrained model online in
another similar study chen et al  a targeted backdoor
attack for two stateofthe art face recognition models that is
deepid sun et al  and vggface parkhi et al  is
presented the authors proposed two categories of backdooring
poisoning attacks that is inputinstancekey attacks and
patternkey attacks using two different data poising strategies
that is inputinstancekey strategies and patternkey strategies
respectively
 trojan attacks
in trojan attacks the attacker inserts malicious content into the
system that looks legitimate but can take over the control of the
system however the purpose of trojan insertion can be varied
for example stealing disruption misbehaving or getting
intended behavior in liu et al  the authors proposed a
stealth infection on neural networks namely sin to realize a
practical supply chain triggered neural trojan attacks also they
proposed a variety of trojan insertion strategies for agile and
practical trojan attacks the proof of the concept is demonstrated
by developing a prototype of the proposed neural trojan attack
ie sin in linux sandbox and used torch collobert et al
 mldl framework for building visual recognition models
using the fashionmnist dataset
 modelreuse attacks
in modelreuse attacks an adversary creates a malicious model
ie adversarial model that inﬂuences the host model to
misbehave on targeted inputs ie triggers in extremely
predictable fashion that is getting a sample classiﬁed into
speciﬁc intended class for instance experimental evaluation
of modelreuse attacks for four pretrained primitive dl models
ie speech recognition autonomous steering face veriﬁcation
and skin cancer screening is evaluated by ji et al 
 data manipulation attacks
those attacks in which training data are manipulated to get
intended behavior by the mldl model are known as data
manipulation attacks data manipulation attacks for stealthily
manipulating traditional supervised ml techniques and logistic
regression lr and cnn models are studied by liao et al 
in the attack strategy the authors added a new constraint on fully
connected layers of the models and used gradient descent for
retraining them and other layers were frozen ie were made
nontrainable
 cyber kill chainbased attacks
kill chain is a term used to deﬁne steps for attacking a target
usually used in the military in cyber kill chainbased attacks the
cloudhosted mldl models are attacked for example a high
figure   distribution of selected publications by publishers over years
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
level threat model targeting ml cyber kill chain is presented by
nguyen  also the authors provided proof of concept by
providing a case study using ibm visual recognition mlaas
ie cognitive classiﬁer for classiﬁcation cats and female lions
and
provided
recommendations
for
ensuring
secure
and
robust ml
 membership inference attacks
in a typical membership inference attack for given input data and
black box access to the ml model an attacker attempts to ﬁgure
out if the given input sample was the part of the training set or
not to realize a membership inference attack against a target
model a classiﬁcation model is trained for distinguishing between
the predictions of the target model against the inputs on which it
was trained and that those on which it was not trained shokri
et al 
 evasion attacks
evasion attacks are inference time attacks in which an adversary
attempts to modify the test data for getting the intended outcome
from
the
mldl
model
two
evasion
attacks
against
watermarking techniques for dl models hosted as mlaas
have been presented by hitaj et al  the authors used
ﬁve publicly available models and trained them for distinguishing
between watermarked and clean nonwatermarked images that
is binary image classiﬁcation tasks
 model inversion attacks
in model inversion attacks an attacker tries to learn about
training
data
using
the
models
outcomes
two
model
inversion techniques have been proposed by yang et al
 that is training an inversion model using auxiliary set
composed by utilizing adversarys background knowledge and
truncationbased method for aligning the inversion model the
authors evaluated their proposed methods on a commercial
prediction mlaas named amazon rekognition
 toward securing cloudhosted
machine learning models q
in this section we present the insights from the systematically
selected articles that provide tailored defense against speciﬁc
attacks and report the articles that along with creating attacks
propose countermeasure for the attacks for cloudhostedthird
party mldl models
 defenses for attacks on cloudhosted
machine learning models thematic
analysis
leveraging cloudbased ml services for computational ofﬂoading
and minimizing the communication overhead is accepted as a
promising trend while cloudbased prediction services have
signiﬁcant beneﬁts however by sharing the model and the
training data raises many privacy and security challenges
several attacks that can compromise the model and data
integrity as described in the previous section to avoid such
issues users can download the model and make inferences locally
however this approach has certain drawbacks including
conﬁdentiality issues service providers cannot update the
models adversaries can use the model to develop evading
strategies and privacy of the user data is compromised to
outline the countermeasures against these attacks we present
the thematic analysis of six articles that are focused on defense
against the tailored attacks for cloudhosted mldl models or
data in addition we also provide the thematic analysis of those
six articles that propose defense against speciﬁc attacks these
articles are classiﬁed into ﬁve major themes  attack type 
defense  target models  dataset and  measured outcomes
the thematic analysis of these systematically reviewed articles
that are focused on developing defense strategies against attacks is
given below
considered attacks for developing defenses the defenses
proposed in the reviewed articles are developed against the
following speciﬁc attacks
 extraction attacks tramèr et al  liu et al 
 inversion attacks liu et al  sharma and chen 
 adversarial attacks hosseini et al  wang et al b
rouhani et al 
 evasion attacks lei et al 
 gan attacks sharma and chen 
 privacy threat attacks hesamifard et al 
 ide channel and cachetiming attacks jiang et al 
 membership inference attacks shokri et al  salem
et al 
most of the aforementioned attacks are elaborated in
previous sections however in the selected articles that are
identiﬁed as either defense or attack and defense articles some
attacks are speciﬁcally created for instance gan attacks side
channel cachetiming attack privacy threats etc therefore the
attacks are worth mentioning in this section to explain the
speciﬁc countermeasures proposed against them in the defense
articles
defenses against different attacks to provide resilience against
these attacks the authors of selected articles proposed different
defense algorithms which are listed below against each type of
attack
 extraction attacks minionn liu et al  rounding
conﬁdence differential and ensemble methods tramèr
et al 
 adversarial attacks redcrypt rouhani et al  and
arden wang et al b
 inversion attacks minionn liu et al  and image
disguising techniques sharma and chen 
 privacy attacks encryptionbased defense hesamifard
et al  jiang et al 
 side channel and cachetiming attacks encryptionbased
defense hesamifard et al  jiang et al 
 membership inference attack dropout and model stacking
salem et al 
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
table   summary of attack types and corresponding defenses for cloudbasedthirdparty mldl models
author
attack
defense
target model
data
measured outcomes
liu et al 
extraction attack and
inversion attack
minionn a defense against information
leakage in dnn to transform into an
oblivious nn
cloudhosted dl models neural network
for cloudbased prediction services
mnist and cifar
response latency and message sizes
rouhani et al
adversarial attacks
redcrypt reconﬁgurable hardware
accelerated framework for the privacy
preserving
cloudhosted dl models
mnist and movielens
throughput
wang et al b
arden to distribute dnn model
computation among edge device and
cloud data centers
partial cloudhosted dnn models
mnist svhn and cifar
latency accuracy and privacy
budget
hosseini et al
incorporating randomness to video
analysis algorithms
google cloud video intelligence api
videos comprising of adversarial
examples
histogram peaks to detect shot
change
sharma and chen
inversion attack and gan
attack
image disguising techniques to ensure the
protection against modelbased
adversarial attacks
cloudhosted dl models
mnist and cifar
accuracy average visual privacy and
fano factor
hesamifard et al
privacy threats due to raw
cloud data
homomorphic encryption to preserve the
privacy and integrity of data in dnn
cloudbased dnn
crab dataset fertility dataset climate
dataset
accuracy and training time
jiang et al 
side channel and cache
timing attack
secure logistic encryption along with
hardwarebased security enhancement
by exploiting software guard extensions
cloudhosted lr models
edinburgh mi wibreast cancer and
monks prob
area under the curve complexity and
model training time
lei et al 
evasion attack
pelican similaritybased analysis of
unknown website with the known
phishing web site
bitdefenders partical processing hosted
on cloud
phishtank phishnet
similarity index
tramèr et al 
extraction attack
rounding conﬁdences to some precision
differential privacy to protect training data
elements ensemble methods
ml models hosted on bigml and amazon
 categories ﬂower dataset face
dataset iris dataset and trafﬁc signs
dataset
success rate given the perturbation
budget
shokri et al 
membership inference
attack
top k class model predictions increase
entropy regularization and reducing
precision of prediction vector
mlaas classiﬁcation models of google
and amazon apis
cifarpurchases locations texas
hospital stays mnist uci adults
accuracy and precision
salem et al 
dropout and model stacking to prevent
overﬁtting
google cloud prediction api
used eight different datasets
precision and recall
wang et al a
misclassiﬁcation attacks
neuron distance model ensemble
method dropout randomization
google cloud ml microsoft cognitive
toolkit cntk and the pytorch
class vgg ﬂower face dataset iris
dataset and trafﬁc signs dataset
googles inceptionv
accuracy and success rate
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
target models different cloudhosted mldl models have
been used for the evaluation of the proposed defenses as shown in
table 
datasets used the robustness of these defenses have been
evaluated using various datasets ranging from small size datasets
eg mnist liu et al  wang et al b rouhani et al
 sharma and chen  and cifar liu et al 
wang et al b sharma and chen  to large size
datasets eg iris dataset tramèr et al  fertility and
climate dataset hesamifard et al  and breast cancer
jiang et al  other datasets include crab dataset
hesamifard et al  face dataset trafﬁc signs dataset
trafﬁc signs dataset tramèr et al  svhn wang et al
b edinburgh mi edinburgh mi wibreast cancerband
monks prob jiang et al  crab dataset fertility dataset
and climate dataset hesamifard et al  each of the defense
techniques discussed above is mapped in table  to the speciﬁc
attack for which it was developed
measured outcomes the measured outcomes based on which
the defenses are evaluated are response latency and message sizes
liu et al  wang et al b throughput comparison
rouhani et al  average on the cache miss rates per second
sharma
and
chen
auc
space
complexity
to
demonstrate approximated storage costs jiang et al 
classiﬁcation accuracy of the model as well as running time
hesamifard et al  sharma and chen  similarity
index lei et al  and training time hesamifard et al 
jiang et al 
 taxonomy of defenses on cloudhosted
machine learning model attacks
in this section we present a taxonomy and summary of different
defensive strategies against attacks on cloudhosted mldl
models as described above in thematic analysis a taxonomy
of these defenses strategies is presented in figure  and is
described next
 minionn
dnns are vulnerable to model inversion and extraction attacks
liu et al  proposed that without making any changes to the
training phase of the model it is possible to change the model into
an oblivious neural network they make the nonlinear function
such as tanh and sigmoid function more ﬂexible and by training
the models on several datasets the authors demonstrated
signiﬁcant results with minimal loss in the accuracy in
addition they also implemented the ofﬂine precomputation
phase to perform encryption incremental operations along
with the simd batch processing technique
 redcrypt
a reconﬁgurable hardwareaccelerated framework is proposed
by rouhani et al  for protecting the privacy of deep
neural models in cloud networks the authors perform an
innovative
and
powerefﬁcient
implementation
of
yaos
garbled circuit gc protocol on fpgas for preserving
privacy the proposed framework is evaluated for different
figure   taxonomy of different attacks realized on the thirdparty cloudhosted machine learning ml or deep learning dl models
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
dl applications and it has achieved up to fold throughput
gain per core
 arden
to ofﬂoad the large portion of dnns from the mobile devices to
the clouds and to make the framework secure a privacy
preserving mechanism arden is proposed by wang et al
b
while
uploading
the
data
to
the
mobilecloud
perturbation noisy samples are included to make the data
secure to verify the robustness the authors perform rigorous
analysis based on three image datasets and demonstrated that this
defense is capable to preserve the user privacy along with
inference performance
 image disguising techniques
while leveraging services from the cloud gpu server the
adversary can realize an attack by introducing malicious
created training data perform model inversion and use the
model for getting desirable incentives and outcomes to
protect from such attacks and to preserve the data as well as
the model sharma and chen  proposed an image
disguising mechanism they developed a toolkit that can be
leveraged to calibrate certain parameter settings they claim
that the disguised images with blockwise permutation and
transformations are resilient to ganbased attack and model
inversion attacks
 homomorphic encryption
for making the cloud services of outsourced mlaas secure
hesamifard
et
al
proposed
a
privacypreserving
framework using homomorphic encryption they trained the
neural network using the encrypted data and then performed
the encrypted predictions the authors demonstrated that by
carefully choosing the polynomials of the activation functions to
adopt neural networks it is possible to achieve the desired accuracy
along with privacypreserving training and classiﬁcation
in a similar study to preserve the privacy of outsourced
biomedical data and computation on public cloud servers
jiang et al  built a homomorphically encrypted model
that reinforces the hardware security through software guard
extensions they combined homomorphic encryption and
software guard extensions to devise a hybrid model for the
security of the most commonly used model for biomedical
applications that is lr the robustness of the secure lr
framework is evaluated on various datasets and the authors
also compared its performance with stateoftheart secure lr
solutions and demonstrated its superior efﬁciency
 pelican
lei et al  proposed three mutationbased evasion attacks
and a samplebased collision attack in white gray and black
box scenarios they evaluated the attacks and demonstrated a
 success rate of attack on googles phishing page ﬁlter
classiﬁer
while
a
success
rate
of
up
to
for
the
transferability on bitdefender trafﬁclight to deal with such
attacks and to increase the robustness of classiﬁers they proposed
a defense method known as pelican
 rounding conﬁdences and differential privacy
tramèr et al  presented the model extraction attacks
against the online services of bigml and amazon ml the
attacks are capable of model evasion monetization and can
compromise the privacy of training data the authors also
proposed and evaluated countermeasures such as rounding
conﬁdences
against
equationsolving
and
decision
tree
pathﬁnding attacks however this defense has no impact on
the regression tree model attack for the preservation of
training data differential privacy is proposed this defense
reduces the ability of an attacker to learn insights about the
training dataset the impact of both defenses is evaluated on the
attacks for different models while the authors also proposed
ensemble models to mitigate the impact of attacks however their
resilience is not evaluated
 increasing entropy and reducing precision
the training of attack using shadow training techniques against
black box models in the cloudbased google prediction api and
amazon ml models are studied by shokri et al  the attack
does not require prior knowledge of training data distribution the
authors emphasize that in order to protect the privacy of medical
related datasets or other publicrelated data countermeasures
should be designed for instance restriction of prediction vector
to top k classes which will prevent the leakage of important
information
or
rounding
down
or
up
the
classiﬁcation
probabilities in the prediction they show that regularization
can be effective to cope with overﬁtting and increasing the
randomness of the prediction vector
 dropout and model stacking
in the study by salem et al  the authors created three
diverse attacks and tested the applicability of these attacks on
eight datasets from which six are similar as used by shokri et al
 whereas in this work news dataset and face dataset is
included in the threat model the authors considered black box
access to the target model which is a supervised ml classiﬁer with
binary classes that was trained for binary classiﬁcation to
mitigate the privacy threats the authors proposed a dropout
based method which reduces the impact of an attack by randomly
deleting a proportion of edges in each training iteration in a fully
connected neural network the second defense strategy is model
stacking which hierarchically organizes multiple ml models to
avoid overﬁtting after extensive evaluation these defense
techniques showed the potential to mitigate the performance
of the membership inference attack
 randomness to video analysis algorithms
hosseini et al designed two attacks speciﬁcally to analyze the
robustness of video classiﬁcation and shot detection hosseini
et al  the attack can subtly manipulate the content of the
video in such a way that it is undetected by humans while the
output from the automatic video analysis method is altered
depending on the fact that the video and shot labels are
generated by api by processing only the ﬁrst video frame of
every second the attack can successfully deceive api to deal
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
with the shot removal and generation attacks the authors
proposed the inclusion of randomness for enhancing the
robustness of algorithms however in this article the authors
thoroughly evaluated the applicability of these attacks in different
video setting but the purposed defense is not rigorously
evaluated
 neuron distance threshold and obfuscation
transfer learning is an effective technique for quickly building
dl student models in which knowledge from a teacher model
is transferred to a student model however wang et al
a discussed that due to the centralization of model
training the vulnerability against misclassiﬁcation attacks
for
image
recognition
on
black
box
student
models
increases the authors proposed several defenses to mitigate
the impact of such an attack such as changing the internal
representation of the student model from the teacher model
other
defense
methods
include
increasing
dropout
randomization which alters the student model training
process modiﬁcation in input data before classiﬁcation
adding redundancy and using orthogonal model against
transfer
learning
attack
the
authors
analyzed
the
robustness of these attacks and demonstrated that the
neuron
distance
threshold
is
the
most
effective
in
obfuscating the identity of the teacher model
 pitfalls and limitations
 lack of attack diversity
the attacks presented in the selected articles have limited scope
and lack diversity that is they are limited to a speciﬁc setting and
the variability of attacks is limited as well however the diversity
of attacks is an important consideration for developing robust
attacks from the perspective of adversaries and it ensures the
detection and prevention of the attacks to be difﬁcult the
diversity of attacks ultimately helps in the development of
robust defense strategies moreover the empirical evaluation
of attack variabilities can identify the potential vulnerabilities
of cybersecurity systems therefore to make a more robust
defense solution it is important to test the model robustness
under a diverse set of attacks
 lack of consideration for adaptable
adversaries
most of the defenses in the systematically reviewed articles are
proposed for a speciﬁc attack and did not consider the adaptable
adversaries on the other hand in practice the adversarial attacks
are an arms race between attackers and defenders that is the
attackers continuously evolve and enhance their knowledge and
attacking strategies to evade the underlying defensive system
therefore the consideration of adaptable adversaries is crucial for
developing a robust and longlasting defense mechanism if we do
not consider this the adversary will adapt to our defensive system
over time and will bypass it to get the intended behavior or
outcomes
 limited progress in developing
defenses
from the systematically selected articles that are collected from
different databases only  articles have presented defense
methods for the proposed attack as compared to the articles
that are focused on attacks that is  in these  articles six have
only discussedpresented a defense strategy and six have
developed a defense against a particular attack this indicates
that there is limited activity from the research community in
developing defense strategies for already proposed attacks in the
literature in addition the proposed defenses only mitigate or
detect those attacks for which they have been developed and
therefore they are not generalizable on the contrary the
increasing interest in developing different attacks and the
popularity
of
cloudhostedthirdparty
services
demand
a
proportionate
amount
of
interest
in
developing
defense
systems as well
 open research issues
 adversarially robust machine learning
models
in recent years adversarial ml attacks have emerged as a major
panacea for mldl models and the systematically selected articles
have highlighted the threat of these attacks for cloudhosted mldl
models as well moreover the diversity of these attacks is drastically
increasing as compared with the defensive strategies that can pose
serious challenges and consequences for the security of cloud
hosted mldl models each defense method presented in the
literature so far has been shown resilient to a particular attack
which is realized in speciﬁc settings and it fails to withstand for yet
stronger and unseen attacks therefore the development of
adversarially robust mldl models remains an open research
problem while the literature suggests that worstcase robustness
analysis should be performed while considering adversarial ml
settings qayyum et al a qayyum et al b ilahi et al
 in addition it has been argued in the literature that most of
ml developers and security incident responders are unequipped
with the required tools for securing industrygrade ml systems
against adversarial ml attacks kumar et al  this indicates
the increasing need for the development of defense strategies for
securing mldl models against adversarial ml attacks
 privacypreserving machine learning
models
in
cloudhosted
ml
services
preserving
user
privacy
is
fundamentally important and is a matter of high concern
also it is desirable that ml models built using users data
should not learn information that can compromise the privacy
of the individuals however the literature on developing privacy
preserving mldl models or mlaas is limited on the other
hand one of the privacypreserving techniques that have been
used for privacy protection for building a defense system for
cloudhosted
mldl
models
that
is
the
homomorphic
encryptionbased protocol jiang et al  has been shown
frontiers in big data  wwwfrontiersinorg
november   volume   article 
qayyum et al
systematic review of cloud ml security
vulnerable to model extraction attack reith et al 
therefore the development of privacypreserving ml models
for cloud computing platforms is another open research problem
 proxy metrics for evaluating security
and robustness
from systematically reviewed literature on the security of cloud
hosted mldl models we orchestrate that the interest from the
research community in the development of novel securitycentric
proxy metrics for the evaluation of security threats and model
robustness of cloudhosted models is very limited however with
the
increasing
proliferation
of
cloudhosted
ml
services
ie mlaas and with the developmentadvancements of
different
attacks
eg
adversarial
ml
attacks
the
development of effective and scalable metrics for evaluating
the robustness mldl models toward different attacks and
defense strategies is required
 threats to validity
we now brieﬂy reﬂect on our methodology in order to identify
any threats to the validity of our ﬁndings first internal validity is
maintained as the research questions we pose in section 
capture the objectives of the study construct validity relies on a
sound understanding of the literature and how it represents the
state of the ﬁeld a detailed study of the reviewed articles along
with deep discussions between the members of the research team
helped ensure the quality of this understanding note that the
research team is of diverse skills and expertise in ml dl cloud
computing mldl security and analytics also the inclusion
and exclusion criteria section  help deﬁne the remit of our
survey data extraction is prone to human error as is always the
case this was mitigated by having different members of the
research team review each reviewed article however we did not
attempt to evaluate the quality of the reviewed studies or validate
their content due to time constraints in order to minimize
selection bias we cast a wide net in order to capture articles
from different communities publishing in the area of mlaas via a
comprehensive
set
of
bibliographical
databases
without
discriminating based on the venuesource
 conclusion
in this article we presented a systematic review of literature that is
focused on the security of cloudhosted mldl models also
named as mlaas the relevant articles were collected from eight
major publishers that include acm digital library ieee xplore
sciencedirect international conference on machine learning
international conference on learning representations journal
of machine learning research usenix neural information
processing systems and arxiv for the selection of articles we
developed a review protocol that includes inclusion and exclusion
formulas and analyzed the selected articles that fulﬁll these
criteria across two dimensions ie attacks and defenses on
mlaas and provide a thematic analysis of these articles across ﬁve
attack and ﬁve defense themes respectively we also identiﬁed
the limitations and pitfalls from the reviewed literature and
ﬁnally we have highlighted various open research issues that
require further investigation
data availability statement
the original contributions presented in the study are included in
the articlesupplementary material further inquiries can be
directed to the corresponding authors
author contributions
aq led the work in writing the manuscript and performed the
annotation of the data and analysis as well ai performed data
acquisition annotation and analysis from four venues and
contributed to the paper writeup mu contributed to writing a
few sections did annotations of papers and helped in analysis wi
performed data scrapping annotation and analysis from four venues
and helped in developing graphics all the ﬁrst four authors validated
the data analysis and contributed to the interpretation of the results
aq and ai helped in developing and reﬁning the methodology for
this systematic review jq conceived the idea and supervises the
overall work jq yek and af provided critical feedback and helped
shape the research analysis and manuscript all authors contributed
to the ﬁnal version of the manuscript
future internet
article
approximate networking for universal
internet access
junaid qadir  arjuna sathiaseelan  umar bin farooq  muhammad usama 
muhammad ali imran  and muhammad shaﬁque 
department of electrical engineering information technology university itupunjab
lahore  pakistan junaidqadirituedupk jq muhammadusamaituedupk mu
computer laboratory university of cambridge cambridge cb fd uk arjunasathiaseelanclcamacuk
school of engineering university of glasgow glasgow g qq uk muhammadimranglasgowacuk
institute of computer engineering vienna university of technology tu wien wien  austria
muhammadshaﬁquetuwienacat
correspondence mscsituedupk
received  october  accepted  december  published  december 
abstract despite the best efforts of networking researchers and practitioners an ideal internet
experience is inaccessible to an overwhelming majority of people the world over mainly due to the
lack of costefﬁcient ways of provisioning highperformance global internet in this paper we argue
that instead of an exclusive focus on a utopian goal of universally accessible ideal networking in which
we have a high throughput and quality of service as well as low latency and congestion we should
consider providing approximate networking through the adoption of contextappropriate tradeoffs
in this regard we propose to leverage the advances in the emerging trend of approximate computing
that rely on relaxing the bounds of preciseexact computing to provide new opportunities for
improving the area power and performance efﬁciency of systems by orders of magnitude by
embracing output errors in resilient applications furthermore we propose to extend the dimensions
of approximate computing towards various knobs available at network layers
approximate
networking can be used to provision global access to the internet for all gaia in a pragmatically
tiered fashion in which different users around the world are provided a different contextappropriate
but still contextually functional internet experience
keywords universal internet access approximate networking global access to the internet for
all gaia
 introduction
the new global development agenda transforming our world the  agenda for sustainable
development composed of  sustainable development goals sdgs has recently been adopted
by the united nations un general assembly in  an important pillar of this movement is
the need to ensure social inclusion wherewith the society strives to achieve shared prosperity which
reaches everyone in the society including women people from minorities and the bottom strata of
human society due to the importance of internet accesswhich has now become a key indicator
of the potential of economic progress with impact imprinted on all spheres of human life personal
societal political economical and educational in both developing and developed countriesthe
provisioning of universal internet access becomes an important stepping stone towards sustainable
development the world over
the fact that internet access can play a large role in facilitating development motivates the
vision of global access to the internet for all gaia currently being formally pursued in the internet
research task force irtf while internet has the capability of fostering development and growth
future internet    doiﬁ
wwwmdpicomjournalfutureinternet
future internet   
 of 
this potential is being thwarted by the inability of billions of people to access the internet according to
recent statistics almost six billion people do not have highspeed internet which makes them unable
to fully participate in the digital economy  bringing the internet to the remaining billions of people
left without will democratize knowledge open up new opportunities and undoubtedly open up
avenues for sustained development
the overwhelming focus of the internet research community has been on improving the ideal
networking experience by providing increasingly higher throughputs along with lower latencies
however this focus has led to an internet design that is very costly which has precluded the
global deployment of the internet we see this in wired technologies such as the modern ﬁberbased
broadband highspeed network which come close to providing ideal network performance have
largely been restricted to urban centers and advanced countries with economical reasons primarily the
high cost of laying ﬁber precluding their universal deployment similarly cellular technologydespite
its great successhas not been able to ensure gaia since it is mainly an urban phenomena that cannot
be used to cost effectively serve rural and remote areas  since internet is overengineered for many
practical applications and needs ie not all applications and users of the internet require highﬁdelity
internet services we argue that a viable gaiaenabling approach is the use of approximate networking
where contextappropriate tradeoffs are adopted to deal with different challenges and impairments
characterizing a certain region we can loosely deﬁne approximate networks as networks that are
close to ideal in terms of quality nature and quantity we proposed the concept of approximate
networking previously in  where the presentation of the concept focused on the use of simple
approximate goodenough services to tame the complexity of the networking infrastructure in a future
world afﬂicted with hard limits due to the exhaustion of natural resources such as fossil fuels in this
paper we argue that apart from its clear use in reducing network complexity with the complementary
beneﬁts of more sustainable cheaper services approximate networking can also be used to satisfy the
widelydiffering and diverse user requirements by taking contextappropriate tradeoffs and thereby help
in realizing the vision of global access to the internet for all gaia
our main idea is for universal internet provisioning of mobile and internet services that it is time
to move away from pursuing overengineered perfect products and focus instead on developing
appropriate good enough solutions our approximate networking idea can be thought of as the
network analog of the emerging computer architectural trend called approximate computing 
which we discuss next
 what is approximate computing
broadly speaking approximate computing leverages the capability of many computing systems
and applications to tolerate some loss of quality and optimality by trading off precision for efﬁciency
where efﬁciency can be in the terms of increased performance or reduced costs in terms of energy
consumed or system costarea approximate computing systems are able to optimize the efﬁciency
of systems by relaxing the commonly applied notion of exact numerical or boolean equivalence
between the speciﬁcation and implementation at multiple layers of the hardware and software stacks
see figure  for a depiction the use of approximate computing is motivated by the following
factors  modern big data applications are based on noisy realworld data  many computing
applications eg recommendation and web search do not have a single golden answer  the
perceptual limitations of users mean that some approximations may not even be noticed and 
many applications existeg images video and soundwhere minor errors and approximations
can be tolerated by different users some recent case studies for applying approximate computing to
video processing  signal processing  and communication systems  have shown early feasibility
the research in the ﬁeld of approximate computing has been led by seminal contributions from the
industry players such as intel  ibm  and microsoft  as well as several research groups
from academia 
future internet   
 of 
figure  whats new about approximate computing adapted from 
 what is approximate networking
with approximate networking we intend to seamlessly integrate the concepts from approximate
computing along with traditional mechanisms for approximations in networking in terms of
approximations adopted by networking protocols and algorithms the concept of approximate
networking is necessary since experience has shown us that universal commissioning of ideal
networks which have extremely high capacity bandwidth and reliability in addition to extremely
low or negligible delays errors and congestion is nonpractical it is important to emphasize that
approximate networking is not a single standalone technique nor is it the ﬁrst time that approximation
has been proposed in networking indeed a number of existing networking techniques already
utilize approximation and are best effort our idea of approximate networking generalizes these
classical ideas and importantly supplements these ideas with recent developments in the ﬁeld of
crosslayered approximate computing particularly at the hardware level to facilitate the design of future
energyefﬁcient and optimized network infrastructure as well as algorithms and protocols we aim to
enable end to end approximation principlesframeworks engaging hardwaresoftware approximation
as well as network layer approximations for systematic approximate networking as this point in time
there has only been rudimentary work done in efﬁciently combining lowlevel approximate computing
modules to construct larger highlevel modules and architectural components approximate computing
has been deployed for a large number of applications including image processing signal processing
machine learning scientiﬁc computing ﬁnancial analysis database search and distributed computing
however its extension to the ﬁeld of networking is practically nonexistent at this point in time with only some
recent preliminary works as exceptions  we anticipate that these hardwarefocused approximate
computing advances will percolate into the ﬁeld of networking and in the future there will be an
increased interest in synergistic approximation management at different layers of the hardware and
software stacks in networking
 why adopt approximate networking
 affordable universal internet gaia
the right of affordable access to broadband internet is enshrined in the  sustainable
development goals of the united nations
the international telecommunication union itu
broadband goal  initiative aims at an optimistic target of universal broadband internet speeds
of  mbps for  a month accessible to everyone in the world by  source alliance for
affordable internet aai report  such an approach which aims at providing an ideal
networking experience universally has historically always failed due to various socioeconomical and
technical issues an important reason is that most modern technologies such as g g longterm
evolution lte and the planned g are urban focused as rural systems being sparsely populated
by deﬁnition do not thus hold much business potential for mobile carriers  the internet is also
future internet   
 of 
large unaffordable when we consider that on average the mobile broadband price and the ﬁxedline
broadband prices are  and  of the average persons monthly income where women and rural
populations are hit the hardest  approximate networking is a particularly appealing option to
reach out to the ofﬂine human population by providing an affordable contextually good enough
service
 diversity of user  application proﬁles
the internets digital divide is not a binary divide there is a spectrum of connectivity
options and digital capabilities accessible to people around the world see figure  in some places
ultra highspeed broadband connections are available while there are hosts of places where there is no
connectivity at all however most places lie somewhere in between user and application proﬁles and
requirement vary greatly at one extreme we have applications that require extremely high throughput
eg video on demand and low latency eg tactile internet on the other extreme we have
applications that have minimal throughput and latency requirements eg smart meters which report
back lowvolume data relatively infrequently users can also have vastly different service requirements
and ﬁnancial strength in the face of such great diversity the approximate networking framework
can avoid the difﬁculties of singlesizeﬁtsall networking solutions furthermore these diversities
can be exploited and applications and users provided services and resources commensurate to
their requirements
figure 
ensuring global access to the internet for all gaia requires provisioning good
enough quality of service qos that accommodates the diversity of applications requirements device
capabilities user proﬁle and requirements
 the pareto principle  law the power of good enough
to help manage the approximate networking tradeoffs it is instructive to remember the
pareto principle alternatively called the  rule  which states roughly that  of the factors
result in  of the overall effect this principle has big implications for approximate networking
since this allows us to provide adequate ﬁdelity to ideal networking by only focusing on the most
important  of the effects the key challenge in approximate networking then becomes the task of
separating the allimportant essential nontrivial factors from the trivial factors which may be omitted
or approximated in this regard we can leverage previous humancomputerinteraction hci research
that has shown that human quality of service qos perception can be ﬂawed eg relatively fast
service may be judged to be unacceptable if the service is not predictable visually appealing and
future internet   
 of 
reliable  in choosing the precise approximate networking tradeoff to adopt such that the users
perceive the least inconvenience
 need of energy efﬁciency
it has been reported that information and communication technology ict is one of the biggest
consumer of the worlds electrical energy using up to  of the overall energy  statistics 
the urgency of delivering on the front of energy efﬁciency is reinforced by the impending decline of
nonrenewable energy resources along with the concomitant increase in ict demand the approximate
networking trend can augment the hardwarefocused approximate computing trend in managing
the brewing energy crisis through the ingenuous use of approximation in particular approximate
networking can help generalize the performance and efﬁciency improvements offered by approximate
computing which have largely been limited to local speedups on a single device to broader network
settings optimizing communicationnetworking cost is important since these costs can be signiﬁcant
eg on mobile phones the wifi and cellular radios require on average an order of magnitude more
power than the cpu or memory 
 contributions of this paper
the main contribution of this paper is to investigate the extension of the concept of
approximate computing to the ﬁeld of networking
we propose approximate networking as
an overarching crosslayered framework that encompasses classical approximation techniques
as well as recentlydeveloped techniques in the ﬁeld of approximate computing to implement
contextappropriate networking tradeoffs that are necessary for the aims of global access to the
internet for all gaia in order to facilitate these tradeoffs apart from the classical approximation
techniques adopted in networking in the areas of softwarehardware algorithms protocols and
architecture approximate networking will also leverage the advances in the fastemerging ﬁeld of
approximate computing as an extra degreeoffreedom for ﬁnergrained tradeoff optimization we also
propose approximate networking as an overarching framework for systematically thinking about
networking tradeoffs that must be adopted for ensuring gaia furthermore we also present an
application of approximate networking in g with a case for low income and rural regions
this paper is organized as follows section  describes approximate networking technologies
in section  we present contextappropriate approximate tradeoffs for networking we describe a case
study for approximate g networks in rural and low income areas in section  we present discussion
issues for approximate networking in section  and conclude in section 
 approximate networking technologies
there exist some errortolerant networking applications that are constrained by the needs for
energy efﬁciency and realtime packet delivery by using approximate computing these applications
can be deconstrained by the relaxation of the integrity requirements for the approximate data
thereby allowing these applications to communicate more efﬁciently ie these applications can
transmit faster over a longer range and using less power see  and generative adversarial networks for launching
and thwarting adversarial attacks on network
intrusion detection systems
muhammad usama muhammad asim siddique latif junaid qadir alaalfuqaha
information technology university punjab pakistan
university of southern queensland australia
hamad bin khalifa university qatar
email muhammadusama muhammadasim junaidqadirituedupk siddiquelatifusqeduau aalfuqahahbkueduqa
abstractintrusion detection systems idss are an essential
cog of the network security suite that can defend the network
from malicious intrusions and anomalous trafﬁc many machine
learning mlbased idss have been proposed in the literature
for the detection of malicious network trafﬁc however recent
works have shown that ml models are vulnerable to adversarial
perturbations through which an adversary can cause idss to
malfunction by introducing a small impracticable perturbation
in the network trafﬁc in this paper we propose an adversarial
ml attack using generative adversarial networks gans that
can successfully evade an mlbased ids we also show that
gans can be used to inoculate the ids and make it more robust
to adversarial perturbations
index termsadversarial machine learning gan ids
i introduction
in cybersecurity network anomaly detection is an important
task rapid growth in network trafﬁc and cyber attacks on
networked applications have made intrusion detection systems
idss a crucial component of the network security suite
given network trafﬁc samples idss are expected to precisely
classify which sample is unusual and malicious without suf
fering from a high false positive rate
recent advances in machine learning ml and deep learn
ing dl techniques have revolutionized vision language and
speech processing the classiﬁcation performance in these
areas has nearly surpassed the human level performance
motivated by the success of the mldl in these areas idss
have also adopted mldl for performing classiﬁcation tasks
to determine anomalous behavior in network trafﬁc however
recently linear and nonlinear mldl classiﬁers are exposed
to be vulnerable to adversarial examples created for fooling
the classiﬁers in reporting malfunctioned classiﬁcation reports
since idss have adopted mldl techniques for classiﬁcation
there integrity has also become questionable
adversarial ml examples are the worstcase domain shifts
of the input samples arising from a fundamentally ﬂawed
assumption in mldl models that the distribution followed
by the training data will also be encountered at inference time
which is not the case in the real world adversaries exploit this
shortcoming and use local search combinatorial optimization
or convex programming to ﬁnd the adversarial perturbation
which compromises the integrity of mldl performance
in this work we utilize generative adversarial networks
gans  for creating an adversarial ml attack on mldl
based idss where the details of mldl technique used in
the ids are unavailable to the adversary gans belong to a
family of generative models based on differentiable generator
networks the core idea of gans is to pit a generator network
against a discriminator network in an interactive game theory
like setting the goal of the generator network is to learn the
best approximation of the training data whereas the goal of
the discriminator network is to distinguish between samples
from original data and generated data
we employ gans to introduce a strategic adversarial per
turbation in network data to compromise the ids performance
and then to counter this adversarial perturbation we introduce
a gan model in the ids ml model to ensure robustness our
results indicate that we can successfully evade mldlbased
idss using the adversarial perturbation generated through
gans interestingly gan technology cannot only be used
for attacking idss but also for empowering them our results
show that by using a ganbased defense idss can be made
robust against previously seen as well as unseen adversarial
perturbations
the major contributions of this paper are
 we propose and validate a ganbased adversarial ml
attack on a blackbox ids our proposed ganbased
attack is the ﬁrst adversarial attack that can successfully
evade idss while ensuring that the functional behavior
of the network trafﬁc is preserved
 we propose a ganbased training mechanism for defense
purposes which improves the robustness of the ids
against adversarial perturbations during the attack and
the defense procedures the functional behavior of the
network trafﬁc is ensured by only altering the non
functional characteristics of the network trafﬁc
the rest of the paper is organized as follows in the next
section we will provide a brief review of the related research
that focuses on producing adversarial examples for idss using
gans we discuss some preliminaries in section iii in which
we provide the problem formulation assumed threat model
considered dataset and the constraint of preserving func
  ieee
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
tional behavior while launching adversarial attacks section
iv introduces our ganbased adversarial attack methodology
and presents the results of our attack technique section v
describes the details of the proposed defense mechanism
against adversarial examples and highlights that the proposed
defense increases the robustness of ids against adversarial
perturbations finally the paper is concluded
ii related work
intrusion detection is a process of detecting malicious
activities in the network trafﬁc many mldlbased intrusion
detection schemes have been proposed over the years  
  but most of these schemes have suffered from high
false positive rates and class imbalance issues another major
issue associated with mldlbased idss is their vulnerability
to the adversarial examples where an adversary adds an
imperceptible perturbation to a legitimate trafﬁc sample to
create a false sense of security this aspect of mldlbased
idss has been relatively unexplored and requires immediate
attention
most of the recent works in developing adversarial per
turbation for network security applications are focused on
malware classiﬁcation and portable executable pe classiﬁ
cation grosse et al  proposed an adversarial perturbation
for deep neural networks dnns based malware classiﬁer
where they have used fast gradient sign method fgsm
and jacobian based saliency map attack jsma for creating
adversarial malware examples in our previous work  we
have explored the adversarial attacks and defenses in cognitive
selforganizing networks where we have performed fgsm
jsma and basic iterative method bim attack on malware
classiﬁers to highlight that future mldlbased networks
will be very vulnerable to adversarial perturbations anderson
et al  proposed an adversarial perturbation for pe by
using reinforcement learning technique to evade dnn based
classiﬁers similarly kolosnjaji et al  proposed a gradient
based adversarial perturbation that evades the malware pe
classiﬁer by only perturbing  of the total bytes xu et
al  proposed an adversarial perturbation using genetic
programming to produce an adversarial portable document ﬁle
pdf to evade the dnn classiﬁer while ensuring the semantic
properties of the pdf
the fundamental idea of the gan is to generate adversarial
examples which have its basis like all generative models in
learning the true underlying distribution of the data there are
few examples where gans have also been used for creating
adversarial examples in malware pe and idss hu et al 
used gans for making adversarial examples for dlbased
blackbox malware classiﬁer but their model does not ensure
the functional behavior of the malware executable similarly
lin et al  proposed wasserstein gan  based adversar
ial example generating mechanism for a mldlbased black
box ids although they claim that the functional behavior of
the network trafﬁc was preserved but they have altered two
functional features of the network trafﬁc which invalidate their
claim on the preservation of functional behavior of adversarial
network trafﬁc
in this paper we have proposed a ganbased adversarial
example crafting technique which successfully evades the
mldlbased blackbox ids and also ensures the preservation
of functional behavior of adversarial network trafﬁc we have
also proposed a very effective defense against adversarial
ml examples using gans to improve the robustness of the
mldlbased idss
iii preliminaries
a problem deﬁnition
suppose x is the feature set with n number of features
and let xi yi is a sample where xi x is a legitimate
network trafﬁc sample and yi y is true class label where
y represent the number of classes the ids aims to learn
a classiﬁer f  x 
y which is a true representation of
the incoming network trafﬁc the goal of the adversary is
to generate an imperceptible adversarial perturbation δ which
when added to a legitimate sample xi constitute an adversarial
example xand gets classiﬁed as fxi  δ  yi we present
a framework by using gans to construct xthat successfully
evade a blackbox ids we have also proposed a ganbased
defense to improve the robustness of mldl techniques used
in idss against adversarial examples
b threat model
 adversarial capabilities
in this paper we assume
blackbox settings where the adversary can only query the
ids for related labels we further assume that adversary has
prepared an oracle by simultaneously querying the ids rest
of the information about the ids is not accessible to the
adversary
 adversarial goal the goal of the adversary is to gen
erate such adversarial examples which evade and compromise
the integrity of the deployed ids
c dataset
we have evaluated proposed ganbased adversarial exam
ples on kdd dataset widely used for benchmarking ids
performance  the dataset consists of ﬁve classes namely
normal probe dos ur and rl representing the different
types of intrusion trafﬁc for idss to evaluate each record in
the dataset consists of  features  of them are continuous
and  are categorical features onehot representation is used
to encode the categorical features details of the datasets
features and its relation with the attack types are provided
in table i
d constraint of preserving functional behavior
a very important constraint on adversarial ml examples is
to preserve the functional behavior of the perturbed examples
for computer vision the adversary has to maintain the visual
appearance of the adversarial examples for language process
ing examples adversary has to preserve the semantic meaning
while creating adversarial text examples for malware and pe
adversary has to ensure that an dversarial perturbation does
not alter the executability of the malware or pe for network
trafﬁc features the adversary has to ensure that an adversarial
perturbation does not invalidate the network trafﬁc features
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
table i
division of the features on the basis of their meaning in the
network traffic
feature type
features
intrinsic
duration protocol type service
ﬂag src bytes dst bytes land
wrong fragment urgent
content
hot num failed logins logged in
num compromised root shell su attempted
num root num ﬁle creations num shells
num access ﬁles num outbound cmds
s host login s guest login
timebased
trafﬁc features
count srv count serror rate srv serror rate
rerror rate srv rerror rate same srv rate
diff srv rate srv diff host rate
hostbased
trafﬁc features
dst host count dst host srv count
dst host same srv rate dst host diff srv rate
dst host same src port rate
dst host srv diff host rate dst host serror rate
dst host srv serror rate dst host rerror rate
dst host srv rerror rate
to completely understand the preservation of functional
behavior of network trafﬁc features especially network attack
trafﬁc we need to take a step back and understand the feature
extraction method from tcpdump records feature extraction
for idss from tcpdump records are extensively explained in
 where they have devised a fourlayer feature extraction
scheme this scheme is based on the nature of the attack in
network trafﬁc ﬂows
these four steps of feature extraction are as follows
 firstly intrinsic features from the network trafﬁc ﬂow
are extracted these features are necessary for any
network trafﬁc validity any alteration in these features
will invalidate the network trafﬁc
 secondly timebased features were extracted these
features provides timebased characteristics of normal
and malicious trafﬁc these features along with intrinsic
features are necessary for identifying probe and dos
attacks ur and rl attacks do not require timebased
network trafﬁc statistics as these attacks are embedded
in contents of the packets so any change in the time
based features of the network trafﬁc ﬂow features will
invalidate the network trafﬁc characteristics
 thirdly once the intrinsic and timebased features are
extracted from network trafﬁc then content features
from ﬂow trafﬁc were extracted to detect ur and rl
attacks content features are not required for probe and
dos attack detection any alteration in these features
will not invalidate the probe and dos attack in this
paper we have used content features to generate adver
sarial examples
 lastly hostbased trafﬁc features were extracted these
features along with intrinsic and timebased features
are necessary for slowprobe attack detection any
alteration in these features will not only change the
hostbased information but also invalidates the trafﬁc
ﬂow
we have provided the taxonomy of the feature sets and their
table ii
relation of each feature set with different network attacks
in the dataset
attack types
feature sets
probe
dos
ur
rl
intrinsic
d
d
d
d
timebased
d
d
content
d
d
hostbased
d
fig 
an illustration of how our proposed ganbased adversarial attack
can lead to an instance of the probe attack class being classiﬁed by the dnn
based blackbox ids as normal while keeping the functional attributes of the
probe class unchanged
relation with the functional behavior of the attack trafﬁc in
table ii our ganbased adversarial attack only adds pertur
bation to content features to ensure at the functional behavior
is preserved this also highlights that to perform an adversarial
attack the attacker must have complete domain knowledge
this is also the reason why many adversarial attacks eg
fgsm bim jsma are not applicable to network trafﬁc as
these attacks do not ensure the preservation of the functional
behavior of network trafﬁc features
an illustrative example of how the functional behavior of
the network trafﬁc features is preserved is presented in figure
 as the proposed attack is creating adversarial examples
of probe class the adversary has to ensure that functional
behavior of the intrinsic timebased and hostbased network
trafﬁc features are preserved figure  shows that adversarial
examples produced by our proposed ganbased framework
have only altered the content features which fool mldl
based classiﬁer in classifying the probe attack trafﬁc as
normal trafﬁc
iv ganbased attack methodology
in this section we will provide the framework designed for
creating adversarial examples to evade mldlbased idss
a adversarial attack using gans
gans consist of two neural networks namely a genera
tor g and a discriminator d provided the input examples
x  x x  xn g tries to generate counterfeit exam
ples ideally from the underlying data distribution px that
deceives the d in accepting them as original samples from set
x meanwhile d learns to discriminate between legitimate
examples from x and counterfeited examples from g this
learning process is formulated as a minimax game between
g and d the optimization function describing this adversarial
game is given by 
min
g max
d
epx log dx  epz log dgz
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
fig  gans for evading mldlbasedidss highlighting the procedure of generator and discriminator network training
where pz is the distribution of latent random variables z
and is usually deﬁned to be a known and simple distribution
such as n i or ua b training g and d is performed
by taking alternative gradient steps to ensure that g can learn
to deceive the d and d can learn to detect the counterfeit
examples
figure  depicts the overall architecture opted for gener
ating adversarial examples the proposed gan framework
consists of three components namely a generator network
g a discriminator network d and a blackbox mldl
based classiﬁer f the input xi x is divided into two
portions namely functional and nonfunctional attributes this
division is performed on the basis of attribute contributions to
the functional behavior of the network trafﬁc g takes non
functional attributes of the data as an input and generates
a perturbation δ of the size of nonfunctional attributes of
the input then we concatenate the functional portion of the
original trafﬁc x and generated δ this concatenation is given
as xgx the concatenated samples are fed to d which is
responsible for classifying between original and counterfeited
examples
d is trained to mimic the behavior of ids this is ac
complished by feeding both malicious and normal trafﬁc to
both ids and discriminator and predictions from ids are used
as labels for the training of d contrary to d g is trained
speciﬁcally on malicious data m such that d  a proxy for
ids is fooled the designed adversarial loss for g and d are
provided in equations  and 
lg  min
g
epz log dgzx
ld  min
d
epxfx logdx
the goal of the g is to generate such counterfeited exam
ples known to be malicious that are indistinguishable from
the legitimate trafﬁc x and the goal of the d is to distinguish
between legitimate and counterfeited examples while training
g the d is considered ﬁxed and reversible the complete loss
function used in the proposed gan framework is given as
min
g max
d
epz log dgzx  epxfx logdx
the training procedure for the gan is provided in algo
rithm  whereas the details of the gan architecture used and
its hyperparameters are shown in table iii
algorithm  gan training algorithm
input gdxm
output gd
for t     do
for tg    gsteps do
xbatch m
θg θg ηθglgxbatch
adam update
end for
for td    dsteps do
xbatch x
ybatch fxbatch
θd θd ηθdldxbatch ybatch
adam update
end for
end for
table iii
gan architecture and hyperparameters
operation
units
nonlinearity
dropout
generator g
dense
dense
dense
relu
relu
relu
discriminator d
dense
dense
dense
relu
relu
sigmoid
hyperparameters
optimizer
learning rate
batch size
latent dimensions
iterations
weight initialization
adam
xavier initializer
b results of ganbased adversarial attack
the proposed ganbased adversarial attack is used to
construct the adversarial examples for the probe class these
generated examples are subjected to mldlbased blackbox
idss which gets fooled in believing probe attack trafﬁc as
normal class trafﬁc the functional behavior of the attack
trafﬁc is ensured by following the procedure provided in
section iii we have only considered classiﬁcation between
normal and probe class network trafﬁc but the provided
framework is applicable to other network trafﬁc classes as
well
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
fig  performance evaluation of our ganbased adversarial attack frame
work previous attack approaches are not shown as a baseline of comparison
as they are not applicable in our settings as they unlike our approach do
not ensure the preservation of networking functional behavior
to highlight the effectiveness of proposed ganbased ad
versarial attack we have chosen to perform a series of ex
periments where we employed dnn logistic regression lr
support vector machine svm knearest neighbor knn
na
ıve bayes nb random forest rf decision trees dt
and gradient boosting gb techniques as blackbox ids
since the proposed gan framework only generates adversarial
examples for one class at a time we have used the gan
framework for producing adversarial examples for probe class
we have used accuracy precision recall and f score as
evaluation parameters for the evasion attack
figure  provides a comparison between the accuracy of
blackbox mldlbased ids before the adversarial attack and
after it highlighting that the proposed ganbased adversarial
attack compromises the integrity of the mldlbased ids
while ensuring the functional behavior of the network trafﬁc
decay in the performance of blackbox mldlbased classi
ﬁer demonstrates that adversarial examples are increasing the
number of false positives and forcing the mldl classiﬁer to
learn wrong decision boundaries
v ganbased defense methodology
in this section we discuss how an ids can defend against
proposed adversarial ml attack by opting adversarial training
using generative ml models
a adversarial training by using generative model in ids
adversarial training  is a method for injecting adver
sarial examples in training data to ensure that mldl model
learns the possible adversarial perturbations this new way
of training mldl model will improve the robustness and
generalization of mldl models by training on clean and
adversarial examples  to the best of our knowledge
adversarial training has not yet been explored in mldl
based idss for defending against adversarial examples a
shortcoming attached to the method of adversarial training
is that it only provides robustness against the adversarial
examples it was trained on and the mldlbased ids will
still be evaded by unknown adversarial perturbations
to overcome this shortcoming we have proposed a gan
based method depicted in figure  for adversarial training
of mldl models in blackbox idss for defending against
adversarial ml attacks
fig  outline of ganbased adversarial training for mldlbased idss
our proposed ganbased adversarial defense works by in
cluding a generative model in the mldlbased ids pipeline
and the ids model is not only trained on the input data but
also on the adversarial samples generated by the generative
model although this procedure resembles adversarial training
our approach is different since using a generative model such
as gan in an ids will introduce the robustness against both
known and unknown adversarial perturbations
b results of ganbased adversarial training
results in table iv highlight that the proposed procedure
of defending against adversarial network trafﬁc has improved
the robustness of the mldlbased ids a clear improvement
in precision recall and f score in table iv indicates that
the false positive problem associated with mldlbased ids
has also been taken care off by utilizing the proposed gan
based adversarial defense against adversarial perturbations in
network trafﬁc features
figure  provides a comparison between the accuracy of
different mldl techniques before an adversarial ml attack
after the attack after adversarial training and after gan
based adversarial training it is very evident from ﬁgure  that
the proposed ganbased adversarial training performed better
fig 
performance of ganbased adversarial mldl attack and defense
for blackbox ids
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
table iv
performance evaluation of proposed ganbased adversarial attack and defense framework on dnn rf lr nb dt knn svm
and gb schemes evaluation parameters are all in 
mldl
scheme
dnn
rf
lr
nb
performance
before
attack
after
attack
after
adv
training
after
ganbased
adv training
before
attack
after
attack
after
adv
training
after
ganbased
adv training
before
attack
after
attack
after
adv
training
after
ganbased
adv training
before
attack
after
attack
after
adv
training
after
ganbased
adv training
accuracy
precision
recall
fscore
mldl
scheme
dt
knn
svm
gb
performance
before
attack
after
attack
after
adv
training
after
ganbased
adv training
before
attack
after
attack
after
adv
training
after
ganbased
adv training
before
attack
after
attack
after
adv
training
after
ganbased
adv training
before
attack
after
attack
after
adv
training
after
ganbased
adv training
accuracy
precision
recall
fscore
than the simple adversarial training procedure the improve
ment in robustness using ganbased adversarial training can
be further improved by carefully selecting the hyperparameters
of gan in the ids we have also noticed a unique result where
nb has shown a drastic improvement against adversarial
perturbations once we have performed ganbased adversarial
training nb decouples class conditional feature densities
a clear improvement in the accuracy of the blackbox ids
performance after including gan in its training pipeline also
strengthen our decision of using gan as a defense against
adversarial perturbations
vi conclusions
in this paper we have proposed a ganbased adversarial
attack on blackbox mldlbased idss the proposed adver
sarial attack has successfully evaded the ids while ensuring
the preservation of functional behavior of the network trafﬁc
features we have reported the results for only one class but the
proposed attack is applicable to other network trafﬁc classes
we have also proposed and validated a ganbased defense
against adversarial perturbations to ensure robustness against
adversarial ml attacks our results highlight that a gan
based defense has improved the robustness of idss against
adversarial perturbations in the future we will concentrate
on improving our ganbased attack and defense framework
so that it can also be applied to other networking related tasks
another important future work is to design a discrete domain
gan purely for networking applications
data driven framework for analysis of air quality landscape for
the city of lahore
a rahman m usama m tahir m uppal
lahore university of management sciences lums pakistan
abdurrahman muhammadusama tahir mominuppallumsedupk
commission iv wg iv
key words air quality air quality monitoring system low cost air quality monitoring stations air quality data
abstract
several pakistani cities are among the worlds most polluted in the previous three years air pollution in lahore has been con
siderably over world health organization guideline levels endangering the lives of the citys more than  million citizens in 
this paper we investigate the citys capability to combat air pollution by analyzing three essential aspects  data  capacity 
and  public awareness several studies have reported the need for expansion of the current air quality monitoring network in 
this work we also provide a contextaware location recommendation algorithm for installing the new air quality stations in lahore 
data from four publicly available referencegrade continuous air quality monitoring stations and nine lowcost air quality measuring 
equipment are also analyzed our findings show that in order to measure and mitigate the effects of air pollution in lahore there 
is an urgent need for capacity improvement installation of referencegrade and lowcost air quality sensors and public availability 
of reliable air quality data we further assessed public awareness by conducting a survey the questionnaire results showed huge 
gaps in public awareness about the harms of the air quality conditions lastly we provided a few recommendations for designing 
datadriven policies for dealing with the current apocalyptic air quality situation in lahore
introduction
air pollution is defined as the contamination of indoor or out
door air with chemical physical or biological agents modifying
the characteristics of air most common sources of outdoor air
pollution include exhaust combustion from motor vehicles in
dustrial emissions forest fires livestock farming fertilizer and
power plants major constituents of air pollution are particu
late matter pm carbon monoxide co ozone o nitrous
nox and sulfur oxide sox
pm includes fine particles
suspended in the air these particles are usually  micro
meter pm and  micrometer pm in diameter vallero
 these particles are a byproduct of combustion in mo
tor vehicles burning fossil fuels industrial processes and other
sources of smoke other indirect sources are different chem
ical reactions of nox and sox in air major health effects of
the pm pollutants are decreased lung function eye nose and
throat irritation difficulty breathing aggravated asthma non
fatal heart attacks and even premature deaths in people with a
lung or heart disease history
particulate matter is a significant contributor to air pollution
air quality is measured using air quality monitoring systems
aqms which are technically validated by organizations such
as the united states environmental protection agency epa
among others and are also known as referencegrade aqms
referencegrade aqms are costly and require a significant
amount of upkeep
the pm values recorded by these
referencegrade stations are regarded authentic and are utilized
by appropriate authorities to issue health advisories in most
developed and underdeveloped countries there is a severe gap
in the installed referencegrade aqms resulting in huge cover
age gaps and inconsistent air quality data considering sparse
corresponding author
resources and the overburdened economies of developing coun
tries expansion of the current air quality measurement network
in a short time is a challenge on the other hand lowcost al
ternatives exist but the trustworthiness of their reported values
is frequently questioned many studies have been conducted to
enhance the performance of lowcost sensors according to the
literature a mix of referencegrade aqms and lowcost sensors
can aid in the development of urban cityscale measurement
networks while keeping the economic aspects of developing na
tions in check gulia et al  usama et al 
air pollution has emerged as a significant issue in the subcon
tinent pakistan has recently seen a yearly smog season that
lasts from november to february each year multiple pakistani
cities have made the list of the worlds most polluted cities in
recent years lahore the provincial capital of punjab is one
of the worlds three most polluted cities the current state of
lahores air quality puts the lives of the citys  million resid
ents in grave danger for the most part of the last three years
the air quality index aqi stayed between poor to severe the
aqi is a metric used to quantify the effect of air pollution on hu
man health based on limited exposure the higher the aqi the
more health risks there are in winters the smog fog and haze
results in the closure of the major highways airports and trans
portation incurring economic losses and social unrest many
road accidents due to smog are also reported resulting in deaths
and financial losses
conditions deteriorated to the point where the government was
compelled to take action to protect the public from additional
exposure and pollution it includes the closure of brick kilns
in  and the enforcement of conventional brick kiln conver
sion to zigzag technology with lower air pollutants mukhtar
 httpswwwpbsgovpkcontent
finalresultscensus
the international archives of the photogrammetry remote sensing and spatial information sciences volume xlviiiw 
th international conference on smart data and smart cities sdsc  october  sydney australia
this contribution has been peerreviewed 
httpsdoiorgisprsarchivesxlviiiw   authors  cc by  license
 
 in recent years the government has also issued orders
to shut down industries during the pollution season which has
had a disastrous effect on the economy in  punjab govern
ment also decided to close every monday for nearly a month to
combat smog these circumstances need a thorough examina
tion of the citys air quality landscape in this study we focused
on the available pm data sources in lahore pakistan and in
vestigated the capability of the city to handle the issue of poor
air quality
air quality and a citys capability to tackle air pollution are
quantified using three indicators  capacity  data and 
public awareness here capacity refers to public and private
measurement infrastructure data refers to the public availabil
ity of air quality measurements to develop datadriven policies
and public awareness refers to the general publics interest in
the issue and how the public views the ramifications of air qual
ity issues in this paper we make the following analysis and
contributions
 we have collected and prepared a dataset of the
pm measurement data from various publicaly available
sources referencegrade aqms and lowcost sensors and
analyze it to further reflect on the robustness and authenti
city of the reported data from the public sources
 based on the prepared dataset and the context information
of lahore city we have developed an algorithm for recom
mending deployment positions of new air quality measure
ment sensors we have also reflected upon the validity of
these results and how more context information can yield
better sensor deployment
 perception versus reality plays a vital role in swaying the
opinion of the urban public to adopt better practices for en
suring prevention against the hazardous effects of air pol
lution we have conducted a survey to gauge perception
vs reality of the air quality in lahore and this work also
provides the crux of these findings
the remainder of the paper is structured as follows in the next
section we will provide specifics on the air pollution data for
lahore city as well as the sources section  describes the pro
posed contextbased location recommendation approach for air
quality sensor placement and the results achieved section 
will discuss the survey conducted during this location recom
mendation approach to determine how individuals view the is
sue of air quality in lahore
section  contains a brief yet
informative discussion on the validity of the acquired results
finally in section  the work is concluded along with a dis
cussion on potential future directions
air quality data of lahore
needless to say the poor air quality in the city of lahore has
significantly adverse health effects on its residents life index
aqli from the energy policy institute at the university of
chicago epic released its  annual report on the effects
of poor air quality on the health of an average pakistani citizen
greenstone and fan  greenstone and fan  the
aqli report suggests that an average pakistani tends to lose
 years of life expectancy if the current levels of air pollution
 httpsdsalumsedupkgrandchallengefund
blogarchive
persist greenstone and fan  it also reports that in a
few most polluted areas the loss in life expectancy can go up
to  years greenstone and fan  an average citizen of
lahore is expected to gain  years worth of life expectancy
if the world health organization who guidelines for pm
are met
environmental protection departmentsagencies often collect
air quality data and health advisories are issued based on
predefined aqi readings pakistan like any other develop
ingunderdeveloped country does not have an adequate number
of aqms installed thus there is a scarcity of available air qual
ity data for most of the country only four referencegrade air
quality monitors and a few lowcost sensors with publicly avail
able air quality data are available in lahore we have confined
our investigation to pm because air quality data for majority
of lahore is not accessible for other criteria pollutants figure
 provides the location of the referencegrade and lowcost air
quality monitors in lahore city
figure  there are four referencegrade and eight lowcost air 
quality monitoring stations in lahore the figure depicts the 
location of the sensors on the map of lahore
three referencegrade sensors in lahore are from environ
mental protection department epd punjab and one from 
us consulate air quality station the data from epd is avail
able at daily granularity in pdf format the pdf files were 
digitized using pythonbased tools as well as manual scrapping 
the data from us embassy was available at hourly granularity 
we have converted both sources to daily granularity for com
parison and depicted the data timeline in figure  there are 
eight lowcost sensors deployed by purpleair with publicly 
available pm concentration values in lahore we have also 
converted them in daily granularity and figure  depicts the 
timeline of the data availability here we also want to note that 
there are a few other lowcost sensors in lahore deployed by 
iqair but their recorded data is not publicly available
we have noticed that two of the referencegrade stations 
stopped reporting pm values in mid dental college 
station and mid met station respectively only two 
referencegrade aqms are reporting pm concentrations for 
approximately  square kilometers which is not acceptable
 httpsepdpunjabgovpkaqi
 httpswwwairnowgovinternational
usembassiesandconsulatespakistanlahore
 httpswwwpurpleaircom
 httpswwwiqaircom
the international archives of the photogrammetry remote sensing and spatial information sciences volume xlviiiw 
th international conference on smart data and smart cities sdsc  october  sydney australia
this contribution has been peerreviewed 
httpsdoiorgisprsarchivesxlviiiw   authors  cc by  license
 
figure  timeline plot of pm data for reference grade 
sensors
figure  timeline plot of pm data for lowcost grade sensors
by any stretch of the imagination all lowcost sensors came 
online in midaugust  their calibration and ability to 
cater to context while reporting data lacks credibility
 air quality monitoring network of
lahore
in a recent verdict the lahore high court ordered the punjab 
government to take concrete steps to curb the air pollution in 
lahore the court also stated that corporations should also ful
fill their corporate social responsibility and reduce emissions 
and government must enforce the already existing suggestions 
from the lahore smog commission report and punjab clean air 
act to mitigate the smog situation the lahore smog commis
sion report recommended that the punjab government must in
crease the active referencegrade air quality monitoring stations 
from three to twelve based on the smog commission report 
epd punjab needs to install nine more referencegrade aqms 
here the challenging bit is to determine the optimal location 
for the installation of aqms several factors need to be con
sidered before deciding on the optimal installation location a 
few of these factors are namely availability of land possible 
conflicts with future urban construction and expansion plans 
accessibility to maintenance staff and other services security 
of the site and some heuristic constraints developed by previ
ous experiences etc despite the fact that these conditions are 
strong administrative markers for the installation research on 
air quality sensor placement suggests that a contextaware data
driven method can give optimal installation locations
sun et al proposed a citizencentric air quality sensor place
ment technique where they have used cambridge city traffic 
patterns point of interest values and demographic statistics as 
context information they modelled the location recommend
ation as a linear integer programming model in which both the 
objective function location and the constraints context are 
considered to be linear which we believe will result in a high
 httpsdatalhcgovpkreported_judgmentsgreen_
bench_orders
 footnoteurlhttpsepdpunjabgovpksystem
filessmogcommissionreportpdf
rate of false positive locations as the number of sensors to be
placed increases sun et al  kelp et al presented a
pm sensor placement approach where they used multiresol
ution dynamic mode decomposition mrdmd on  years of
historical pm data to suggest new sensor location kelp et
al  zhou et al compared five sensor placement tech
niques random minimization of the matrix condition num
ber for sensor placement empirical interpolation method for
sensor placement local extremabased techniques and qr
factorization method for sensor placement from the control
theory and fluid dynamics literature on a couple of satellite
derived huge pm datasets from china zhou et al 
though the compared techniques are well embedded in the lit
erature we do not have this sort of highresolution spatiotem
poral dataset available for lahore city mohar et al used qr
factorization singular value decomposition svd and ma
chine learningbased techniques to design an optimal sensor
placement technique for signal reconstruction in control sys
tems manohar et al  though this technique has shown
promise in sensor and actuator placement given the small num
ber of sensors in our case  and limited untrustworthy sparse
historical data the technique is highly likely to produce false
positives there are a few other optimal sensor placement tech
niques from communication systems and traditional sensors
network literature younis and akkaya  but these tech
niques are not optimal for a gappy untrustworthy sparse and
small dataset to determine the best locations for sensor place
ment in lahore city
microsofts urban air project is at the cutting edge of sensor
placement research for air quality measurements they have
developed a method that uses attributes from the previously in
stalled sensors and historical air quality data from existing sta
tions to suggest suitable locations for future air quality stations
hsieh et al  hsieh et al used an affinity graphbased
technique to determine the optimal location for aqms place
ment for bejing city in china the proposed procedure also
incorporates the historical pm concentrations meteorology
data road network poi data etc to ensure that appropriate
context is also incorporated in the optimal location selection
hsieh et al  zheng et al  the technique pro
posed in this paper is an extension of the affinity graphbased
approach where we have included various context features col
lected from lahore city and used whatever historical air quality
data is available
affinity graph based location recommendation sys
tem
hsieh et al used affinity graphs with a greedy entropy min
imization model to develop a location recommendation system
for aqms installation location recommendation hsieh et al
 initially the city is divided into graph nodes and edges
where every edge has an associated weight and every node
has an associated set of features road networks residential
areas commercial areas industrial areas public spaces met
eorological features and other factors that may contribute to
variation in air pollution since most location recommenda
tion techniques are designed and tested for developed countries
with historical data on air pollution and related context features
are publicly available the location recommendation for the new
aqms becomes a simple task since we are trying to predict
the location of the aqms for an underdevelopeddeveloping
 httpswwwmicrosoftcomenusresearchproject
urbanair
the international archives of the photogrammetry remote sensing and spatial information sciences volume xlviiiw 
th international conference on smart data and smart cities sdsc  october  sydney australia
this contribution has been peerreviewed 
httpsdoiorgisprsarchivesxlviiiw   authors  cc by  license
 
figure  flow chart of the station location recommendation algorithm
city where the available historical data is sparse and untrust
worthy and context features are also not available the simple
learning task becomes a real hassle
for lahore we have collected historical air quality data from
all known publicly available sources the data was cleaned and
preprocessed by following the data science principles clean
ing normalization outlier detection etc we have combined
the referencegrade aqms data with lowcost sensors data to
further improve the volume of the dataset gathering the con
text data for lahore city is challenging as to the best of our
knowledge it is not publicly available we have employed geo
graphic information systems gis tools for collecting context
information such as commercial hubs industrial areas traffic
hotspots etc the meteorology data was available the road
network was extracted using satellite imagery and machine
learning techniques figure  depicts the identified commercial
hubs industrial areas drainage streams and traffic hotspots
figure  identified pollution hotspots in lahore
since the proposed method is inspired from hsieh et al  
we recommend the interested reader to see hsieh et al  
for indepth details on how affinity g raphs c an b e leveraged 
for designing location recommendation algorithms our model
works in two stages the first step is to compute the probability
distribution of unlabeled nodes using feature weight matrices
graph weight matrices and labeled nodes the entropy for each
node is computed in the second phase and the node with the
lowest entropy is marked as the labeled node and given the low
est rank for a recommendation for the installation of a new air
quality station the model is given a new set of labeled and
unlabeled nodes iteratively a more detailed description of the
aqms location inference method in the following steps
 the input to the proposed location inference technique is
labeled node list labeled node air quality values histor
ical context features associated with each node unla
belled node list candidate node locations and features
associated with the unlabelled candidate nodes
 based on the input an affinity graph is created and graph
weight initialization is performed in our case we have
initialized it with all s
 after the initialization we have computed the initial en
tropy with the uniform underlying distribution of un
labeled nodes and the feature weight matrix is updated
using gradient descent the probability distribution of the
updated unlabelled nodes is estimated using a harmonic
function and the entropy of the updated graph is com
puted
 the difference between the entropy of pre and post
graph updates is computed and subjected to a difference
threshold if the entropy difference is less than the pre
defined threshold value we ranked the node with the low
est entropy in the reverse order and assigned the node to a
labeled node predicted aqi assignment whereas if the
entropy difference is greater than the predefined threshold
the algorithm will go back and update the graph and fea
ture weights and entropy is recomputed
 if there is no unlabeled node left in the graph the proposed
algorithm will output the n highestranked nodes which
in our case are the first nine nodes since we have conver
ted lahore into a graph grid the label of the top n nodes
will also provide their location information on the map
 we observed an inherent problem of clustering multiple
recommended nodes in this algorithm we noticed that
the international archives of the photogrammetry remote sensing and spatial information sciences volume xlviiiw 
th international conference on smart data and smart cities sdsc  october  sydney australia
this contribution has been peerreviewed 
httpsdoiorgisprsarchivesxlviiiw   authors  cc by  license
 
the conversion of unlabeled nodes from near the labeled
nodes converged to the point where none of the nodes
were labeled because the node with the lowest entropy was
tagged as a labeled node it is an issue when the number of
recommended locations is more than one thus multiple
nodes were recommended in a cluster to tackle this prob
lem we introduced another loop to recommend only one
location in every iteration and use the previous recommen
ded location as a labeled node in the next iteration
the flow chart for the algorithm used for inferring the optimal
aqms placement is depicted in figure 
we tested the proposed algorithm with the available air quality
data for lahore city and the collected context features the pro
posed aqms location recommended algorithm provided  re
commended for new aqms deployment the output of the pro
posed model for the recommendation of  stations for lahore
city is provided in figure  referencegrade aqms are usually
deployed by the environmental protection departmentagencies
which epd punjab will do in the future though for now we are
planning to deploy  lowcost on the recommended locations
to collect pm concentrations in future work we intend to
analyze the efficiency of the proposed location algorithm using
the reported data from all air quality measurement sources
figure  recommended locations for installation of air quality 
stations yellow with the locations of currently installed stations 
red
 public awareness
the third component of accessing the ability of a city to deal 
with the air quality issue is its public awareness following the 
tradition in the literature liu et al  pantavou et al  
lou et al  maione et al  we have designed a sur
vey with only ten simple questions addressing the perception of 
the air quality among citizens and how this perception is built 
and whether they are taking any measures to avoid detrimental 
consequences of the air pollution in lahore city the question
naire varied from general public perception of air pollution and 
public information sources to the selfreported levels of health 
impact due to air pollution
we have conducted this survey from st december  to 
th january  we have received  responses from dif
ferent universities in lahore as expected nearly  of the
participants were between  years old
 of the re
sponses came from males and  from female participants
we collected responses from  different public and private uni
versities in lahore nearly  of the responses suggested that
the air quality in lahore ranges from very poor to severe 
said severe and  said very poor nearly  of the re
sponses suggested that smogfoghaze is their sensory percep
tion for air quality this response statistics also show that many
people think that air pollution only exists in winter and as soon
as the smog is gone the air quality is back to normal which is
not the case this response also suggests the lack of information
about air pollution among young people our result also shows
that news mobile applications and social circles are domin
ant ways to get air qualityrelated information nearly  of
people responded that they do not take any precautions to deal
with air pollution  of the total responses suggested that
they have a respiratory condition and out of those  people
 said that their condition aggravated due to poor air quality
in lahore lastly  of people suggested that transport is the
major contributor to poor air quality in lahore the rest of the
people responded in favor of industries agriculture etc the
responses distribution about the potential sources of the survey
are depicted in figure  more details on our survey and results
are available on our blogpost
this survey suggests the need to raise public awareness about
the dangers of air pollution and we suggest that including com
ponents on air pollution its causes and ways to deal with it
must be included in the school college and university cur
riculum we also recommend public meetings town halls and
seminars to increase awareness among people we also sug
gest the give incentives to the residential and commercial areas
where the air quality improves
figure  public awareness survey response on the perception 
about the potential air pollution sources in lahore
 discussion and recommendations
in this article we assessed lahores ability to cope with the 
growing air pollution problem in three areas data capability 
and public awareness our findings show that lahores present 
air quality monitoring network has significant gaps and the city 
is unable to deal with the everincreasing menace of air pollu
tion lahore does not have enough aqms installed and the 
available aqms data is gappy unreliable and does not reflect 
the severity of the air pollution we suggest that epd punjab 
needs to increase the referencegrade aqms and also support
 httpsdsalumsedupkgrandchallengefund
blogarchive
the international archives of the photogrammetry remote sensing and spatial information sciences volume xlviiiw 
th international conference on smart data and smart cities sdsc  october  sydney australia
this contribution has been peerreviewed 
httpsdoiorgisprsarchivesxlviiiw   authors  cc by  license
 
the deployment of lowcost sensors epd also has to ensure
an ample amount of calibration and chemical analysis facilities
to further the quality of sensing and source apportionment the
development of a public dashboard is prevalent where all public
and private data on the air quality is gathered and analyzed and
made available to the public there is a dire need for academic
and industrial partners to further enhance the agenda on gath
ering reliable air quality data and using machine learning and
other predictions technique to prepare the epd for upcoming
air quality challenges
in this work we also did our bit by designing an aqms place
ment algorithm that incorporates the local context to provide
optimal location this effort is also a candidate solution to effi
ciently using the limited financial resources available here we
also want to note that deploying  aqms in lahore will not
solve the data availability issue general public housing societ
ies and institutions also have to play an active role in the dens
ification of the air quality monitoring network we recommend
that all government and private housing societies universities
industries hospitals etc install aqms near reference or low
cost and make the date available to the public and government
public awareness is the third component of accessing the abil
ity of lahore city to cope with the air quality issues our sur
vey indicates the lack of awareness about the air quality issues
our survey also reveals disparities between public perception
and real air quality there is an urgent need to raise public
knowledge about air quality through awareness campaigns and
community activities the general public is unaware of the vari
ous resources for reporting air quality more emphasis should
be placed on preventative measures such as wearing masks in
stalling air purifiers and reducing outside activity during pollu
tion studies on source apportionment may aid in quantifying
the sources of air pollution in pakistan we recommend includ
ing air quality and associated information in school college
and university curricula collaborating with religious experts to
emphasize the issue of air quality in friday sermons and other
religious gatherings supporting public awareness events such
as seminars and town halls and offering incentives to the resid
ential and commercial areas where the air quality improves
challenges
there are a few significant obstacles and tradeoffs that devel
opingunderdeveloped nations must confront which necessit
ate a concerted global effort to address the air pollution prob
lem following are a few challenges keeping in view the un
derdevelopeddeveloping countries
 data collection and public datasets collecting air qual
ity data is a difficult process since varying concentrations
of air contaminants are involved given the environmental
and health dangers associated with poor urban air qual
ity it is critical to creating a centralized realtime air qual
ity data monitoring and processing system sensorcentric
data collection and crowdcentric data collection are two
approaches for obtaining urban data eg air quality data
poi meteorological data etc there are two types of
sensorcentric paradigms these classifications are based
on whether the sensors gathering data are mobile de
ployed on a moving item or static deployed on a fixed
location there are two types of crowdsourced data col
lection active data created through participation surveys
and checkins and passive data generated by users pass
ively while using the urban infrastructure it is important
to understand what type of approach can help gather the
most reliable and larage amount of air quality data usama
et al 
 tradeoff between economic growth and air pollution
most developing countries are trying to manage their eco
nomies and the balance between economic expansion and
air pollution is almost always skewed toward economic
growth
finding a middle ground between economic
growth and air pollution is a challenging task health and
environmental budgets are diminishing making it difficult
for developing countries to detect report and improve the
air quality xu and li  usama et al 
 regularization and air quality measurements
un
derdevelopeddeveloping countries must implement data
driven policies with regularisation based on data and local
context once these policies are developed the adminis
tration must guarantee that they are executed yamineva
and romppanen  usama et al 
 public
awareness
unfortunately
in
under
developeddeveloping
nations
public
understanding
of the hazards of air pollution and efforts to ameliorate its
consequences is relatively low with the development of
social media applications and the internet penetration the
government may easily overcome this challenge the ad
ministration should use social media platforms television
shows print and digital platforms town halls seminars
hackathons conferences and so on to disseminate as
much information as possible about the effects of air
pollution on human health and the local economy major
air pollution sources and what options the public has to
help reduce emissions
conclusions
in this article we assessed lahores potential to deal with the
looming challenges of air pollution across three dimensions
data capacity and public awareness the goal of gaining ac
cess to lahores ability to deal with air quality on the afore
mentioned verticals is to establish the groundwork for building
a framework for developing an air quality network for under
developed countries we also proposed an optimal placement
suggestion approach for installing air quality monitoring sta
tions finally we have identified a few challenges that develop
ing nations must solve in order to avert the air apocalypse
jade datadriven automated jammer detection
framework for operational mobile networks
caner kilinc mahesh k marina muhammad usama salih ergut jon crowcroft tugrul gundogdu
ilhan akinci
the university of edinburgh the alan turing institute turkcelluniversity of cambridgeoredata
abstractwireless
jammer
activity
from
malicious
or
malfunctioning devices cause significant disruption to mobile
network services and user qoe degradation in practice detection
of such activity is manually intensive and costly taking days and
weeks after the jammer activation to detect it we present a
novel datadriven jammer detection framework termed jade
that leverages continually collected operatorside celllevel kpis to
automate this process as part of this framework we develop two
deep learning based semisupervised anomaly detection methods
tailored for the jammer detection use case jade features further
innovations including an adaptive thresholding mechanism and
transfer learning based training to efficiently scale jade for
operation in realworld mobile networks using a realworld g
ran dataset from a multinational mobile network operator we
demonstrate the efficacy of proposed jammer detection methods
relative to commonly used anomaly detection methods we also
demonstrate the robustness of our proposed methods in accurately
detecting jammer activity across multiple frequency bands and
diverse types of jammers we present realworld validation
results from applying our methods in the operators network
for online jammer detection we also present promising results
on pinpointing jammer locations when our methods spot jammer
activity in the network along with cell site location data
i introduction
jamming is the intentional interference aimed at disrupting
wireless communications services and as such can be seen as
a denial of service dos attack   the use and sale
of jamming devices commonly referred to as jammers is
therefore illegal in many countries eg   and any
violations may result in imprisonment or fines eg  
nevertheless jammers targeting all wireless communications
technologies continue to be widely available and in fact
quite affordable see  for example the threat posed
by jammers to robust wireless communications including
on mobile networks is expected to become worse in the
future with lowcost and opensource softwaredefined radio
sdr platforms becoming easily available to arm malicious
actors 
in this paper we consider jamming in operational mobile
networks and in particular focus on the problem of detecting
jammer activity in this context the activation of jammers can
severely deteriorate the service quality in a mobile network
fig  shows the impact on selected celllevel key performance
indicators kpis due to the presence of a jammer using
data from an operational g network we observe that the
jammer activation effectively shuts down the network for users
forcing uplink ul and downlink dl traffic volumes and
throughputs down to nearzero the levels of received signal
strength indicator rssi can also be elevated by over db
x increase with a jammer these results highlight the
potential risk posed by jammers to the robustness of mobile
networks this applies not just to currently deployed g and
g networks that the society heavily relies on for personal
mobile communications emergency response systems and
public safety networks but also for future g networks that
aspire to support diverse use cases including ultrareliable and
lowlatency communications services eg connected vehicles
remote surgery
the jammer detection in current practice however is
a highly manual process that is costly and slow resulting
in degradation in user quality of experience qoe while
the jammer induced interference is detected and resolved
when significant service quality deterioration or network
outage is noticed which may be prompted by user reporting
radio network engineers manually examine large volumes
of multidimensional network kpi data to diagnose the
problem which may also require field testing moreover
when jammer activity is intermittent it can be perceived as
a radio network problem and result in misguided network
reconfigurationsoptimizations thus in current operational
mobile networks according to the operators themselves it
may take days or weeks after the jammer activation for it to
be detected this suggests that jammer detection is a perfect
use case for automation in mobile networks that can not only
lead to savings in operating expenditure opex costs for
operators but also enhance user qoe jammer detection is
also the first step that can enable further troubleshooting to
identify and pinpoint the interference source
in view of the above we aim at automated jammer detection
for operational mobile networks that can automatically and
quickly detect jammer deactivations then trigger alarms to
kickstart downstream resolution processes while this clearly
involves reliable detection of all kinds of malicious jammers
we also aim to detect the operation of other unintentional
interference sources eg malfunctioning devices dect
phones that can cause jammerlike impact on the network
achieving this goal however is hard as it requires addressing
the following challenges
 any available groundtruth label information on jammer
activations to build an automated detection system may
be limited to small parts of the network andor short
periods of time due to the scale of the task and manual
nature of the process so practical jammer detection
  ieee
ieee infocom   ieee conference on computer communications    ieee  doi infocom
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
fig  impact of jammer presence on three celllevel kpis
a uldl traffic volumes b uldl throughputs and c
uplink rssi
methods need to generalize well to be applied to bulk
of the data that is unlabeled
 jammers can have very diverse behaviors some jammers
once activated may stay continuously active while others
exhibit complex discontinuous activation patterns they
also differ from each other in their type eg military
drone specific jammer dect phone the networks
eg g g and frequency bands they target in our
realworld dataset we have encountered jammers that
can affect as many as ten different frequency bands
moreover newer types of jammers with a priori unknown
characteristics can emerge over time
 jammer related activity needs to be disambiguated
from network kpi dynamics induced from normal and
expected behavior eg due to user mobility network
overload but this can be challenging for example with
active but distant jammers
to this end we present jade which to the best of our
knowledge is the first automated jammer detection framework
for operational mobile networks by treating jammer activity
as abnormal or anomalous from the mobile radio access
network ran infrastructure side jade approaches jammer
detection as an anomaly detection problem  jade is
envisioned for operator side deployment and considers cells at
each tower site as measurement vantage points it continually
monitors the time series of various kpis at each of these cells
to detect anomalous behavior over time
at the core of jade are two deep learning based time
series anomaly detection methods that we developed they work
with multivariate kpi data at each cell in the first method a
multivariate long short term memory lstm neural network
model tracks the variation of uplink rssi observed at each
cell to predict its future value and detects an anomaly jammer
activation when the difference between the predicted and
the actual value is more than a threshold the second method
models multivariate kpi time series using a lstm autoencoder
model and the associated reconstruction error over time is
compared against a threshold to detect jammer activation
to address the several challenges outlined above ie limited
labeled data ability to detect new and a priori unknown
jammer activity discrimination of jammer activity from normal
kpi dynamics jade operates in a semisupervised anomaly
detection mode  in that it relies only on normal data
for training the above outlined models this jammer agnostic
nature of jade also makes it robust for detecting jammers
that may exhibit adversarial behaviors jade also embeds a
mechanism to adaptively set thresholds to detect anomalies
thereby adjust the boundary between normal and abnormal
events to efficiently support the detection of jammers at
scale in realworld mobile networks across multiple cells and
operating frequency bands we employ transfer learning 
to develop one frequency and cell agnostic model instead of a
different model for each cell and frequency band
in summary we make the following key contributions
 we propose jade a novel datadriven jammer activity
detection framework for operational mobile networks
iii which addresses this problem for the first time
it incorporates two alternative customtailored semi
supervised deep learning based anomaly detection
methods for the jammer detection task along with an
adaptive thresholding mechanism jade also leverages
transfer learning towards efficient modeling and ease of
deployability
 we extensively evaluate the jade framework using a g
radio access network ran dataset from a multinational
mobile network operator iv
 our results show that the anomaly detection methods
developed for jade outperform a wide range of
commonly used anomaly detection methods when
applied to the jammer detection task and also confirm
the effectiveness of jades adaptive thresholding
mechanism
 we
demonstrate
the
robustness
of
the
jade
framework powered by transfer learning in accurately
detecting jammer activity across multiple frequency
bands and diverse types of jammers
 we also present realworld validation results by
applying our methods in the operators network for
online jammer detection
 as a downstream use case of jade we consider
jammer localization specifically we demonstrate the
potential for pinpointing jammer locations based on
jammer activity detections in the mobile network
using jade and combining them with cell site
location data
next section describes our datasets and evaluation metrics
ii preliminaries
a datasets
a unique and noteworthy aspect of our work is the use of
real g ran datasets from a multinational mobile network
operator for our evaluations overall these datasets outlined
below consist of about a million samples of radio network kpis
measured at an hourly time resolution over several months
training dataset this dataset contains normal data
collected during periods with no jammer activation which
is verified manually by the radio engineers from the operators
network it is used for training the two semisupervised anomaly
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
detection methods we developed as part of the proposed
jade framework this dataset consists of around 
measurement samples in total that were collected over a period
of three months from  different cell tower sites hosting 
distinct cells operating over five lte uplink frequency bands
 mhz  mhz  mhz 
mhz and  mhz each sample is a timestamped
at hourly granularity tuple of  different radio network kpis
measured at a cell uplink and downlink traffic volumes
mb average uplink and downlink user throughputs at
pdcp layer mbps average uplink rssi dbm eutran
radio access bearer erab setup success  evolved
radio access bearer erab drop  lte random access
channel rach success  and voice over lte volte
drop 
testing dataset in contrast to the training dataset this
dataset corresponds to periods with jammer activation events
specifically it is made up of three subdatasets each
corresponding to a different jammers activity over a  week
period these three jammers are arbitrarily named by the
operator as j j and j among these j affects three
frequency bands  mhz  mhz 
 mhz and has a discontinuous onoff activation pattern
on the other hand j and j have continuous activation
patterns which means once activated they stay active until
they are switched off j and j operate on  mhz
and  mhz bands respectively all these three sub
datasets are manually labeled by radio network engineers from
the operator with groundtruth on jammer activeabsent for each
sample these groundtruth labels are key to our study in that
they enable evaluation of different jammer detection methods
considered in this paper overall the testing dataset consists of
 samples with groundtruth annotated kpi data kpis
captured in each sample are same as in the training dataset
each of the three subdatasets contain data for at least  cells
for the above datasets we have conducted preprocessing
steps to impute missing values with the average of neighboring
values
and
normalized
each
kpi
value
via
minmax
normalization we did further feature extraction based on
the timeseries of the above listed kpis following a similar
methodology to the one in  which led to  features in
all besides the datasets described above the proposed jade
framework and constituent jammer detection methods are
validated through trials on the operator side in ivc we
present results for two additional different jammers labeled
j and j encountered during the field trial period in the
case study on jammer localization based on jammer detection
events ivd we also use the groundtruth location data
for j j and j jammers along with the location data
of surrounding cell tower sites from the operator to assess
jammer localization accuracy
b evaluation metrics
here we describe our metrics to evaluate the various jammer
detection methods developedconsidered in this paper these
fig  relative importance of different features kpis for the
random forests based classifier
metrics are defined in terms of four possible outcomes that can
result from applying a jammer detection method which are
 truepositive tp jammer activity detected when such
activity is actually present as per the groundtruth
 falsepositive fp jammer activity detected when in fact
there is no jammer activity
 truenegative tn jammer activity not detected when
jammer activity is absent as per the groundtruth
 falsenegative fn jammer activity not detected even
though jammer is actually active
an effective jammer detection method minimizes both fps
and fns two commonly used measures to assess the extent
to which a given method achieves these goals are precision
and recall as defined below
precision 
tp
tp  fp
recall 
tp
tp  fn
higher values for both these metrics are desired a lower
value of precision equivalently a higher number of fps leads
to an increase in opex to diagnose confirm and localize
jammer activity eg by field visits and testing when in
reality there is none on the other hand a lower value of recall
equivalently a high number of fns shows that the method
in question fails to detect all jammer activation events and
thus risks prolonged degradation of user qoe until the jammer
activity is eventually detected and stopped given the above
having high precision and high recall are equally important
as such we consider a composite metric called fscore that
weighs precision and recall equally by taking a harmonic mean
of the two as defined below
fscore 
p recision 
recall
iii the jade framework
in this section we describe our proposed jade framework
for datadriven automated jammer detection in operational
mobile networks in detail by way of motivation we start by
examining the limitations of commonly used jammer detection
approach based on supervised classification thereby highlight
recall is sometimes also referred to as sensitivity or true positive rate
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
a challenge that an effective jammer detection method design
needs to address
a limitations of supervised binary classification approach
a straightforward approach to jammer detection is to treat
it as a supervised binary classification problem in fact most
recent works on jammer detection  though aimed at
 networks take this approach and show random forests
rf  to be the most effective classifier here we assess
the effectiveness of supervised binary classification approach
towards jammer detection in operational mobile networks
considering rf as the classifier
since we need a labeled dataset for training and testing
with supervised classification we use one of our testing sub
datasets for the j jammer outlined in section iia for this
study each sample in this dataset is a tuple kpi data labeled
as jammer activeabsent the dataset overall spans over 
cells across three different frequency bands  cells in 
mhz  cells in mhz and  cells in 
mhz it is a fairly balanced dataset with  
jammer active inactive samples we do a  split of this
dataset to create training and test data for the rf based binary
classifier which leads to a test set with  cells in 
mhz  in mhz  in mhz
we first use the rf feature importance  test to examine
the relative importance of the different features from the
classifiers perspective with the results shown in fig  we
find that the average uplink rssi is the most important
feature followed by uldl traffic volumes and throughputs
interestingly the percentage of volte drops has the least
predictive effect on the classifier perhaps because call drops
could happen due to a myriad of factors beyond the jammer
presence eg due to network overload or coverage issues
fig  shows the box plot results for precision recall and f
score metrics separately for each frequency band where the j
jammer operates with each box plot capturing the distribution
for the metric across different cells we observe that precision
and recall values are less than ideal and range between 
 and  respectively the relatively lower recall
results indicate that this supervised classifier method errs more
towards missing some jammer activation events than causing
false alarms the combined effect measured by fscore is
worse with a median value between  and 
crucially this poor classification performance is noticed for
cases with fewer cells and less data in the training dataset
this highlights a key issue with supervised classification based
approach to jammer detection  more and diverse labeled
data is needed compared to getting normal class data it is
difficult and very costly to produce a large and diverse labeled
dataset with jammer activation events more data can be
available for normal periods as reflected by our datasets
where  samples or at least  of the total data is for
the normal category but supervised classifiers fail to take
advantage of such data
fig  precision recall and fscore performance of random
forests based supervised binary classifier
b jade overview
the foregoing discussion not only highlights limitations
with the supervised classification based approach but a key
challenge to be addressed in jammer detection method design
ie limited or no data labeled with jammer effect another
challenge is that there exist numerous types of jammers and
each has its own different characteristics and impact on mobile
network performance eg due to affecting different sets of
frequency bands gathering training data that represents all
jammer types is simply impractical moreover identifying the
decision boundary between normal network behavior and that
affected by jammer activity through the radio network kpis is
challenging due to the inherent kpi dynamics
our proposed jade framework illustrated in fig 
addresses the above challenges jade is envisioned for operator
side deployment and considers cells at each tower site as
measurement vantage points to aid in online jammer detection
it relies on continual monitoring of time series of various kpis
at each of these cells and collecting this data at the operator
ran data lake facility this data is then preprocessed to address
issues such as missing values by imputing with neighboring
ones before putting it through the jammer detection pipeline
in jade
jade approaches jammer detection in an operational mobile
network as a timeseries anomaly detection problem 
by considering that jammer activity manifests as abnormal
or anomalous in the time series of radio network kpis
to address the aforementioned challenges jade adopts the
semisupervised form of anomaly detection  by solely
relying on and leveraging potentially abundant normal data
for model training this also makes jade independent of
the type and behavior of a jammer thereby enabling robust
detection across diverse types of jammers at the core of jade
are two alternative deep learning based anomaly detection
models besides jade incorporates an adaptive mechanism
for these models to set thresholds that represent the boundary
between normal and anomalous samples also rather than
have a separate anomaly jammer detection model per cell or
frequency band jade employs transfer learning  towards
one cell and frequency band agnostic model we elaborate on
the above components of jade in the following subsections
c deep learning models for celllevel anomaly detection
here we describe the two anomaly detection based models
we develop as part of jade for jammer activity detection
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
fig  illustration of the jade framework
 autoencoder ae  based model  rssi prediction
based model both these models operate at the cell level and
take multivariate time series data for radio network kpis as
input but aim to detect anomalous samples in the time series
through different approaches as elaborated below since we
are dealing with timeseries data we use lstm  cells in
the architecture of both models
 autoencoder ae based anomaly detection model
fig a illustrates the proposed lstm autoencoder based
model that takes multivariate time series as input the core
idea is to encode each input sample using an lstm network
and decode it using another lstm network anomaly detection
relies on the inability to faithfully decode the input sample
with a sufficient amount of training data ie normal samples
the ae model learns to reconstruct the normal samples the
reconstruction error for normal samples will therefore be lower
compared to the reconstruction error of samples in the presence
of a jammer
as mentioned above the ae model has two components an
encoder and a decoder the encoder represents the input sample
in the latent space whereas the decoder aims to reconstructs
the latent domain back to the input sample the encoder in
our model consists of four layers the number of lstm cells
in the first layer is equal to the number of features in the input
sample while the following three layers have   and 
lstm cells respectively then the decoder reconstructs the
input sample from the dimensional latent space the decoder
also consists of four layers where the number of lstm cells
in its first three layers are   and  respectively the
number of lstm cells in the last layer of the decoder equals
the input sample size in terms of features to the ae model
we use mean squared error mse as a loss function and
trained the model for  epochs for every cell in the training
dataset we empirically optimize the hyperparameters with
grid search
 we use rmsprop as an optimizer and
relu as an activation function with a batch size of  since
the network kpis have inherent noise and variations we did
not introduce any additional noise in the input of the ae
towards better generalization
 rssi prediction based anomaly detection model we
now present an alternative anomaly detection model for jammer
activity detection that focuses on predicting the uplink rssi
over time considering that this kpi is seen to be the most
fig  a autoencoder based anomaly detection model b
rssi prediction based anomaly detection model
important feature in our earlier study on supervised binary
classification based jammer detection fig  the essential
idea here is to train a timeseries prediction model that takes
as input multivariate time series of kpis and predicts the rssi
for each following time step the prediction error is expected
to be low for normal samples as the model is trained with
data consisting of such samples but the presence of jammer
activity can yield higher prediction errors which can then be
identified as anomalies jammer activation events
fig b illustrates our rssi prediction based anomaly
detection model which leverages the stateoftheart lstm
based time series prediction model architecture our model
consists of four lstm layers the input layer three hidden
lstm layers and one fully connected output layer the lstm
cells in the input layer are equal to the number of features in
each input sample the following three hidden layers have 
 and  lstm cells respectively the output layer is a fully
connected dense layer with a single neuron that outputs rssi
predictions specifically our model predicts the rssi for the
following  time steps based on multivariate kpi time series
for the past  time steps along a moving window like in the
ae model the hyperparameters are experimentally optimized
with grid search relu is used as an activation function and
the batch size is 
 single and multikpi models we consider two variants
of the above described models
 single kpi model that considers only one kpi specifically
rssi in essence ae and rssi prediction versions of this
model deal with rssi kpi time series note that each sample
in the input time series to these models is multivariate with
 different features due to feature extraction during data
preprocessing
 multikpi model that considers all  kpis in our dataset
including other kpis like uplinkdownlink throughput and
rach success rate this is naturally a multivariate time series
with  features in each sample of the input time series again
due to the feature extraction step
these single and multikpi models allow us to understand
the added benefit of considering the various different kpis
beyond just the uplink rssi
d adaptive thresholding
the two anomaly detection models described in the previous
subsection produce a reconstructionprediction error for each
new sample in a cell kpi time series but to detect whether
that sample is an anomaly due to jammer activity or other such
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
fig  representative result showing the performance gain
with our grubbs test based adaptive thresholding approach
compared to the stateoftheart nσ approach
interference we need a threshold error level representing the
boundary between normal and anomalous samples correctly
setting this threshold is equally key to effective jammer
detection it can be seen as deciding the tradeoff between
fp and fn probabilities
different approaches are taken for this thresholding in the
literature some works do this manually relying on human
expert feedback to setadapt thresholds eg  but
this is unviable in our setting feng et al  simply use the
median reconstruction error as the threshold which is again not
robust most recent wireless anomaly detection works however
approach this thresholding by assuming that errors are generated
from a gaussian distribution some of these works 
set the threshold based on a desired fp probability which is
not appropriate in our setting as we also would like to have
equally good precision and recall performance
other works  adopt a nσ thresholding approach
for some small value of n where σ is the standard deviation
of the error distribution this essentially means that a sample
is considered an anomaly if its error reconstructionprediction
error in our case is more than nσ away from the mean of
the error distribution obtained using normal training data
while the reconstructionprediction errors across all samples
in the training data also follow a gaussian distribution in
our case results not shown due to space limit we find the
nσ thresholding approach is not robust in our setting as we
show shortly we observe that this is because of the diversity
among cells and so the impact of a jammer on those cells is
also different there also exist other works eg  that
empirically obtain a fixed threshold
we instead take a tailored adaptive thresholding approach
on a per cell basis by examining the time series of
reconstructionprediction errors in each cell to detect
anomalies our proposed approach to this issue can be seen as
an adaptation of grubbs test  for single outlier detection
in univariate data note that the data for thresholding purposes
refers to either reconstruction or prediction errors depending on
the anomaly detection model used and it is therefore univariate
in the following we describe our proposed thresholding
method
we start by defining two hypotheses h there are no
outliers in the data and h there is exactly one outlier in
the data we also define grubbs test statistic to be calculated
fig  average rssi distribution across cells using different
uplink frequency bands
for each new data error sample yi
g_calc  maxyi y 
s
where y and s respectively represent the mean and standard
deviation of the error data samples considered for outlier
detection based on the above we detect an outlier yi or
equivalently reject the null hypothesis h hypothesis of no
outliers if the calculated test statistic is greater than a critical
value as defined on the right hand side of the equation below
g_calc  n 
n
s
tαnn
n   tαnn
where n is the number of training error samples considered
initially t refers to the tdistribution and α is the significance
level related to the desired confidence interval if on the
other hand g_calc is less than or equal to the critical value
then we conclude there is no outlier in the set of n samples
we bootstrap the above statistic calculation with a series
of n error samples ϵ from the training data and view it as
a window then when we apply an anomaly detection model
one of the two from the previous subsection to each new
sample in the radio network kpi time series for a cell we
slide the window and include the new error sample ϵnew to
recalculate the statistic if it is greater than the critical value
the new error sample corresponds to an outlier anomaly and
so we undo the window sliding to ignore ϵnew otherwise
ϵnew is now part of the set of error samples considered for
outlier detection in this work we set α to  equivalent to
 confidence interval and empirically set n to 
fig  demonstrates the effectiveness of our above described
grubbs test based thresholding approach with the nσ
approach for different typical values of n   and  for
the j ul  mhz test dataset and using the
multikpi rssi prediction based anomaly detection model
box plots reflect the distribution of each metric across all cells
in this dataset these results clearly any single static threshold
is not effective generally while our adaptive approach always
yields the best performance we have observed similar
performance improvement with our approach with the other
test datasets omitted due to space limitations
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
fig  relative performance of ad models in jade on the
j ul  mhz test dataset
e transfer learning
our proposed solution for detecting jammer activity via
anomaly detection model with adaptive thresholding approach
thus far implicitly considered a single cell scenario in
practice however each cell tower site hosts multiple cells
possibly configured on different frequency bands moreover
an operators network deployment may have thousands of such
cell sites but training and maintaining a per cell or even per
frequency band anomaly detection models is not scalable from
a deployment perspective
we therefore aim at a single cell and frequency agnostic
anomaly detection model one per each alternative discussed
in iiic we cannot however base such a model by training
it on single cell or even single frequency band as different
cells and frequency bands have diverse behavior in terms of
radio network kpis and jammer effect for example the rssi
distributions across cells on different uplink frequency bands
shown in fig  clearly highlight such diversity so we train
our target cell and frequency agnostic model using normal
data from different cells and frequency bands to make this
training efficient we leverage transfer learning tl 
specifically we train the cell and frequency agnostic model
as follows we start with a frequency band and a cell within
that band once the model is trained with data for that cell we
treat that as the start point for training on a different cell from
the same frequency band reusing the already trained models
weights as opposed to starting from scratch once the model
is trained across all cells of a frequency band then it is used
as the base model for training on cells for another frequency
band we repeat this process until we cover all frequency bands
and cells in the training data which ultimately results in the
frequency and cell agnostic model
iv evaluation
in this section we evaluate the performance of the proposed
jade framework using the operator provided g ran datasets
described in iia in terms of the precision recall and fscore
metrics defined in iib
a comparative evaluation of anomaly detection methods
in the previous section we have already presented evaluation
results that show the effectiveness of the adaptive thresholding
mechanism in jade here we evaluate the different anomaly
fig  performance of baseline ad methods on the j ul
  mhz test dataset
detection ad model alternatives in jade relative to
commonly used ad methods  
recall from iiic that the jade framework offers four
different ad models ae and rssi prediction based models
each with single and multikpi versions we train these models
using the training dataset iia we evaluate using the j
ul  mhz part of the testing dataset for
comparison we consider five diverse and commonly used
ad methods zscore local outlier factor oneclass svm
robust covariance and isolation forest to make these baseline
methods work with our multidimensional kpi data we use
principal component analysis pca  based dimensionality
reduction to represent the dataset in twodimensional space
fig  shows the performance comparison between the four
jade ad models we observe that the multikpi version of ae
based ad model performs worse than the other three models
especially in terms of recall however the single kpi version
specifically rssi of the ae model relatively performs much
better we attribute this to the characteristics of kpis other
than rssi that allow reconstruction even in jammer presence
resulting in some jammer activations going undetected rssi
prediction based ad models both perform well with higher
than  values in all three metrics the multikpi version
of rssi prediction based model offers the best performance
overall which suggests that considering all kpis is beneficial
although marginally relatively the baseline methods perform
quite poorly with values for all metrics less than  which is
no better than the random guess based on the known probability
of jammer activation events in the test dataset as prior fig 
these results provide a convincing justification for developing
tailored ad methods for kpi based jammer detection as we
do in jade
b robustness across diverse frequencies  jammer types
so far we have considered the jade performance on one
uplink frequency band j ul and with jammer type
j here we evaluate across different frequency bands
and jammer types to assess its robustness for this study
we consider the best performing model from the previous
experiment as the jade ad model  the multikpi version
of rssi prediction based ad model
we first compare the jammer detection performance between
frequencyspecific and frequencyagnostic versions of the
chosen jade ad model on different frequencies that j
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
fig  the performance of multikpi version of rssi
prediction based ad model in jade on different j frequency
bands comparing tl based frequencyagnostic model with
frequencyspecific models
fig  training time gain from using tl to train the frequency
agnostic multikpi rssi prediction based ad model
jammer operates on the frequencyagnostic version is obtained
with tl based training as described in iiie results shown
in fig  indicate that the frequencyagnostic model though
marginally worse than its frequencyspecific counterparts yields
greater than  value for all metrics in more than  of the
cells the training time from using tl relative to not using it
is shown in fig  which clearly demonstrates the training
efficiency gain that tl provides
to study robustness of jade jammer detection performance
we apply the tl based frequencyagnostic model as in the
previous experiment on j and j parts of the testing dataset
results shown in fig  clearly confirm the effectiveness
of jade for these other jammer types the root of the
robustness property of jade lies in its design choice to rely
on semisupervised form of anomaly detection training only
on normal data
c field validation
so far our evaluation of jade performance was based on
operator provided data labeled with groundtruth on jammer
activity ie the testing dataset in iia we now present
results validating jade performance in the field at the operator
side for this purpose we provided the radio network engineers
at the operator with the implementation of jades tl based
frequencyagnostic ad model as in the last experiment it was
used to reliably detect a different type of jammer j with
discontinuous activation pattern as shown in fig 
jade was also used at the operator side to detect a military
grade jammer j targeting different uplink frequencies due
to the complex nature of this jammer activity it was not
practical like with j to manually label the groundtruth
by the operators radio engineers nevertheless we visually
demonstrate in fig  how jade is able to detect jammer
activity on a sample cell affected by this jammer during the
fig  the performance of tl based frequencyagnostic
jade ad model on j and j part of the testing dataset
fig  operatorside field validation with j jammer
field trial period jade was also used to detect jammerlike
activity that was eventually diagnosed to be due to a hardware
related problem see fig  which shows the versatility of
our jade approach to detect both intentional and unintentional
interference behavior affecting mobile network operations
d jammer localization case study
here we briefly discuss a case study for jade on jammer
localization the idea is to use the jammer detection results with
jade in conjunction with cell site location data to estimate a
jammers location jammer localization is a kind of transmitter
localization problem as cell sites surrounding a jammer detect
its activity with jade as receivers and it can be localized
based on sensed signals at those sites
as our purpose here is not on jammer localization algorithm
design per se but rather on showing the usefulness of jade for
such downstream task we consider three most commonly used
transmitter localization algorithms  max rssi centroid and
weighted centroid with max rssi the location of the cell site
where jammer is detected with max rssi is taken as jammers
location estimate with weighted centroid rssi weighted
geometric center of cell site locations that detect the jammer
is estimated as the jammer location we use the groundtruth
jammer locations provided by the operator to calculate location
estimation errors as euclidean distance between groundtruth
and estimated locations
fig a shows the obtained results for j j and j
jammers in our testing dataset while fig b zooms in on
the results for j case even with these commonly used
localization algorithms we find that jammers can be localized
within a few hundred meters of the groundtruth which is
sufficient in practice for radio engineers to pinpoint the source
of jamming activity between the three jammers considered
j is located in the country side with sparser mobile network
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
fig  detection of j military jammer activity on a sample
cell with jade
fig  detection of hardware induced interference with jade
during the field trial period
infrastructure explaining the relatively higher localization
errors
v related work
in
the
last
decade
wireless
jamming
has
received
considerable attention in the research literature the earlier
work surveyed in   mainly focused on jamming in
the context of ad hoc and sensor networks and  based
wireless lans and multihop networks a significant early
work  considers jamming in sensor networks considering
 networks  examines local and collaborative
detection methods while  focus on distinguishing different
types of jamming attacks more recent works in this
line of research focus on machine learningbased jammer
detection    with most of them taking a
supervised classification approach and concluding that the
random forest method performs the best
closer to our target setting jamming in mobile networks
specifically glte is considered in    in
contrast to our focus on jammer detection in operational
mobile networks these works concentrate on highlighting
vulnerabilities of the lte system to jamming attacks and
proposing mitigation methods  also presents a threat
assessment of the lte system that identifies the weakest
points in its physical phy layer while   observe
that jamming the uplink is more effective for an attacker than
the downlink due to the relatively lower transmission power
limit for lte ues in the former
we are unaware of any previous work that leverages
kpi data to detect jammers in mobile networks by treating
them as anomalies or otherwise but there exist works in
mobile networks and beyond that use kpi data for anomaly
detection    while   are focused on
mobile networks augmented with selforganising network
son features opprentice  targets anomaly detection
in the context of internetbased service delivery  
advocate the use of supervised classification for anomaly
detection based on ensemble methods specifically random
forest in opprentice  and manual labeling to address
the groundtruth issue on the other hand  uses a simple
zscore  like statistical method to detect anomalies at the
fig  a jammer localization errors with different algorithms
b location estimates for j jammer
kpi level and then uses correlation among kpi anomalies
to determine celllevel anomalies absence  is another
broadly related work that detects service disruptions in mobile
networks using anonymized call detail record cdr data the
essential idea here is to monitor spatiotemporal customer usage
based on anonymized cdrs and identifying deviations from
historical usage as anomalies
also broadly related is the recent work on deep learning
based rfspectrum anomaly detection from the spectrum
monitoring perspective   to detect unauthorized
transmissions misconfigured transmitters etc in contrast to
these works the anomaly detection methods we develop rely
on celllevel kpi data and are tailored for automated and
scalable jammer detection in operational mobile networks our
work is also unique due to the use of an operator provided
g network dataset for evaluations and realworld validations
vi conclusions
we have presented jade an online framework for jammer
activity detection in operational mobile networks at its core
the jade framework consists of deep learning based semi
supervised anomaly detection models that solely rely on
normal training data also jade incorporates an adaptive
mechanism for addressing the thresholding issue for celllevel
anomaly detection moreover the jade framework utilizes
transfer learning to enable itself to scalably work across
many cells and multiple frequency bands we have evaluated
the jade framework on a g ran dataset provided by a
multinational mobile network operator with jammer activation
events labeled for different types of jammers field validation
is also conducted and it shows the effectiveness of the jade
framework in the wild lastly we also provide promising results
on the use of jammer detections from jade for localization
of jammers along with cell site location data
loradrl deep reinforcement learning based
adaptive phy layer transmission parameters
selection for lorawan
inaam ilahi muhammad usama muhammad omer farooq muhammad umar janjuaand junaid qadir
information technology university lahore pakistan
department of systems and computer engineering carleton university canada
abstract the performance of denselydeployed lowpower
widearea networks lpwans can signiﬁcantly deteriorate due
to packets collisions and one of the main reasons for that is
the rulebased phy layer transmission parameters assignment
algorithms lorawan is a leading lpwan technology where
lora serves as the physical layer here we propose and evaluate a
deep reinforcement learning drlbased phy layer transmission
parameter assignment algorithm for lorawan our algorithm
ensures fewer collisions and better network performance com
pared to the existing stateoftheart phy layer transmission
parameter assignment algorithms for lorawan our algorithm
outperforms the state of the art learningbased technique achieving
up to  improvement of pdr in some cases
i introduction
over the next few years the internet of things iot networks
are expected to grow exponentially most iot end devices
eds are expected to be i lowcost ii longrange and
iii ultralowpower these eds will provide vital information
for intelligent decision making in many smart applications in
diverse ﬁelds such as healthcare systems inventory manage
ment and smart parking the large number of eds deployed in
such networks poses signiﬁcant challenges such as low packet
delivery ratio pdr and high overall power consumption due
to these challenges there is a need for an effective commu
nication technique that can enable simultaneous transmissions
from several devices while i reducing packet collisions and
ii keeping power consumption low
longrange lora is a lowpower wideareanetwork lp
wan protocol that enables multiple simultaneous transmis
sions through customization of phy layer transmission param
eters lorawan  is the open mac layer speciﬁcation for
lora lorawan uses pure aloha as the mac protocol
primarily because a simple protocol better suits lowpower eds
as aloha does not sense a communication channel before
transmission therefore with an increase in data trafﬁc load the
network performance deteriorates in the light of the above dis
cussion loras ability of phy layer parameter customization
can become helpful as an intelligent phy layer transmission
parameter assignment algorithm can not only make up for
alohas performance issues it can also result in lower power
consumption due to reduced number of collisions
a decision of selecting an appropriate phy layer transmis
sion parameter such as spreading factor channel frequency and
power is impacted by a number of factors a couple of most
important factors in this regard are i channel condition and
ii distance of an ed from a gateway it is a wellknown fact
that interference and data trafﬁc load is not constant hence the
channel condition is variable with respect to time hence there
is an absolute need for a proactive intelligent and adaptive
phy layer transmission parameter adjustment algorithm for a
lorawan network hence here we present a networkaware
drl framework for eds phy layer parameters selection
with the aim of maximizing pdr and lowering the power
consumption
the following are our major contributions
 we have presented a drlbased adaptive phy layer
transmission parameters selection algorithm for lora
based eds
 we perform performance evaluation of our algorithm
under different environment settings and show that our
proposed algorithm shows an improvement of more than
 of pdr upon the learning based technique in some
cases while being adaptive at the same time
ii background
a lora networks
lora utilizes the chirp spread spectrum css technique for
encoding signals into chirp pulses spread over a wide spectrum
css enables longrange communication with robustness against
interference and noise while keeping the datarate low lora
allows the selection of different phy layer transmission param
eters spreading factor coding rate bandwidth frequency and
power for each device the values of these parameters affect
communication range data rate resilience against interference
and a receivers ability to decode the signal in lora a
transceiver can select a bandwidth bw in the range 
to  khz and mostly a lora transceiver operates at 
khz  khz or  khz spreading factor sf deﬁnes
the ratio between the symbol rate and the chirp rate lora
provides seven sf rates to choose from sf to sf coding
rate cr deﬁnes the level of protection against interference
lora deﬁnes four coding rates 
 
 
 
 a lora radio can
transmit between  to  dbm in  db steps however due
to hardware limitations the mentioned range is mostly limited
between  to  dbm
  ieee
 ieee th conference on local computer networks lcn    ieee  doi lcn
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
table i general comparison of loradrl loramab and
lorasim
learning
adaptive
supports
mobility
average time
to convergence
lorasim
rulebased
loramab
 khours
with no mobility
loradrl
 khours
b deep reinforcement learning
reinforcement learning rl provides the ability to solve dy
namic sequential decisionmaking problems the conventional
rl solutions have suffered from computational complexities
due to the curse of dimensionality problem qlearning  an
rl algorithm which involves learning using delayed rewards
suffers from the same problem as soon as the representation of
the environment becomes complex mnih et al  introduced
drl by proposing deep qnetworks dqn a combination
of deep neural network dnn and qlearning as a solution
to the stated problem in the case of dqns the policy is
represented by the dnn van et al  pointed out that the
dqns may overestimate the qvalues and propose a new
method called double deep qlearning ddqn in ddqn the
action selection is proposed by an online network but its value
estimation for the update is done by using a target network this
not only helps estimating better qvalues but also increases the
stability of learning
c related work
bor et al  proposed lorasim simulator for experimenting
with different lora settings this simulator provides an ability
for dynamic phy layer parameters selection where ﬁxed sub
sets of the phy layer parameter combinations are used to en
sure collision avoidance the only problem with their technique
is that it suffers from the problems associated with a rulebased
mechanism ta et al  proposed the use of rl for dynamic
phy layer transmission parameters selection for lorabased
eds they pointed out multiple issues with lorasim for
example using perfectly orthogonal spreading factors based
on their identiﬁed weakness in lorasim they proposed another
discrete event simulator named loramab we identify
multiple issues with loramab i loramab in terms of its
computational complexity is exponentially complex and hence
not feasible for a large number of eds ii loramab does not
account for the movement of eds which makes it inapplicable
in a network consisting of mobile eds such as healthcare
smart vehicles etc iii due to a missing specialized objective
function eds have the option of choosing any of the available
power levels without particularly focusing on saving power as
a solution to the abovestated issues we propose an adaptive
phy layer transmission parameters selection algorithm based
on drl a comparison of our approach loradrl with prior
work loramab and lorasim is presented in table i
iii proposed phy layer transmission parameters
selection algorithm
to the best of the authors knowledge there is no drlbased
solution available in the literature for phy layer transmission
parameter adaption that assures minimalist collisions in a lora
based network
a problem formulation
we model the lora network with a total k lora eds
in a network and with all eds being within the range of
a lorawan gateway the algorithm is centralized with a
ddqn being run on the gateway the gateway is not limited
in hardware and power resources hence is able to efﬁciently
run a ddqn the whole operation is formulated as a markov
decision process mdp where s denotes the state of the
environment allocated actions distance from gateway a
denotes the action the combination of sf and power proposed
by the ddqn and r denotes the reward at a timestep the
goal of the agent is to propose action in order to minimize the
collisions while keeping power usage as low as possible
b rewardcost function
the proposed reward function takes into account the pdr
packet airtime and power usage of an ed the rewardcost
function is given in equation  in the equation pdrt and
att represent pdr and airtime in seconds respectively at time
instance t in the case of the availability of multiple power
levels we change the reward function as given in equation 
rt  a pdrt b att
rt  a pdrt b att  c pwrt
where
pwr  powermax powerchosen
powermax powermin
where a b  c are the relative constants used to assign
appropriate weights to pdr at and pwr we have tested
the following combinations of the constants a   b  
a   b   and a   b   c   these
constants act as hyperparameters and can be chosen according
to the requirements of the application hence in the reward
function we have proposed to actively penalize the learning
agent until it is able to achieve a good pdr while keeping the
power consumption as low as possible
c proposed algorithm
algorithm  shows the workﬂow of the proposed algorithm
major beneﬁts of our proposed algorithm are
 adaptive behaviour the ability of ddqn to contin
uously learn based on the current performance makes
it adaptive to the changing environment hence always
changing the policy in the favor of better available
actions
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
algorithm  drl in lora networks  learning process
input qnetwork structure
output trained qnetwork
 initialize both the target and online qnetworks
 initialize the memory replay buffer
 while ep  maxepisodes do
while steps  maxedcount do
initialize the lora network
compute state of the network st
feed the state to the dnn to get action at
taken action at at state st
simulate the environment
compute reward rt and next state st
collect m datapoints st at st rt using policy π
and add it to the memory
sample minibatch from memory
compute the change in values using target qnetwork
q
φ yj  rj  γ maxa
j qφs
j a
j
update the online qnetwork φ
φ α p
j
dqφsjaj
dφ
qφsj aj yj
if steps  targetupdateinterval then
update the target qnetwork φ
end if
end while
 end while
table ii speciﬁcations of the ddqn
no of layers
no of neurons
 
activations
relu relu linear
learning rate
memory capacity
batch size
gamma for qvalues
initial epsilon
final epsilon
change in epsilon
update frequency
 mobility support the learning is being performed on
the gateway and is independent of the individual eds and
the model can handle mobile eds
 computationally efﬁcient the algorithm uses a small
dnn in ddqn hence requiring very few computational
resources our algorithm runs on the gateway and does
not put extra burden on the resource constrained eds
hence adds to the applicability of our algorithm in real
scenarios
iv performance evaluation
in our experiments we consider an environment of  lora
eds spread in a radius of  meters with a single basestation
at the center we use a data frame size of  bytes typical iot
use cases generate small data packets hence byte frame size
can represent a large number of iot use cases the data is being
generated using a poison distribution with a mean rate λ of
fig  pdr of loradrl and loramab in a lora network
of  uniformly distributed mobile lora eds with both the
capture effect and the intersf collisions enabled the mobility
speed was set to  mh a sharp drop in the pdr of
loramab can be seen which shows its inability to learn in
an environment comprising of mobile lora eds
 minutes the simulation time is set to  times of the mean
rate the bandwidth is ﬁxed at  khz for all eds currently
we have considered a single channel the speciﬁcations of the
neural network are given in table ii
a learning of the proposed algorithm
the pdr of our algorithm while learning is shown in fig
 the ﬁgure shows that our agent can converge its learning in
 khours however loramab is not able to learn a better
pdr in case of an environment consisting of mobile lora eds
eds in the experimental setup are mobile and they follow the
gaussmarkov mobility model an improvement of more than
 can be seen in the pdr over loramab as the learning
is independent of the eds so we propose the training of the
model to be done in a simulation the trained model can then be
ﬁnetuned in a real environment due to the adaptive behavior
of drl compared to lorasim and loramab our model will
be less susceptible to adversarial attacks which in the case of
lora can be frequency jamming etc
b experiment  performance evaluation using uniformly dis
tributed eds
fig a shows the performance of our algorithm in a ﬁeld
consisting of lora eds distributed uniformly we have tested
with the capture effect ce and intersf collisions the effect
of these cannot be clearly seen in the provided graphs but
will be noticeable in dense iot networks it can be seen that
our model can achieve a pdr greater than  in a network
containing  eds in a single channel environment fig a
shows the average power usage per packet sent it shows that
our agent can achieve an average power usage of  joule
per packet with  eds in the network which is an optimal
power choice the eds have only a single power level to choose
from ie  db
c experiment  performance evaluation based on varying
percentages of intelligent eds
we compare the effect on overall performance in a network
containing different percentages of intelligent eds we consider
an ed whose decision is made by the drl agent as an intelli
gent ed we have tested with     and 
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
a experiment  uniformly distributed eds
with a single available power level choice
b experiment  performance of lora net
work containing different percentages of intel
ligent eds
c experiment  uniformly distributed eds
with multiple available power level choices
fig  depiction of performance of our proposed loradrl it can be seen that our proposed algorithm has achieved an optimal
pdr while ensuring low power usage in experiment  it is visible that the intelligent device percentage is directly proportional
to the performance high pdr  low powerusage all results are reported with  conﬁdence interval
intelligent eds the eds other than the intelligent ones choose
a random parameter combination out of the available parameter
combinations we dont limit the parameter combination of any
ed all the available combinations are available to the ed to
choose from eds have only a single power level to choose
from ie  db it can be seen that the performance deteriorates
in case of a reduction in the count of intelligent devices when
eds choose a random parameter combination the packets either
suffer collisions or they are lost on the other hand if an ed is
intelligent the parameters are chosen by the gateway based on
the environment hence fewer collisions the obtained results
have been shown in fig b
d experiment  performance evaluation using multiple avail
able power levels
in this experiment we add multiple power levels as a choice
   dbs for a power level to be used in this case the
reward function given in equation  is used the results are
shown in fig c it can be seen that our agent can achieve
an optimal per packet power usage of  joule which is much
less than the average per packet power usage in the scenario of
a single choice of power level ie  joule hence our agent
can save power while ensuring the same pdr performance as
in the case of one power level
v conclusions
we have provided and tested the ﬁrst deep reinforcement
learning drlbased approach for adaptive phy layer pa
rameters selection in dense lora networks that ensures fewer
collisions and better performance than the existing stateofthe
art phy layer parameter assignment algorithms we show that
our algorithm is not only adaptive and computationally efﬁcient
but is also able to support mobile end devices

urban air quality measurements a survey
muhammad usama abdur rahman zubair khalid muhammad tahir momin uppal
lahore university of management sciences lums pakistan
email muhammadusama abdurrahman zubairkhalid tahir mominuppallumsedupk
abstracturban air quality is increasingly becoming a cause for concern for the health of the human population the poor air quality is
already wreaking havoc in major cities of the world where serious health issues and reduction of average human life by a factor of years
are reported the air quality in developing countries can become worse as they undergo development the urban air quality varies
nonlinearly depending upon the various factors such as land use industrialization waste disposal trafﬁc volume etc to address this
problem it is necessary to look at the plethora of available literature from multiple perspectives such as types and sources of pollutants
meteorology urban mobility urban planning and development health care economics etc in this paper we provide a comprehensive
survey of the stateoftheart in urban air quality we ﬁrst review the fundamental background on air quality and present the emerging
landscape of urban air quality we then explore the available literature from multiple urban air quality measurement projects and provides
the insights uncovered in them we then take a look at the sources that are signiﬁcantly contributing to polluting the air quality finally we
highlight open issues and research challenges in dealing with urban air pollution
introduction
air pollution is deﬁned as the release of pollutants in the
air that has detrimental consequences on human health
and the planet as a whole these pollutants can be from
manmade sources or natural sources  natural sources
of air pollution include ﬁres sand storms volcanic activity
fumaroles and others the manmade air pollutants are
gases droplets particulate matter and radiation are emitted
into the atmosphere due to human activity such as burning
wood coal gas oil alcoholbased fuels diesel kerosene
biomass waste etc it also includes power plants and
chemical factories that emitted toxic gases particulate matter
and radiation in the environment these air pollutants
are causing issues such as acid rains urban smog ozone
depletionholes indoor air pollution and global warming
 air pollution is a complex amalgamation of natural and
human activities the impact of this relationship is evident
in metropolitan areas beijing dehli etc where criteria
pollutants meteorology infrastructure and various emission
entities collectively deteriorate the air quality it is iteratively
reported in the literature that  to  of the pollution
in the developing world is due to automobile emissions
where vehicles using lowgrade oil on poorly planned road
infrastructure are major contributors to the poor air quality
 major cities in the world are suffering from rapid
degradation of the air quality that has pernicious outcomes
on the health of the citizens economy plantation crops and
livestock 
a decline in human life expectancy in metropolitan areas
is accredited to their poor air quality the problem will get
even worse with the urban development taking place in
underdeveloped countries  in  world health organi
zation who categorized air pollution as a carcinogen for
human beings  who also estimated two million deaths
per year and numerous respiratory illnesses because of poor
urban air quality  the global rise in air pollution has
resulted in a sharp growth in various allergies and respiratory
diseases the impact of air pollution is not limited to the
metropolitan areas it also affects the environment on a global
scale causing health concerns far away from its origin in
 air pollution alone caused  million death worldwide
and if the current trend continues by  the deaths caused
by ambient air pollution will be nearly  million people
per year  in  out of all cardiovascular deaths
 were caused by air pollution similarly  deaths
due to lung cancer were because of air pollution and air
pollution was the reason for  of the total deaths caused
by strokes   four million new asthma cases and 
million premature childbirths per year are attributed to fossil
fuelbased air pollutants that cause a dent in the gdp 
furthermore air pollution appears to be a risk factor not
yet quantiﬁed in neurodevelopmental disorders in kids and
neurodegenerative illnesses in adults   
air pollution not only affects human health on a global
scale but it also has an enormous economic cost the cost
for air pollution emitted by burning fossil fuels in  is
approximately  trillion usd that is  of the global
global gross domestic product gdp  it is way less than
the money needed to reduce the effect of the air pollution
caused by burning fossil fuels the toll of air pollution on
the economy is estimated by looking at the six aspects 
cost of human life  peoples ability to work  effects
on the food  reduction in the ability of the ecosystem to
work  damages to the historical monuments and  cost
of remediation and restoration the economic burden of air
pollution on the gdp of china is  for india it is 
for russia it is  for germany and us it ranges from
 to  for japan united kingdom and france it ranges
from  to    it indicates that a monumental
effort is needed to address the air pollution is the need of the
hour
 httpsuneceorgairpollutionandeconomicdevelopment
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
   by the authors distributed under a creative commons cc by license
figure  organization of the paper
another victim of air pollution is agriculture where bad
air quality is considered a signiﬁcant contributor to yield
reduction for many decades air pollution is rapidly becom
ing a threat to food production and safety  effects of air
pollution on human health have been covered rigorously in
the literature compared to agriculture the adverse effects
of air pollution on the crops vary with the concentration
of the pollutants geographical locations and meteorology
burning wood and fossil fuel produce sulfur dioxide that
reduces the life and yield of the crops rising levels of
acid deposition ammonia o and co are also affecting the
crops in the developing world in  india reports a 
reduction in the wheat and rice crop yield due to ambient
air pollution   it also highlights the need for serious
reconsideration in environmental policies around the world
to ensure food security
the global temperature has risen by c over pre
industrial levels the climatic catastrophe is upon us the
whole world has started feeling the repercussions like
wildﬁres heat waves droughts etc air pollution has played
a vital part in this climatic catastrophe united nations
sustainable development goals unsdg  and 
directly aim at reducing the mortality rate due to ambient
air pollution and the adverse aspects of particulate air
pollution in urban areas by  achieving these unsdg
 httpswwwbritannicacomtechnologyagricultural
technologytheeffectsofpollution
 httpssustainablefoodtrustorgarticlestheimpactofair
pollutiononcrops
goals for reducing the adverse effects of air pollution in
underdeveloped and developing countries is perhaps a
challenging task
identifying the pollution sources contributions and
root causes spatiotemporal manner are the vital challenges
associated with urban air quality measurements lastly
based on the spatiotemporal analysis of the urban air quality
making policy recommendations for reducing air pollution
is the motivation for this study in this paper we have tried
to answer the following question through a extensive review
of the existing literature
what are the major air quality modelling and mea
surement techniques
what are the major sources of air pollution and how
to best classify them
what is the situation of the air quality around the
globe and what are the best practices followed for
mitigating the poor air quality
how the major air quality measurement and im
provement projects are measuring and dealing with
the urban air pollution and what challenges are
needed to be addressed in order to improve the
effectiveness of these projects
what are the open research challenges in measuring
the urban air quality
contributions of the paper
in this paper we build upon the existing literature available
on the air quality measurement and provide a comprehensive
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
paper
surveyreview
this paper provides a comprehensive comparison of literature available on static mobile and community sensorsbased air quality monitoring networks
in the urban environment it also identiﬁes shortcomings in the existing air quality monitoring networks
this study examines several environmental sensors and discusses the effects of air pollution on human health it also gives future guidance in the
development of individualcentric pollution monitoring tools
reviewed the lowcost sensorbased system for measuring the air quality and the calibrations of the sensors using machine learning techniques
the paper also discusses the research challenges and open challenges in using lowcost sensorbased air quality monitoring systems
reviewed and summarized the lowcost sensing literature for air quality monitoring the review also discusses the shortcomings in the data obtained
from the lowcost sensors and open issues in designing lowcost sensorbased air quality networks
paper provides a brief survey of the techniques of using chemical sensing crowdsourcing iot and machine learning in air quality assessment
paper provides the results of a twoyear air quality monitoring and data collection
the paper examines the literature on the existing iotbased lowcost air quality monitoring systems and brieﬂy discusses a few challenges
this paper reviews the literature on air quality sensor calibration and identiﬁes the origins of biases and errors in a lowcost air quality sensing network
it also studies and compares multiple recalibration techniques of lowcost air quality sensor networks lastly it also provides the limitations and future
avenues in the calibration and recalibration of the air quality sensors
the paper conducts a literature review on the lowcost high spatial and temporal resolution air quality monitoring network it also suggests future
research themes
this paper reviews the iotbased air quality monitoring networks and brieﬂy discusses the challenges in designing air quality measurement networks
the paper provides a comparative analysis of machine learningbased urban air quality prediction techniques
this paper reviews indoor and outdoor air pollution monitoring using wireless sensor networks
the paper reviews multiple papers reports white papers and various websites on the role of urban computing in air quality management
it also covers the techniques of incorporating datadriven mitigation strategies opted by different countries
this paper reviews the literature on multiple effects of the air pollution monitoring strategies used in south africa it also discusses the
challenges involved in designing the air pollution networks in the air pollution monitoring network
the research compares stationary dynamic and pollution data analysis methodologies in depth the methodology hardware components
communication mechanism assessment and performance of the air quality system are all compared
a comprehensive survey on the unmanned air vehiclebased air quality measurement techniques for criteria pollutants along with challenges
and open research directions are covered in this paper
this research reviews the literature on air quality sensor technologies and air quality management systems
this paper reviews the air quality standards set by various environmental protection organizations in the world it also gives an
overview of several aspects of lowcost sensing equipment and methodologies
this paper reviews the literature on iotbased machine learningenabled continuous air quality monitoring and prediction literature
this paper provides a brief survey of air pollution monitoring systems along with some speciﬁc measurement strategies
this paper gives a summary of the problems involved in monitoring urban air quality
this paper examines the literature on crowdsourcingbased air quality monitoring and identiﬁes possible ﬂaws as well as future research directions
based on the existing literature on the development of an air quality monitoring network this paper provides the nuts and bolts for
designing the next generation of air quality monitoring networks
table  various surveysreviews on various aspects of air quality measurement
review of the related work the major contributions of this
paper are as follows
we provide the fundamentals of air quality measure
ments along with a nonexhaustive summary of the
air pollutants and their potential sources
we present a comprehensive survey of the techniques
for measuring the urban air quality along with several
sensors famously used for measuring the pollutants
we also discuss the previousongoing air quality
measurement projects from various entities and also
summarize a few root cause analyses from the liter
ature for determining the contributors in urban air
pollution
we also highlight the challenges in designing an air
quality measurement network and how the urban con
text information can help bring more useful insights
in determining and translating the airquality
finally we highlight the open research issues and
future directions in measuring and learning from
urban air quality
organization of the paper
the rest of the paper is organized as follows section 
provides a primer on the air quality it also provides a brief
overview of the air quality landscape of the world while
also covering the details of the major air pollutants and their
sources section  discusses the various approaches available
in the literature for designing an air quality measurement
network this section also provides details of the various
sensors available for measuring particular pollutants in the
air lastly this section also discusses the diversity in the
air quality data its relationship with the different context
variables and how to ensure proper pre and postprocessing
section  provides a comprehensive literature review of the
stateoftheart in urban air quality standards in the world
this section also covers projects from various organizations
for measuring and analyzing air quality in different parts of
the world section  discusses the challenges in designing
and measuring the urban air quality and also takes a critical
look at the available literature for providing an exhaustive
list of challenges tradeoffs tussles and opportunities in
measuring and analyzing the urban air quality section 
discusses the open research issues and future directions the
paper has been concluded in section 
primer on air quality
in this section we discuss the preliminaries of the air
quality then we provide an air quality landscape and major
pollutants lastly this section provides a discussion on the po
tential sources of air pollution before describing the details
of the air pollutants it is vital to understand the composition
of pollutantfree dry air dry air is essentially a combination
of nitrogen  and oxygen  the remaining 
is a combination of argon  and extremely minute
quantities of carbon dioxide methane hydrogen helium
and others water vapor is also a typical albeit very variable
component of the atmosphere ranging from  to  by
volume in humid conditions the moisture content of air can
reach 
 httpswwwadborgprojectsmain
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
table  aqi scale used for indexing the realtime pollution and there impact on human health unit followed in this table is
µgm unless mentioned otherwise
aqi
pollution
level
pm
 hour
pm
 hour
co
 hour
mgm
no
 hour
so
 hour
nh
 hour
pb
 hour
o
 hour
cautionary statement
implications on
human health
good
none
no health risk
satisfactory
the extended outdoor activity
must be avoided by children
adults and people with respiratory
issues
the air quality is adequate
nevertheless some pollutants
may pose a considerable health
risk to a limited number of
people who are very sensitive
to air pollution
moderate
the extended outdoor activity
must be avoided by children
adults and people with respiratory
issues
members of sensitive groups
may experience health effects
the general population is not
likely to be affected
poor
people with respiratory diseases
take precautions and avoid
extended outdoor activities
everyone else should also
limit outdoor activities
the general population may
begin to experience health
effects members of sensitive
groups may experience serious
health effects
very poor
people with respiratory diseases
take precautions and avoid
all outdoor activities everyone
else should also limit outdoor
activities
health warnings of emergency
conditions the entire population
is more likely to be
affected
severe
everyone should avoid all
outdoor activities
health alert everyone may
experience more serious
health effects
air pollution
air pollutants are particles gases or droplets emitted in
the environment that exceeds the environments capacity of
absorption dilution and dissipation these pollutants are
gases solid particles liquid droplets etc the effect of these
pollutants at a scale is termed as air pollution air pollution
is increasingly becoming a signiﬁcant contributor in causing
public health heart and lung disease respiratory diseases
etc and environmental issues global warming acid rains
reduction in crop yields depletion of the ozone layer etc
at a global scale
criteria pollutants
us environmental protection agency epa divided air
pollutants into the following six categories that provide
sufﬁcient enough information for determining the overall air
quality are known as criteria pollutants
carbon monoxide co carbon monoxide is a gas
emitted into the atmosphere due to the fossil fuel
burning in automotive vehicles it has no smell or
color it reduces the oxygen supply to the body parts
thus hindering proper functioning it also causes
headaches dizziness heart and respiratory issues
nitrogen oxides nitrogen oxide is a gas emitted
in the atmosphere due to the fossil fuel burning in
vehicles and power plants it has a smell and reddish
brown color it causes coughs shortness of breath and
respiratory infections it is also a major contributor
to acid rain that is very harmful to crops plants and
animals
sulfur dioxide so sulfur dioxide is a colorless
gas emitted into the air due to oil and coalburning
power plants and chemical factories it has a rotten
egglike smell it is a contributor to acid rain that is
harmful to crops plants and animals it is also very
harmful to people with respiratory diseases
ozone o ozone is not directly emitted in the
atmosphere it is a byproduct of the reaction between
 httpswwwbritannicacomscienceairpollution
nitrogen oxide and organic compounds under the
sunlight nitrogen dioxide and organic compounds
emissions are due to a wide range of processes such
as coaloilburning power plants factories trees etc
ozone here must not be confused with the ozone
layer present in the stratosphere it is the main
contributor to smog that can lead to respiratory issues
such as asthama it also causes ear nose and throat
ent issues ozone is also harmful to crops and
plants
particulate matter solidliquid droplets suspended
in the air called particulate matter these particles are
inhalable with a width less than  mm and a size as
small as  mm pm and pm are prime
examples of these particles pm and pm are
inhalable particles with a size less than or equal to 
micrometers and less than or equal to  micrometers
respectively these particulate pollutants cause lungs
and heart issues and are harmful to crops and plants
lead pb lead is a toxic metal with many variants
it is emitted into the environment by automotive
vehicles burning substandard gasoline the chemical
factories and power plants are also contributors to
emitting this toxic metal into the atmosphere lead
causes kidney issues strokes and heart failure 
sources of air pollution
sources of air pollution are generally divided into four
categories
natural sources
natural events are the initial sources of air pollution in
the world these events are also fundamental parts of the
ecosystem and also had an associated planetary cost forest
ﬁres volcanic eruptions dust storms decomposing organic
matter biological processes in the soil lightning and sea
spray are a few examples of the natural events degrading
the air quality the natural events result in creating different
 httpswwwnpsgovsubjectsairsourceshtm
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
table  list of acronyms
who
world health organization
gdp
gross domestic product
unsdg
united nations sustainable development group
epa
environmental protection agency
co
carbon monoxide
so
sulfur dioxide
o
ozone
ent
ear nose and throat
pm
particulate matter
pb
lead
ent
ear nose and throat
aqi
air quality index
aqli
air quality life index
ncap
national clean air program
naaqs
national ambient air quality standard
us
united states
ncap
national clean air program
naaqs
national ambient air quality standard
case
clean air and sustainable environment project
aqg
air quality guidelines
eea
european environmental agency
modis
moderate resolution imaging spectroradiometer
gam
generalized additive model
ctm
chemical transport model
poi
point of interest poi
ams
american meteorological society
iscst
industrial source complex framework
ctdmplus
complex terrain dispersion model
ocd
offshore and coastal dispersion
cmaq
community multiscale air quality
cmaqddm
cmaq decoupled direct method
cmaqisam
cmaq integrated source apportionment method
camx
comprehensive air quality model with extensions
remsad
regional modeling system for aerosols and deposition
uamv
urban airshed model variable grid
cmb
chemical mass balance
pmf
positive matrix factorization
epa
environmental protection agency
frm
federal reference methods
fem
federal equivalence methods
crf
conditional random field
arma
autoregressionmovingaverage
lr
linear regression
nn
neural network
rt
regression tree
fep
frequently evolving patterns
gc
grangercausality
epic
energy policy institute at the university of chicago
ghair
ghana urban air quality project
escrap
educating school children to tackle air pollution
ai
artiﬁcial intelligence
iot
internet of things
types of criteria pollutants volatile organic compounds and
biological pollutants
mobile sources
mobile sources of air pollution are considered very deadly for
human health here trafﬁc encompasses cars buses trucks
trains planes etc mobile sources are also considered one of
the major sources of air pollution air pollution is a result
of the vehicles used for commuting people and resources
 the vehicle exhaust suspended and resuspended road
dust brake dust and tire wear are sources of trafﬁcrelated
emissions  mobile emissions sources result in different
criteria pollutants and volatile organic compounds with
harmful effects on the ecosystem
stationary sources
stationary air pollution sources include power plants in
dustrial facilities oil reﬁneries industries sewage treatment
and so forth stationary sources of air pollution are often
known as point sources the burning of fossil fuels metal
processing processes boilers in industries and power plants
oil reﬁning procedures solvents glues and paint thinners are
all producers of criterion pollutants such as volatile organic
compounds and hazardous pollutants mercury dioxin etc
area sources
air pollution sources such as agricultural areas ﬁreplaces
construction processes in cities heating and cooling units
in the buildings are categorized as area sources of urban
air pollution the pollutants from area sources result in
particulate matter and other criteria pollutants household
emissions also contribute to the degradation of air quality
processes like biomass combustion fossil fuel burning such
as coal diesel kerosene oil etc tobacco smoking and cen
tral air conditioning are a few important sources of household
emissions household emissions create different criteria and
biological pollutants since this paper only considers ambient
air pollution indoor air pollution sources are out of the scope
of this work we also want to note here that multiple sources
from diverse surroundings contribute to urban air pollution
which varies depending on the geographical location of
the pollution sources in the city wind direction and speed
humidity and other meteorological conditions and so on
therefore attributing urban air pollution to a single pollution
source is an inaccurate approach to look at this issue the
relationship between criteria pollutants and their sources
is provided in table  the table is made based on the
information provided by the us epa and nps
air quality index
the air quality index aqi is a metric used for quantifying
and communicating the air quality in a particular location
aqi suggest the amount of air pollutant in the air over a
speciﬁc average interval these air pollution concentration
values are measured by a sensor or extrapolated from
a simulationemulation model the concentration of the
pollutant and time window is used to determine the dose of
the air pollution and insights from epidemiological research
provide its health impacts based on these health impacts
a color code and a health advisory are issued for a speciﬁc
range of the aqi values the air quality information varies
for different countries based on their air quality standards
and thus their air quality indices aqi value for a given
pollutant is determined by the following piecewise linear
function 
i  ihigh ilow
chigh clow
c clow  ilow
where i is the air quality index c is the concentration of the
pollutant clow is the concentration breakpoint that is less
than or equal to c chigh is the concentration breakpoint that
is greater than or equal to c ilow is the index breakpoint
corresponding to clow and ihigh is the index breakpoint
corresponding to chigh
measurement data for aqi is averaged over one hour
there are few pollutants such as ozone o pm and pm
 httpswwwbritannicacomscienceairpollution
 httpswwwnpsgovsubjectsairsourceshtm
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
table  relation between criteria pollutants and pollution sources categories along with their environmental risks
criteria pollutant
pollution sources
environmental risks
carbon monoxide co
mobile stationary and natural
pollution sources
smog and asphyxiation in vertebrates
nitrogen oxides nox
mobile and stationary pollution
sources
smog acid rain respiratory issues
in vertebrates
sulfur dioxide so
mobile and stationary pollution
sources
acid rain and respiratory issues
in vertebrates
ozone o
mobile stationary and area
pollution sources
the main contributor of the smog in urban
areas
particular matter pmx
mobile stationary natural and
area pollution sources
haze acid rain serious damages to health
and buildings
lead pb
mobile and stationary pollution
sources
reduction in biodiversity and neurological
issues
where average over multiple hours is needed to compute a
correct aqi value table  provides a detailed description
of different pollution levels of various pollutants for india
along with their health advisory and impacts on human
health associated with it different countries have their air
quality policies and thus have different cutoff values
air quality landscape
before proceeding with the discussions of air quality mod
eling and measurement it is imperative to examine the
current global air quality landscape by gleaning insights from
various studies on the impact of air pollution and mitigation
initiatives undertaken in various parts of the world the air
quality life index aqli  report released in july 
suggests that air pollution was the most prominent risk to
human health before the pandemic covid and after it
as well  many countries are now putting a lot of effort
into designing policies for reducing emissions albeit the
progress is slow and many countries are still struggling to
cope with the air quality issue in this section we examine the
air quality landscapes particulate air pollution of various
countries as well as air pollution and the policies used by
these countries to address air pollution challenges
asia
china
china is the most populated country in the world it is home
to  of the total population of the world  of its
population lives in cities in  the concentration of the
pm in beijing city was so high that it seemed that the
city will become uninhabitable  at the time an average
person in the beijing city was exposed to approximately 
µgm of pm air pollution it is nine times higher than the
who recommended value for pm in january  the
situation got even worse when the pm concentration went
 to  times higher than the who recommended value
and the city ofﬁcials warned people to stay indoors  the
guardian describes it as beijings airpocalypse similarly
in shanghai the air pollution went beyond the critical level
there the recorded pm concentration was six times more
than the who recommended value
given the situation in  the chines government
released a national air quality action plan worth  billion
 httpsappcpcbccrcomccr docsfinalreport aqi pdf
 httpsaqicnorgscale
usd with the sole purpose of bringing the air pollution
down the plan has three goals
reduce the pm by  relative to its value in 
reduce the pm by  in beijingtianjinhebei
by  in the pearl river delta and by  in the
yangtze river delta
reduce annual pm of beijing to  µgm
the national air quality action plan worked for china
by  the pm concentration in beijingtianjinhebei
went down by  in pearl and yangtze delta the air
pollution went down by  and  respectively this
success was achieved due to a collaborative effort from
different government entities in reducing the dependency
on coal controlling car emissions increasing renewable
energy enforcing emission policies reducing steel and plastic
manufacturing and replacing coal boilers with natural gas
or electric heaters  though these steps have improved
the air quality in china the war against air pollution is not
over as longterm solutions for bringing air pollution down
to the whos recommended values are needed
india
india is the nd most populated country in the world with
 of the population of the world  of the total indian
population lives in cities india is also the nd most polluted
country in the world in  the average pm value
was  µgm that is seven times higher than the who
recommended value  microgramscubic meter delhi
uttar pradesh and northern india are the most polluted
areas where air pollution is reducing almost a decade of
life expectancy of the residents   aqli india fact
sheet  also suggests that  of the indian population
are exposed to air pollution levels not observed anywhere in
 the concentration of the pm reached an emergency
level  µgm
in  india declared war against pollution and an
nounced a ﬁveyear national clean air program ncap with
 million usd for the ﬁrst two years  the goal of ncap
is to bring the air pollution down by  to  in  cities
which are over the national ambient air quality standard
naaqs by building institutional capacity in monitoring
and mitigating the air pollution  the potential impact of
ncap in the coming years is a  improvement in the air
quality and an improvement of  to  years in the total life
expectancy of the general public 
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
indonesia
indonesia is the th most populated country in the world
with a  urban population more than  of its popula
tion is exposed to air pollution that is poorer than the whos
air quality standards indonesia is also facing wildﬁre issues
in  nearly  wildﬁres were recorded the average
pm concentration in indonesia is µgm  jakarta
is the most congested and one the most polluted city in the
world  of the pm and  of pm particles in
jakarta air pollution are emitted by the automotive vehicles
ten coal power plants around the city are also adding to the
particulate pollution by emitting black carbon  in 
the air quality in sumatra and kalimantan was below the
who recommended threshold in the last  years the air
quality in these cities has gone three times poorer than the
recommended value this shift is because of illegal peatland
agriculture deforestation and wildﬁres 
the indonesian government has taken initial steps in
overcoming the air quality issue by adopting the euro 
fuel enforcing automotive health monitoring policies and
developing a peatland restoration agency indonesias coal
based energy production has doubled in the last ten years
and this is due to the tradeoff between the economy and
pollution a lot of collaborative effort is needed to ensure the
better air quality in indonesia
pakistan
pakistan is the ﬁfth most populated country with one of
the highest population growth rates  on the aqli
pollution ranking it is ranked th in the most polluted
countries pakistan has seen a  increase in the pm
concentration in the last two decades  lahore has the
poorest air quality in pakistan where pm concentration is
six times higher µgm than the whos recommended
value  if this level of pollution concentration is sustained
an average person in lahore will lose approximately 
years of life expectancy almost  of the total population
is exposed to pollution levels higher than the recommended
who air pollution values 
citing this looming threat the pakistani government
started enforcing the air pollution regulations for improving
urban air quality in  following three initiatives are taken
to ensure improvement of the air quality
stubble burning is a major contributor to air pollu
tion in pakistan the government of punjab banned
stubble burning and promoted alternative methods
for getting rid of stubble
emission regulations were enforced on the vehicles
factories and brick kilns
for improving the air quality pakistan has also
shut down many coalbased power plants for two
months this measure has improved the air quality
but resulted in many power outages
pakistan can improve air quality sustainably by exploiting re
newable power sources and continuously enforcing emission
regulations
bangladesh
bangladesh is the th most populated country in the world
with a  urban population bangladesh is also the most
polluted country in the world   the air pollution
there is so intense that an average person loses approximately
 years of life expectancy nearly  of the bangladesh
population is exposed to air pollution nearly seven times
more than the who recommended air pollution concentra
tion µgm for pm major sources of air pollution in
bangladesh are brick kilns vehicle emissions cement facto
ries unplanned constructions and steel rerolling  in
metropolitans like dhaka the concentration of the particulate
pollutants pm and pm stayed manifold higher than
the recommended air pollution concentration values the
concentration of other air pollutants like inorganic gases is
noted to stay below the recommended values
given the dangerous situation of the ambient air quality
in major cities the bangladesh government has started imple
menting various countermeasures to control and mitigates
air pollution bangladesh developed  ﬁxed continuous air
quality measurement stations in  major cities the stations
are capable of measuring the concentration of various types
of air pollutants the recorded data from these monitoring
stations helps develop a spatiotemporal map of different air
pollutants that translates into the identiﬁcation of the air
pollution trends in the country data gathered through these
monitoring stations is also used for developing air models
and aqi for public information
on the policy front many initiatives are taken to enforce
the emission policies on brick cement and related industries
by banning the import of coal with high sulfur content
bangladeshs government is also incentivizing the industry
to move towards renewable and energyefﬁcient production
procedures initiatives like clean air and sustainable en
vironment project case and grater dhaka sustainable
transport are also working with the brick cement and
transport industries to reduce emissions strict enforcement
and monitoring are necessary to ensure the improvement in
the ambient air quality and the department of environment
in bangladesh has started doing that
nepal
nepal is suffering from a grim air pollution problem almost
all of its population is living in an air pollution concentration
higher than the who recommended values according to
the aqli nepal fact sheet  nepal is ranked as the third
most polluted country in the world with an average pm
concentration of µgm that is ﬁve times higher than the
acceptable concentration value the average person in nepal
is expected to lose at least ﬁve years worth of life expectancy
if the current levels of air pollution persist the brick kiln
fuel burning vehicle emissions and road dust are primary
contributors to nepals air pollution nepal is far behind in
combating the air quality issues that are affecting the health
of its citizens more details on the air quality about asian
countries such as south korea  thailand  etc are
available on 
europe
compared to asia europe already has better air quality the
majority of europes concentration of particulate pollutants
is below the european unions air pollution limits µgm
but over threequarters of europes population lives in
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
regions that do not satisfy the world health organizations
who stricter recommendation of µgm  the entire
population of poland belarus slovakia the czech republic
slovenia hungary lithuania armenia belgium germany
moldova cyprus and ukraine and the netherlands and
san marino are exposed to pollution levels that do not satisfy
who guidelines  warsaw po valley and milan are
three severely polluted areas in europe if particle pollution
levels matched who guidelines people would gain one
year and two months  bursa turkeys industrial center
suffers from severe particle pollution as well the population
of bursa will gain one year and one month if the level of
pollutants are reduced to meet who guidelines largescale
biomass burning and unfavorable weather conditions are
causing air quality issues in the northern fennoscandia
region norway sweden finland and russia  in the
last two decades northern europe has seen a rise in air
pollution due to several largescale biomass burning episodes
in eastern europe causing serious consequences for human
health and local ecosystems
according to the european environmental agency eea
air quality report   of the european population
data gathered from  countries is exposed to the pm
concentration levels more than the eea limits and 
more than the who air quality guidelines aqg value for
pm pollutants almost  of the deployed air pollution
station have reported these statistics according to eea
standards for pm only  of the population is exposed
to pm concentrations higher than the eea standards
as per the who aqg guidelines  of the european
population was exposed to pm concentrations higher
than the recommended values  aq monitoring station
reported these statistics according to the same air quality
report  of the population in europe is exposed to ozone
concentrations higher than the eea recommended values
at aqg levels approximately  of the population is
exposed to ozone levels higher than the aqg recommended
values  of the air quality monitoring stations have
reported ozone values higher than the aqg recommended
values only  of the population is exposed to no levels
higher than the eea and who aqg values so is also on
the decline in europe only less than  of the european
population is exposed to concentrations higher than the eea
recommended values and  if measured at the who aqg
values due to covid statistics reported in the eea air
quality  report are based on numbers from 
europe is leading the way in the developed world in
introducing legislation and standards for improving air
quality over the years the eu has developed a procedure
for member countries to access their air quality and share
their data with the eea eea has also provided the member
states with ambient air quality values for twelve major air
pollutants table  provides the standard values of air
pollution concentration for the eu eu has prescribed the
following principles for member states to measure and report
their air quality
 httpseceuropaeuenvironmentairqualityindexhtm
 httpseurlexeuropaeusummarychapterenvironment
htmlroot defaultsum  codeddcsum  coded
dlocaleen
each member state will divide its territory into zones
measure the air quality in each zone using sensors
modeling or an empirical method
report the air quality data to the european commis
sion accordingly
zones where the air quality is poorer than the air
quality standards table  the member state will
provide a plan to address the sources of emission in
the zone and ensure compliance with the limit value
before the date when the limit value formally enter
into force
the member state will disseminate the aqi value to
the public
united states
the united states us is the rd most populated country in
the world with  of the world population living there
over  of the total population lives in the cities the us is
a success story when it comes to air pollution mitigation in
 the us introduced the clean air act and after that the
air pollution gone down by   this decay in pollution
has added  years to the life expectancy of us citizens
los angeles once known as the smog capital of the world
now reduced air pollution by  only  of the total us
population is exposed to air quality poorer than the who
recommended air quality guidelines 
africa
west and central africa have  countries with a  million
total population the average air pollution concentration
pm is around µgm that is twice the who recom
mended values for the pm with current levels of air
pollution an average person tends to lose approximately 
years of life expectancy benin congo republic of the congo
and the democratic republic of the congo ghana nigeria
and togo are among the top air polluted countries in the
region these countries are also ranked among the countries
having the worst air quality in the world according to the
aqli air pollution ranking nigeria is ranked th in the most
polluted country in few nigerian cities onitsha lagos etc
an average person is expected to lose four to six years of
life expectancy brazzaville in the republic of congo has
the worst concentration of pm µgm and resulting
in  years of reduction in the total life expectancy of an
average person the volta region in ghana is also suffering
from a poor air quality situation where the air pollution
concentration is four times the who aqg values the air
quality meeting the who aqg values will add three years
to the life expectancy of an average person in ghana burning
fossil fuels is the primary reason for air pollution in central
and west africa coal consumption is expected to increase
exponentially in the coming years
the african countries have to strike a balance between
economic growth and air pollution air quality data gath
ering and environment preservation policies are still not
designed only cameron has introduced the national air
quality standard for particulate pollution the african coun
tries need a coordinated effort to control the emissions and
implementation of air quality standards and environmental
preservation policies
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
figure  nuts and bolts of a comprehensive air quality model the ﬁgure is opted and improved from 
air
quality
monitoring
modelling
and
measurement techniques
in this section we discuss air quality monitoring modeling
and measurement techniques we divide this section into
four major components along with a necessary discussion
and lesson learned subsection the four major components
are air quality monitoring networks air quality modeling
techniques air quality measurement techniques and air
quality data
air quality monitoring network
an air quality monitoring network is used to acquire con
sistent objective and standardized information regarding a
regions air quality this information may include concentra
tions of target pollutants it also allows for necessary steps to
be taken in any environmental protection and public health
safety effort these steps include determination and control
of emission sources and keeping the public informed about
the state of the air quality  madruga et al  discuss
the air quality monitoring network with the perspective
of public exposure to pollutants in literature air quality
network design usually proceeds in two steps generation
of the ﬁne spatial distribution of pollutants and based on
that optimization of the location of the new sensor to add to
the system usero et al  describe the establishment of an
air quality monitoring network in seville spain to monitor
nitrogen dioxide and ozone levels following the european
unions ambient air quality assessment legislation mofarrah
et al  have used the multiplecriteria method with spatial
correlation to determine the optimal number of air quality
monitoring stations in an air quality monitoring network in
riyadh saudi arabia
by far efforts in establishing air quality monitoring
networks are broadly categorized in the following groups
fixed station air quality monitoring
fixed air quality monitoring stations are the most reliable
standardized accurate and highly expensive method fixed
air quality stations require highly trained staff and resources
to manage the measurement and maintenance operation
sometimes these costs even exceed the purchase cost of the
station thus most of the ﬁxed air quality monitoring stations
around the globe are installed and operated by government
agencies in us  air quality stations are installed by state
environmental agencies the eea receives data from 
 and  stations for measuring no pm and pm
respectively
various efforts have been made to create an ideal air
quality monitoring network that can offer comprehensive air
quality measurements elkamel et al  use a multiplecell
approach to create a monthly spatial distribution for pollu
tants and use it in a heuristic optimization algorithm to iden
tify the optimal conﬁguration of a monitoring network hsieh
et al  use a semisupervised inference model to predict
air quality of unknown areas and an entropyminimization
model to predict the best locations for establishing new
stations zhu et al  use bayesian maximum entropy with
a multiobjective optimization model to optimize the design
of an air quality monitoring network kang et al  derive
an air quality inference model using a higherorder graph
convolution network they employed a greedy method to
minimize information entropy which offers a prioritized list
of places for additional air quality measurement stations to
be installed the air quality measurement node placement
method  enhances overall network performance as well
as air quality prediction for a speciﬁc urban area of the city
as cities continue to expand and city dynamics are always
changing an optimal method to analyze and redistribute
the installed network is required hao et al  employs
an atmospheric dispersion model and genetic algorithm to
maximize coverage with minimum overlap yu et al 
use satellite observations to assess the representativeness
of installed air quality stations using a stratiﬁed sampling
method efforts have also been put into developing and
assessment of lowcost air quality monitoring alternatives
mobile air quality monitoring
given the price and the nature of the ﬁxed air quality
monitoring stations there has been a lot of attention to
the development of mobile air quality monitoring stations
mobile air quality monitoring stations offer a costeffective
solution with several promising features such as high
resolution spatial pollutant mapping and crossvalidation
of air quality measurements some of the most prominent
 httpswwwepagovoutdoorairqualitydata
airdatabasicinformation
 httpswwwconcaweeuwpcontentuploadseaq
trends digitalpdf
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
papers
input data
spatial distribution generation method
location recommendation technique
 year of data from  stations
met data pois road networks
graph convolutional neuralnetwork
greedy entropy minimization
fixed station data integrated with data
generated through copert iii
generative adversarial networks
kl divergence and
kmeans clustering
 year of ﬁxed station and met data
bayesian maximum entropy
multiobjective optimization
 months of data from  ﬁxed
stations met data pois road networks
afﬁnitygraph based inference model
greedy entropy minimization
met data with simulated data from
epa cmaq and camx models
simulated through cmaq and
camx models
objective function and
cost minimization
generated based on trafﬁc composition
industrial source complex isc model
multiobjective optimization
integration of satellite data with
ground station data
mathematical model
multiobjective optimization
 years of sampling campaign
spatial inverse distance weighted interpolation
multiobjective optimization
 years of met and pollution data
multiobjective optimization
table  review of research on air quality network design
research efforts in developing and utilizing mobile air quality
stations are summarized in table 
satellite based air quality monitoring
the use of satellitebased sensors for the determination of
air quality has been gaining momentum for a long time now
li et al  use modis moderate resolution imaging
spectroradiometer data along with meteorological factors to
analyze their relationship with groundbased pm stations
they use a nonlinear regression model to predict pm
forecast fowlie et al  analyze the relationship of ground
based pm stations with satellitebased estimates and their
effect on the environmental protection agencys policies
kim et al  discuss the launch of the gems satellite
for monitoring air quality they discuss the techniques of
sensing different air quality parameters through satellites
stebel et al  explore the use of existing satellite data to
derive particulate matter estimates and their correlation with
groundbased stations they have also extended the sensing
algorithm to report more on the air quality parameters
integrating satellite data with ground stations
sullivan et al  evaluate the need for satellites to
cover the gaps in the existing installed ﬁxed station air
quality monitoring network and the impacts it can produce
alvarado et al  have done a comprehensive analysis on
the integration of satellite data into a prediction of ground
air quality for lowincome countries they have used two
models to predict groundlevel pm namely generalized
additive model gam and chemical transport model
ctm after analyzing the results they provide further
recommendations on the ability of satellite estimates to
bolster air quality monitoring networks li et al  discuss
the integration of a lowcost air quality sensor network
with ﬁxed ground stations and satellite data to enhance
pollution mapping their studies have shown that integrating
the three datasets can vastly improve spatial distribution
and resolution their system can also perform quite well
under different weather conditions where the satellite remote
sensing data alone tends to be biased
air quality modelling techniques
the environment is a complex reactive system where multi
ple physical and chemical processes are happening contin
uously the air quality measurement at a speciﬁc location
and time provides a conditional spatiotemporal snapshot of
the environment the interpretation of spatiotemporal air
quality information requires a conceptual understanding
of atmospheric dynamics that is not possible without a
sophisticated air quality model measurement alone is also
not enough for policymakers to devise an effective plan
to address the looming challenge of air quality the air
quality models provide necessary mathematical information
for understanding the complex interactions between different
variables affecting air quality therefore a combination of air
quality measurement and air quality models can yield real
progress in understanding and solving the air quality issues
in urban centers
a comprehensive air quality model is supposed to
take into consideration the meteorology chemical trans
formations emission patterns known source information
point of interest poi and removal processes and provide
spatiotemporal emission ﬂuxes and pollutant concentrations
it also highlights the relation between the rate of change
in pollution concentrations and the potential sources 
figure  illustrates the bare minimum inputs and output
of an air quality model the three most commonly used
air quality modeling approaches are dispersion photochem
ical and receptor modeling we brieﬂy describe all three
modeling techniques along with their different variants
air quality is not a local phenomenon understanding the
contribution of different variables in the air quality landscape
is a challenging task modeling these contributions is not
possible through classical air quality modeling techniques
for completeness we have included the famous classical
air quality modeling techniques though these techniques
are not suitable to model the complex relationships between
different contributing variables in the air quality at a scale
many advanced modeling techniques are designed based on
the insights from these classical techniques
box models the box model is the simplest model
for estimating the concentrations of air pollutants
the box model compares a domains airshed to a
rectangular box within which the pollutants mass
is entirely contained  it is used for labscale air
quality experiments it is also suitable for modeling
indoor air quality more information on the box model
is available on  
gaussian models gaussian models are the most
popular air quality models used in the literature to
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
no
paper
mobile
platform
sensing
platform
sensing
parameters
study
area
time of
the study
mixed
customized
hardware
co no
o
california us
 weeks
 
cycle bike
bus train walk
customized
hardware
co no
o
california us
 weeks
 
driving cycling
jogging
node
sensors
co
sydney australia
 week
driving cycling
jogging
node
sensors
co
sydney australia
 week
  
walking driving
cycling
teco
envboard
pmx
germany
 hours
walking
customized
hardware
co
o
switzerland
 month
walking cycling
bike car bus train
customized
hardware
co no
o
california us
 month
cycle bike car
hazewatch
node
co no
o
new south wales
australia
 week
cycle
magee microaeth ae
lowcost sensors
pmx tsp
black carbon co
antwerp belgium
 days
car
custom hardware
node sensors
co pmx
new york
new jersey us
bus
customized
hardware
pm
hangzhou china
google street
view vehicle
laboratory grade
analyzers
black carbon nox
oakland us
 year
mixed
customized
hardware
co co ch
india
trash trucks
customized
hardware
pmx
cambridge us
 months
car
customized
hardware
co co no
chennai india
table  review of research on mobile air quality sensing
figure  a nonexhaustive taxonomy of air quality modelling techniques from us epa
model the repercussions of air pollution in various use
cases these models are frequently used in regulatory
applications the gaussian model assumes that the
plume spread is a result of molecular diffusion pollu
tant concentrations in the plume spread horizontally
and vertically  the solution to the diffusion
equation with varying initial value and boundary
conditions results in a gaussian distribution of the
pollutant concentrations  for further details on
the gaussian air quality models we refer the reader
to  
eulerian models the eulerian air quality modeling
approach is considered one of the most signiﬁcant
modeling techniques it is often known as the grid
model technique in this technique the area under
consideration is divided into equal size small grid
cells and conservation of the mass equation is solved
for a speciﬁc type of pollutants concentrations 
a set of mathematical equations in a given coordinate
system explain the transport diffusion transforma
tion and deposition of pollutant emissions in each cell
 this modeling approach is used for studying
and simulating longrange transport air quality over
the entire airshed further details on the eulerian air
quality modeling we refer the reader to  
lagrangian models the lagrangian models calculate
the wind trajectories and the transportation of the
plume along these trajectories for sourceoriented
models these trajectories are calculated forward in
time and for receptorbased models these trajectories
are calculated back in time  lagrangian model
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
ing is frequently used to span a longer time duration
up to years these models are also used to model the
concentrations of the particulate matter in the air for
more information on the lagrangian models we refer
the reader to  
dispersion modelling
air dispersion models formulate and simulate the dispersion
of the pollutants emitted by different sources the simulation
provides an estimation of the downward air pollutant
concentration dispersion models are used to predict the
concentration for speciﬁc scenarios such as the change of the
pollution source these models are more suited for pollutants
that react in the environment and spread over large distances
the models are also widely used by regulatory bodies during
the preparation and evaluation of air permit applications
public safety and emergency response personals utilize these
models to determine toxicity in the air due to possible gas
release events environmental protection agencies around the
globe measure the effect of emissions from different sources
and pollution control strategies by using the dispersion
models
aermod modeling system the american meteo
rological society amsus epa regulatory model
improvement committee aermic a joint working
group of scientists from the ams and the epa
created the aermod dispersion modeling system it
is a steadystate gaussian plume model that includes
air dispersion based on planetary boundary layer
turbulence structure and scaling ideas as well as
handling of complex terrain simple and intricate
topography it generates pollutant concentrations
in the ambient air on a daily monthly and yearly
basis it is an updated version of the industrial
source complex iscst framework proposed by
the usepa for analysing the inﬂuence of industrial
sources on air quality in the coming years 
 aermod consists of a dispersion model
for shortrange dispersion of air pollutants from
various sources a meteorological data preprocessor
aermet and a terrain preprocessor aermap
  the aermod dispersion model takes
preprocessed meteorological parameters and pre
processed relation between complex terrain features
and air pollution plumes to produce an air quality
model   further details on various ver
sions of its source codes implementation details
and variable details are available at 
ctdmplus perry et al  proposed the techni
cal formulation of the complex terrain dispersion
model ctdmplus later paumier et al 
provided a performance characterization study of
ctdmplus the objective for this project by us epa
was to design a dispersion model that can model
and predict the air pollution concentration in the
mountainous terrain ctdmplus is a point source
gaussian air quality model for complex terrain that
uses a ﬂow algorithm to provide the deformation in
the plume trajectory caused by the mountainous
terrain it is capable of simulating the ﬂow and
distortions in the plume near predeﬁned three
dimensional d terrain features while remaining
simple by applying ﬂowdistortion adjustments to
ﬂatterrain gaussian and bigaussian pollution
distributions   the ctdmplus requires a
signiﬁcant amount of information on the topography
and weather to produce an efﬁcient dispersion
model which often represents a bottleneck in many
circumstances more information on various versions
of the ctdmplus source code implementation
details and variable details are available at 
ocd hanna et al  introduced the offshore
and coastal dispersion ocd model which can
simulate the impacts of offshore emission sources
on coastal air quality it is based on a steadystate
gaussian model that can cater to the varying disper
sion characteristics between over and underwater
sealand interface and aerodynamic effects hourly
meteorological data from water and land sites is
necessary for the ocd model to predict air quality
turbulence intensities are also frequently used along
with the hourly meteorological data but they are not
mandatory more information on various versions of
the ctdmplus source code implementation details
and variable details are available at  
though us eea recommends aermod ctdmplus and
ocd for air quality modeling they also provide an alter
native list of models that can be used by the regulatory
applications on a casebycase justiﬁcation
photochemical modelling
photochemical air quality models are often used to evaluate
the effectiveness of the control strategies for regulatory anal
ysis and attainment demonstrations photochemical models
can model the air quality at different spatial scales local
regional national global etc photochemical air quality
models are also known as photochemical grid models these
models are used to evaluate the changes in the concentrations
of the criteria pollutants due to the changes in the associated
variables meteorological conditions emission sources etc
similarly these models are also used for accessing the
sensitivity of the pollutant predictions in different use cases
photochemical grid models are also used to evaluate the
performance of pollution control policies they simulate the
concentration of the air pollutants at a large scale by using
a complex set of mathematical equations to characterize
different atmospheric processes physical and chemical two
types of commonly used photochemical air quality models
are the lagrangian trajectory model and the eulerian grid
model the lagrangian trajectory model uses the moving
frame of reference for modeling the air quality whereas the
eulerian grid model applies ﬁxed d geometric models to the
ground to model the air quality of a particular geographical
area
community
multiscale
air
quality
cmaq
cmaq modeling system is a stateoftheart pho
tochemical air quality modeling system it uses
d eulerian modeling system to simulate the ef
fect of the criteria pollutants in urbantoregional
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
tohemispheric scale cmaq is developed and
distributed by us epa as an opensource suite of
air quality modeling programs that can simulate
multiple air pollution use cases and predicts the con
centrations based on the historical data of the criteria
pollutants cmaq is used to simulate and estimate
the performance of epa missions for understanding
and forecasting air pollution human exposure to air
pollution watershed acidiﬁcation  deposition
of nitrogen and sulfur  and many other air
pollutionrelated use cases three common types of
cmaq are
wrfcmaq wong et al  proposed a
combination of weather research and fore
casting with the inputs of the cmaq eg
aerosol concentration to introduce the effect
of the chemistry into the weather this coupled
design meteorology from cmaq and the
chemistry from weather research and fore
casting component is known as wrfcmaq
information from cmaq such as aerosol
concentration is transmitted into wrf so that
the chemistry can inﬂuence the weather more
details on the wrfcmaq are available in
cmaqddm
cmaq
decoupled
direct
method cmaqddm offers concentrations
and deposition sensitivity statistics for user
speciﬁed parameters  the motivation for
cmaqddm comes from the desire to mea
sure the concentrations of the pollutants by
changing one or a few parameters out of many
predeﬁned air quality model parameters 
air quality models usually take emissions as
input and predict their concentrations cmaq
ddm provides the ability to the policymakers
to look at the pollution landscape by tweaking
the parameters of interest or emission sources
eg wildﬁres vehicles etc more details on
the cmaqddm are available in  
cmaqisam cmaq integrated source ap
portionment method cmaqisam is a vari
ant of cmaq that measures the attribution of
the source in the overall value of the pollutant
concentrations predictedoutputted by the air
quality models for example identifying the
proportion of the smog created by the stubble
burning in a neighboring city this can be
achieved by running the cmaq twice ﬁrst
with all emission use cases and second by
removing the source of interest but this will
be complex and computationally expensive
cmaqisam this issue by calculating source
attribution of many sources directly by the
model in one simulation simon et al 
used cmaqisam for characterizing co and
nitrogen oxides sources in the baltimore area
kwok et al  used cmaqisam to un
derstand the pm sources and their effects
 httpsgithubcomusepacmaq
on the air quality more details on the cmaq
isam are available in  
comprehensive air quality model with extensions
camx camx is another famous air quality
model in photochemical modeling camx modeling
system models the air quality with all criteria pollu
tants for a large scale city state country continent
level it takes emissions meteorology data land use
surface topography initial and boundary conditions
and chemistryrelated values as input and performs
source attribution sensitivity and process analyses
estes et al  used camx to model the exceptional
air quality events in near realtime in taxes to
estimate the ozone impact in three use cases biomass
burning in mexico stratospheric ozone intrusion
anthropogenic emissions in mexico few critical
resources where camx based modeling is used for
air quality policymaking are available in  
regional modeling system for aerosols and depo
sition remsad remsad is another air quality
modeling system that models the particulate haze
and other criteria pollutants it is a regional scale
modeling system that can simulate the physical and
the reactive processes in the environment to show
the effects of the spatiotemporal changes in the air
pollutant concentration on the overall ambient air
quality
urban airshed model variable grid uamv in
the early s the most commonly used air mod
eling system was uamv photochemical modeling
system uamv was widely used for air quality
studies focused on ozone it is a d photochemical
grid model that can model the effects of the chemical
and physical processes in the environment on the
concentrations of air pollutants uamv also pro
vided a spatiotemporal distribution of the emissions
of various air pollutants uamv is outdated and no
longer used for air quality modeling
receptor modelling
the third category of the air quality models is called receptor
models these models are mathematical techniques for
recognizing and quantifying the origins of air pollution at
a particular receptor location  receptor models are
different from dispersion and photochemical air quality
models they do not require meteorological chemical and
emission data to estimate the participation of the pollution
sources in the air pollution concentrations at the receptor
the receptor model uses the chemical and inert properties
of gases so co etc and the particulate matter particles
to determine to contributions of the emission sources in the
pollution concentrations at the receptor  
chemical mass balance cmb the cmb  is a
model for estimating the contribution of the emission
sources to air pollution at the receptor locations
cmb uses spatial ambient data and information
 httpswwwcamxcom
 httpremsadicfconsultingcom
 httpuamvicfconsultingcom
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
about the pollution sources to determine the source
contributions cmb quantiﬁes the contributions at
the receptor based on the distinct source types rather
than individual emission sources a drawback of
cmb is its inability to distinguish between emis
sion sources with the same chemical and physical
properties more details on the cmb are available in
unmix unmix model uses a formulabased on a
form of factor analysis to determine the chemical
species in the air and their sources it does not take
the chemical proﬁle of the pollution sources as input
instead it generates the chemical proﬁle to estimate
the number of pollution sources their syntheses and
their participation in the air pollution at the receptor
location
positive matrix factorization pmf pmf  is
another air quality model which takes different
features from sediments wet deposition surface
water ambient air indoor air etc to identify the
species of air pollutants pmf also determines the
contributions of the pollution sources at the receptor
the us epa no longer updates pmf and it no longer
supports newer operating systems
air quality measuring sensors
the air quality sensors are the most crucial component of any
air quality monitoring network these sensors are used to
determine the concentration of pollutants in the air typically
these sensors are built with a lego connection for the data
acquisition card and data telemetry is accomplished using
wifi or cellular communication in practice data processing
is done on the cloud rather than on the sensor however there
have been a few situations where data is preprocessed on
the air quality sensors speciﬁcations of air quality sensors
are broadly given by the following parameters
accuracy this is a measure of how close the read
ings of sensors would be as compared to the actual
pollutant value
precision this is a measure of how well the sensor
reproduces the same reading a sensor with low
precision can give different readings at different
times with the same pollutant level
range and detection limitations this is the mea
sure of range of pollutant concentration that the
sensor is able to detect correctly sensor performance
may vary with different concentration of pollutant
copollutant interference cross interference from
other pollutants also affect sensor readings it is
intended to minimize the copollutant interference
when measuring a certain pollutant
environmental interference sensor performance
may vary under different environmental conditions
such as low and high temperature humidity sun
light etc
noise noise is the source of inaccuracy in sensor
readings the effect of noise should be minimized to
produce more precise and accurate sensor readings
 httpswwwepagovairresearch
unmixmodelenvironmentaldataanalyses
signal drift this is the drift in readings which
occurs due to inherent sensor measurement methods
and degradation of sensors components many
air quality sensors suffer from signal drift when
selecting a sensor it should be ensured that the
drift can either be handled or it does not affect the
readings to a signiﬁcant level
response time different sensors can produce read
ings with different minimum time intervals it should
be ensured that the selected sensor is able to produce
readings with acceptable time intervals
multisite measurement performance this is an in
dicator that generalizes the copollutant interference
and the environmental interference of sensor
measurement techniques
a summary of the types of sensors and measurement
techniques has been show in ﬁgure 
particulate matter measurement of particulate mat
ter concentration is broadly categorized in three
methods gravimetric microbalance and optical mea
surements whalley et al  gravimetric method
is widely used by regulatory and certiﬁcation au
thorities it is based on weight difference of a ﬁlter
medium before and after the gas is passed through
the ﬁlter microbalance method uses the change
in resonant frequency to measure the particulate
matter concentration by far the most popular choice
for measurement commercial realtime particulate
matter sensors is the optical method scattering or
absorption of a light beam is measured to determine
the concentration of particulate matter
gases the two major sensor types used for sensing
gaseous pollutants are electrochemical sensor 
and metal oxide sensors metal oxide sensors typi
cally require more power to heat up to very high
temperatures to enable signiﬁcant sensitivity to target
detection gas that also increases the start up time of
sensor electrochemical sensors require less power to
operate and thus allow for fast startup time and cost
savings generated over life time of sensor
sensing solutions
oem sensors oem sensors comprise of just the
sensing element further interfacing and signal con
ditioning is required to convert the sensor output
to meaningful numbers these sensors are popular
choice for original equipment manufacturers
sensing systems sensing systems are built upon the
oem sensors and the output is provided in digital
format sensing systems are available for both indoor
and outdoor air quality monitoring apart from
digital output many sensors are also available with
extra features such as wifi or cellular connectivity
and mobile application to view the sensor outputs
as well as the resulting air quality index for many
commercial and indoor air quality measurement
 httpswwwemersoncomdocumentsautomation
whitepaperelectrochemicalvssemiconductorgasdetectionen
pdf
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
figure  the ﬁgure shows a taxonomy of air quality sensors along with their working principle and detected pollutants
systems high accuracy is not required and thus are
free from regulatory requirements these systems
are widely available in market and their price is
usually below  the data available through such
sensors is not accurate and it can sometimes produce
unknown errors weather conditions can also affect
such sensing systems
to mitigate all of the above problems and to provide
a standard measurement system the government
deﬁnes a certain set of regulations to conform to
for the measurement of air quality and pollutants
detailed speciﬁcations of measurement and reporting
of the concentration of pollutants is often provided
by the countrys environmental protection agency in
us environmental protection agency epa provides
federal reference methods frm and federal equiv
alence methods fem for measurement of pollutants
frms specify the most scientiﬁcally sound technique
to report the concentration of pollutant and it becomes
the basis of criteria for evaluation of other measure
ment methods fem provides techniques that are cost
effective and easier to implement and yet can provide
comparable level of accuracy with the fems such
systems are very expensive and their price can range
up to  they also highly trained technical staff
for its operation and maintenance annual operating
expenses may also exceed the system cost on the
other hand the data provided through these systems
is highly consistent and accurate in a variety of
weather and environmental conditions 
air quality measurement projects
urbanair
urban air is a microsoftfunded initiative that began in
 it is a subproject of microsofts urban computing
table  air quality standards for the european union
pollutants
concentration
averaging
period
permitted
exceedences
each year
pm
µgm
 year
na
so
µgm
 hour
µgm
 hour
no
µgm
 hour
µgm
 hour
na
pm
µgm
 hour
µgm
 year
na
lead pb
µgm
 year
na
co
mgm
 hours mean
na
benzene
µgm
 year
na
o
µgm
 hour mean
 days average
over  years
arsenic as
ngm
 year
na
cadmium cd
ngm
 year
na
nickel ni
ngm
 year
na
polycyclic
aromatic
hydrocarbons
ngm
 year
na
 which intends to use big data eg trafﬁc ﬂow human
mobility and geographical data to solve key urban issues
such as pollution transportation congestion and energy
consumption the primary goal of urban air was to measure
analyze forecast and assist in the improvement of urban air
quality in cities such as beijing china in addition urban air
sought to discover relationships between various air quality
trends to determine the sources of pollution in different
urban locations
the urban air project consists of four steps
inferring ﬁnegrained air quality
forecasting air quality at each station
optimal deployment of air quality monitoring sta
tions
root cause analysis of urban air pollution
following is a brief description of each step
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
table  air quality standards for the united states
pollutant
primary
secondary
averaging time
level
form
carbon
monoxide
primary
 hours
 ppm
not to be exceeded more
than once per year
 hour
 ppm
lead
primary and
secondary
rolling 
month average
 µgm
not to be exceeded
nitrogen
dioxide
primary
 hour
 ppb
th percentile of  hour
daily maximum concentrations
averaged over  years
primary and
secondary
 year
 ppb
annual mean
ozone
primary and
secondary
 hours
 ppm
annual th highest daily maximum
hour concentration averaged
over  years
pm
primary
 year
 µgm
annual mean averaged over  years
secondary
 year
 µgm
annual mean averaged over  years
primary and
secondary
 hours
 µgm
th percentile averaged
over  years
pm
primary and
secondary
 hours
 µgm
not to be exceed more than once
per year on an average of
 years
sulphur
dioxide
primary
 hour
 ppb
th percentile of  hour daily
maximum concentrations
averaged over  years
secondary
 hours
 ppm
not to be exceeded more than once
per year
inferring ﬁnegrained air quality
as a ﬁrst step the urban air project sought to infer air
quality in areas where air quality stations were not available
 it is a difﬁcult undertaking since accessible air quality
data is sparse and limited to tackle this challenge zheng
et al  gathered context data from a range of additional
sources meteorology road networks trafﬁc ﬂow poi and
human mobility that have an indirect impact on air quality
after acquiring the context data it is fused with sparse
aqi data from known locations then spatial and temporal
classiﬁers are used for inferring the aqi values at unknown
places the spatial classiﬁer is an artiﬁcial neural network
ann that takes a subset of data and tries predicting
aqi for unknown nodes by using pearson correlation of
known features between nodes the temporal classiﬁer
takes the timedependent factors and tries predicting aqi for
unknown nodes using a linearchain conditional random
field crf the training is performed by iteratively adding
unknown nodes to the set of known nodes that are classiﬁed
conﬁdently by the models for inferring aqi value at
some unknown locationgrid features are applied to each
classiﬁer independently only those aqi values are reported
where both classiﬁers have higher conﬁdence results of
the experiment are compared with different interpolation
techniques like linear gaussian classical dispersion model
decision tree crf and ann the initial step of urban
air only inferred pm and no values for beijing and
shanghai in subsequent work zheng et al  combined
the spatiotemporal model with a realtime feature extraction
database to make userfriendly web and mobile applications
forecasting air quality at each station
following the successful inference of aqi values at arbitrary
sites the next phase in the urban air project was to forecast
aqi values at speciﬁc station locations  forecasting aqi
values is critical because it allows policymakers to better un
derstand air pollution trends and develop preventative and
mitigation policies the method of estimating the next aqi
value at a certain time granularity based on prior aqi values
is known as aqi forecasting various connected aspects
such as meteorology wind speeds temperature and so on
might have an impact on the forecasting process therefore
a realtime database is utilized to give meteorological data
humidity temperature and wind speed as well as weather
forecasts and aqi values for each station site
the forecasting component of the urban air project
gathers data from  stations in  chinese cities with
each instance having concentrations of six air pollutants
no so o co pm and pm zheng et al 
employed the four predictors listed below to forecast the
aqi value at a station
a temporal predictor is used to anticipate the aqi
value using a linear regression model on the data
a spatial predictor is used to provide the surrounding
context to a neural network which forecasts an aqi
value based on the context data
a prediction aggregator trains a regression tree to
give various weights to the ﬁrst two predictions under
different scenarios
finally an inﬂection predictor is employed to simulate
any rapid changes in aqi values and is only utilized
in exceptional cases rain etc
for the ﬁrst  hours the aqi value after each hour is
predicted while for the next h h and h
a minmax range of aqi is forecasted zheng et al 
performed forecasting for  air quality stations in beijing
and compared their results with techniques like auto
regressionmovingaverage amra linear regression lr
all neural network annall and regression tree rt
all
deployment of air quality monitoring stations
the placement of air quality sensors in suitable places is
critical for obtaining relevant air quality data hsieh et al
 solve the sensor placement problem with a restricted
budget in the urban air project hsieh et al  used a two
stage technique to handle this problem the ﬁrst phase is to
infer the air quality at an unknown place and the second
is to pick candidate locations depending on the conﬁdence
of the inference the city of beijing has split into km x
km patches for inference with each patch referred to as a
node by linking these nodes with known and unknown aqi
values a network is formed some of the linkages are made
with the help of historical geographical and environmental
factors local meteorology road network data and pois are
used to provide weight to edges once the graph is complete
an unknown aqi value is calculated using a weighted sum of
aqi values from known modes instead of only obtaining a
single value for aqi a distribution is learnt at each unknown
node the weights of the graph are modiﬁed over numerous
rounds to get a better distribution minimize entropy loss
for recommending the locations of the station ﬁrst ﬁnd
the node with the best distribution or lower entropy loss
and rank it the last in the list after assigning a rank to this
node label it as a known node and again run the inferring
algorithm to ﬁnd new inference after this ﬁnd the node
with the best distribution and assign it second last this step
is repeated until all nodes are ranked
identiﬁcation of root cause of air pollution
the placement of air quality stations is motivated by the
need to identify the root causes of air pollution urban air
also seeks to identify the underlying causes of urban air
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
pollution understanding the root cause of air pollution is
extremely beneﬁcial to policymakers in government and
environmental protection agencies because data collection
involves noise collecting insights for establishing the root
cause of air pollution becomes a difﬁcult job zhang et al
 and nguyen et al  integrated historical data with
bayesian learning approaches   to uncover air
pollution causal pathways data used in   includes
measurements of six air pollutants pm pm no co
o so and ﬁve meteorological measurements tempera
ture pressure humidity wind speed and wind direction
which are updated hourly for three areas north china
yangtze river delta and pearl river delta understanding
the root cause of air pollution is based on pattern mining and
bayesian learning the initial stage in pattern mining is to
locate frequently evolving patterns fep it is accomplished
by ﬁrst identifying patterns that happen often at the station
and then applying a projection to them as done by preﬁxscan
 then feps of neighboring stations are compared
and possible causative agents for each sensorstation are
retrieved the pattern mining module decreases the number
of variables which aids in decreasing computation cost for
the next stage in learning the bn structure on in the
worstcase scenario
the bayesian learning module of the root cause identiﬁ
cation pipeline combines the concentration measurements of
each pollutant at the target node with the spatial data from
candidate causers at the multiple time stamps following
data integration initial routes for the n most signiﬁcant
sensor for the target locationstation are created each of
these paths is then assigned a grangercausality gc score
  once the score is assigned to the pathways
the context data is integrated with pathways zhang et al
 determine the number of subclasses using a hidden
confounding variable and then repeatedly optimize the
initial paths by reducing em loss
the urban air project was a great success as it helped in
reducing air pollution in china based on the insights from
this project the environmental protection agencies and the
chines government have taken policylevel steps and the
air pollution in china is under control
aqli project
the air quality life index aqli is another famous air
quality measurement project by the energy policy institute
at the university of chicago epic aqli project introduced
a new metric for measuring the impact of air quality called
air quality life expectancy instead of the conventional aqi
metric this new metric translates the impact of air pollution
on the life expectancy of a human being
the aqli work is based on the pm data collected via
satellite monitoring combined with the global population
data obtained from the  global landscan global popu
lation database  the aqli index is an extension of the
previous work done by greenstone et al in understanding
and quantifying the impact of particulate air pollution on
the expectancy of human life  once both datasets are
collected a gridcellbased procedure is used for combining
global population data with the satellitedriven pm data
loss in life expectancy is calculated for each grid where
each grid corresponds to a km x km area on the ground
the loss in life expectancy due to pm is computed based
on the previous work by ebenstein et al  which shows
that with every µgm of sustained exposure to pm
life expectancy decreases by  years assuming that life
expectancy varies linearly with pm exposure the loss in
life expectancy is multiplied by  for each incremental
exposure to µgm of pm beyond the who threshold
level µgm of pm
the aqli project has resulted in aqli index which
provides a countrylevel loss in life expectancy based on
the pm concentrations this project provides a thorough
analysis of the air pollution situation in many countries and
also covers the policy level steps taken by different countries
eg china india for mitigating the impact of air pollution
on the life expectancy of their citizens though this project
only covers the impact of pm the insights and policy level
suggestions provided in the aqli reports can help improve
the air quality of any part of the world this project is also
an excellent example of how to set up an air quality indexing
study for other criteria pollutants
afriqair
air pollution is a major problem in africa with research
indicating that air pollution causes around  premature
deaths every year  unfortunately there arent many
referencegrade air quality monitoring stations in africa
therefore it is difﬁcult to interpolate the actual situation of
the air pollution the afriqair project tries to tackle this
issue by developing a continentscale air quality monitoring
network afriqair is an african air quality monitoring
initiative  the initiative employs a network of both high
quality and lowcost air quality sensors by mid there
are approximately  nodes spread throughout  african
nations ghana rwanda uganda kenya south africa
democratic republic of congo cote divoire niger congo
etc afriqair has the following three goals for improving
the air quality situation in africa
creating the physical infrastructure required to mea
sure and monitor air quality across the continent it
entails a mix of highquality and lowcost air quality
assessment equipment as well as the necessary
power sources and data telemetry systems
local capacity building to use manage and analyze
the developed physical infrastructure
finally ensure that the physical infrastructures data
and insights are accessible and actionable
the data gathered through these  measurement platforms
across africa is opensourced in daily hourly and minute
granularity and can be readily used for air quality research
ghana urban air quality project ghair
urban air and aqli projects are being carried out on a
global scale using cuttingedge technology and techniques
for planning modeling monitoring and extracting insights
many underdeveloped countries with limited resources do
 httpsaqliepicuchicagoedutheindex
 httpwwwafriqairorg
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
not have this opportunity with the ghana urban air quality
initiative ghair we hope to show the reader how a
relatively impoverished nation may set up an air quality
monitoring project
ghana is west africas secondmost populated country
behind nigeria ghana is dealing with severe pollution
problems and it is reported that air pollution killed over
 people in   in  ghana started the ghair
project to solve the problem through cuttingedge research
the environmental protection agency of ghana has limited
resources and proper technical human resources to solve
these issues ghair uses lowcost air quality sensors to
bridge the data gap various studies have highlighted that
lowcost sensors might be a great chance to overcome the
air pollution data gap in underdeveloped countries 
ghair has the following four objectives that are also in
line with the unsdgs 
creating a dense lowcost air quality sensor network
in metropolitan areas to collect realtime spatiotem
poral air quality data that may be used to impact air
pollution management policy
launching public awareness campaigns about the
effects of urban air pollution and how residents may
safeguard their health in areas with poor air quality
improving the air quality by introducing behavioral
changes in the communities
performing epidemiological research to highlight the
health issues of air pollution exposure in vulnerable
populations for the public health department
the ghair presently employs a mix of lowcost pur
pleair sensors clarity nodes ramps and modulairpm
sensors these sensors have been installed in six of ghanas
major cities accra tema cape coast takoradi and kumasi
ghair has also just placed ten sets of teom ab pm
monitoring sensors provided by the uk environmental
agency automatic urban and rural network  the
ghair presently employs a mix of lowcost purpleair
sensors clarity nodes ramps and modulairpm sensors
these sensors have been installed in six of ghanas major
cities accra tema cape coast takoradi and kumasi
ghair has also just placed ten sets of teom ab pm
monitoring sensors provided by the uk environmental
agency automatic urban and rural network  ghair
project is also going to launch a program called escrap
educating school children to tackle air pollution project
with the help of the royal society the projects goal is to
create awareness among schoolchildren about air quality and
how they may help to improve it the motto of the project is
school children as agents for improved air quality
they are now experiencing several difﬁculties in getting
data from sensors these concerns include the availability of
wifi at deployment sites for data telemetry and sensor power
supply to address these issues ghair is experimenting with
solar energy to power the sensors  furthermore they
are attempting to leverage gprs for data telemetry despite
these challenges the ghair project has enormous potential
for bridging ghanas data gap on air quality
hazewatch
pm concentrations above who standards have been
found in new south wales australia particularly in sydney
the department of environment climate change and water
deccw has already placed  stations in various sites
across sydney and data is published hourly aqi levels
and corresponding health advisories are provided based
on this pollution data unfortunately these stations are
separated by tens of kilometers resulting in inadequate
spatial resolution because of the low spatial resolution
complicated interpolation procedures are needed to report
aqi values as a result the deccw aqi monitoring
network does not represent actual levels of air pollution and
exposure to overcome these shortcomings sivaraman et al
 designed a lowcost urban air quality monitoring system
known as hazewatch hazewatch utilizes many lowcost
mobile sensor units installed in cars to measure air pollution
concentrations as well as users mobile phones to tag and
upload data in realtime the outcome of the projects is its
costeffectiveness better spatial resolution and personalized
exposure tools the project measured no co and o
though hazewatch ﬁlled the gap in spatial resolution it has
faced multiple challenges in calibration sensor design mass
deployment health outcome interpretation etc the project
has resulted in multiple research publications on designing
pollution monitoring sensors  data transmission
  database connectivity  android interface
design  pollution modeling  data visualization 
and exposure modeling 
citisense
developing a countrywide air quality network based on
referencegrade nearreference and lowcost air quality mon
itoring sensing solutions for each pollutant is a complicated
endeavor it requires a lot of money infrastructure and
technical expertise thus environmental governance through
citizen empowerment is gaining traction the purpose of
these programs is to encourage individuals in deploying low
cost sometimes nearreferencegrade monitoring equipment
and share air quality data the integration of data from
residents and referencegrade sensing equipment can assist in
obtaining a more granular picture of air quality resulting in
more effective air quality improvement measures the euro
pean commission has ﬁnanced citisense 
a project that uses cuttingedge earth observation technology
to build and test environmental monitoring systems the
projects goal was to create citizen observatories that would
allow residents to gather and monitor environmental data
in order to formulate community policies the citisense
project produced a number of air quality sensor devices as
well as mobile and other communication technologies the
key contributions of the citisense project were
studying and mitigating hurdles in the citizens in
volvement in environmental decision making
designing the tools and technologies to enable the
citizens in collecting urban environmental data
providing lowcost measuring solutions and data
fusion methods for scientiﬁc analysis
 httpscordiseuropaeuprojectid
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
integrating newer sensing technologies iot and other
ict technologies cloud platforms data analysis and
learning techniques to enhance community participa
tion in the form of personal environmental monitoring
devices
the citi sense initiative distributed  air quality mon
itoring units around europe and  volunteers helped
test the personal air quality monitoring devices a total of
 citizen observatories were also developed in nine major
cities of europe barcelona belgrade edinburgh haifa
ljubljana oslo ostrava vienna and vitoriagasteiz an
air perception application was also a critical part of the
project and  people used it to report and get air quality
information in  nearly  million environmental
observations were collected using the citisense sensor
network and other additional observation tools further
involvement of the citizens was ensured by feedback surveys
questionnaires focus group discussions and interviews the
citisense initiative resulted in environmental monitoring
systems across europe as well as citizen engagement in
environmental governance the insights from the citi
sense project has resulted in many research publications
dealing with lowcost air quality sensing and performance
assessments   pollution hotspot detection
 data assimilation   missing data
imputation methods  epidemiology studies  air
quality sensor calibrations   localized real
time pollution effects     zero emission
studies  wireless and distribution network design
suggestions for air quality networks  pollution exposure
assessment   enduser feedback   
toolkits for monitoring urban air quality  and new
citizen observatory design 
opensense ii
generating a comprehensive spatiotemporal map of air
pollution requires a lot of data from multiple sources only
referencegrade air quality data is not enough as they are
very expensive and there can be a few referencegrade air
quality monitors in a city opensense ii aims to integrate
data from heterogeneous devices and crowdsourcing with
reference grade measurements to generate a spatiotemporal
map of urban air pollution and estimate the health impacts
due to air pollution exposure opensense ii project generates
granular air pollution maps of zurich and lausanne and also
studies the impact of air pollution exposure on human health
opensense ii uses data air pollution data communication
platforms sensors personalized health recommendations
etc from another project known as nanotera project
opensense the data from the nanotera project is com
bined with crowdsourcing and humancentric computation
techniques for highresolution air pollution maps the air
quality data is also gathered by deploying sensing systems
on buses and electric cars opensense ii also pushed the
stateoftheart in generating highresolution spatiotemporal
air quality maps    mobile sensor networks
for air quality monitoring   and estimating the
impact of pmx on human health and personalized health
recommendations 
root cause analysis of the urban air pollution
the efforts put into designing modeling measuring and
developing cuttingedge air quality measurement facilities
are only to understand the root cause of urban air pollution
and how it affects human health and the global tempera
ture many studies have been conducted using air quality
data acquired from air quality networks to identify the
causescontributors of air pollution karagulian et al 
performed a systematic analysis on the air quality data of 
countries from the who website and highlighted the major
sources of air pollution according to their study of available
data trafﬁc emissions contribute  of air pollution pm
industrial activities contribute  domestic fuel burning
contributes  natural dust and salt contribute  and
unidentiﬁed causes linked to humans contribute  
jiang et al  investigated the spatiotemporal features of
air pollution in six chinese cities and applied the granger
causality test  to evaluate the impact of a citys air
quality on surrounding cities and vice versa according to
their study air pollution is very high in the winters and
early springs and stays low in summer and autumn they
also discovered a unidirectional association between the air
quality of baoding and beijing where the air pollution from
baoding has a signiﬁcant impact on beijings air quality
since baoding is more polluted than beijing 
wang et al  found that particulate matter from
transportation industry agricultural activities fuel burning
construction and demolition accounts for  to  of overall
air pollution in china wang et al  also discovered
that the  extended haze event in centraleastern china
was caused by a shift in meteorological conditions 
employed synthetic atmospheric circulation to determine
the sources of air pollution trafﬁc emissions and high
levels of energy consumption are identiﬁed as contributors
to the haze and poor air quality in centraleastern china
 recently there has been a surge in datadriven root
cause analysis techniques  these techniques are
motivated by the success of big data and artiﬁcial intelligence
ai in many other domains for detecting and comprehend
ing the root cause of urban air pollution we advocate a
combination of traditional modelingcausal methodologies
with cuttingedge ai techniques
urban air quality challenges
despite a plethora of work in measuring and understanding
air quality there are various challenging aspects in tracking
and measuring air quality in this section we take a look at
the challenges needed to be addressed for rapid improve
ment in ambient and indoor air pollution
data collection and public datasets
collecting the air quality data is a challenging task as it
involves different concentrations of air pollutants given the
environmental cost and health risks of poor urban air quality
it is imperative to develop a central realtime air quality
data measurement and processing system two paradigms
for gathering urban data ie air quality data poi mete
orological data etc are sensorcentric data collection and
crowdcentric data collection the sensorcentric paradigm
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
has two categories these categories are based on whether
the data collecting sensors are mobile deployed on a moving
object or static deployed on a ﬁxed location the crowd
centric data collection is also divided into two categories
activedata generated via participatory surveys and check
ins or passive data generated by users passively while using
the urban infrastructure
gathering air quality and related data via these two
paradigms is difﬁcult because of the following challenges
in static sensorcentric air quality data collection
sensors are deployed at a ﬁxed location and they
communicate at a predeﬁned frequency to the cen
tral database ie cloud server this static sensor
deployment makes the air quality measurement a
resource constraint system limited budget land use
workforce for maintaining the system etc as a
result data gathered from very few sensors ﬁxed at
different locations in an urban environment is sparse
and not sufﬁcient representative of the air quality
situation of the city
in static sensorcentric air quality data collection
where the number of sensors is limited the optimal
placement of the air quality sensors for gathering
representative enough data becomes a challenge
though mobile sensorcentric data collection help
resolve the issues faced in air quality data gathering
due to the ﬁxed nature of the static sensorcentric
approach it has its challenges the air quality data
gathered from the sensors mounted on moving objects
such as buses bikes taxis uavs etc is skewed by
the movement of these moving objects for example
buses are usually used as a means of the commute
from a busy ﬁxed route the gathered data will
provide a good representation of the air quality along
the buss route but it will not provide a true depiction
of urban air quality
another challenge in mobile sensorcentric air quality
data is the redundancy in the collected data since the
sensorsmounted vehicle will be following a route es
pecially buses the data collected will be redundant
and the data from less traversed routes will be sparse
it will result in an imbalanced data distribution any
deduction made from the distribution will be biased
towards the most frequent route
human as a sensor is another way of getting the
data for inferring the air quality data generated
by the citizens passively while accessing the urban
infrastructure call data record public wiﬁ passenger
bus card swipes taxi pick and drop locations etc is
useful in determining the context of urban pollution
here the key challenges are the privacy of the users
the security of the service providers and meeting the
legal requirements of data protection
participatory crowdsensing is a procedure opted for
gathering the context data used for inferring the urban
air quality where the measurement campaigns and
surveys are used to collect the data imbalance data
coverage unavailability of ground truth to measure
the quality of the collected air quality data and
noisy and fake data reporting are a few challenges
associated with the participatory crowdsensing for air
qualityrelated data
to overcome these challenges in air quality data collection
along with its proper context requires a great deal of planning
and understanding of the urban environment selecting the
right kind of sensors an acceptable level of measurement
granularity designing a proper measurement campaign
choosing the appropriate clouddatabase and ensuring the
quality of the collected air pollution data and the motivation
to make it public can help develop a comprehensive air
quality dataset for determining the correct air quality values
nevertheless a hybrid approach combining sensorcentric
expertintheloop data collection techniques can yield better
air quality data collection
air quality monitoring networks in underdeveloped
countries
the air quality situation in underdeveloped nations is dire
yet they are unable to address it due to a lack of air quality
monitoring networks deploying these networks across the
country necessitates large sums of money and planning that
in many underdeveloped countries is not available without
an adequate and extensive air quality monitoring network
in place economically developing nations are unable to
gather air quality data and as a result lack policies for
monitoring and combating air pollution trends lowcost air
quality monitoring stations are used instead of actual weather
stations and deployed in a few countries developing a
countrywide lowcost air quality sensorsbased network
remains a very challenging task
tradeoff between economic growth and air pollu
tion
the tradeoff between economic growth and air pollution im
plies that economic expansion is connected to industrializa
tion and transportation which necessitates the combustion of
gasoline and other energy sources resulting in air pollution
finding the right balance between economic growth and
air pollution is a daunting task for many countries other
variables such as population urban density and urban
planning exacerbate the difﬁculty of this task
regularization and air quality measurements
even though there are several environmental regulatory
bodies and a plethora of regulatory rules but we continue to
see that air quality in urban areas is becoming a predicament
the implementation of these standards is an issue that
many governments are unable to address for a variety of
reasons including a lack of education ﬁnancial resources
political and religious divisions lack of global and regional
cooperation and so on 
urban planning and air quality
urban planning plays a vital role in improving the air
quality of the city unfortunately many metropolitans around
the world are suffering from the worst air quality due to
exponential growth in population trafﬁc congestions high
built densities and lack of urban planning canyon street the
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
street design in which both sides of the roadway are bordered
by buildings has a poor dispersion rate thus vehicle exhaust
remains in greater quantities than usual producing severe
health issues and air pollution avoiding canyon street design
in urban planning might help to reduce urban air pollution
reducing urban air pollution from trafﬁc is strongly linked to
initiatives for encouraging active commuting travel by low
energyconsuming vehicles and lowering carbon emissions
urban planning and its relationship with different urban
environmental concerns is an area in which much ingenuity
is required
personalized contextaware air quality measure
ment applications
designing contextaware air quality monitoring systems are
gaining traction air quality is heavily reliant on several
context factors pois meteorology etc and interpreting
air quality measurements without taking the context into
account might create bias in the measurements people
with respiratory or ocular diseases are especially sensitive
to air pollution and should be warned about it the aqi
measurements are insufﬁcient for these patients it is very
challenging to develop contextaware custommade air qual
ity monitoring applications a few emerging applications use
the internet of things iot and tailored context to deliver
customized warnings on the severity of air pollution in a
speciﬁc city location  
impact of climate change on the air quality
climate change has started causing many problems in
different parts of the world climate change can inﬂuence the
local air quality and vice versa an increase in the ground
level o is observed as the atmosphere gets warmer due
to climate change and this groundlevel o is expected to
cause dense smogs in urban areas the jury is out on the
effectiveness of climate change on particulate matterbased
air pollution 
indoor air pollution
air quality within the buildings houses schools shopping
malls airports etc concerning the health of the people
health is termed as indoor air quality iaq it is described
in the literature that the iaq in homes is  to  times
more polluted than the ambient air pollution  co
microbiological contamination owing to moisture insufﬁ
cient ventilation fuel burning incorrect building design
and commonly used construction materials are a few of
the causes of increased indoor air pollution levels long
term respiratory disorders cancer heart disease and short
term ent irritations headaches tiredness nausea health
problems can be caused by poor iaq people have been
staying indoors for the last two years as a result of the covid
 restriction and indoor air pollution in homes  
and hospitals has skyrocketed  with this exceptional
circumstance iaq improvement is both vital and challenging
 httpswwwepagovairresearch
airqualityandclimatechangeresearch
conclusions
the urban air quality is turning out to be daunting health and
economic challenge for the metropolitan centers around the
globe the lack of measuring infrastructure is making this
situation even harder this paper provides a nonexhaustive
yet comprehensive survey of the urban air quality measuring
methodologies standards and initiatives operating through
out the globe we have also emphasized the challenges
restricting the urban air quality measurement we also
invite the readers to ponder upon these challenges and offer
suggestions for better air quality in our cities

urban air quality measurements a survey
muhammad usama abdur rahman zubair khalid muhammad tahir momin uppal
lahore university of management sciences lums pakistan
email muhammadusama abdurrahman zubairkhalid tahir mominuppallumsedupk
abstracturban air quality is increasingly becoming a cause for concern for the health of the human population the poor air quality is
already wreaking havoc in major cities of the world where serious health issues and reduction of average human life by a factor of years
are reported the air quality in developing countries can become worse as they undergo development the urban air quality varies
nonlinearly depending upon the various factors such as land use industrialization waste disposal trafﬁc volume etc to address this
problem it is necessary to look at the plethora of available literature from multiple perspectives such as types and sources of pollutants
meteorology urban mobility urban planning and development health care economics etc in this paper we provide a comprehensive
survey of the stateoftheart in urban air quality we ﬁrst review the fundamental background on air quality and present the emerging
landscape of urban air quality we then explore the available literature from multiple urban air quality measurement projects and provides
the insights uncovered in them we then take a look at the sources that are signiﬁcantly contributing to polluting the air quality finally we
highlight open issues and research challenges in dealing with urban air pollution
introduction
air pollution is deﬁned as the release of pollutants in the
air that has detrimental consequences on human health
and the planet as a whole these pollutants can be from
manmade sources or natural sources  natural sources
of air pollution include ﬁres sand storms volcanic activity
fumaroles and others the manmade air pollutants are
gases droplets particulate matter and radiation are emitted
into the atmosphere due to human activity such as burning
wood coal gas oil alcoholbased fuels diesel kerosene
biomass waste etc it also includes power plants and
chemical factories that emitted toxic gases particulate matter
and radiation in the environment these air pollutants
are causing issues such as acid rains urban smog ozone
depletionholes indoor air pollution and global warming
 air pollution is a complex amalgamation of natural and
human activities the impact of this relationship is evident
in metropolitan areas beijing dehli etc where criteria
pollutants meteorology infrastructure and various emission
entities collectively deteriorate the air quality it is iteratively
reported in the literature that  to  of the pollution
in the developing world is due to automobile emissions
where vehicles using lowgrade oil on poorly planned road
infrastructure are major contributors to the poor air quality
 major cities in the world are suffering from rapid
degradation of the air quality that has pernicious outcomes
on the health of the citizens economy plantation crops and
livestock 
a decline in human life expectancy in metropolitan areas
is accredited to their poor air quality the problem will get
even worse with the urban development taking place in
underdeveloped countries  in  world health organi
zation who categorized air pollution as a carcinogen for
human beings  who also estimated two million deaths
per year and numerous respiratory illnesses because of poor
urban air quality  the global rise in air pollution has
resulted in a sharp growth in various allergies and respiratory
diseases the impact of air pollution is not limited to the
metropolitan areas it also affects the environment on a global
scale causing health concerns far away from its origin in
 air pollution alone caused  million death worldwide
and if the current trend continues by  the deaths caused
by ambient air pollution will be nearly  million people
per year  in  out of all cardiovascular deaths
 were caused by air pollution similarly  deaths
due to lung cancer were because of air pollution and air
pollution was the reason for  of the total deaths caused
by strokes   four million new asthma cases and 
million premature childbirths per year are attributed to fossil
fuelbased air pollutants that cause a dent in the gdp 
furthermore air pollution appears to be a risk factor not
yet quantiﬁed in neurodevelopmental disorders in kids and
neurodegenerative illnesses in adults   
air pollution not only affects human health on a global
scale but it also has an enormous economic cost the cost
for air pollution emitted by burning fossil fuels in  is
approximately  trillion usd that is  of the global
global gross domestic product gdp  it is way less than
the money needed to reduce the effect of the air pollution
caused by burning fossil fuels the toll of air pollution on
the economy is estimated by looking at the six aspects 
cost of human life  peoples ability to work  effects
on the food  reduction in the ability of the ecosystem to
work  damages to the historical monuments and  cost
of remediation and restoration the economic burden of air
pollution on the gdp of china is  for india it is 
for russia it is  for germany and us it ranges from
 to  for japan united kingdom and france it ranges
from  to    it indicates that a monumental
effort is needed to address the air pollution is the need of the
hour
 httpsuneceorgairpollutionandeconomicdevelopment
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
   by the authors distributed under a creative commons cc by license
figure  organization of the paper
another victim of air pollution is agriculture where bad
air quality is considered a signiﬁcant contributor to yield
reduction for many decades air pollution is rapidly becom
ing a threat to food production and safety  effects of air
pollution on human health have been covered rigorously in
the literature compared to agriculture the adverse effects
of air pollution on the crops vary with the concentration
of the pollutants geographical locations and meteorology
burning wood and fossil fuel produce sulfur dioxide that
reduces the life and yield of the crops rising levels of
acid deposition ammonia o and co are also affecting the
crops in the developing world in  india reports a 
reduction in the wheat and rice crop yield due to ambient
air pollution   it also highlights the need for serious
reconsideration in environmental policies around the world
to ensure food security
the global temperature has risen by c over pre
industrial levels the climatic catastrophe is upon us the
whole world has started feeling the repercussions like
wildﬁres heat waves droughts etc air pollution has played
a vital part in this climatic catastrophe united nations
sustainable development goals unsdg  and 
directly aim at reducing the mortality rate due to ambient
air pollution and the adverse aspects of particulate air
pollution in urban areas by  achieving these unsdg
 httpswwwbritannicacomtechnologyagricultural
technologytheeffectsofpollution
 httpssustainablefoodtrustorgarticlestheimpactofair
pollutiononcrops
goals for reducing the adverse effects of air pollution in
underdeveloped and developing countries is perhaps a
challenging task
identifying the pollution sources contributions and
root causes spatiotemporal manner are the vital challenges
associated with urban air quality measurements lastly
based on the spatiotemporal analysis of the urban air quality
making policy recommendations for reducing air pollution
is the motivation for this study in this paper we have tried
to answer the following question through a extensive review
of the existing literature
what are the major air quality modelling and mea
surement techniques
what are the major sources of air pollution and how
to best classify them
what is the situation of the air quality around the
globe and what are the best practices followed for
mitigating the poor air quality
how the major air quality measurement and im
provement projects are measuring and dealing with
the urban air pollution and what challenges are
needed to be addressed in order to improve the
effectiveness of these projects
what are the open research challenges in measuring
the urban air quality
contributions of the paper
in this paper we build upon the existing literature available
on the air quality measurement and provide a comprehensive
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
paper
surveyreview
this paper provides a comprehensive comparison of literature available on static mobile and community sensorsbased air quality monitoring networks
in the urban environment it also identiﬁes shortcomings in the existing air quality monitoring networks
this study examines several environmental sensors and discusses the effects of air pollution on human health it also gives future guidance in the
development of individualcentric pollution monitoring tools
reviewed the lowcost sensorbased system for measuring the air quality and the calibrations of the sensors using machine learning techniques
the paper also discusses the research challenges and open challenges in using lowcost sensorbased air quality monitoring systems
reviewed and summarized the lowcost sensing literature for air quality monitoring the review also discusses the shortcomings in the data obtained
from the lowcost sensors and open issues in designing lowcost sensorbased air quality networks
paper provides a brief survey of the techniques of using chemical sensing crowdsourcing iot and machine learning in air quality assessment
paper provides the results of a twoyear air quality monitoring and data collection
the paper examines the literature on the existing iotbased lowcost air quality monitoring systems and brieﬂy discusses a few challenges
this paper reviews the literature on air quality sensor calibration and identiﬁes the origins of biases and errors in a lowcost air quality sensing network
it also studies and compares multiple recalibration techniques of lowcost air quality sensor networks lastly it also provides the limitations and future
avenues in the calibration and recalibration of the air quality sensors
the paper conducts a literature review on the lowcost high spatial and temporal resolution air quality monitoring network it also suggests future
research themes
this paper reviews the iotbased air quality monitoring networks and brieﬂy discusses the challenges in designing air quality measurement networks
the paper provides a comparative analysis of machine learningbased urban air quality prediction techniques
this paper reviews indoor and outdoor air pollution monitoring using wireless sensor networks
the paper reviews multiple papers reports white papers and various websites on the role of urban computing in air quality management
it also covers the techniques of incorporating datadriven mitigation strategies opted by different countries
this paper reviews the literature on multiple effects of the air pollution monitoring strategies used in south africa it also discusses the
challenges involved in designing the air pollution networks in the air pollution monitoring network
the research compares stationary dynamic and pollution data analysis methodologies in depth the methodology hardware components
communication mechanism assessment and performance of the air quality system are all compared
a comprehensive survey on the unmanned air vehiclebased air quality measurement techniques for criteria pollutants along with challenges
and open research directions are covered in this paper
this research reviews the literature on air quality sensor technologies and air quality management systems
this paper reviews the air quality standards set by various environmental protection organizations in the world it also gives an
overview of several aspects of lowcost sensing equipment and methodologies
this paper reviews the literature on iotbased machine learningenabled continuous air quality monitoring and prediction literature
this paper provides a brief survey of air pollution monitoring systems along with some speciﬁc measurement strategies
this paper gives a summary of the problems involved in monitoring urban air quality
this paper examines the literature on crowdsourcingbased air quality monitoring and identiﬁes possible ﬂaws as well as future research directions
based on the existing literature on the development of an air quality monitoring network this paper provides the nuts and bolts for
designing the next generation of air quality monitoring networks
table  various surveysreviews on various aspects of air quality measurement
review of the related work the major contributions of this
paper are as follows
we provide the fundamentals of air quality measure
ments along with a nonexhaustive summary of the
air pollutants and their potential sources
we present a comprehensive survey of the techniques
for measuring the urban air quality along with several
sensors famously used for measuring the pollutants
we also discuss the previousongoing air quality
measurement projects from various entities and also
summarize a few root cause analyses from the liter
ature for determining the contributors in urban air
pollution
we also highlight the challenges in designing an air
quality measurement network and how the urban con
text information can help bring more useful insights
in determining and translating the airquality
finally we highlight the open research issues and
future directions in measuring and learning from
urban air quality
organization of the paper
the rest of the paper is organized as follows section 
provides a primer on the air quality it also provides a brief
overview of the air quality landscape of the world while
also covering the details of the major air pollutants and their
sources section  discusses the various approaches available
in the literature for designing an air quality measurement
network this section also provides details of the various
sensors available for measuring particular pollutants in the
air lastly this section also discusses the diversity in the
air quality data its relationship with the different context
variables and how to ensure proper pre and postprocessing
section  provides a comprehensive literature review of the
stateoftheart in urban air quality standards in the world
this section also covers projects from various organizations
for measuring and analyzing air quality in different parts of
the world section  discusses the challenges in designing
and measuring the urban air quality and also takes a critical
look at the available literature for providing an exhaustive
list of challenges tradeoffs tussles and opportunities in
measuring and analyzing the urban air quality section 
discusses the open research issues and future directions the
paper has been concluded in section 
primer on air quality
in this section we discuss the preliminaries of the air
quality then we provide an air quality landscape and major
pollutants lastly this section provides a discussion on the po
tential sources of air pollution before describing the details
of the air pollutants it is vital to understand the composition
of pollutantfree dry air dry air is essentially a combination
of nitrogen  and oxygen  the remaining 
is a combination of argon  and extremely minute
quantities of carbon dioxide methane hydrogen helium
and others water vapor is also a typical albeit very variable
component of the atmosphere ranging from  to  by
volume in humid conditions the moisture content of air can
reach 
 httpswwwadborgprojectsmain
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
table  aqi scale used for indexing the realtime pollution and there impact on human health unit followed in this table is
µgm unless mentioned otherwise
aqi
pollution
level
pm
 hour
pm
 hour
co
 hour
mgm
no
 hour
so
 hour
nh
 hour
pb
 hour
o
 hour
cautionary statement
implications on
human health
good
none
no health risk
satisfactory
the extended outdoor activity
must be avoided by children
adults and people with respiratory
issues
the air quality is adequate
nevertheless some pollutants
may pose a considerable health
risk to a limited number of
people who are very sensitive
to air pollution
moderate
the extended outdoor activity
must be avoided by children
adults and people with respiratory
issues
members of sensitive groups
may experience health effects
the general population is not
likely to be affected
poor
people with respiratory diseases
take precautions and avoid
extended outdoor activities
everyone else should also
limit outdoor activities
the general population may
begin to experience health
effects members of sensitive
groups may experience serious
health effects
very poor
people with respiratory diseases
take precautions and avoid
all outdoor activities everyone
else should also limit outdoor
activities
health warnings of emergency
conditions the entire population
is more likely to be
affected
severe
everyone should avoid all
outdoor activities
health alert everyone may
experience more serious
health effects
air pollution
air pollutants are particles gases or droplets emitted in
the environment that exceeds the environments capacity of
absorption dilution and dissipation these pollutants are
gases solid particles liquid droplets etc the effect of these
pollutants at a scale is termed as air pollution air pollution
is increasingly becoming a signiﬁcant contributor in causing
public health heart and lung disease respiratory diseases
etc and environmental issues global warming acid rains
reduction in crop yields depletion of the ozone layer etc
at a global scale
criteria pollutants
us environmental protection agency epa divided air
pollutants into the following six categories that provide
sufﬁcient enough information for determining the overall air
quality are known as criteria pollutants
carbon monoxide co carbon monoxide is a gas
emitted into the atmosphere due to the fossil fuel
burning in automotive vehicles it has no smell or
color it reduces the oxygen supply to the body parts
thus hindering proper functioning it also causes
headaches dizziness heart and respiratory issues
nitrogen oxides nitrogen oxide is a gas emitted
in the atmosphere due to the fossil fuel burning in
vehicles and power plants it has a smell and reddish
brown color it causes coughs shortness of breath and
respiratory infections it is also a major contributor
to acid rain that is very harmful to crops plants and
animals
sulfur dioxide so sulfur dioxide is a colorless
gas emitted into the air due to oil and coalburning
power plants and chemical factories it has a rotten
egglike smell it is a contributor to acid rain that is
harmful to crops plants and animals it is also very
harmful to people with respiratory diseases
ozone o ozone is not directly emitted in the
atmosphere it is a byproduct of the reaction between
 httpswwwbritannicacomscienceairpollution
nitrogen oxide and organic compounds under the
sunlight nitrogen dioxide and organic compounds
emissions are due to a wide range of processes such
as coaloilburning power plants factories trees etc
ozone here must not be confused with the ozone
layer present in the stratosphere it is the main
contributor to smog that can lead to respiratory issues
such as asthama it also causes ear nose and throat
ent issues ozone is also harmful to crops and
plants
particulate matter solidliquid droplets suspended
in the air called particulate matter these particles are
inhalable with a width less than  mm and a size as
small as  mm pm and pm are prime
examples of these particles pm and pm are
inhalable particles with a size less than or equal to 
micrometers and less than or equal to  micrometers
respectively these particulate pollutants cause lungs
and heart issues and are harmful to crops and plants
lead pb lead is a toxic metal with many variants
it is emitted into the environment by automotive
vehicles burning substandard gasoline the chemical
factories and power plants are also contributors to
emitting this toxic metal into the atmosphere lead
causes kidney issues strokes and heart failure 
sources of air pollution
sources of air pollution are generally divided into four
categories
natural sources
natural events are the initial sources of air pollution in
the world these events are also fundamental parts of the
ecosystem and also had an associated planetary cost forest
ﬁres volcanic eruptions dust storms decomposing organic
matter biological processes in the soil lightning and sea
spray are a few examples of the natural events degrading
the air quality the natural events result in creating different
 httpswwwnpsgovsubjectsairsourceshtm
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
table  list of acronyms
who
world health organization
gdp
gross domestic product
unsdg
united nations sustainable development group
epa
environmental protection agency
co
carbon monoxide
so
sulfur dioxide
o
ozone
ent
ear nose and throat
pm
particulate matter
pb
lead
ent
ear nose and throat
aqi
air quality index
aqli
air quality life index
ncap
national clean air program
naaqs
national ambient air quality standard
us
united states
ncap
national clean air program
naaqs
national ambient air quality standard
case
clean air and sustainable environment project
aqg
air quality guidelines
eea
european environmental agency
modis
moderate resolution imaging spectroradiometer
gam
generalized additive model
ctm
chemical transport model
poi
point of interest poi
ams
american meteorological society
iscst
industrial source complex framework
ctdmplus
complex terrain dispersion model
ocd
offshore and coastal dispersion
cmaq
community multiscale air quality
cmaqddm
cmaq decoupled direct method
cmaqisam
cmaq integrated source apportionment method
camx
comprehensive air quality model with extensions
remsad
regional modeling system for aerosols and deposition
uamv
urban airshed model variable grid
cmb
chemical mass balance
pmf
positive matrix factorization
epa
environmental protection agency
frm
federal reference methods
fem
federal equivalence methods
crf
conditional random field
arma
autoregressionmovingaverage
lr
linear regression
nn
neural network
rt
regression tree
fep
frequently evolving patterns
gc
grangercausality
epic
energy policy institute at the university of chicago
ghair
ghana urban air quality project
escrap
educating school children to tackle air pollution
ai
artiﬁcial intelligence
iot
internet of things
types of criteria pollutants volatile organic compounds and
biological pollutants
mobile sources
mobile sources of air pollution are considered very deadly for
human health here trafﬁc encompasses cars buses trucks
trains planes etc mobile sources are also considered one of
the major sources of air pollution air pollution is a result
of the vehicles used for commuting people and resources
 the vehicle exhaust suspended and resuspended road
dust brake dust and tire wear are sources of trafﬁcrelated
emissions  mobile emissions sources result in different
criteria pollutants and volatile organic compounds with
harmful effects on the ecosystem
stationary sources
stationary air pollution sources include power plants in
dustrial facilities oil reﬁneries industries sewage treatment
and so forth stationary sources of air pollution are often
known as point sources the burning of fossil fuels metal
processing processes boilers in industries and power plants
oil reﬁning procedures solvents glues and paint thinners are
all producers of criterion pollutants such as volatile organic
compounds and hazardous pollutants mercury dioxin etc
area sources
air pollution sources such as agricultural areas ﬁreplaces
construction processes in cities heating and cooling units
in the buildings are categorized as area sources of urban
air pollution the pollutants from area sources result in
particulate matter and other criteria pollutants household
emissions also contribute to the degradation of air quality
processes like biomass combustion fossil fuel burning such
as coal diesel kerosene oil etc tobacco smoking and cen
tral air conditioning are a few important sources of household
emissions household emissions create different criteria and
biological pollutants since this paper only considers ambient
air pollution indoor air pollution sources are out of the scope
of this work we also want to note here that multiple sources
from diverse surroundings contribute to urban air pollution
which varies depending on the geographical location of
the pollution sources in the city wind direction and speed
humidity and other meteorological conditions and so on
therefore attributing urban air pollution to a single pollution
source is an inaccurate approach to look at this issue the
relationship between criteria pollutants and their sources
is provided in table  the table is made based on the
information provided by the us epa and nps
air quality index
the air quality index aqi is a metric used for quantifying
and communicating the air quality in a particular location
aqi suggest the amount of air pollutant in the air over a
speciﬁc average interval these air pollution concentration
values are measured by a sensor or extrapolated from
a simulationemulation model the concentration of the
pollutant and time window is used to determine the dose of
the air pollution and insights from epidemiological research
provide its health impacts based on these health impacts
a color code and a health advisory are issued for a speciﬁc
range of the aqi values the air quality information varies
for different countries based on their air quality standards
and thus their air quality indices aqi value for a given
pollutant is determined by the following piecewise linear
function 
i  ihigh ilow
chigh clow
c clow  ilow
where i is the air quality index c is the concentration of the
pollutant clow is the concentration breakpoint that is less
than or equal to c chigh is the concentration breakpoint that
is greater than or equal to c ilow is the index breakpoint
corresponding to clow and ihigh is the index breakpoint
corresponding to chigh
measurement data for aqi is averaged over one hour
there are few pollutants such as ozone o pm and pm
 httpswwwbritannicacomscienceairpollution
 httpswwwnpsgovsubjectsairsourceshtm
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
table  relation between criteria pollutants and pollution sources categories along with their environmental risks
criteria pollutant
pollution sources
environmental risks
carbon monoxide co
mobile stationary and natural
pollution sources
smog and asphyxiation in vertebrates
nitrogen oxides nox
mobile and stationary pollution
sources
smog acid rain respiratory issues
in vertebrates
sulfur dioxide so
mobile and stationary pollution
sources
acid rain and respiratory issues
in vertebrates
ozone o
mobile stationary and area
pollution sources
the main contributor of the smog in urban
areas
particular matter pmx
mobile stationary natural and
area pollution sources
haze acid rain serious damages to health
and buildings
lead pb
mobile and stationary pollution
sources
reduction in biodiversity and neurological
issues
where average over multiple hours is needed to compute a
correct aqi value table  provides a detailed description
of different pollution levels of various pollutants for india
along with their health advisory and impacts on human
health associated with it different countries have their air
quality policies and thus have different cutoff values
air quality landscape
before proceeding with the discussions of air quality mod
eling and measurement it is imperative to examine the
current global air quality landscape by gleaning insights from
various studies on the impact of air pollution and mitigation
initiatives undertaken in various parts of the world the air
quality life index aqli  report released in july 
suggests that air pollution was the most prominent risk to
human health before the pandemic covid and after it
as well  many countries are now putting a lot of effort
into designing policies for reducing emissions albeit the
progress is slow and many countries are still struggling to
cope with the air quality issue in this section we examine the
air quality landscapes particulate air pollution of various
countries as well as air pollution and the policies used by
these countries to address air pollution challenges
asia
china
china is the most populated country in the world it is home
to  of the total population of the world  of its
population lives in cities in  the concentration of the
pm in beijing city was so high that it seemed that the
city will become uninhabitable  at the time an average
person in the beijing city was exposed to approximately 
µgm of pm air pollution it is nine times higher than the
who recommended value for pm in january  the
situation got even worse when the pm concentration went
 to  times higher than the who recommended value
and the city ofﬁcials warned people to stay indoors  the
guardian describes it as beijings airpocalypse similarly
in shanghai the air pollution went beyond the critical level
there the recorded pm concentration was six times more
than the who recommended value
given the situation in  the chines government
released a national air quality action plan worth  billion
 httpsappcpcbccrcomccr docsfinalreport aqi pdf
 httpsaqicnorgscale
usd with the sole purpose of bringing the air pollution
down the plan has three goals
reduce the pm by  relative to its value in 
reduce the pm by  in beijingtianjinhebei
by  in the pearl river delta and by  in the
yangtze river delta
reduce annual pm of beijing to  µgm
the national air quality action plan worked for china
by  the pm concentration in beijingtianjinhebei
went down by  in pearl and yangtze delta the air
pollution went down by  and  respectively this
success was achieved due to a collaborative effort from
different government entities in reducing the dependency
on coal controlling car emissions increasing renewable
energy enforcing emission policies reducing steel and plastic
manufacturing and replacing coal boilers with natural gas
or electric heaters  though these steps have improved
the air quality in china the war against air pollution is not
over as longterm solutions for bringing air pollution down
to the whos recommended values are needed
india
india is the nd most populated country in the world with
 of the population of the world  of the total indian
population lives in cities india is also the nd most polluted
country in the world in  the average pm value
was  µgm that is seven times higher than the who
recommended value  microgramscubic meter delhi
uttar pradesh and northern india are the most polluted
areas where air pollution is reducing almost a decade of
life expectancy of the residents   aqli india fact
sheet  also suggests that  of the indian population
are exposed to air pollution levels not observed anywhere in
 the concentration of the pm reached an emergency
level  µgm
in  india declared war against pollution and an
nounced a ﬁveyear national clean air program ncap with
 million usd for the ﬁrst two years  the goal of ncap
is to bring the air pollution down by  to  in  cities
which are over the national ambient air quality standard
naaqs by building institutional capacity in monitoring
and mitigating the air pollution  the potential impact of
ncap in the coming years is a  improvement in the air
quality and an improvement of  to  years in the total life
expectancy of the general public 
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
indonesia
indonesia is the th most populated country in the world
with a  urban population more than  of its popula
tion is exposed to air pollution that is poorer than the whos
air quality standards indonesia is also facing wildﬁre issues
in  nearly  wildﬁres were recorded the average
pm concentration in indonesia is µgm  jakarta
is the most congested and one the most polluted city in the
world  of the pm and  of pm particles in
jakarta air pollution are emitted by the automotive vehicles
ten coal power plants around the city are also adding to the
particulate pollution by emitting black carbon  in 
the air quality in sumatra and kalimantan was below the
who recommended threshold in the last  years the air
quality in these cities has gone three times poorer than the
recommended value this shift is because of illegal peatland
agriculture deforestation and wildﬁres 
the indonesian government has taken initial steps in
overcoming the air quality issue by adopting the euro 
fuel enforcing automotive health monitoring policies and
developing a peatland restoration agency indonesias coal
based energy production has doubled in the last ten years
and this is due to the tradeoff between the economy and
pollution a lot of collaborative effort is needed to ensure the
better air quality in indonesia
pakistan
pakistan is the ﬁfth most populated country with one of
the highest population growth rates  on the aqli
pollution ranking it is ranked th in the most polluted
countries pakistan has seen a  increase in the pm
concentration in the last two decades  lahore has the
poorest air quality in pakistan where pm concentration is
six times higher µgm than the whos recommended
value  if this level of pollution concentration is sustained
an average person in lahore will lose approximately 
years of life expectancy almost  of the total population
is exposed to pollution levels higher than the recommended
who air pollution values 
citing this looming threat the pakistani government
started enforcing the air pollution regulations for improving
urban air quality in  following three initiatives are taken
to ensure improvement of the air quality
stubble burning is a major contributor to air pollu
tion in pakistan the government of punjab banned
stubble burning and promoted alternative methods
for getting rid of stubble
emission regulations were enforced on the vehicles
factories and brick kilns
for improving the air quality pakistan has also
shut down many coalbased power plants for two
months this measure has improved the air quality
but resulted in many power outages
pakistan can improve air quality sustainably by exploiting re
newable power sources and continuously enforcing emission
regulations
bangladesh
bangladesh is the th most populated country in the world
with a  urban population bangladesh is also the most
polluted country in the world   the air pollution
there is so intense that an average person loses approximately
 years of life expectancy nearly  of the bangladesh
population is exposed to air pollution nearly seven times
more than the who recommended air pollution concentra
tion µgm for pm major sources of air pollution in
bangladesh are brick kilns vehicle emissions cement facto
ries unplanned constructions and steel rerolling  in
metropolitans like dhaka the concentration of the particulate
pollutants pm and pm stayed manifold higher than
the recommended air pollution concentration values the
concentration of other air pollutants like inorganic gases is
noted to stay below the recommended values
given the dangerous situation of the ambient air quality
in major cities the bangladesh government has started imple
menting various countermeasures to control and mitigates
air pollution bangladesh developed  ﬁxed continuous air
quality measurement stations in  major cities the stations
are capable of measuring the concentration of various types
of air pollutants the recorded data from these monitoring
stations helps develop a spatiotemporal map of different air
pollutants that translates into the identiﬁcation of the air
pollution trends in the country data gathered through these
monitoring stations is also used for developing air models
and aqi for public information
on the policy front many initiatives are taken to enforce
the emission policies on brick cement and related industries
by banning the import of coal with high sulfur content
bangladeshs government is also incentivizing the industry
to move towards renewable and energyefﬁcient production
procedures initiatives like clean air and sustainable en
vironment project case and grater dhaka sustainable
transport are also working with the brick cement and
transport industries to reduce emissions strict enforcement
and monitoring are necessary to ensure the improvement in
the ambient air quality and the department of environment
in bangladesh has started doing that
nepal
nepal is suffering from a grim air pollution problem almost
all of its population is living in an air pollution concentration
higher than the who recommended values according to
the aqli nepal fact sheet  nepal is ranked as the third
most polluted country in the world with an average pm
concentration of µgm that is ﬁve times higher than the
acceptable concentration value the average person in nepal
is expected to lose at least ﬁve years worth of life expectancy
if the current levels of air pollution persist the brick kiln
fuel burning vehicle emissions and road dust are primary
contributors to nepals air pollution nepal is far behind in
combating the air quality issues that are affecting the health
of its citizens more details on the air quality about asian
countries such as south korea  thailand  etc are
available on 
europe
compared to asia europe already has better air quality the
majority of europes concentration of particulate pollutants
is below the european unions air pollution limits µgm
but over threequarters of europes population lives in
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
regions that do not satisfy the world health organizations
who stricter recommendation of µgm  the entire
population of poland belarus slovakia the czech republic
slovenia hungary lithuania armenia belgium germany
moldova cyprus and ukraine and the netherlands and
san marino are exposed to pollution levels that do not satisfy
who guidelines  warsaw po valley and milan are
three severely polluted areas in europe if particle pollution
levels matched who guidelines people would gain one
year and two months  bursa turkeys industrial center
suffers from severe particle pollution as well the population
of bursa will gain one year and one month if the level of
pollutants are reduced to meet who guidelines largescale
biomass burning and unfavorable weather conditions are
causing air quality issues in the northern fennoscandia
region norway sweden finland and russia  in the
last two decades northern europe has seen a rise in air
pollution due to several largescale biomass burning episodes
in eastern europe causing serious consequences for human
health and local ecosystems
according to the european environmental agency eea
air quality report   of the european population
data gathered from  countries is exposed to the pm
concentration levels more than the eea limits and 
more than the who air quality guidelines aqg value for
pm pollutants almost  of the deployed air pollution
station have reported these statistics according to eea
standards for pm only  of the population is exposed
to pm concentrations higher than the eea standards
as per the who aqg guidelines  of the european
population was exposed to pm concentrations higher
than the recommended values  aq monitoring station
reported these statistics according to the same air quality
report  of the population in europe is exposed to ozone
concentrations higher than the eea recommended values
at aqg levels approximately  of the population is
exposed to ozone levels higher than the aqg recommended
values  of the air quality monitoring stations have
reported ozone values higher than the aqg recommended
values only  of the population is exposed to no levels
higher than the eea and who aqg values so is also on
the decline in europe only less than  of the european
population is exposed to concentrations higher than the eea
recommended values and  if measured at the who aqg
values due to covid statistics reported in the eea air
quality  report are based on numbers from 
europe is leading the way in the developed world in
introducing legislation and standards for improving air
quality over the years the eu has developed a procedure
for member countries to access their air quality and share
their data with the eea eea has also provided the member
states with ambient air quality values for twelve major air
pollutants table  provides the standard values of air
pollution concentration for the eu eu has prescribed the
following principles for member states to measure and report
their air quality
 httpseceuropaeuenvironmentairqualityindexhtm
 httpseurlexeuropaeusummarychapterenvironment
htmlroot defaultsum  codeddcsum  coded
dlocaleen
each member state will divide its territory into zones
measure the air quality in each zone using sensors
modeling or an empirical method
report the air quality data to the european commis
sion accordingly
zones where the air quality is poorer than the air
quality standards table  the member state will
provide a plan to address the sources of emission in
the zone and ensure compliance with the limit value
before the date when the limit value formally enter
into force
the member state will disseminate the aqi value to
the public
united states
the united states us is the rd most populated country in
the world with  of the world population living there
over  of the total population lives in the cities the us is
a success story when it comes to air pollution mitigation in
 the us introduced the clean air act and after that the
air pollution gone down by   this decay in pollution
has added  years to the life expectancy of us citizens
los angeles once known as the smog capital of the world
now reduced air pollution by  only  of the total us
population is exposed to air quality poorer than the who
recommended air quality guidelines 
africa
west and central africa have  countries with a  million
total population the average air pollution concentration
pm is around µgm that is twice the who recom
mended values for the pm with current levels of air
pollution an average person tends to lose approximately 
years of life expectancy benin congo republic of the congo
and the democratic republic of the congo ghana nigeria
and togo are among the top air polluted countries in the
region these countries are also ranked among the countries
having the worst air quality in the world according to the
aqli air pollution ranking nigeria is ranked th in the most
polluted country in few nigerian cities onitsha lagos etc
an average person is expected to lose four to six years of
life expectancy brazzaville in the republic of congo has
the worst concentration of pm µgm and resulting
in  years of reduction in the total life expectancy of an
average person the volta region in ghana is also suffering
from a poor air quality situation where the air pollution
concentration is four times the who aqg values the air
quality meeting the who aqg values will add three years
to the life expectancy of an average person in ghana burning
fossil fuels is the primary reason for air pollution in central
and west africa coal consumption is expected to increase
exponentially in the coming years
the african countries have to strike a balance between
economic growth and air pollution air quality data gath
ering and environment preservation policies are still not
designed only cameron has introduced the national air
quality standard for particulate pollution the african coun
tries need a coordinated effort to control the emissions and
implementation of air quality standards and environmental
preservation policies
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
figure  nuts and bolts of a comprehensive air quality model the ﬁgure is opted and improved from 
air
quality
monitoring
modelling
and
measurement techniques
in this section we discuss air quality monitoring modeling
and measurement techniques we divide this section into
four major components along with a necessary discussion
and lesson learned subsection the four major components
are air quality monitoring networks air quality modeling
techniques air quality measurement techniques and air
quality data
air quality monitoring network
an air quality monitoring network is used to acquire con
sistent objective and standardized information regarding a
regions air quality this information may include concentra
tions of target pollutants it also allows for necessary steps to
be taken in any environmental protection and public health
safety effort these steps include determination and control
of emission sources and keeping the public informed about
the state of the air quality  madruga et al  discuss
the air quality monitoring network with the perspective
of public exposure to pollutants in literature air quality
network design usually proceeds in two steps generation
of the ﬁne spatial distribution of pollutants and based on
that optimization of the location of the new sensor to add to
the system usero et al  describe the establishment of an
air quality monitoring network in seville spain to monitor
nitrogen dioxide and ozone levels following the european
unions ambient air quality assessment legislation mofarrah
et al  have used the multiplecriteria method with spatial
correlation to determine the optimal number of air quality
monitoring stations in an air quality monitoring network in
riyadh saudi arabia
by far efforts in establishing air quality monitoring
networks are broadly categorized in the following groups
fixed station air quality monitoring
fixed air quality monitoring stations are the most reliable
standardized accurate and highly expensive method fixed
air quality stations require highly trained staff and resources
to manage the measurement and maintenance operation
sometimes these costs even exceed the purchase cost of the
station thus most of the ﬁxed air quality monitoring stations
around the globe are installed and operated by government
agencies in us  air quality stations are installed by state
environmental agencies the eea receives data from 
 and  stations for measuring no pm and pm
respectively
various efforts have been made to create an ideal air
quality monitoring network that can offer comprehensive air
quality measurements elkamel et al  use a multiplecell
approach to create a monthly spatial distribution for pollu
tants and use it in a heuristic optimization algorithm to iden
tify the optimal conﬁguration of a monitoring network hsieh
et al  use a semisupervised inference model to predict
air quality of unknown areas and an entropyminimization
model to predict the best locations for establishing new
stations zhu et al  use bayesian maximum entropy with
a multiobjective optimization model to optimize the design
of an air quality monitoring network kang et al  derive
an air quality inference model using a higherorder graph
convolution network they employed a greedy method to
minimize information entropy which offers a prioritized list
of places for additional air quality measurement stations to
be installed the air quality measurement node placement
method  enhances overall network performance as well
as air quality prediction for a speciﬁc urban area of the city
as cities continue to expand and city dynamics are always
changing an optimal method to analyze and redistribute
the installed network is required hao et al  employs
an atmospheric dispersion model and genetic algorithm to
maximize coverage with minimum overlap yu et al 
use satellite observations to assess the representativeness
of installed air quality stations using a stratiﬁed sampling
method efforts have also been put into developing and
assessment of lowcost air quality monitoring alternatives
mobile air quality monitoring
given the price and the nature of the ﬁxed air quality
monitoring stations there has been a lot of attention to
the development of mobile air quality monitoring stations
mobile air quality monitoring stations offer a costeffective
solution with several promising features such as high
resolution spatial pollutant mapping and crossvalidation
of air quality measurements some of the most prominent
 httpswwwepagovoutdoorairqualitydata
airdatabasicinformation
 httpswwwconcaweeuwpcontentuploadseaq
trends digitalpdf
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
papers
input data
spatial distribution generation method
location recommendation technique
 year of data from  stations
met data pois road networks
graph convolutional neuralnetwork
greedy entropy minimization
fixed station data integrated with data
generated through copert iii
generative adversarial networks
kl divergence and
kmeans clustering
 year of ﬁxed station and met data
bayesian maximum entropy
multiobjective optimization
 months of data from  ﬁxed
stations met data pois road networks
afﬁnitygraph based inference model
greedy entropy minimization
met data with simulated data from
epa cmaq and camx models
simulated through cmaq and
camx models
objective function and
cost minimization
generated based on trafﬁc composition
industrial source complex isc model
multiobjective optimization
integration of satellite data with
ground station data
mathematical model
multiobjective optimization
 years of sampling campaign
spatial inverse distance weighted interpolation
multiobjective optimization
 years of met and pollution data
multiobjective optimization
table  review of research on air quality network design
research efforts in developing and utilizing mobile air quality
stations are summarized in table 
satellite based air quality monitoring
the use of satellitebased sensors for the determination of
air quality has been gaining momentum for a long time now
li et al  use modis moderate resolution imaging
spectroradiometer data along with meteorological factors to
analyze their relationship with groundbased pm stations
they use a nonlinear regression model to predict pm
forecast fowlie et al  analyze the relationship of ground
based pm stations with satellitebased estimates and their
effect on the environmental protection agencys policies
kim et al  discuss the launch of the gems satellite
for monitoring air quality they discuss the techniques of
sensing different air quality parameters through satellites
stebel et al  explore the use of existing satellite data to
derive particulate matter estimates and their correlation with
groundbased stations they have also extended the sensing
algorithm to report more on the air quality parameters
integrating satellite data with ground stations
sullivan et al  evaluate the need for satellites to
cover the gaps in the existing installed ﬁxed station air
quality monitoring network and the impacts it can produce
alvarado et al  have done a comprehensive analysis on
the integration of satellite data into a prediction of ground
air quality for lowincome countries they have used two
models to predict groundlevel pm namely generalized
additive model gam and chemical transport model
ctm after analyzing the results they provide further
recommendations on the ability of satellite estimates to
bolster air quality monitoring networks li et al  discuss
the integration of a lowcost air quality sensor network
with ﬁxed ground stations and satellite data to enhance
pollution mapping their studies have shown that integrating
the three datasets can vastly improve spatial distribution
and resolution their system can also perform quite well
under different weather conditions where the satellite remote
sensing data alone tends to be biased
air quality modelling techniques
the environment is a complex reactive system where multi
ple physical and chemical processes are happening contin
uously the air quality measurement at a speciﬁc location
and time provides a conditional spatiotemporal snapshot of
the environment the interpretation of spatiotemporal air
quality information requires a conceptual understanding
of atmospheric dynamics that is not possible without a
sophisticated air quality model measurement alone is also
not enough for policymakers to devise an effective plan
to address the looming challenge of air quality the air
quality models provide necessary mathematical information
for understanding the complex interactions between different
variables affecting air quality therefore a combination of air
quality measurement and air quality models can yield real
progress in understanding and solving the air quality issues
in urban centers
a comprehensive air quality model is supposed to
take into consideration the meteorology chemical trans
formations emission patterns known source information
point of interest poi and removal processes and provide
spatiotemporal emission ﬂuxes and pollutant concentrations
it also highlights the relation between the rate of change
in pollution concentrations and the potential sources 
figure  illustrates the bare minimum inputs and output
of an air quality model the three most commonly used
air quality modeling approaches are dispersion photochem
ical and receptor modeling we brieﬂy describe all three
modeling techniques along with their different variants
air quality is not a local phenomenon understanding the
contribution of different variables in the air quality landscape
is a challenging task modeling these contributions is not
possible through classical air quality modeling techniques
for completeness we have included the famous classical
air quality modeling techniques though these techniques
are not suitable to model the complex relationships between
different contributing variables in the air quality at a scale
many advanced modeling techniques are designed based on
the insights from these classical techniques
box models the box model is the simplest model
for estimating the concentrations of air pollutants
the box model compares a domains airshed to a
rectangular box within which the pollutants mass
is entirely contained  it is used for labscale air
quality experiments it is also suitable for modeling
indoor air quality more information on the box model
is available on  
gaussian models gaussian models are the most
popular air quality models used in the literature to
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
no
paper
mobile
platform
sensing
platform
sensing
parameters
study
area
time of
the study
mixed
customized
hardware
co no
o
california us
 weeks
 
cycle bike
bus train walk
customized
hardware
co no
o
california us
 weeks
 
driving cycling
jogging
node
sensors
co
sydney australia
 week
driving cycling
jogging
node
sensors
co
sydney australia
 week
  
walking driving
cycling
teco
envboard
pmx
germany
 hours
walking
customized
hardware
co
o
switzerland
 month
walking cycling
bike car bus train
customized
hardware
co no
o
california us
 month
cycle bike car
hazewatch
node
co no
o
new south wales
australia
 week
cycle
magee microaeth ae
lowcost sensors
pmx tsp
black carbon co
antwerp belgium
 days
car
custom hardware
node sensors
co pmx
new york
new jersey us
bus
customized
hardware
pm
hangzhou china
google street
view vehicle
laboratory grade
analyzers
black carbon nox
oakland us
 year
mixed
customized
hardware
co co ch
india
trash trucks
customized
hardware
pmx
cambridge us
 months
car
customized
hardware
co co no
chennai india
table  review of research on mobile air quality sensing
figure  a nonexhaustive taxonomy of air quality modelling techniques from us epa
model the repercussions of air pollution in various use
cases these models are frequently used in regulatory
applications the gaussian model assumes that the
plume spread is a result of molecular diffusion pollu
tant concentrations in the plume spread horizontally
and vertically  the solution to the diffusion
equation with varying initial value and boundary
conditions results in a gaussian distribution of the
pollutant concentrations  for further details on
the gaussian air quality models we refer the reader
to  
eulerian models the eulerian air quality modeling
approach is considered one of the most signiﬁcant
modeling techniques it is often known as the grid
model technique in this technique the area under
consideration is divided into equal size small grid
cells and conservation of the mass equation is solved
for a speciﬁc type of pollutants concentrations 
a set of mathematical equations in a given coordinate
system explain the transport diffusion transforma
tion and deposition of pollutant emissions in each cell
 this modeling approach is used for studying
and simulating longrange transport air quality over
the entire airshed further details on the eulerian air
quality modeling we refer the reader to  
lagrangian models the lagrangian models calculate
the wind trajectories and the transportation of the
plume along these trajectories for sourceoriented
models these trajectories are calculated forward in
time and for receptorbased models these trajectories
are calculated back in time  lagrangian model
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
ing is frequently used to span a longer time duration
up to years these models are also used to model the
concentrations of the particulate matter in the air for
more information on the lagrangian models we refer
the reader to  
dispersion modelling
air dispersion models formulate and simulate the dispersion
of the pollutants emitted by different sources the simulation
provides an estimation of the downward air pollutant
concentration dispersion models are used to predict the
concentration for speciﬁc scenarios such as the change of the
pollution source these models are more suited for pollutants
that react in the environment and spread over large distances
the models are also widely used by regulatory bodies during
the preparation and evaluation of air permit applications
public safety and emergency response personals utilize these
models to determine toxicity in the air due to possible gas
release events environmental protection agencies around the
globe measure the effect of emissions from different sources
and pollution control strategies by using the dispersion
models
aermod modeling system the american meteo
rological society amsus epa regulatory model
improvement committee aermic a joint working
group of scientists from the ams and the epa
created the aermod dispersion modeling system it
is a steadystate gaussian plume model that includes
air dispersion based on planetary boundary layer
turbulence structure and scaling ideas as well as
handling of complex terrain simple and intricate
topography it generates pollutant concentrations
in the ambient air on a daily monthly and yearly
basis it is an updated version of the industrial
source complex iscst framework proposed by
the usepa for analysing the inﬂuence of industrial
sources on air quality in the coming years 
 aermod consists of a dispersion model
for shortrange dispersion of air pollutants from
various sources a meteorological data preprocessor
aermet and a terrain preprocessor aermap
  the aermod dispersion model takes
preprocessed meteorological parameters and pre
processed relation between complex terrain features
and air pollution plumes to produce an air quality
model   further details on various ver
sions of its source codes implementation details
and variable details are available at 
ctdmplus perry et al  proposed the techni
cal formulation of the complex terrain dispersion
model ctdmplus later paumier et al 
provided a performance characterization study of
ctdmplus the objective for this project by us epa
was to design a dispersion model that can model
and predict the air pollution concentration in the
mountainous terrain ctdmplus is a point source
gaussian air quality model for complex terrain that
uses a ﬂow algorithm to provide the deformation in
the plume trajectory caused by the mountainous
terrain it is capable of simulating the ﬂow and
distortions in the plume near predeﬁned three
dimensional d terrain features while remaining
simple by applying ﬂowdistortion adjustments to
ﬂatterrain gaussian and bigaussian pollution
distributions   the ctdmplus requires a
signiﬁcant amount of information on the topography
and weather to produce an efﬁcient dispersion
model which often represents a bottleneck in many
circumstances more information on various versions
of the ctdmplus source code implementation
details and variable details are available at 
ocd hanna et al  introduced the offshore
and coastal dispersion ocd model which can
simulate the impacts of offshore emission sources
on coastal air quality it is based on a steadystate
gaussian model that can cater to the varying disper
sion characteristics between over and underwater
sealand interface and aerodynamic effects hourly
meteorological data from water and land sites is
necessary for the ocd model to predict air quality
turbulence intensities are also frequently used along
with the hourly meteorological data but they are not
mandatory more information on various versions of
the ctdmplus source code implementation details
and variable details are available at  
though us eea recommends aermod ctdmplus and
ocd for air quality modeling they also provide an alter
native list of models that can be used by the regulatory
applications on a casebycase justiﬁcation
photochemical modelling
photochemical air quality models are often used to evaluate
the effectiveness of the control strategies for regulatory anal
ysis and attainment demonstrations photochemical models
can model the air quality at different spatial scales local
regional national global etc photochemical air quality
models are also known as photochemical grid models these
models are used to evaluate the changes in the concentrations
of the criteria pollutants due to the changes in the associated
variables meteorological conditions emission sources etc
similarly these models are also used for accessing the
sensitivity of the pollutant predictions in different use cases
photochemical grid models are also used to evaluate the
performance of pollution control policies they simulate the
concentration of the air pollutants at a large scale by using
a complex set of mathematical equations to characterize
different atmospheric processes physical and chemical two
types of commonly used photochemical air quality models
are the lagrangian trajectory model and the eulerian grid
model the lagrangian trajectory model uses the moving
frame of reference for modeling the air quality whereas the
eulerian grid model applies ﬁxed d geometric models to the
ground to model the air quality of a particular geographical
area
community
multiscale
air
quality
cmaq
cmaq modeling system is a stateoftheart pho
tochemical air quality modeling system it uses
d eulerian modeling system to simulate the ef
fect of the criteria pollutants in urbantoregional
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
tohemispheric scale cmaq is developed and
distributed by us epa as an opensource suite of
air quality modeling programs that can simulate
multiple air pollution use cases and predicts the con
centrations based on the historical data of the criteria
pollutants cmaq is used to simulate and estimate
the performance of epa missions for understanding
and forecasting air pollution human exposure to air
pollution watershed acidiﬁcation  deposition
of nitrogen and sulfur  and many other air
pollutionrelated use cases three common types of
cmaq are
wrfcmaq wong et al  proposed a
combination of weather research and fore
casting with the inputs of the cmaq eg
aerosol concentration to introduce the effect
of the chemistry into the weather this coupled
design meteorology from cmaq and the
chemistry from weather research and fore
casting component is known as wrfcmaq
information from cmaq such as aerosol
concentration is transmitted into wrf so that
the chemistry can inﬂuence the weather more
details on the wrfcmaq are available in
cmaqddm
cmaq
decoupled
direct
method cmaqddm offers concentrations
and deposition sensitivity statistics for user
speciﬁed parameters  the motivation for
cmaqddm comes from the desire to mea
sure the concentrations of the pollutants by
changing one or a few parameters out of many
predeﬁned air quality model parameters 
air quality models usually take emissions as
input and predict their concentrations cmaq
ddm provides the ability to the policymakers
to look at the pollution landscape by tweaking
the parameters of interest or emission sources
eg wildﬁres vehicles etc more details on
the cmaqddm are available in  
cmaqisam cmaq integrated source ap
portionment method cmaqisam is a vari
ant of cmaq that measures the attribution of
the source in the overall value of the pollutant
concentrations predictedoutputted by the air
quality models for example identifying the
proportion of the smog created by the stubble
burning in a neighboring city this can be
achieved by running the cmaq twice ﬁrst
with all emission use cases and second by
removing the source of interest but this will
be complex and computationally expensive
cmaqisam this issue by calculating source
attribution of many sources directly by the
model in one simulation simon et al 
used cmaqisam for characterizing co and
nitrogen oxides sources in the baltimore area
kwok et al  used cmaqisam to un
derstand the pm sources and their effects
 httpsgithubcomusepacmaq
on the air quality more details on the cmaq
isam are available in  
comprehensive air quality model with extensions
camx camx is another famous air quality
model in photochemical modeling camx modeling
system models the air quality with all criteria pollu
tants for a large scale city state country continent
level it takes emissions meteorology data land use
surface topography initial and boundary conditions
and chemistryrelated values as input and performs
source attribution sensitivity and process analyses
estes et al  used camx to model the exceptional
air quality events in near realtime in taxes to
estimate the ozone impact in three use cases biomass
burning in mexico stratospheric ozone intrusion
anthropogenic emissions in mexico few critical
resources where camx based modeling is used for
air quality policymaking are available in  
regional modeling system for aerosols and depo
sition remsad remsad is another air quality
modeling system that models the particulate haze
and other criteria pollutants it is a regional scale
modeling system that can simulate the physical and
the reactive processes in the environment to show
the effects of the spatiotemporal changes in the air
pollutant concentration on the overall ambient air
quality
urban airshed model variable grid uamv in
the early s the most commonly used air mod
eling system was uamv photochemical modeling
system uamv was widely used for air quality
studies focused on ozone it is a d photochemical
grid model that can model the effects of the chemical
and physical processes in the environment on the
concentrations of air pollutants uamv also pro
vided a spatiotemporal distribution of the emissions
of various air pollutants uamv is outdated and no
longer used for air quality modeling
receptor modelling
the third category of the air quality models is called receptor
models these models are mathematical techniques for
recognizing and quantifying the origins of air pollution at
a particular receptor location  receptor models are
different from dispersion and photochemical air quality
models they do not require meteorological chemical and
emission data to estimate the participation of the pollution
sources in the air pollution concentrations at the receptor
the receptor model uses the chemical and inert properties
of gases so co etc and the particulate matter particles
to determine to contributions of the emission sources in the
pollution concentrations at the receptor  
chemical mass balance cmb the cmb  is a
model for estimating the contribution of the emission
sources to air pollution at the receptor locations
cmb uses spatial ambient data and information
 httpswwwcamxcom
 httpremsadicfconsultingcom
 httpuamvicfconsultingcom
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
about the pollution sources to determine the source
contributions cmb quantiﬁes the contributions at
the receptor based on the distinct source types rather
than individual emission sources a drawback of
cmb is its inability to distinguish between emis
sion sources with the same chemical and physical
properties more details on the cmb are available in
unmix unmix model uses a formulabased on a
form of factor analysis to determine the chemical
species in the air and their sources it does not take
the chemical proﬁle of the pollution sources as input
instead it generates the chemical proﬁle to estimate
the number of pollution sources their syntheses and
their participation in the air pollution at the receptor
location
positive matrix factorization pmf pmf  is
another air quality model which takes different
features from sediments wet deposition surface
water ambient air indoor air etc to identify the
species of air pollutants pmf also determines the
contributions of the pollution sources at the receptor
the us epa no longer updates pmf and it no longer
supports newer operating systems
air quality measuring sensors
the air quality sensors are the most crucial component of any
air quality monitoring network these sensors are used to
determine the concentration of pollutants in the air typically
these sensors are built with a lego connection for the data
acquisition card and data telemetry is accomplished using
wifi or cellular communication in practice data processing
is done on the cloud rather than on the sensor however there
have been a few situations where data is preprocessed on
the air quality sensors speciﬁcations of air quality sensors
are broadly given by the following parameters
accuracy this is a measure of how close the read
ings of sensors would be as compared to the actual
pollutant value
precision this is a measure of how well the sensor
reproduces the same reading a sensor with low
precision can give different readings at different
times with the same pollutant level
range and detection limitations this is the mea
sure of range of pollutant concentration that the
sensor is able to detect correctly sensor performance
may vary with different concentration of pollutant
copollutant interference cross interference from
other pollutants also affect sensor readings it is
intended to minimize the copollutant interference
when measuring a certain pollutant
environmental interference sensor performance
may vary under different environmental conditions
such as low and high temperature humidity sun
light etc
noise noise is the source of inaccuracy in sensor
readings the effect of noise should be minimized to
produce more precise and accurate sensor readings
 httpswwwepagovairresearch
unmixmodelenvironmentaldataanalyses
signal drift this is the drift in readings which
occurs due to inherent sensor measurement methods
and degradation of sensors components many
air quality sensors suffer from signal drift when
selecting a sensor it should be ensured that the
drift can either be handled or it does not affect the
readings to a signiﬁcant level
response time different sensors can produce read
ings with different minimum time intervals it should
be ensured that the selected sensor is able to produce
readings with acceptable time intervals
multisite measurement performance this is an in
dicator that generalizes the copollutant interference
and the environmental interference of sensor
measurement techniques
a summary of the types of sensors and measurement
techniques has been show in ﬁgure 
particulate matter measurement of particulate mat
ter concentration is broadly categorized in three
methods gravimetric microbalance and optical mea
surements whalley et al  gravimetric method
is widely used by regulatory and certiﬁcation au
thorities it is based on weight difference of a ﬁlter
medium before and after the gas is passed through
the ﬁlter microbalance method uses the change
in resonant frequency to measure the particulate
matter concentration by far the most popular choice
for measurement commercial realtime particulate
matter sensors is the optical method scattering or
absorption of a light beam is measured to determine
the concentration of particulate matter
gases the two major sensor types used for sensing
gaseous pollutants are electrochemical sensor 
and metal oxide sensors metal oxide sensors typi
cally require more power to heat up to very high
temperatures to enable signiﬁcant sensitivity to target
detection gas that also increases the start up time of
sensor electrochemical sensors require less power to
operate and thus allow for fast startup time and cost
savings generated over life time of sensor
sensing solutions
oem sensors oem sensors comprise of just the
sensing element further interfacing and signal con
ditioning is required to convert the sensor output
to meaningful numbers these sensors are popular
choice for original equipment manufacturers
sensing systems sensing systems are built upon the
oem sensors and the output is provided in digital
format sensing systems are available for both indoor
and outdoor air quality monitoring apart from
digital output many sensors are also available with
extra features such as wifi or cellular connectivity
and mobile application to view the sensor outputs
as well as the resulting air quality index for many
commercial and indoor air quality measurement
 httpswwwemersoncomdocumentsautomation
whitepaperelectrochemicalvssemiconductorgasdetectionen
pdf
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
figure  the ﬁgure shows a taxonomy of air quality sensors along with their working principle and detected pollutants
systems high accuracy is not required and thus are
free from regulatory requirements these systems
are widely available in market and their price is
usually below  the data available through such
sensors is not accurate and it can sometimes produce
unknown errors weather conditions can also affect
such sensing systems
to mitigate all of the above problems and to provide
a standard measurement system the government
deﬁnes a certain set of regulations to conform to
for the measurement of air quality and pollutants
detailed speciﬁcations of measurement and reporting
of the concentration of pollutants is often provided
by the countrys environmental protection agency in
us environmental protection agency epa provides
federal reference methods frm and federal equiv
alence methods fem for measurement of pollutants
frms specify the most scientiﬁcally sound technique
to report the concentration of pollutant and it becomes
the basis of criteria for evaluation of other measure
ment methods fem provides techniques that are cost
effective and easier to implement and yet can provide
comparable level of accuracy with the fems such
systems are very expensive and their price can range
up to  they also highly trained technical staff
for its operation and maintenance annual operating
expenses may also exceed the system cost on the
other hand the data provided through these systems
is highly consistent and accurate in a variety of
weather and environmental conditions 
air quality measurement projects
urbanair
urban air is a microsoftfunded initiative that began in
 it is a subproject of microsofts urban computing
table  air quality standards for the european union
pollutants
concentration
averaging
period
permitted
exceedences
each year
pm
µgm
 year
na
so
µgm
 hour
µgm
 hour
no
µgm
 hour
µgm
 hour
na
pm
µgm
 hour
µgm
 year
na
lead pb
µgm
 year
na
co
mgm
 hours mean
na
benzene
µgm
 year
na
o
µgm
 hour mean
 days average
over  years
arsenic as
ngm
 year
na
cadmium cd
ngm
 year
na
nickel ni
ngm
 year
na
polycyclic
aromatic
hydrocarbons
ngm
 year
na
 which intends to use big data eg trafﬁc ﬂow human
mobility and geographical data to solve key urban issues
such as pollution transportation congestion and energy
consumption the primary goal of urban air was to measure
analyze forecast and assist in the improvement of urban air
quality in cities such as beijing china in addition urban air
sought to discover relationships between various air quality
trends to determine the sources of pollution in different
urban locations
the urban air project consists of four steps
inferring ﬁnegrained air quality
forecasting air quality at each station
optimal deployment of air quality monitoring sta
tions
root cause analysis of urban air pollution
following is a brief description of each step
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
table  air quality standards for the united states
pollutant
primary
secondary
averaging time
level
form
carbon
monoxide
primary
 hours
 ppm
not to be exceeded more
than once per year
 hour
 ppm
lead
primary and
secondary
rolling 
month average
 µgm
not to be exceeded
nitrogen
dioxide
primary
 hour
 ppb
th percentile of  hour
daily maximum concentrations
averaged over  years
primary and
secondary
 year
 ppb
annual mean
ozone
primary and
secondary
 hours
 ppm
annual th highest daily maximum
hour concentration averaged
over  years
pm
primary
 year
 µgm
annual mean averaged over  years
secondary
 year
 µgm
annual mean averaged over  years
primary and
secondary
 hours
 µgm
th percentile averaged
over  years
pm
primary and
secondary
 hours
 µgm
not to be exceed more than once
per year on an average of
 years
sulphur
dioxide
primary
 hour
 ppb
th percentile of  hour daily
maximum concentrations
averaged over  years
secondary
 hours
 ppm
not to be exceeded more than once
per year
inferring ﬁnegrained air quality
as a ﬁrst step the urban air project sought to infer air
quality in areas where air quality stations were not available
 it is a difﬁcult undertaking since accessible air quality
data is sparse and limited to tackle this challenge zheng
et al  gathered context data from a range of additional
sources meteorology road networks trafﬁc ﬂow poi and
human mobility that have an indirect impact on air quality
after acquiring the context data it is fused with sparse
aqi data from known locations then spatial and temporal
classiﬁers are used for inferring the aqi values at unknown
places the spatial classiﬁer is an artiﬁcial neural network
ann that takes a subset of data and tries predicting
aqi for unknown nodes by using pearson correlation of
known features between nodes the temporal classiﬁer
takes the timedependent factors and tries predicting aqi for
unknown nodes using a linearchain conditional random
field crf the training is performed by iteratively adding
unknown nodes to the set of known nodes that are classiﬁed
conﬁdently by the models for inferring aqi value at
some unknown locationgrid features are applied to each
classiﬁer independently only those aqi values are reported
where both classiﬁers have higher conﬁdence results of
the experiment are compared with different interpolation
techniques like linear gaussian classical dispersion model
decision tree crf and ann the initial step of urban
air only inferred pm and no values for beijing and
shanghai in subsequent work zheng et al  combined
the spatiotemporal model with a realtime feature extraction
database to make userfriendly web and mobile applications
forecasting air quality at each station
following the successful inference of aqi values at arbitrary
sites the next phase in the urban air project was to forecast
aqi values at speciﬁc station locations  forecasting aqi
values is critical because it allows policymakers to better un
derstand air pollution trends and develop preventative and
mitigation policies the method of estimating the next aqi
value at a certain time granularity based on prior aqi values
is known as aqi forecasting various connected aspects
such as meteorology wind speeds temperature and so on
might have an impact on the forecasting process therefore
a realtime database is utilized to give meteorological data
humidity temperature and wind speed as well as weather
forecasts and aqi values for each station site
the forecasting component of the urban air project
gathers data from  stations in  chinese cities with
each instance having concentrations of six air pollutants
no so o co pm and pm zheng et al 
employed the four predictors listed below to forecast the
aqi value at a station
a temporal predictor is used to anticipate the aqi
value using a linear regression model on the data
a spatial predictor is used to provide the surrounding
context to a neural network which forecasts an aqi
value based on the context data
a prediction aggregator trains a regression tree to
give various weights to the ﬁrst two predictions under
different scenarios
finally an inﬂection predictor is employed to simulate
any rapid changes in aqi values and is only utilized
in exceptional cases rain etc
for the ﬁrst  hours the aqi value after each hour is
predicted while for the next h h and h
a minmax range of aqi is forecasted zheng et al 
performed forecasting for  air quality stations in beijing
and compared their results with techniques like auto
regressionmovingaverage amra linear regression lr
all neural network annall and regression tree rt
all
deployment of air quality monitoring stations
the placement of air quality sensors in suitable places is
critical for obtaining relevant air quality data hsieh et al
 solve the sensor placement problem with a restricted
budget in the urban air project hsieh et al  used a two
stage technique to handle this problem the ﬁrst phase is to
infer the air quality at an unknown place and the second
is to pick candidate locations depending on the conﬁdence
of the inference the city of beijing has split into km x
km patches for inference with each patch referred to as a
node by linking these nodes with known and unknown aqi
values a network is formed some of the linkages are made
with the help of historical geographical and environmental
factors local meteorology road network data and pois are
used to provide weight to edges once the graph is complete
an unknown aqi value is calculated using a weighted sum of
aqi values from known modes instead of only obtaining a
single value for aqi a distribution is learnt at each unknown
node the weights of the graph are modiﬁed over numerous
rounds to get a better distribution minimize entropy loss
for recommending the locations of the station ﬁrst ﬁnd
the node with the best distribution or lower entropy loss
and rank it the last in the list after assigning a rank to this
node label it as a known node and again run the inferring
algorithm to ﬁnd new inference after this ﬁnd the node
with the best distribution and assign it second last this step
is repeated until all nodes are ranked
identiﬁcation of root cause of air pollution
the placement of air quality stations is motivated by the
need to identify the root causes of air pollution urban air
also seeks to identify the underlying causes of urban air
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
pollution understanding the root cause of air pollution is
extremely beneﬁcial to policymakers in government and
environmental protection agencies because data collection
involves noise collecting insights for establishing the root
cause of air pollution becomes a difﬁcult job zhang et al
 and nguyen et al  integrated historical data with
bayesian learning approaches   to uncover air
pollution causal pathways data used in   includes
measurements of six air pollutants pm pm no co
o so and ﬁve meteorological measurements tempera
ture pressure humidity wind speed and wind direction
which are updated hourly for three areas north china
yangtze river delta and pearl river delta understanding
the root cause of air pollution is based on pattern mining and
bayesian learning the initial stage in pattern mining is to
locate frequently evolving patterns fep it is accomplished
by ﬁrst identifying patterns that happen often at the station
and then applying a projection to them as done by preﬁxscan
 then feps of neighboring stations are compared
and possible causative agents for each sensorstation are
retrieved the pattern mining module decreases the number
of variables which aids in decreasing computation cost for
the next stage in learning the bn structure on in the
worstcase scenario
the bayesian learning module of the root cause identiﬁ
cation pipeline combines the concentration measurements of
each pollutant at the target node with the spatial data from
candidate causers at the multiple time stamps following
data integration initial routes for the n most signiﬁcant
sensor for the target locationstation are created each of
these paths is then assigned a grangercausality gc score
  once the score is assigned to the pathways
the context data is integrated with pathways zhang et al
 determine the number of subclasses using a hidden
confounding variable and then repeatedly optimize the
initial paths by reducing em loss
the urban air project was a great success as it helped in
reducing air pollution in china based on the insights from
this project the environmental protection agencies and the
chines government have taken policylevel steps and the
air pollution in china is under control
aqli project
the air quality life index aqli is another famous air
quality measurement project by the energy policy institute
at the university of chicago epic aqli project introduced
a new metric for measuring the impact of air quality called
air quality life expectancy instead of the conventional aqi
metric this new metric translates the impact of air pollution
on the life expectancy of a human being
the aqli work is based on the pm data collected via
satellite monitoring combined with the global population
data obtained from the  global landscan global popu
lation database  the aqli index is an extension of the
previous work done by greenstone et al in understanding
and quantifying the impact of particulate air pollution on
the expectancy of human life  once both datasets are
collected a gridcellbased procedure is used for combining
global population data with the satellitedriven pm data
loss in life expectancy is calculated for each grid where
each grid corresponds to a km x km area on the ground
the loss in life expectancy due to pm is computed based
on the previous work by ebenstein et al  which shows
that with every µgm of sustained exposure to pm
life expectancy decreases by  years assuming that life
expectancy varies linearly with pm exposure the loss in
life expectancy is multiplied by  for each incremental
exposure to µgm of pm beyond the who threshold
level µgm of pm
the aqli project has resulted in aqli index which
provides a countrylevel loss in life expectancy based on
the pm concentrations this project provides a thorough
analysis of the air pollution situation in many countries and
also covers the policy level steps taken by different countries
eg china india for mitigating the impact of air pollution
on the life expectancy of their citizens though this project
only covers the impact of pm the insights and policy level
suggestions provided in the aqli reports can help improve
the air quality of any part of the world this project is also
an excellent example of how to set up an air quality indexing
study for other criteria pollutants
afriqair
air pollution is a major problem in africa with research
indicating that air pollution causes around  premature
deaths every year  unfortunately there arent many
referencegrade air quality monitoring stations in africa
therefore it is difﬁcult to interpolate the actual situation of
the air pollution the afriqair project tries to tackle this
issue by developing a continentscale air quality monitoring
network afriqair is an african air quality monitoring
initiative  the initiative employs a network of both high
quality and lowcost air quality sensors by mid there
are approximately  nodes spread throughout  african
nations ghana rwanda uganda kenya south africa
democratic republic of congo cote divoire niger congo
etc afriqair has the following three goals for improving
the air quality situation in africa
creating the physical infrastructure required to mea
sure and monitor air quality across the continent it
entails a mix of highquality and lowcost air quality
assessment equipment as well as the necessary
power sources and data telemetry systems
local capacity building to use manage and analyze
the developed physical infrastructure
finally ensure that the physical infrastructures data
and insights are accessible and actionable
the data gathered through these  measurement platforms
across africa is opensourced in daily hourly and minute
granularity and can be readily used for air quality research
ghana urban air quality project ghair
urban air and aqli projects are being carried out on a
global scale using cuttingedge technology and techniques
for planning modeling monitoring and extracting insights
many underdeveloped countries with limited resources do
 httpsaqliepicuchicagoedutheindex
 httpwwwafriqairorg
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
not have this opportunity with the ghana urban air quality
initiative ghair we hope to show the reader how a
relatively impoverished nation may set up an air quality
monitoring project
ghana is west africas secondmost populated country
behind nigeria ghana is dealing with severe pollution
problems and it is reported that air pollution killed over
 people in   in  ghana started the ghair
project to solve the problem through cuttingedge research
the environmental protection agency of ghana has limited
resources and proper technical human resources to solve
these issues ghair uses lowcost air quality sensors to
bridge the data gap various studies have highlighted that
lowcost sensors might be a great chance to overcome the
air pollution data gap in underdeveloped countries 
ghair has the following four objectives that are also in
line with the unsdgs 
creating a dense lowcost air quality sensor network
in metropolitan areas to collect realtime spatiotem
poral air quality data that may be used to impact air
pollution management policy
launching public awareness campaigns about the
effects of urban air pollution and how residents may
safeguard their health in areas with poor air quality
improving the air quality by introducing behavioral
changes in the communities
performing epidemiological research to highlight the
health issues of air pollution exposure in vulnerable
populations for the public health department
the ghair presently employs a mix of lowcost pur
pleair sensors clarity nodes ramps and modulairpm
sensors these sensors have been installed in six of ghanas
major cities accra tema cape coast takoradi and kumasi
ghair has also just placed ten sets of teom ab pm
monitoring sensors provided by the uk environmental
agency automatic urban and rural network  the
ghair presently employs a mix of lowcost purpleair
sensors clarity nodes ramps and modulairpm sensors
these sensors have been installed in six of ghanas major
cities accra tema cape coast takoradi and kumasi
ghair has also just placed ten sets of teom ab pm
monitoring sensors provided by the uk environmental
agency automatic urban and rural network  ghair
project is also going to launch a program called escrap
educating school children to tackle air pollution project
with the help of the royal society the projects goal is to
create awareness among schoolchildren about air quality and
how they may help to improve it the motto of the project is
school children as agents for improved air quality
they are now experiencing several difﬁculties in getting
data from sensors these concerns include the availability of
wifi at deployment sites for data telemetry and sensor power
supply to address these issues ghair is experimenting with
solar energy to power the sensors  furthermore they
are attempting to leverage gprs for data telemetry despite
these challenges the ghair project has enormous potential
for bridging ghanas data gap on air quality
hazewatch
pm concentrations above who standards have been
found in new south wales australia particularly in sydney
the department of environment climate change and water
deccw has already placed  stations in various sites
across sydney and data is published hourly aqi levels
and corresponding health advisories are provided based
on this pollution data unfortunately these stations are
separated by tens of kilometers resulting in inadequate
spatial resolution because of the low spatial resolution
complicated interpolation procedures are needed to report
aqi values as a result the deccw aqi monitoring
network does not represent actual levels of air pollution and
exposure to overcome these shortcomings sivaraman et al
 designed a lowcost urban air quality monitoring system
known as hazewatch hazewatch utilizes many lowcost
mobile sensor units installed in cars to measure air pollution
concentrations as well as users mobile phones to tag and
upload data in realtime the outcome of the projects is its
costeffectiveness better spatial resolution and personalized
exposure tools the project measured no co and o
though hazewatch ﬁlled the gap in spatial resolution it has
faced multiple challenges in calibration sensor design mass
deployment health outcome interpretation etc the project
has resulted in multiple research publications on designing
pollution monitoring sensors  data transmission
  database connectivity  android interface
design  pollution modeling  data visualization 
and exposure modeling 
citisense
developing a countrywide air quality network based on
referencegrade nearreference and lowcost air quality mon
itoring sensing solutions for each pollutant is a complicated
endeavor it requires a lot of money infrastructure and
technical expertise thus environmental governance through
citizen empowerment is gaining traction the purpose of
these programs is to encourage individuals in deploying low
cost sometimes nearreferencegrade monitoring equipment
and share air quality data the integration of data from
residents and referencegrade sensing equipment can assist in
obtaining a more granular picture of air quality resulting in
more effective air quality improvement measures the euro
pean commission has ﬁnanced citisense 
a project that uses cuttingedge earth observation technology
to build and test environmental monitoring systems the
projects goal was to create citizen observatories that would
allow residents to gather and monitor environmental data
in order to formulate community policies the citisense
project produced a number of air quality sensor devices as
well as mobile and other communication technologies the
key contributions of the citisense project were
studying and mitigating hurdles in the citizens in
volvement in environmental decision making
designing the tools and technologies to enable the
citizens in collecting urban environmental data
providing lowcost measuring solutions and data
fusion methods for scientiﬁc analysis
 httpscordiseuropaeuprojectid
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
integrating newer sensing technologies iot and other
ict technologies cloud platforms data analysis and
learning techniques to enhance community participa
tion in the form of personal environmental monitoring
devices
the citi sense initiative distributed  air quality mon
itoring units around europe and  volunteers helped
test the personal air quality monitoring devices a total of
 citizen observatories were also developed in nine major
cities of europe barcelona belgrade edinburgh haifa
ljubljana oslo ostrava vienna and vitoriagasteiz an
air perception application was also a critical part of the
project and  people used it to report and get air quality
information in  nearly  million environmental
observations were collected using the citisense sensor
network and other additional observation tools further
involvement of the citizens was ensured by feedback surveys
questionnaires focus group discussions and interviews the
citisense initiative resulted in environmental monitoring
systems across europe as well as citizen engagement in
environmental governance the insights from the citi
sense project has resulted in many research publications
dealing with lowcost air quality sensing and performance
assessments   pollution hotspot detection
 data assimilation   missing data
imputation methods  epidemiology studies  air
quality sensor calibrations   localized real
time pollution effects     zero emission
studies  wireless and distribution network design
suggestions for air quality networks  pollution exposure
assessment   enduser feedback   
toolkits for monitoring urban air quality  and new
citizen observatory design 
opensense ii
generating a comprehensive spatiotemporal map of air
pollution requires a lot of data from multiple sources only
referencegrade air quality data is not enough as they are
very expensive and there can be a few referencegrade air
quality monitors in a city opensense ii aims to integrate
data from heterogeneous devices and crowdsourcing with
reference grade measurements to generate a spatiotemporal
map of urban air pollution and estimate the health impacts
due to air pollution exposure opensense ii project generates
granular air pollution maps of zurich and lausanne and also
studies the impact of air pollution exposure on human health
opensense ii uses data air pollution data communication
platforms sensors personalized health recommendations
etc from another project known as nanotera project
opensense the data from the nanotera project is com
bined with crowdsourcing and humancentric computation
techniques for highresolution air pollution maps the air
quality data is also gathered by deploying sensing systems
on buses and electric cars opensense ii also pushed the
stateoftheart in generating highresolution spatiotemporal
air quality maps    mobile sensor networks
for air quality monitoring   and estimating the
impact of pmx on human health and personalized health
recommendations 
root cause analysis of the urban air pollution
the efforts put into designing modeling measuring and
developing cuttingedge air quality measurement facilities
are only to understand the root cause of urban air pollution
and how it affects human health and the global tempera
ture many studies have been conducted using air quality
data acquired from air quality networks to identify the
causescontributors of air pollution karagulian et al 
performed a systematic analysis on the air quality data of 
countries from the who website and highlighted the major
sources of air pollution according to their study of available
data trafﬁc emissions contribute  of air pollution pm
industrial activities contribute  domestic fuel burning
contributes  natural dust and salt contribute  and
unidentiﬁed causes linked to humans contribute  
jiang et al  investigated the spatiotemporal features of
air pollution in six chinese cities and applied the granger
causality test  to evaluate the impact of a citys air
quality on surrounding cities and vice versa according to
their study air pollution is very high in the winters and
early springs and stays low in summer and autumn they
also discovered a unidirectional association between the air
quality of baoding and beijing where the air pollution from
baoding has a signiﬁcant impact on beijings air quality
since baoding is more polluted than beijing 
wang et al  found that particulate matter from
transportation industry agricultural activities fuel burning
construction and demolition accounts for  to  of overall
air pollution in china wang et al  also discovered
that the  extended haze event in centraleastern china
was caused by a shift in meteorological conditions 
employed synthetic atmospheric circulation to determine
the sources of air pollution trafﬁc emissions and high
levels of energy consumption are identiﬁed as contributors
to the haze and poor air quality in centraleastern china
 recently there has been a surge in datadriven root
cause analysis techniques  these techniques are
motivated by the success of big data and artiﬁcial intelligence
ai in many other domains for detecting and comprehend
ing the root cause of urban air pollution we advocate a
combination of traditional modelingcausal methodologies
with cuttingedge ai techniques
urban air quality challenges
despite a plethora of work in measuring and understanding
air quality there are various challenging aspects in tracking
and measuring air quality in this section we take a look at
the challenges needed to be addressed for rapid improve
ment in ambient and indoor air pollution
data collection and public datasets
collecting the air quality data is a challenging task as it
involves different concentrations of air pollutants given the
environmental cost and health risks of poor urban air quality
it is imperative to develop a central realtime air quality
data measurement and processing system two paradigms
for gathering urban data ie air quality data poi mete
orological data etc are sensorcentric data collection and
crowdcentric data collection the sensorcentric paradigm
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
has two categories these categories are based on whether
the data collecting sensors are mobile deployed on a moving
object or static deployed on a ﬁxed location the crowd
centric data collection is also divided into two categories
activedata generated via participatory surveys and check
ins or passive data generated by users passively while using
the urban infrastructure
gathering air quality and related data via these two
paradigms is difﬁcult because of the following challenges
in static sensorcentric air quality data collection
sensors are deployed at a ﬁxed location and they
communicate at a predeﬁned frequency to the cen
tral database ie cloud server this static sensor
deployment makes the air quality measurement a
resource constraint system limited budget land use
workforce for maintaining the system etc as a
result data gathered from very few sensors ﬁxed at
different locations in an urban environment is sparse
and not sufﬁcient representative of the air quality
situation of the city
in static sensorcentric air quality data collection
where the number of sensors is limited the optimal
placement of the air quality sensors for gathering
representative enough data becomes a challenge
though mobile sensorcentric data collection help
resolve the issues faced in air quality data gathering
due to the ﬁxed nature of the static sensorcentric
approach it has its challenges the air quality data
gathered from the sensors mounted on moving objects
such as buses bikes taxis uavs etc is skewed by
the movement of these moving objects for example
buses are usually used as a means of the commute
from a busy ﬁxed route the gathered data will
provide a good representation of the air quality along
the buss route but it will not provide a true depiction
of urban air quality
another challenge in mobile sensorcentric air quality
data is the redundancy in the collected data since the
sensorsmounted vehicle will be following a route es
pecially buses the data collected will be redundant
and the data from less traversed routes will be sparse
it will result in an imbalanced data distribution any
deduction made from the distribution will be biased
towards the most frequent route
human as a sensor is another way of getting the
data for inferring the air quality data generated
by the citizens passively while accessing the urban
infrastructure call data record public wiﬁ passenger
bus card swipes taxi pick and drop locations etc is
useful in determining the context of urban pollution
here the key challenges are the privacy of the users
the security of the service providers and meeting the
legal requirements of data protection
participatory crowdsensing is a procedure opted for
gathering the context data used for inferring the urban
air quality where the measurement campaigns and
surveys are used to collect the data imbalance data
coverage unavailability of ground truth to measure
the quality of the collected air quality data and
noisy and fake data reporting are a few challenges
associated with the participatory crowdsensing for air
qualityrelated data
to overcome these challenges in air quality data collection
along with its proper context requires a great deal of planning
and understanding of the urban environment selecting the
right kind of sensors an acceptable level of measurement
granularity designing a proper measurement campaign
choosing the appropriate clouddatabase and ensuring the
quality of the collected air pollution data and the motivation
to make it public can help develop a comprehensive air
quality dataset for determining the correct air quality values
nevertheless a hybrid approach combining sensorcentric
expertintheloop data collection techniques can yield better
air quality data collection
air quality monitoring networks in underdeveloped
countries
the air quality situation in underdeveloped nations is dire
yet they are unable to address it due to a lack of air quality
monitoring networks deploying these networks across the
country necessitates large sums of money and planning that
in many underdeveloped countries is not available without
an adequate and extensive air quality monitoring network
in place economically developing nations are unable to
gather air quality data and as a result lack policies for
monitoring and combating air pollution trends lowcost air
quality monitoring stations are used instead of actual weather
stations and deployed in a few countries developing a
countrywide lowcost air quality sensorsbased network
remains a very challenging task
tradeoff between economic growth and air pollu
tion
the tradeoff between economic growth and air pollution im
plies that economic expansion is connected to industrializa
tion and transportation which necessitates the combustion of
gasoline and other energy sources resulting in air pollution
finding the right balance between economic growth and
air pollution is a daunting task for many countries other
variables such as population urban density and urban
planning exacerbate the difﬁculty of this task
regularization and air quality measurements
even though there are several environmental regulatory
bodies and a plethora of regulatory rules but we continue to
see that air quality in urban areas is becoming a predicament
the implementation of these standards is an issue that
many governments are unable to address for a variety of
reasons including a lack of education ﬁnancial resources
political and religious divisions lack of global and regional
cooperation and so on 
urban planning and air quality
urban planning plays a vital role in improving the air
quality of the city unfortunately many metropolitans around
the world are suffering from the worst air quality due to
exponential growth in population trafﬁc congestions high
built densities and lack of urban planning canyon street the
preprints wwwpreprintsorg    not peerreviewed    posted  april                    doipreprintsv
street design in which both sides of the roadway are bordered
by buildings has a poor dispersion rate thus vehicle exhaust
remains in greater quantities than usual producing severe
health issues and air pollution avoiding canyon street design
in urban planning might help to reduce urban air pollution
reducing urban air pollution from trafﬁc is strongly linked to
initiatives for encouraging active commuting travel by low
energyconsuming vehicles and lowering carbon emissions
urban planning and its relationship with different urban
environmental concerns is an area in which much ingenuity
is required
personalized contextaware air quality measure
ment applications
designing contextaware air quality monitoring systems are
gaining traction air quality is heavily reliant on several
context factors pois meteorology etc and interpreting
air quality measurements without taking the context into
account might create bias in the measurements people
with respiratory or ocular diseases are especially sensitive
to air pollution and should be warned about it the aqi
measurements are insufﬁcient for these patients it is very
challenging to develop contextaware custommade air qual
ity monitoring applications a few emerging applications use
the internet of things iot and tailored context to deliver
customized warnings on the severity of air pollution in a
speciﬁc city location  
impact of climate change on the air quality
climate change has started causing many problems in
different parts of the world climate change can inﬂuence the
local air quality and vice versa an increase in the ground
level o is observed as the atmosphere gets warmer due
to climate change and this groundlevel o is expected to
cause dense smogs in urban areas the jury is out on the
effectiveness of climate change on particulate matterbased
air pollution 
indoor air pollution
air quality within the buildings houses schools shopping
malls airports etc concerning the health of the people
health is termed as indoor air quality iaq it is described
in the literature that the iaq in homes is  to  times
more polluted than the ambient air pollution  co
microbiological contamination owing to moisture insufﬁ
cient ventilation fuel burning incorrect building design
and commonly used construction materials are a few of
the causes of increased indoor air pollution levels long
term respiratory disorders cancer heart disease and short
term ent irritations headaches tiredness nausea health
problems can be caused by poor iaq people have been
staying indoors for the last two years as a result of the covid
 restriction and indoor air pollution in homes  
and hospitals has skyrocketed  with this exceptional
circumstance iaq improvement is both vital and challenging
 httpswwwepagovairresearch
airqualityandclimatechangeresearch
conclusions
the urban air quality is turning out to be daunting health and
economic challenge for the metropolitan centers around the
globe the lack of measuring infrastructure is making this
situation even harder this paper provides a nonexhaustive
yet comprehensive survey of the urban air quality measuring
methodologies standards and initiatives operating through
out the globe we have also emphasized the challenges
restricting the urban air quality measurement we also
invite the readers to ponder upon these challenges and offer
suggestions for better air quality in our cities
original article
fake visual content detection using twostream convolutional neural
networks
bilal yousaf  muhammad usama  waqas sultani  arif mahmood  junaid qadir
received  february   accepted  january   published online  january 
 the authors under exclusive licence to springerverlag london ltd part of springer nature 
abstract
rapid progress in adversarial learning has enabled the generation of realisticlooking fake visual content to distinguish
between fake and real visual content several detection techniques have been proposed the performance of most of these
techniques however drops off signiﬁcantly if the test and the training data are sampled from different distributions this
motivates efforts towards improving the generalization of fake detectors since current fake content generation techniques
do not accurately model the frequency spectrum of the natural images we observe that the frequency spectrum of the fake
visual data contains discriminative characteristics that can be used to detect fake content we also observe that the
information captured in the frequency spectrum is different from that of the spatial domain using these insights we
propose to complement frequency and spatial domain features using a twostream convolutional neural network archi
tecture called twostreamnet we demonstrate the improved generalization of the proposed twostream network to several
unseen generation architectures datasets and techniques the proposed detector has demonstrated signiﬁcant performance
improvement compared to the current stateoftheart fake content detectors with the fusing of frequency and spatial
domain streams also improving the generalization of the detector
keywords deepfakes  twostream network  frequency stream  combination of discrete fourier transform and discrete
wavelet
 introduction
recent technological advancements in artiﬁcial intelli
gence ai have led to various beneﬁcial applications in
vision language and speech processing however at the
same time the power of these technologies may be
exploited by adversaries for illegal or harmful uses for
example deepfakesa portmanteau of the terms deep
learning and fakemay be used to produce or alter
photorealistic audiovisual content with the help of deep
learning for an illegal or harmful purpose deepfake
technology enables one to effectively synthesize realistic
looking fake audio or video of a real person speaking and
performing in any arbitrary way  the term deepfake
was ﬁrst coined by a reddit community for synthetically
replacing the face of a person with the face of another
person the term expanded with time to include similar
techniques such as lipsync   facial expression
reenactment  fullbody and background manipulation
as well as audio synthesis 
 junaid qadir
jqadirqueduqa
bilal yousaf
msdsituedupk
muhammad usama
muhammadusamalumsedupk
waqas sultani
waqassultaniituedupk
arif mahmood
arifmahmoodituedupk
department of computer science information technology
university itu lahore pakistan
lahore university of management sciences lums
lahore pakistan
department of computer science and engineering cse
college of engineering qatar university doha qatar
department of electrical engineering information
technology university itu lahore pakistan
neural computing and applications  
httpsdoiorgs
volv
 volv
the rise of technology such as deepfake has eroded the
traditional conﬁdence in the authenticity of audio and video
as any digital content audio video text can be easily
subverted using advanced deep learning techniques for
synthesizing images trained on readily accessible public
videos and images  the gravity and urgency of the
deepfake threat can be gauged by noting that in recent
times a ceo was scammed using deepfake audio for
  and a fake video of the president of gabon
has resulted in a failed coup attempt other potential effects
of the deepfake threat include danger to journalism and
democratic norms because elections can be manipulated
and democratic discourse may be disrupted by creating
fake speeches of contending leaders   unfortunately
most of the current research focuses on creating and
improving deepfakes and there is a lack of focus on
reliable deepfake detection for instance among those
papers uploaded to arxiv in   papers focused on
generative adversarial networks gans a common
method for deepfake generation while only  papers
related to antiforgery related topics 
recent research shows that neural networks can be used
for detecting fake content  these methods however
require a large amount of fake and real training data to
accurately learn the data distributions of both classes the
performance of these methods drops signiﬁcantly on the
unseen fake data if sampled from a different distribution or
a different generation process it is because the underlying
model may overﬁt the available training data and therefore
lose its ability to generalize to unseen data to enable the
model to classify previously unseen data will require a
large amount of data from the new distribution which may
not always be available in such problems attackers and
defenders are continuously improving their approaches and
rolling out new attacks and defenses therefore it may be
very difﬁcult to collect a large amount of fake data for new
manipulation techniques ideally for such scenarios a fake
content detector is needed that should be able to detect fake
data without explicit training on that particular type of fake
content
nataraj et al  proposed to improve the detectors for
fake images by using handcrafted cooccurrence matrices
as input features they can produce good results on only
one unseen test set however their approach did not per
form well on other types  zhang et al  discovered
that classiﬁers do not generalize well between gan
models and proposed to use the discrete fourier transform
dft spectrum of full images as an input to the deep
learning models to detect fake images in contrast we
propose to calculate dft on x blocks of the images and
to combine these with discrete wavelet transform dwt
features furthermore instead of using only the informa
tion from the frequency domain we also propose to
combine the artifacts from the spatial domain and show
through extensive experiments that this technique gener
alizes well on many unseen test sets
in the current work we propose a twostream network
for fake visual content detection the ﬁrst stream called
spatial stream detects the fake data employing rgb
images while the second stream dubbed as frequency
stream utilizes a combination of dft and dwt for dis
criminating fake and real visual content the frequency
stream exploits the fact that the distribution of the fre
quency spectrum of the fake visual data remains distinct
from the distribution of the real data frequency spectrum
this is illustrated in fig  which shows the dftmagni
tude spectrum for a sample of real and fake images it can
be seen that the frequency spectrum has patterns that are
different from that of real images these differences are
used to classify the fake versus real content to elaborate
the frequency spectrum differences further we have shown
the average spectra of the fake and real images from 
different gan generators following the method used by
 we used all the images available in our test set to
calculate the spectrum on the high passed ﬁltered images
and then took the average fig  since the information
captured by the frequency stream is different from the
information captured by the spatial stream both these
streams complement each other and fusing them can
provide better performance and generalization to unseen
fake data detection to the best of our knowledge this is
the ﬁrst work that studies crossmodal information fusion
to improve fake content detection generalization
the main contributions of this paper are summarized
next
a novel twostream architecture for fake visual content
detection consisting of a spatial stream ss and a
frequency stream fs is proposed the ss learns the
difference between the distributions of real and fake
visual content in the spatial space using rgb images
fake
real
fig  dftmagnitude spectrum for fake and real images has
discriminative features which can be exploited for improved fake
detection performance
neural computing and applications  
while the fs learns to discriminate between the
distributions of real and fake content in the frequency
domain the coefﬁcients of the stationary frequencies
are captured using dft while the coefﬁcients of
spatially varying multiscale frequencies are captured
using haar wavelet transform the spatial and fre
quency information complement each other and there
fore
their
fusion
improves
fake
visual
content
detection
the proposed twostream network comprising a fre
quency and a spatial domain stream has outperformed
the stateoftheart fake detection methods with a
signiﬁcant margin a detailed analysis of the proposed
approach is performed and we empirically demonstrate
that the proposed approach is robust across different
quality jpeg compression and blurriness artifacts
in sect  we discuss the related work and cover the tra
ditional image forensics techniques and the latest deep
learningbased image forensics algorithms with a prime
focus on generalization in sect  we present our proposed
methodology with preprocessing schemes training and
testing procedures in sect  we introduce the datasets
used for evaluating and providing the results of our
experiments section  critically evaluates the performance
and the generalization of the proposed methodology by
performing an ablation study finally sect  concludes the
paper and also points towards future directions
 related work
in this section we brieﬂy review recent works needed to
understand the stateoftheart solutions in image forensics
we have divided this section into four subsections we
begin with a brief overview of the handcrafted image
forensic techniques followed by a discussion on deep
learningbased image forensic approaches after that we
discuss methods that focus on improving generalization
finally we conclude the section by covering the stateof
theart frequencydomain techniques that are speciﬁcally
designed for image forensic applications
 handcrafted image forensics
a variety of methods are available in the literature for
detecting traditional image manipulation techniques most
of these manipulations are designed with the help of image
editing tools the traditional techniques make use of hand
crafted features to detect speciﬁc clues that are created as a
result of different manipulations for example several
blind noise estimation algorithms have been proposed to
detect region splicing forgeries   popescu et al 
detected the image forgeries by estimating the resampling
in the images haodong et al  integrated tampering
possibility maps to improve forgery localization yuanfang
et al  identiﬁed potential artifacts in hue saturation
dark and bright channels of fake colorized images and
developed detection methods based on histograms and
feature encoding similarly peng et al  used contact
information of the standing objects and their supporting
planes extracted from their reconstructed d poses to
detect splicing forgeries however these techniques are
unable to provide comparable performance to that of pixel
based methods in realistic situations in recent works
learningbased techniques have become the preferred
method compared to traditional image forensics for
achieving stateoftheart detection performance 
 deep learning based image forensics
due to the success of deep learning in different ﬁelds
several researchers have recently leveraged deep learning
approaches for fake visual content detection yan et al 
proposed an algorithm based on difference images dis
and illuminant map im as feature extractors to detect re
colorized images quan et al  designed a deep cnn
network with two cascaded convolutional layers to detect
biggan
real
fake
cyclegan
deepfake
guagan
imle
progan
san
sitd
stargan
stylegan
fig  we show that average spectrum calculated on highpass
ﬁltered image similar to zhang et al  for fake and real images
have discriminative features which can be exploited for improved
fake detection performance using the method of zhang et al 
we ﬁrst calculate the spectra of all the images in the test set and then
take average of all
neural computing and applications  
computergenerated images mccloskey et al  detec
ted fake images by exploiting artifacts in the color cues
whereas li et al  used face warping artifacts for the
forgery detection li et al  noticed that eye blinking in
fake videos is different from the natural videos and used
this fact to expose the fake videos similarly yang et al
 have detected deepfakes by identifying the inconsis
tent head poses recently afchar et al  proposed two
compact
forgery
detection
networks
meso
and
mesoinception in which forgery detection is done by
analyzing the mesoscopic properties of deepfake videos
similarly nataraj et al  have shown that features
extracted from the cooccurrence matrix can help improve
fake data detection wang et al  proposed an anomaly
detectorbased approach that uses pretrained face detec
tors as a feature extractor yang et al  proposed the use
of saliency maps to distinguish between real and fake
images guo et al  proposed a procedure for identi
fying fake face images by exploiting the gangenerated
artifacts in the iris of the eye most of the aforementioned
fake image detection techniques fail to distinguish between
real and fake images if the visual data is sampled from a
different distribution
 methods focused on generalization
in this subsection we brieﬂy describe the fake detection
approaches focused on generalization cozzolino et al 
proposed an autoencoderbased method to improve the
performance of the model where learned weights are
transferred for a different generation method zhang et al
 proposed a generalizable architecture named auto
gan and evaluated its generalization ability on two types
of generative networks xuan et al  proposed that by
using gaussian blur or gaussian noise one can destroy
unstable lowlevel noise cues and force models to learn
more intrinsic features to improve the generalization ability
of the model similarly wang et al  suggested that
careful preand postprocessing with data augmentation
such as blur and jpeg compression improves the gen
eralization ability they have also shown improved fake
detection results on multiple test sets by training on just
one image generation network
 frequency domain methods
gueguen et al  extracted features from the frequency
domain to perform classiﬁcation tasks on images ehrlich
et al  proposed an algorithm to convert the convolu
tional neural network cnn models from the spatial
domain to the frequency domain xu et al  proposed
learning in the frequency domain and have shown that the
performance of object detection and segmentation tasks
gets improved in the frequency domain as compared to
using the spatial rgb domain durall et al  have
shown that fake images have a difference in highfre
quency coefﬁcients compared to the natural images which
he used for fake detection wang et al  have shown
that the artifacts in the frequency spectrum of fake images
can be detected zhang et al  proposed that if instead
of raw pixels frequency spectrum ddct on all 
channels is used as an input to the fake image detector the
performance of the detector improves these frequency
response base detectors target speciﬁc properties of the
image generation process therefore their performance
degrades when fake images from unseen distributions are
tested in contrast to these existing methods the proposed
algorithm fuses information from the spatial domain and
the frequency domain to achieve improved generalization
also we propose to fuse dft with wavelet transform to
improve the discrimination in the frequency domain these
innovations have resulted in signiﬁcant improvement in
fake content detection compared to the existing methods
 methodology
improving the generalizability of a fake detection model is
critical for its success in realworld applications where the
fake content may be generated by unknown processes we
propose a generalizable fake detection model based on a
twostream convolutional network architecture shown in
fig 
the proposed architecture is motivated by the excellent
performance of twostream networks in action recognition
in videos to the best of our knowledge the proposed
network performs quite well on both seen and unseen data
and has outperformed existing stateoftheart sota
methods in a wide range of experiments as we shall discuss
in later sections our proposed twostream network is novel
and such a combination of frequency stream and the spatial
stream has not been proposed before in the following we
discuss the rgb to ycbcr conversion dft dwt and
the proposed architecture in more detail
 the rgb to ycbcr transformation
the three channels in rgb color space are correlated with
each other we consider an orthogonal color space for
improved representation in our experiments we have used
ycbcr that has performed better than rgb space as
recommended in previous research   the following
 the eyes and mouth are determined as the mesoscopic features in
the forgery detection in the deepfake videos
neural computing and applications  
formulas are used to convert from rgb to ycbcr color
space
y ¼ kryr þ kgyg þ kbyb cr
¼ b  y cb  r  y kry þ kgy þ kby ¼ 
ðþ
where kry kgy and kby are the coefﬁcients for color
conversion whose values are speciﬁed in table  according
to the standards in our implementation we used itu
 a review of frequency domain transforms
to fully capture the frequency information from a ycbcr
image we compute dft and dwt for each imagedis
crete fourier transform dft using dft one can
decompose a signal into sinusoidal components of various
frequencies ranging from  to maximum value possible
based on the spatial resolution for two dimensional data
ie images of size w  h the dft can be computed using
the following formula
xwh ¼
x
w
n¼
x
h
m¼
xwhe
ip
n wne
ip
m hm ðþ
where w is the horizontal spatial frequency h is the vertical
spatial frequency xwh is the pixel value at coordinates w
h and xwh carries the magnitude and phase information of
frequency at coordinates w h discrete wavelet trans
form dwt wavelet transform decomposes an image into
four different subband images high and low pass ﬁlters
are applied at each row column and then they are down
sampled by  to get the high and lowfrequency compo
nents of each row column separately in this way the
original image is converted into four subband images
highhigh hh highlow hl lowhigh lh and
lowlow ll each subband image preserves different
features hh region preserves highfrequency components
in both horizontal and vertical direction hl preserves
highfrequency components in the horizontal direction and
lowfrequency components in the vertical direction lh
preserves lowfrequency components in the vertical direc
tion and highfrequency components in the horizontal
direction and ﬁnally ll preserves lowfrequency com
ponents in the vertical direction and lowfrequency com
ponents in the horizontal direction
wav
elet
image
dft
stage
stage
stage
stage
stage
class 
score 
fusion
spatial stream
frequency stream
conv 
x
b
b
b
r
r
r
b
b
b
b
r
r
r
conv 
block
identity 
block
r
relu
b
batchnorm
conv batch
norm relu max
pool
conv
block
id
block
x
avg
pool flatten max
pool
conv
block
id
block
x
conv
block
id
block
x
conv
block
id
block
x
zero
pad
stage
stage
stage
stage
stage
conv batch
norm relu max
pool
conv
block
id
block
x
avg
pool flatten max
pool
conv
block
id
block
x
conv
block
id
block
x
conv
block
id
block
x
zero
pad
r
g
b
conv 
x
conv 
x
add
conv 
x
conv 
x
conv 
x
conv 
x
add
fig  proposed twostream convolutional neural network twostreamnet the two network streams capture spatial and frequency domain
artifacts separately and their outputs are fused at the end of the network to produce classiﬁcation scores
neural computing and applications  
 frequency stream
in this stream two different types of the frequency spec
trum are fused to get improved frequency domain repre
sentation which can better discriminate between the real
and the fake visual content an overview of the frequency
spectrum fusion is shown in fig 
the three ycbcr channels are then transformed to the
frequency domain using two different types of transfor
mations including dft and dwt each channel is divided
into a nonoverlapping block of size    pixels and a
transformation is applied on each block independently the
resulting coefﬁcients are then concatenated back to obtain
the arrays of the original image size the output of the dft
converts one input channel into two output channels cor
responding to real and imaginary coefﬁcients similarly
the dwt converts one input channel into  output channels
corresponding to low frequencies ll high and low fre
quencies hl high frequencies hh and low and high
frequencies lh for three input channels ycbcr we
obtain  output channels  from dft and  from dwt
all of these frequency output channels are concatenated to
form d cubes of size h  w  c where h is the height
and w is the width of the image and c are the number
of channels we empirically observe that both dft and
dwt are necessary to capture essential information in the
frequency domain at varying scales for improving the
generalization ability of the proposed network
 spatial stream
in this stream rgb channels of the image are passed as
input to the resnet  as the classiﬁer rgb images
are augmented in a special way using jpeg compression
and gaussian blur as recommended by wang et al 
this stream is trained individually and plugged in the
twostreamnet at the test time
 two stream network architecture
the proposed twostream network architecture is shown in
fig  resnet network is used as a backbone in both of
the streams of the proposed architecture since the number
of input channels in the frequency stream is larger as
compared to the spatial stream therefore the ﬁrst layer of
fs is accordingly modiﬁed both streams are indepen
dently trained and the output of both streams is fused using
the class probability averaging fusion method in this
fusion scheme both streams contribute equally to the
output to produce the ﬁnal classiﬁcation probability the
table  coefﬁcients kry and kby of color conversion from rgb to
ycbcr
reference standard
kry
kby
 itu  itut  
 itu  itut  
 smpte m 
r
g
b
y
cb
cr
y
cb
cr
y
cb
cr
r
i
r
i
r
i
hh
hl
ll
lh
hh
hl
ll
lh
hh
hl
ll
lh
r
i
hh
hl
ll
lh
r
i
 x  x 
 x  x 
 x  x 
 x  x 
 x  x 
discrete fourier transform
discrete wavelet transform
fig  proposed preprocessing pipeline the input image is ﬁrst
converted to ycbcr color space and then transformed to the
frequency domain by applying dft and wavelet transforms
dwt after dft we get real r and imaginary i channels and
after wt we get four channels hh hl lh and ll the resulting
channels are concatenated to form d cubes which are then provided
as input to the frequency stream for further processing
neural computing and applications  
performance of the combined scores is signiﬁcantly better
than the performance of the individual streams
 experiments and results
training dataset following the protocol used by  the
proposed twostream network is trained using the fake
images generated by progan  and tested on the ima
ges generated by many other gans progan has  dif
ferent ofﬁcially released models trained on different object
categories of the lsun dataset which is a largescale
image dataset containing around one million labeled ima
ges for each of the  scene categories and  object cat
egories  we choose  airplane bird boat bottle
bus car cat chair dog horse motorbike person sofa
train and tv monitor out of  models to create our val
idation and training set we generated k fake images for
training and  fake images for validation using each of
the  models for each of these  categories of fake
images we collect k of real images for training and 
for validation randomly from the lsun dataset  in
total we have k training images and k validation
images for real images we center crop the images equal to
the size of the shorter edge and then resize the images to
  
testing dataset testing dataset images were generated
using
completely
unseen
generators
as
described
in
table  to remain consistent with the current state of the
art the same generators are selected as that of  the
real images for testing purposes are obtained from the
repository for each generator
 implementation details
for training the fs we use the adam  optimizer with
an initial learning rate of  weight decay of 
and a batch size of  for all the training sets we train the
proposed network for  epochs large training data has
helped the model to converge quickly lastly we select the
best model based on the validation set while training each
stream data augmentation based on gaussian blur and
jpeg compression with  probability is used
 evaluation metrics
we have used following metrics in our evaluation
fscore fscore is the harmonic mean of precision
and recall and is calculated below as
f ¼   precision  recall
precision  recall 
where precision is the number of true positives divided by
the summation of true positives and false positives and the
recall is the number of true positive results divided by the
number of all samples that should have been identiﬁed as
positive
accuracy accuracy is deﬁned as the ratio of the correct
predictions over the total number of predictions made and
is calculated as below
accuracy ¼
tp þ tn
tp þ tn þ fp þ fn  ðþ
where tp fp tn and fn represents is the number of true
positives false positives true negatives and false negative
respectively
 comparison with the existing stateofthe
art algorithms
we thoroughly evaluated the performance of the proposed
method on the test dataset and compared it with the
existing stateoftheart  we also compared the
robustness analysis of our approach against some common
realworld perturbations in table  we have shown a
comparison of our results with the best results of wang
et al  blurjpeg their results from their
ofﬁcial web link results show that our fs approach
performs very well on the unseen manipulations and out
performs the stateoftheart on several test sets while
having competitive performance on the remaining results
of the twostream architecture demonstrate that our com
plete approach outperformed the stateoftheart in almost
all of the cases analysis of the results shows that when
both spatial and frequency streams are combined into a
twostream architecture they complement each other in a
way that their combined accuracy is greater than any of
them individually this clearly shows that fs convnet has
learned distinctive features that were not learned by ss
convnet overall the combination of fs and ss plays a
vital role in improving the generalization ability of the fake
image detectors
in table  we compare our method to four different
models cycim cycspec autoim autospec of zhang
et al  they released four models with two kinds of
variations ﬁrst they used two datasets generated using two
different gan architectures cyclegan and autogan
referenced as cyc and auto in table  and as a second
variation they passed images as input to one model and
frequency spectrum in the other model referenced as im
and spec in table  results of our approach show that our
 httpswwwyfioplsun
 httpspeterwanggithubiocnndetection
neural computing and applications  
table  comparison of the proposed frequency stream fs and twostream network with
the stateoftheart method  using average accuracy best results of wang et al  with
data augmentation using blur and jpeg  are reported where  mean jpeg compression
is applied on  images the same augmentation is also used in the proposed approaches
both our approach and that of wang et al are trained using progan only and tested on the
data generated by  unseen generation processes mentioned in the top row
metrics
method
stargan
stylegan
sitd
biggan
stylegan
cyclegan
whichfaceisreal
san
deepfake
guagan
crn
imle
accuracy
wang et al  spatial stream
frequency stream ours
two stream ours
fscore fake
wang et al  spatial stream
frequency stream ours
two stream ours
fscore real
wang et al  spatial stream
frequency stream ours
two stream ours
table  comparison of the proposed twostream network with zhang et al  using
accuracy we compare the proposed network with  models released by  each one was
trained using one of two image sources cyclegan cyc and autogan auto as well as
one of two image representations images im and spectrum spec the blue text shows the
same training and testing data
method
star gan
style gan
sitd
big gan
style gan
cycle gan
which face is real
san
deep fake
gua gan
crn
imle
zhang et al  cycim
zhang et al  cycspec
zhang et al  autoim
zhang et al  autospec
two stream ours
neural computing and applications  
twostream architecture outperformed all models of zhang
et al  in almost all of the test sets fig 
in fig a we have shown samples of the fake images
which are misclassiﬁed by the stateoftheart and are
correctly classiﬁed by our proposed twostream approach
these results demonstrate the ability of the proposed
approach to detect highquality fake images which are even
very hard to discriminate by humans figure b shows the
fake images which are misclassiﬁed by both wang et al
 and us
robustness analysis in realworld settings fake images
may
undergo
several
postprocessing
operations
like
compression smoothness etc therefore we have evalu
ated the performance of the proposed model on the images
which are postprocessed using jpeg compression and
gaussian blur speciﬁcally we apply gaussian blur with
different standard deviations including      and
jpeg compression with jpeg image quality factor of 
    results in fig  show that our approach is
robust to common perturbations for most of the models
the proposed approach signiﬁcantly outperformed the state
oftheart method at varying blur levels similarly the
proposed approach also performed better than the stateof
theart methods for a wide range of jpeg compression
 ablation study
in this section we thoroughly validate the different com
ponents of the proposed approach by performing an abla
tion study table 
 combining dft and dwt
as shown in fig  we propose to combine dwt and dft
for better feature representation and robust fake content
detection to verify the effectiveness of using both trans
formations while keeping all the experimental settings the
same we experimented with dft and dwt separately
after training for  epochs the best epoch is chosen based
jpeg
blur
accuracy
accuracy
accuracy
accuracy
accuracy
accuracy
accuracy
accuracy
jpeg quality
jpeg quality
sigma
sigma
a
b
fig  robustness comparison of the proposed algorithm with wang
et al  for gaussian blur and jpeg compression artifacts in most
experiments the proposed twostream net we apply gaussian blur
and jpeg compression of different sizes on the test sets and measure
the effect on the accuracy of our model our model performs near to
the best for all the crossmodal datasets even when a large blurring
effect is applied results show that our proposed solution is more
robust as compared to the state of the art
neural computing and applications  
biggan
guagan
san
crn
sitd
imle
stargan
deepfake
stylegan
whichfaceisreal
cyclegan
stylegan
b
a
neural computing and applications  
on validation data accuracy the results shown in table 
demonstrate that a combination of dft and dwt is
essential to produce robust feature representation for fake
image detection
 effect of block size
we study the effect of using different block sizes instead of
computing dft over the whole image in table  we have
shown results of computing dft on the block size of
         and    fullimage size
note that the block size experiments are performed while
keeping identical experimental settings results demon
strate that  block size has consistently outperformed
other block sizes therefore transforming the image to the
frequency domain using  blocks for dft is more
effective for fake image detection
 effect of colorspace
we evaluate the effectiveness of converting images into
ycbcr color space before frequency transformations we
performed two experiments using the same settings to
compare the performance of rgb with ycbcr color space
results in table  show that converting an image to ycbcr
colorspace adds more discriminative features in the fre
quency domain and helps in better fake image detection
 limitations
the computation of dft and dwt is computationally
expensive therefore to implement it for fake content
detection in realtime applications using video data may be
a potential limitation however this limitation can be
overcome by using parallel computation of dft and dwt
figure b shows failure cases of the proposed algorithm
which are the result of nondiscriminative frequency
domain features please note that these fake images are
high quality and very hard to discriminate even for
humans
bfig  a examples of fake images correctly detected by the proposed
twostream network however misclassiﬁed by wang et al 
b examples of fake image misclassiﬁed by both our proposed method
and that of wang et al 
table  details of the testing dataset
dataset
real images
fake images
stargan 
stylegan 
sitd 
biggan 
stylegan 
cyclegan 
whichfaceisreal 
gaugan 
deepfake 
crn 
imle 
san 
table  evaluation of dft and dwt combination for fake image
detection percentage accuracy is reported for the full image using
only dft only dwt and the combination dft  dwt
dataset
dft
dwt
dft  dwt
stargan 
stylegan 
sitd 
biggan 
stylegan 
cyclegan 
whichfaceisreal 
gaugan 
deepfake 
crn 
imle 
san 
table  fake image detection accuracy variation by varying block
sizes for dft transform the block size  has produced best
results and is therefore used in our experiments
dataset
 x 
 x 
 x 
fullimage
stargan 
stylegan 
sitd 
biggan 
stylegan 
cyclegan 
whichfaceisreal 
gaugan 
deepfake 
crn 
imle 
san 
neural computing and applications  
 conclusions
this paper addresses the problem of fake image detection
for this purpose a twostream network is proposed con
sisting of a spatial stream and a frequency stream the
proposed method generalizes to unseen fake image gener
ator distributions much better than the current stateofthe
art approaches the proposed method is also found to be
more robust to the common image perturbations including
blur and jpeg compression artifacts the improved per
formance is leveraged by combining two types of fre
quency domain transformations namely discrete fourier
transform dft and discrete wavelet transform dwt
both transformations are applied upon ycbcr colorspace
and different frequency domain channels are concatenated
to discriminate fake images from the real ones by
exploiting the differences between the real and the fake
image frequency responses improved fake detection per
formance is achieved in the future we aim to extend this
work for fake video and audio detection
funding the authors did not receive support from any organization
for the submitted work
declarations
conflict of interest we wish to confirm that there are no known
conflicts of interest associated with this publication
ethical approval we confirm that the manuscript has been read and
approved by all named authors and that there are no other persons
who satisfied the criteria for authorship but are not listed we further
confirm that the order of authors listed in the manuscript has been
approved by all of us we understand that the corresponding author
is the sole contact for the editorial process including editorial
manager and direct communications with the office
vol
 
social network analysis and mining   
httpsdoiorgs
original article
a deep dive into covidrelated messages on whatsapp in pakistan
r tallal javed    muhammad usama  waleed iqbal  junaid qadir  gareth tyson  ignacio castro  
kiran garimella
received  june   revised  october   accepted  october   published online  november  
 the authors under exclusive licence to springerverlag gmbh austria part of springer nature 
abstract
the spread of covid and the lockdowns that followed led to an increase in activity on online social networks this has 
resulted in users sharing unfiltered and unreliable information on social networks like whatsapp twitter facebook etc in 
this work we give an extended overview of how pakistans population used public whatsapp groups for sharing informa
tion related to the pandemic our work is based on a major effort to annotate thousands of text and imagebased messages 
we explore how information propagates across whatsapp and the user behavior around it specifically we look at political 
polarization and its impact on how users from different political parties shared covidrelated content we also try to 
understand information dissemination across different social networkstwitter and whatsappin pakistan and find that 
there is no significant bot involvement in spreading misinformation about the pandemic
keywords  misinformation  infodemic  social computing
  introduction
applications like twitter facebook and whatsapp are ena
bling millions of users to connect and interact this has led 
to sharing ideas getting exposed to different ideologies and 
absorbing information at an unprecedented pace out of all 
these services and apps whatsapp is the most popular and 
widely used medium of communication this has created a 
closed social network of more than  billion users apart 
from having a huge user base it also has the most active 
users at a time out of all the social networks two billion 
users 
this makes whatsapp a very important medium for anal
ysis as it is a major tool for opinion formation and social 
exchange due to its endtoend encryption it is becoming a 
medium of choice for antigovernment movements sharing 
of radical ideas and gang operations uk says whatsapp 
 similarly whatsapp is also used for the propagation 
of antisocial behavior a study on brazils whatsapp users 
resende et al a revealed how whatsapp can be an 
effective tool for the spread of disinformation a study con
ducted in india saha et al  revealed the spread of hate 
speech and islamophobia on whatsapp these problems are 
exacerbated by the fact that content moderation in what
sapp is rather limited the content of a group is only mod
erated by the groups administrators admins have very few 
 
	 r tallal javed 
	
tallaljavedituedupk
	
muhammad usama 
	
muhammadusamalumsedupk
	
waleed iqbal 
	
wiqbalqmulacuk
	
junaid qadir 
	
jqadirquedupk
	
gareth tyson 
	
gtysonqmulacuk
	
ignacio castro 
	
icastroqmulacuk
	
kiran garimella 
	
garimellmitedu
	
information technology university of the punjab lahore 
pakistan
	
qatar university doha qatar
	
lahore university of management sciences lahore 
pakistan
	
queen merry university london uk
	
mit cambridge usa
	
social network analysis and mining  
 
 
page  of 
tools at hand either restrict who can post content or remove 
certain users from the group group admins cannot even do 
the simple moderation task of deleting a users post as a 
result the moderation abilities on whatsapp are very scant
this work is an extended version of our earlier prelimi
nary analysis of covidrelated messages being dis
seminated across public whatsapp groups by pakistani 
users javed et al  in this extended version in addi
tion to looking at the type of messages being disseminated 
across covid in pakistani whatsapp groups we also 
try to understand the impact that political affiliation has on 
a groups overall sentiment related to covid and the 
types of messages being propagated our main research 
questions are 
rq	
what type of messages about covid are dis
seminated in public whatsapp groups of pakistan
rq	
what is the general user behavior when sharing a 
message specifically is there a connection between a 
groups political affiliation and the content that is being 
shared
rq	
is there reciprocation between information dis
semination related to covid over whatsapp and 
twitter
rq	
what type of sentiment is expressed by users when 
sharing covid messages does this vary on the 
basis of political affiliation
to answer these research questions we have gathered the 
data from  publicly accessible whatsapp groups during 
january  april   this dataset is the first of 
its kind giving us a unique opportunity to analyze covid
related discussion from one of the largest countries in the 
world involving a multimodal environmentimages and 
textand multiple social networking platforms of commu
nicationwhatsapp and twitter
we start by analyzing the content disseminated in these 
 public groups and extract the covidrelated 
content out of them extracted content is separated into 
image video text documents and links using our dataset 
which we make publicly available we make the following 
contributions
	 we analyze the groups and messages therein with a focus 
on political affiliations
	 we give an overview of how users with different political 
affinities spread covidrelated messages we also 
show that on average  of the content shared is mis
information
	 we give an overview of the prevailing sentiment of 
covid posts and find that the sentiment is mostly 
negative
  
related work
  
misinformation on social media
many studies have been conducted that gave a special focus 
to rumors and misinformation prior to the events of the 
 us presidential elections starbird et al  how
ever the events of the us presidential election have since 
triggered a flurry of work on this topic as a result there 
have been many papers attempting to understand the impact 
social media has the amount of misinformation present on 
it and the amount of exposure users have to this informa
tion david et al  iosifidis and nicoli  bovet 
and makse  for example during the  elections 
social media were used extensively to manipulate social 
media users to sway their political inclinations grinberg 
et al  analyzed twitter to understand the extent of 
political manipulation present during this period similarly 
badawy et al  used twitter to understand the effects 
the russian internet research agency might have had on 
american twitter users they characterize the interactions 
of twitter republican and democratic users with the rus
sian trolls
there are various methods for detecting misinformation 
they can be divided into two major approaches content
based and propagationbased habib et al  performed 
a systematic literature review to understand different meth
odologies for detecting misinformation in online social net
works chen et al  performed an analysis of twitter to 
understand different types of misinformation their analysis 
relied on a graph of users based on the content they share in 
other similar works zollo and quattrociocchi  cinelli 
et al  the authors provide analysis on social media 
users and their interactions with controversial topics and 
content a study on instagram was conducted by trevisan 
et al  where they gave detailed insights on how users 
interact with political content similarly many researchers 
have conducted independent studies in line with those men
tioned earlier zhang and ghorbani  shu et al  
 sharma et al  zhou and zafarani  zarei 
et al 
  
analyzing content on whatsapp
the whatsapp messaging service is the most actively used 
online social network in the world whatsapp is a closed 
  in this study we only focus on text and images and leave the analy
sis over video content for future work
  https
tinyu
rl
com
snam
pakis
tan
social network analysis and mining  	
 
page  of  
network without any official access for analyzing its con
tent as a result not a lot of work has been done to analyze 
its content and user interactions it is a documented fact that 
whatsapp is being actively used for the dissemination of 
misinformation boadle  perrigo  due to the 
popularity of whatsapp in certain regions political par
ties have been actively using whatsapp groups to reach 
the masses goel  surveys performed in brazil and 
india lokniti  newman et al  two of the largest 
democracies show that one in six users are part of a political 
group on whatsapp
garimella and tyson  were the first to provide 
tools for analyzing public whatsapp groups and collecting 
data at scale these tools have enabled researchers to study 
whatsapp at scale and created a window into the world 
of whatsapp some of the recent studies can be found 
at evangelista and bruno  resende et al b 
yadav et al  garimella and eckles  where 
researchers analyzed public whatsapp groups in various 
contexts resende et al  gave a unique insight by ana
lyzing doctored images used to fuel political smear cam
paigns against opposing parties on public whatsapp groups 
in brazil similarly garimella and eckles  analyze 
the images in indian whatsapp groups during the  
indian elections the study found that  of the images 
contained misinformation using reverse image search on 
google images in parallel melo et al  gather ana
lyze and visualize public whatsapp groups and identify 
the extent of misinformation found in india indonesia and 
brazil apart from text messages and images whatsapp has 
a large content of audio files maros et al  analyzed 
 public whatsapp groups and proposed that audio mes
sages containing misinformation spread much more farther 
and wider
  
the covid infodemic
our work revolves around understanding health informa
tion being shared on whatsapp and how users interact 
with it while considering the political inclination of users 
the covid pandemic has also created an infodemic as 
declared by the world health organization an infodemic 
refers to the inflow of information that is so large that users 
are unable to discriminate effectively between misinfor
mation and correct information it is already documented 
that whatsapp is a source of misinformation related to 
health purnell  ranging from wrong symptoms to 
ineffective treatments bhatnagar and choubey  javed 
et al  this makes it critical to understand the health 
content present in whatsapp groups
apart from whatsapp researchers have provided a dash
board to analyze health misinformation on twitter sharma 
et al  they analyze  million tweets and also perform 
a countrywide analysis of sentiment they also provide 
an uptodate view of how people are reacting to covid
related content on twitter similarly singh et al  
look at twitter based misinformation about covid and 
give insights about the propagation of misinformation on 
online social networks is in line with the rise of cases in a 
given demographic another study on twitter kouzy et al 
 found that some tags have more misinformation than 
others pointing toward potential safe tags on twitter cinelli 
et al  analyze different social networks for covid
related content they analyze twitter instagram reddit 
gab and youtube giving a comprehensive picture of the 
state of covid content on these websites they not only 
do content analysis but also try to understand the propaga
tion of misinformation on these social networks
  
our works novelty
this work is an extension of our previous work javed et al 
 in this study we analyze covidrelated discus
sions on whatsapp and explore the political influence in 
this context since whatsapp is a popular and frequently 
used application it is critical to understand how the popu
lace is utilizing the platform during the pandemic and how 
the platform facilitates the spread of misinformation while 
doing so we extract valuable insights from the dataset and 
try to quantify how misinformation and politics can be 
intertwined
studies have been conducted to analyze whatsapp mes
sages for political events in brazil and india on the con
trary this study tries to understand the impact whatsapp is 
having on the infodemic in pakistan while considering the 
political nature of our groups since pakistan is a muslim 
majority country religion is relevant in the daily life of the 
pakistani citizens we offer a first insight into how religion 
and politics together play a role in this infodemic
  
methodology
we use a multitude of techniques for data collection annota
tion and analysis of data we also create novel algorithms 
to better understand the content being shared the details of 
these methods are discussed below
  
dataset preparation
whatsapp allows its user base to create either public or 
private whatsapp groups a private group can only be 
joined through an invite which is sent by the admin himself 
  https
en
wikip
edia
org
wiki
impor
tance_
of_
relig
ion_
by_
count
ry
	
social network analysis and mining  
 
 
page  of 
whereas for the public groups whatsapp allows users to 
enable joining these groups by means of an invite url this 
invite url can be shared by any number of users and the 
users can join a group by clicking this url the invite url 
has a specific structure of the form chat
whats
app
com
 
many groups eg for politics sports religion share these 
invite urls on social networks for easy visibility hence 
increasing their community size and reach
group selection leveraging the unique structure of pub
lic whatsapp groups we used facebook and google search 
to find whatsapp invite urls to ensure we find groups 
from pakistani political parties the url was often used in 
conjunction with a political partys name or pakistan we 
also used pakistani ip to ensure google and facebook give 
results from pakistan as a priority we also used the keyword 
whatsapp along with political parties names or slogans 
all of these queries have been logged for the convenience 
of new researchers in this domain and can be found online
following these techniques we found in total  public 
pakistani whatsapp groups a loose criterion was set to 
make sure the groups joined are in line with our research 
goals and will provide meaningful value to the overall data
set we manually analyzed a groups bio name and profile 
pic if any of these were not in line with our research goals 
the group was removed from our dataset removed groups 
mostly were sales purchase groups or groups made only 
for sharing jokes furthermore we analyzed the remaining 
groups for activity over a week in case a group did not have 
any significant activity or the activity was not organic eg 
a sales group they were removed from our dataset after 
these pruning steps a total of  public groups were used 
to provide the analysis that follows
whatsapp data collection to join these groups we 
relied extensively on the tools created and provided by gari
mella and tyson  these tools use selenium enabling 
automated joining of public whatsapp groups whatsapp 
messages are stored on a users device in an encrypted form 
and is further protected by being placed in the root folder 
the root folder is a secure folder and users do not have 
access to it a rooted android phone having an unlocked 
bootloader and root folder was used to obtain the decrypted 
database the database is located in the datadata folder of 
the root drive the media contents images videos are 
stored online on whatsapp servers and need to be accessed 
using the urls provided in the database using these urls 
we downloaded images locally and decrypted them using 
a public tool this tool was not functional out of the box 
hence it was modified for our convenience and ease dur
ing our data collection it was observed that whatsapp 
periodically deletes content from their servers as a result 
if a media file was not downloaded in a respectable amount 
of time the media content could not be retrieved hence 
a pipeline was created to extract data on weekly basis an 
overview of our dataset can be seen in table 
  
annotating covid text messages
covid text messages were extracted using a keyword
filtering approach rashed et al  provide a diction
ary of keywords related to covid we used that and 
translated these words into equivalent urdu terms we also 
added small variations to these terms like spelling mis
takes and multiple spellings to ensure that we capture a 
large dataset some of the sample keywords are corona 
covid covid covid and coronavirus it 
should be noted that although this ensures that we get a 
large chunk of covidrelated messages we still will 
miss some this approach resulted in  text messages 
table    stats of our whatsapp 
dataset as collected from public 
pakistani whatsapp groups
a detailed breakdown is given 
for 
our 
observed 
window 
between march  and april  
data type
dataset
groups
admins
users
all messages
text messages
 
images
videos
audio
documents
lockdown imposed 
on provincial level
fig    percentage of messages per day for both text and images a 
spike in images related to covid was seeing from  onward 
after lockdown was announced by punjab on provincial level
  https
cutt
ly
yxhx
bd
  https
github
com
ddz
whats
app
media
decry
pt
social network analysis and mining  	
 
page  of  
related to covid between march  and april   
the dates roughly correspond with the first wave of covid
 in pakistan
figure  gives a comparison of daily covidrelated 
and noncovidrelated messages in our dataset one 
can observe the irregularity in the percentage of images 
related to covid compared to the stable flow of text 
messages it was observed that rather than writing text mes
sages users found it more convenient to share images like 
news snippets and pictures from hospitals in fig  the 
vertical dotted line represents lockdown being imposed 
on the provincial level before the lockdown was officially 
imposed two spikes in percentage of images can be seen 
these spikes relate to people sharing news about a mass 
spread event observed near the capital city after the lock
down an awareness campaign was started by the govern
ment in which images that contained helpful info related to 
covid were shared users in our groups actively shared 
these informative images another interesting debate that 
occurred during this time was the rulings on offering prayers 
in mosques since pakistan is a muslim majority country 
many users shared sayings of scholars and news snippets 
related to this event as images it is interesting to know that 
wrt percentage  and in contrast to the trend seen for 
text messages  users were more inclined to share covid
related images than noncovid images see fig 
  
annotating covid images
twentyfive percent of the messages in our whatsapp data
set contained images we categorized images into covid
 and noncovidrelated images using manual 
annotators two annotators tagged a total of  images 
between march  and april   this resulted in  
noncovid images and  covid images the 
two annotators had an interannotator agreement score of 
 for the cases in which the annotators disagreed the 
annotators were allowed to discuss the case and give a final 
label unlike text annotation the annotators used a set of 
rules to identify the difference between covid images 
and noncovid images if any of the following rules 
applied to an image it was labeled as covid 
	 contained coronavirus covid or any other related 
terminology in urdu or english
	 contained information relating to a lockdown or any 
restrictions being imposedrelaxed by the government 
on business or publicprivate institutions
	 contained any precautionary measures like prayers for 
protection from disease herbal medications etc
	 contained any 
ieee communications surveys  tutorials vol  no  second quarter 
securing connected  autonomous vehicles
challenges posed by adversarial machine
learning and the way forward
adnan qayyum
 muhammad usama
 junaid qadir
 senior member ieee
and ala alfuqaha
 senior member ieee
abstractconnected and autonomous vehicles cavs will
form the backbone of future nextgeneration intelligent trans
portation systems its providing travel comfort road safety
along
with
a
number
of
valueadded
services
such
a
transformationwhich will be fuelled by concomitant advances
in
technologies
for
machine
learning
ml
and
wireless
communicationswill enable a future vehicular ecosystem that
is better featured and more efﬁcient however there are lurking
security problems related to the use of ml in such a critical set
ting where an incorrect ml decision may not only be a nuisance
but can lead to loss of precious lives in this paper we present
an indepth overview of the various challenges associated with
the application of ml in vehicular networks in addition we for
mulate the ml pipeline of cavs and present various potential
security issues associated with the adoption of ml methods in
particular we focus on the perspective of adversarial ml attacks
on cavs and outline a solution to defend against adversarial
attacks in multiple settings
index
termsconnected
and
autonomous
vehicles
machinedeep learning adversarial machine learning adversar
ial perturbation perturbation detection and robust machine
learning
i introduction
i
n recent years connected and autonomous vehicles
cavs have emerged as a promising area of research the
connected vehicles are an important component of intelligent
transportation systems its in which vehicles communicate
with each other and with communications infrastructure to
exchange safety messages and other critical information eg
trafﬁc and road conditions one of the main driving force
for cavs is the advancement of machine learning ml
methods particularly deep learning dl that are used for
decision making at different levels unlike conventional con
nected vehicles the autonomous selfdriving vehicles have
manuscript received may   revised october   accepted
february   date of publication february   date of current
version may   corresponding author adnan qayyum
adnan
qayyum
is
with
the
computer
science
department
information
technology
university
lahore
pakistan
email
adnanqayyumituedupk
muhammad usama and junaid qadir are with the electrical engineering
information technology university lahore  pakistan
ala alfuqaha is with the information and computing technology
division college of science and engineering hamad bin khalifa university
doha qatar and also with the computer science department college of
engineering and applied sciences western michigan university kalamazoo
mi  usa
digital object identiﬁer comst
two important characteristics namely automation capability
and cooperation connectivity  in future smart cities cavs
are expected to have a profound impact on the vehicular
ecosystem and society
the phenomenon of connected vehicles is realized through
technology known as vehicular networks or vehicular adhoc
networks vanets  over the years various conﬁgurations
of connected vehicles have been developed including the use of
dedicated shortrange communications dsrc in the united
states and itsg in europe based on the ieee p
standard however a recent study  has shown many limita
tions of such systems such as  shortlived infrastructure
tovehicle iv connection  nonguaranteed quality of
service qos and  unbounded channel access delay etc
to address such limitations the rd generation partnership
project gpp has been initiated with a focus on leveraging
the high penetration rate of long term evolution lte and
g cellular networks to support vehicletoeverything vx
services  the purpose of developing vx technology is
to enable the communication between all entities encountered
in the road environment including vehicles communications
infrastructure pedestrians cycles etc
the impressive ability of mldl to leverage increasingly
accessible data along with the advancement in other concomi
tant technologies such as wireless communications seems
to be set to enable autonomous and selforganizing con
nected vehicles in the future in addition future vehicular
networks will evolve from normal to autonomous vehicles and
will enable ubiquitous internet access on vehicles ml will
have a predominant role in building the perception system of
autonomous and semiautonomous connected vehicles
despite the development of different conﬁgurations of con
nected vehicles they are still vulnerable to various security
issues and there are various automotive attack surfaces that
can be exploited  the threat is getting worse with the
development of fully autonomous vehicles as the autonomous
vehicles are being equipped with many sensors such as cam
eras radar lidar and mechanical control units etc
these sensors share critical sensory information with onboard
devices through can bus and with other nearby vehicles as
well the backbone of selfdriving vehicles is the onboard
intelligent processing capabilities using the data collected
through the sensory system this data can be used for many
other purposes eg getting information about vehicle kinetics
x c
 ieee personal use is permitted but republicationredistribution requires ieee permission
see httpswwwieeeorgpublicationsrightsindexhtml for more information
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
table i
comparison of this paper with existing survey and review papers on the security of machine learning ml and connected and
autonomous vehicles cavs legend means covered  means not covered means partially covered
trafﬁc ﬂow road and network conditions etc such data can be
potentially used for improving the performance of the vehicu
lar ecosystem using adaptive datadriven decision making and
can also be used to accomplish various destructive objectives
therefore ensuring data integrity and security are necessarily
important to avoid various risks and attacks on cavs
it is common for the perception and control systems of
cavs to be built using mldl methods however mldl
techniques have been recently found vulnerable to carefully
crafted adversarial perturbations  and different physical
world attacks have been successfully performed on the vision
system of autonomous cars   this has raised many pri
vacy and security concerns about the use of such methods
particularly for securitycritical applications like cavs in this
paper we aim to highlight various security issues associated
with the use of ml and we present a review of adversar
ial ml literature mainly focusing on cavs in addition we
also present a taxonomy of possible solutions to restrict adver
sarial ml attacks and open research issues on autonomous
connected vehicles and ml
ml in general and dl schemes speciﬁcally perform excep
tionally well in learning hidden patterns from data dl
schemes such as deep neural networks dnn have out
performed humanlevel intelligence in many perception and
detection tasks by accurately learning from a large corpus
of training data and classifyingpredicting with high accu
racy on unseen realworld test examples as dl schemes
produce outstanding results they have been used in many real
world securitysensitive tasks such as perception system in
selfdriving cars anomaly and intrusion detection in vehicular
networks etc mldl schemes are designed for benign and
stationary environments where it is assumed that the training
and test data belongs to the same statistical distribution the
application of this assumption in a realworld application is
ﬂawed as training and test data can have different statistical
distributions which gives rise to an opening for adversaries
to compromise the mldlbased systems furthermore the
lack of interpretability of the learning process imperfections
in training process and discontinuity in the inputoutput
relationship of dl schemes also resulted in an incentive for
adversaries to fool the deployed mldl system 
contributions of this paper in this paper we build upon
the existing literature available on cavs and present a com
prehensive review of that literature a comparison of this
paper with existing surveys on security of cavs is presented
in table i the following are the major contributions of
this study
 we formulate the ml pipeline of cavs and describe
in detail various security challenges that arise with the
increasing adoption of ml techniques in cavs specif
ically emphasizing the challenges posed by adversarial
ml
 we present a taxonomy of various threat models and
highlight the generalization of attack surfaces for general
ml autonomous and connected vehicle applications
 we review existing adversarial ml attacks with a special
emphasis on their relevance for cavs
 we review robust ml approaches and provide a tax
onomy of these approaches with a special emphasis on
their relevance for cavs and
 finally we highlight various open research problems
that require further investigation
organization of the paper the organization of this paper
is depicted in figure  the history introduction and various
challenges associated with connected and automated vehicles
cavs are presented in section ii section iii presents an
overview of the ml pipeline in cavs the detailed overview
of adversarial ml and its threats for cavs are described
in section iv an outline of various solutions to robus
tify applications of ml along with common methods and
recommendations for evaluating robustness are presented in
section v section vi presents open research problems on
the use of ml in the context of cavs finally we con
clude the paper in section vii a summary of the salient
acronyms used in this paper is presented in table ii for
convenience
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
fig 
outline of the paper
ii connected and autonomous vehicles cavs
history introduction and challenges
in this section we provide the history introduction back
ground of cavs along with different conventional and security
challenges associated with them
a autonomous vehicles and levels of automation
the society of automotive engineers sae has deﬁned a
taxonomy of driving automation that is organized in six lev
els the sae deﬁned the potential of driving automation at
each level that is depicted in figure  moreover according
to a recent scientometric and bibliometric review article on
autonomous vehicles  different naming conventions have
been used over the years to refer to autonomous vehicles
these names are illustrated in figure  note that the year
denotes the publication year of the ﬁrst paper mentioning the
corresponding name
the sae deﬁnes the operational design domain odd for
the safe operation of autonomous vehicles as the speciﬁc
conditions under which a given driving automation system or
feature thereof is designed to function including but not lim
ited to driving modes  odd refers to the domain of
operation which an autonomous vehicle has to deal with an
odd representing an ability to drive in good weather condi
tions is quite different from an odd that embraces all kinds
of weather and lighting conditions the sae recommends
that odd should be monitored at runtime to gauge if the
autonomous vehicle is in a situation that it was designed to
safely handle
b development of autonomous vehicles historical
overview
selfdriving vehicles especially ones considering lower lev
els of automation referring to the taxonomy of automation as
presented in figure  have existed for a long time in 
francis udina presented a remote controlled car famously
known as american wonder in the  new york
worlds fair general motors futurama exhibited aspects of
what we call selfdriving car today general motors and rca
initiated the ﬁrst work around the design and development of
selfdriving vehicles in the early s  that was followed
by prof robert fenton at the ohio state university from
in  ernst dickens at university of munich designed a
robotic van that can drive autonomously without trafﬁc and by
 the robotic van drove up to  kmhr later he started the
development of driving scenes recognition tools using video
imagery  that was followed by a demonstration performed
under the eureka prometheus project the supersmart vehi
cle systems ssvs program in europe  and japan 
were also based on the earlier work of ernst dickens in
 four vehicles drove in a convoy using magnetic mark
ers on the road for relative positioning a similar test was
repeated in  with eight vehicles using radar systems and
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
fig 
the taxonomy of the levels of automation in driving
table ii
list of acronyms
vv communications this work has paved the way for mod
ern adaptive cruise control and automated emergency braking
systems this rd work then witnessed initiatives of pro
grams like the path program by caltrans and the university
of california in  in particular the work on selfdriving
got huge popularity with the demonstration of research work
done by the national automated highway systems consortium
nahsc during   and this climax remained until
fig 
the illustration of different naming conventions used for referring
autonomous vehicles in past years the year denotes the publication year of
ﬁrst paper mentioning corresponding name we see that selfdriving car is
not entirely a new concept and it is referred to through a number of terms
source 
in  the defense advanced research project agency
darpa announced the grand autonomous vehicles challenge
and held the ﬁrst episode in  the ﬁrst grand challenge
was won by carnegie mellon university cmu and their car
only drove nearly seven miles where the ﬁnish line was at
 miles in  the second episode of the darpa grand
challenge was held in which ﬁve out of twentythree teams
were able to reach the ﬁnish line
this time stanford universitys vehicle stanley has won
the challenge in the third episode of darpa grand challenge
in  universities were invited to present the autonomous
vehicles on busy roads to shift the perception of the public
tech and automobile industries about the design and feasibility
of autonomous vehicles
in  google hired the team leads of stanford and cmu
autonomous vehicle projects and started pushing towards their
selfdriving car design on the public roads by the year 
googles selfdriving car has navigated approximately 
thousand miles on the roads of california in quest of achiev
ing the target of  million miles by  in  vislab
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
fig 
the timeline for the development of autonomous vehicles
a spinoff company of the university of parma successfully
completed the international autonomous driving challenge by
driving two orange vans  km with minimal driver inter
ventions from university of parma in italy to shanghai in
china a year later in  volvo demonstrated the road
train concept where one vehicle controls several other vehicles
behind it in order to avoid road congestion in  tesla cars
have started the commercial sales of highway speed intelligent
cruise control based cars with minimal human intervention
in october  google selfdriving car has successfully
achieved the  million miles target it is expected that by
 the state departments of motor vehicles dmv may
permit selfdriving cars on the highways with their special
lanes and control settings by  it is expected that public
transportation will also become driverless and by  it is
foresighted that we will have level autonomous vehicles a
timeline for the development of autonomous vehicles over the
past decades is depicted in figure 
c introduction to connected and autonomous
vehicles cavs
the term connected vehicles refers to the technologies
services and applications that together enable intervehicles
connectivity in connected vehicles settings the vehicles are
httpswwwforbescomsitesjoannmullertheroadtoself
drivingcarsatimelinecf
fig  the basic system architecture of connected vehicles having three types
of communications vehicletovehicle vv infrastructuretoinfrastructure
ii and infrastructuretovehicle iv
equipped with a wide variety of onboard sensors that commu
nicate with each other via can bus and nearby communica
tion infrastructures and vehicles as illustrated in figure 
the applications of connected vehicles include everything
from trafﬁc safety roadside assistance infotainment efﬁ
ciency telematics and remote diagnostics to autonomous
vehicles and gps in general the connected vehicles can be
regarded as a cooperative intelligent transport system  and
fundamental component of the internet of vehicles iov 
a review of truck platooning automation projects formulating
the settings of connected vehicles described earlier together
with various sensors ie radar lidar localization laser
scanners etc and computer vision techniques is presented
in  the key purpose of initiating and investigating such
projects is to reduce energy consumption and personnel costs
by automated operation of following vehicles furthermore it
has been suggested in the literature that throughput on urban
roads can be doubled using vehicle platooning 
cavs is an emerging area of research that is drawing sub
stantial attention from both academia and industry the idea
of connected vehicles has been conceptualized to enable inter
vehicle communications to provide better trafﬁc ﬂow road
safety and greener vehicular environment while reducing fuel
consumption and travel cost there are two types of nodes in
a network of connected vehicles  vehicles having onboard
units obus and  roadside wireless communication infras
tructure or roadside units rsus the basic conﬁguration of
a vehicular network is shown in figure  there are three
modes of communications in such networks vehicletovehicle
vv infrastructuretoinfrastructure ii and vehicleto
infrastructure vi besides these there are two more types
of communicationvehicle to pedestrian vp and vehicle
to anything vxthat are expected to become part of the
future connected vehicular ecosystem
in modern vehicles selfcontained embedded systems called
electronic control units ecus are used to digitally control a
heterogeneous combination of components such as brakes
lighting entertainment and drivetrainpowertrain etc 
there are more than  such embedded ecus in a car that
are executing about  million expressions of code and are
interconnected to control and provide different functionalities
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
fig 
autonomous vehicles major sensor types their range and position ﬁgure adapted from 
fig 
the systematic software workﬂow of autonomous vehicles nuts and bolts of all important operational blocks of software workﬂows are depicted to
provide reader with a better understanding of the system design involved in developing a stateofart autonomous vehicle
such as acceleration steering and braking  the secu
rity of ecus can be compromised and remote attacks can be
realized to gain control of the vehicle as illustrated in 
modern cavs utilize a number of onboard sensors includ
ing proximity short middle and long range sensors while
each of these sensors works in its dedicated range they can
act together to detect objects and obstacles over a wide range
the major types of sensors deployed in autonomous vehicles
and their sensing range are shown in figure  and are brieﬂy
discussed next
 proximity sensors m ultrasonic sensors are proximity
sensors that are designed to detect nearby obstacles when
the car is moving at a low speed especially they provide
parking assistance
 short range sensors m there are two types of short
range sensors  forward and backward cameras and 
short range radars srr forward cameras assist in traf
ﬁc signs recognition and lane departure while backward
cameras provide parking assistance and srr help in blind
spot detection and cross trafﬁc alert
 medium range sensors m the lidar and
mediumrange radars mrr are designed with a medium
range and are used for pedestrian detection and collision
avoidance
 long range sensors m long range radars lrr
enable adaptive cruise control acc at high speeds in
conjunction with the information collected from internal
sensors and from other vehicles and nearby rsu 
the software design of autonomous vehicles utilizing
mldl schemes is divided into ﬁve interconnected modules
namely environmental perception mapping module planning
module controller module and system supervisor figure 
highlights the software design of autonomous vehicles and
it also provides the sensory input required for each software
module to perform the designated task
d securityrelated challenges in developing robust cavs
modern vehicles are controlled by complex distributed com
puter systems comprising millions of lines of code executing
on tens of heterogeneous processors with rich connectivity
provided by internal networks eg can  while this
structure has offered signiﬁcant efﬁciency safety and cost
beneﬁts it has also created the opportunity for new attacks
ensuring the integrity and security of vehicular systems is
crucial as they are intended to provide road safety and are
essentially life critical
different types of attacks on vehicular networks are
described below
 application layer attacks the application layer attacks
affect the functionality of a speciﬁc vehicular application such
as beaconing and message spooﬁng application layer attacks
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
can be broadly classiﬁed as integrity or authenticity attacks
and are brieﬂy described below
a integrity attacks in the message fabrication attack the
adversary continuously listens to the wireless medium
and upon receiving each message fabricates its con
tent accordingly and rebroadcasts it to the network
modiﬁcation of each message may have a different effect
on the system state and depends solely on the design of
the longitudinal control system a comprehensive sur
vey on attacks on the fundamental security goals ie
conﬁdentiality integrity and availability can be found
in  in the spooﬁng attack the adversary imitates
another vehicle in the network to inject falsiﬁed messages
into the target vehicle or a speciﬁc vehicle preceding the
target therefore the physical presence of the attacker
close to the target vehicle is necessarily not required
in a recent study  the use of onboard adas sen
sors is proposed for the detection of location spooﬁng
attack in vehicular networks a similar type of attack
in a vehicular network can be gps spooﬁngjamming
attack  in which an attacker transmits false loca
tion information by generating strong gps signals from a
satellite simulator in addition a thief can use integrated
gpsgsm jammer to restrain a vehicles antitheft system
from reporting the vehicles actual location  in the
replay attack the adversary stores the message received
by one of the networks nodes and tries to replay it later
to attain evil goals  the replayed message contains
old information that can cause different hazards to both
the vehicular network and its nodes for example con
sider the message replaying attack by a malicious vehicle
that is attempting to jam trafﬁc 
b authenticity attacks authenticity is another major chal
lenge in vehicular networks which refers to protecting
the vehicular network from inside and outside mali
cious vehicles possessing falsiﬁed identity by denying
their access to the system  there are two types of
authenticity attacks namely sybil attack and imperson
ation attacks  in a sybil attack a malicious vehicle
pretends many fake identities  and in an imperson
ation attack the adversary exploits a legitimate vehicle
to obtain network access and performs malicious activi
ties for example a malicious vehicle can impersonate a
few nonmalicious vehicles to broadcast falsiﬁed mes
sages  this type of attack is also known as the
masquerading attack
to avoid application layer attacks various cryptographic
approaches can be effectively leveraged especially when an
attacker is a malicious outsider  for instance digital
signatures can be used to ensure messages integrity and to
protect them against unauthorized use  in addition dig
ital signatures can potentially provide both data and entity
level authentication moreover to prevent replay attacks a
timestampbased random number nonce can be embed
ded within messages while the aforementioned methods are
general there are other unprecedented challenges related to
vehicular networks implementation deployment and stan
dardization for example protection against security threats
becomes more challenging with the presence of a trusted
compromised vehicle with a valid certiﬁcate in such cases
datadriven anomaly detection methods can be used  
a survey on anomaly detection for enhancing the security of
connected vehicles is presented in 
 network layer attacks network layer attacks are dif
ferent from the application layer attacks in a way that they can
be launched in a distributed manner one prominent example
of such attacks on vehicular systems is the use of vehicular
botnets to attempt a denial of service dos or distributed
denial of service ddos attack the potential of vehicu
lar networkbased botnet attack for autonomous vehicles is
presented in  the study demonstrates that such an attack
can cause severe physical congestion on hot spot road seg
ments resulting in an increased trip duration of vehicles in the
target area another way to realize the dos attack is to use
network jamming that causes disruption in the communications
network over a small or large geographic area as discussed
earlier current conﬁgurations of vehicular networks are based
on the ieee p standard that uses single control chan
nel cch with multiple service channels sch and can be
attacked by attempting single channel or multichannel jam
ming by swiping between all channels various conventional
techniques can be adopted to mitigate network layer attacks
such as frequency hopping channel and technology switching
etc coalition or platooning attack is a similar type of attack
in which a group of compromised vehicles can cooperate to
perform malicious activities such as blocking or interrupting
communications between legitimate vehicles
 system level attacks the attacks on the vehicles hard
ware and software are known as system level attacks and can
be performed by either malicious insiders at the time of devel
opment or outsiders using unattended vehicular access such
attacks are more serious in nature as they can cause damage
even in the presence of the deployed state of the art secu
rity measures and secure endtoend communications  for
instance if the onboard hardware or software system of a
vehicle is maliciously modiﬁed then the information exchange
between the vehicle and communication systems will be inac
curate and with such a phenomenon the overall performance
and security of the vehicular network will be compromised
in  authors investigated a noninvasive sensor spooﬁng
attack on cars antilock braking system such that the braking
system mistakenly reports a speciﬁc velocity
 privacy breaches
in vehicular networks vehicles
broadcast safety messages periodically that contain critical
information such as vehicle identity current location veloc
ity acceleration etc the adversary can exploit such kind of
information by attempting an eavesdropping attack which is
a type of passive attack and is more difﬁcult to be detected
therefore preserving the privacy of vehicles and drivers is
of utmost importance this allows the vehicles to commu
nicate with each other without disclosing their identities
which is accomplished by masking their identities eg using
pseudonyms in vehicular networks knowing the origin of
the message is crucial for authentication purposes therefore
vehicles should be equipped with privacypreserving authen
tication mechanism ensuring that the communication among
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
vehicles vv and with infrastructure vi is conﬁdential
however intervehicular communication can be eavesdropped
by anyone within the radio range eg a malicious vehicle
can collect and misuse conﬁdential information similarly an
attacker can construct location proﬁles of vehicles by establish
ing a connection with the rsu therefore the effectiveness of
pseudonymous or even complete anonymous schemes in vehic
ular networks remains vulnerable to privacy breaches 
 sensors attacks although sensors of autonomous vehi
cles are by design resilient to environmental noises such as
acoustical interference from nearby objects and vehicles etc
however current sensors cannot resist intentional noise and
it can be injected to realize various attacks such as jamming
and spooﬁng
 attacks on perception system the perception system
of selfdriving vehicles is developed using various computer
vision techniques including modern mldlbased methods
for identifying objects eg pedestrians trafﬁcs signs and
symbols etc the perception system of selfdriving vehicle
is highly vulnerable to the physical world and adversarial
attacks for example suppose were learning a controller f x
to predict the steering angle in an autonomous car as a func
tion of the visionbased input captured into a feature vector
x the adversary may introduce small manipulations ie x is
modiﬁed into x  such that the predicted steering angle f x 
is maximally distant from the optimal angle y
 intrusion detection the detection of malicious activ
ities is one of the major challenges of vanets intrusion
detection systems enable the identiﬁcation of various types of
attacks being performed on the system eg sink and black
hole attacks etc without such a system communication in
vehicular networks is highly vulnerable to numerous attacks
such as selective forwarding rushing and sybil attacks etc
to detect the selective forwarding attack a trust system based
method utilizing local and global detection of attacks among
internodes mutual monitoring and detection of abnormal driv
ing patterns is presented in  alheeti et al proposed a
system for intelligent intrusion detection of gray holes and
rushing attack 
 certiﬁcate revocation
the security mechanism of
vehicular networks is based on trusted certiﬁcation authority
ca that manages the identities and credentials of the vehicles
by issuing valid certiﬁcates to them the vehicles are essen
tially unable to operate in the system without a valid certiﬁcate
and validity of certiﬁcate must be revoked after a certain
amount of time the revocation process is a challenging task
administratively due to challenges such as the identiﬁcation of
nodes with illegitimate behavior and the need to change the
registered domain moreover it is necessary to restrain mali
cious nodes by revoking their certiﬁcates to prevent them from
attacking the system to tackle this problem three different
certiﬁcate revocation protocols have been proposed in 
e nonsecurityrelated challenges in deploying cavs
the phenomenon of connected vehicles is realized using
a technology named vehicular networks which have various
challenges that need to be addressed for their efﬁcient deploy
ment in the longer term that are described below
 high mobility of nodes the large scale mobility of
vehicles in vehicular networks result in a highly dynamic
topology thus raising several challenges for the communica
tion networks  in addition the dynamic nature of trafﬁc
can lead to a partitioned network having isolated clusters
of nodes  as the connections between the vehicles and
nearby rsus are shortlived the wireless channel coherence
time is short this makes accurate realtime channel estima
tion more challenging at the receiver end this necessitates the
design of dynamic and robust resource management protocols
that can efﬁciently utilize available resources while adapting
to the vehicular density variations 
 heterogeneous and stringent qos requirements
in
vehicular networks there are different modes of communi
cations that can be broadly categorized into vv and vi
communications in vv communications vehicles exchange
safetycritical information eg information beacons road and
trafﬁc conditions among each other known as basic safety
messages bsm this communication which can be per
formed periodically or when triggered by some event requires
high reliability and is sensitive to delay 
in vi communications on the other hand vehicles can
communicate with nearby communications infrastructure to
get support for route planning trafﬁc information opera
tional data and to access entertainment services that requires
more bandwidth and frequent access to the internet eg for
downloading highquality maps and accessing infotainment
services etc therefore the heterogeneous and stringent qos
requirements of vanets cannot be simultaneously met with
traditional wireless design approaches
 learning dynamics of vehicular networks as dis
cussed above vehicular networks exhibit high dynamicity
thus to meet the realtime and stringent requirements of vehic
ular networks historical datadriven predictive strategies can
be adopted eg traditional methods like hidden markov mod
els hmm and bayesian methods  in addition to using
traditional ml methods more sophisticated dl models can
be used for example recurrent neural networks rnn and
long short term memory lstm have been shown beneﬁcial
for time series data and can be potentially used for modeling
temporal dynamics of vehicular networks
 network congestion control vehicular networks are
geographically unbounded and can be developed for a city
several cities and countries as well the unbounded nature
of vehicular networks leads to the challenge of network con
gestion  as the trafﬁc density is high in urban areas as
compared to rural areas particularly during rush hours that
can possibly lead to network congestion issues
 time constraints the efﬁcient application of vehic
ular networks requires hard realtime guarantees because
it lays out the foundation for many other applications
and services that require strict deadlines  for exam
ple trafﬁc ﬂow prediction  trafﬁc congestion con
trol  and path planning  therefore safety messages
should be broadcasted in acceptable time either by vehicles
or rsus
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
fig 
the machine learning ml pipeline of cavs comprising of four major modules  perception  prediction  planning and  control
table iii
overview of machine learning mlbased research on different vehicular networks applications
iii the ml pipeline in cavs
the driving task elements of selfdriving vehicles that can
beneﬁt from ml can be broadly categorized into the following
four major components as shown in figure 
 perception assists in perceiving the nearby environment
and recognizing objects
 prediction predicting the actions of perceived objects
ie how environmental actors such as vehicles and
pedestrians will move
 planning route planning of vehicle ie how to reach
from point a to b
 decision making  control making decisions relating
to vehicle movement ie how to make the longitudinal
and lateral decisions to control and steer the vehicle
these components are combined to develop a feedback
system for enabling the phenomenon of selfdriving without
any human intervention this ml pipeline can then facili
tate autonomous realtime decisions by leveraging insights
from the diverse types of data eg vehicles behav
ioral patterns network topology vehicles locations and
kinetics information etc that can be in easily gathered
by cavs
in the remainder of this section we will discuss some of
the most prominent applications of mlbased methods for
performing these tasks a summary is presented in table iii
a applications of ml for the perception task in cavs
different ml techniques particularly dl models have
widely been used for developing the perception system of
autonomous vehicles  in addition to using video cam
eras as major visionary sensors these vehicles also use other
sensors for detection of different events in the cars surround
ings eg radar and lidar the surrounding environment
of the autonomous vehicles is perceived in two stages 
in the ﬁrst stage the whole road is scanned for the detec
tion of changes in the driving conditions such as trafﬁc
signs and lights pedestrian crossing and other obstacles etc
in the second stage knowledge about the other vehicles is
acquired in  a cnn model is trained for developing direct
perception representation of autonomous vehicles
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
b applications of ml for the prediction task in cavs
in cavs accurate and timely prediction of different events
encountered in driving scenes is another important task which
is mainly accomplished using different ml and dl algo
rithms for instance autonomous vehicles uses dl models
for the detection and localization of obstacles  different
objects eg vehicles pedestrians and bikes etc  and
their behavior eg tracking pedestrians along the way 
and trafﬁc signs  and trafﬁc lights recognition 
another prediction tasks in cavs that involve the applica
tion of mldl methods are vehicle trajectory and location
prediction  efﬁcient and intelligent wireless communi
cation  and trafﬁc ﬂow prediction and modeling 
moreover ml schemes have also been used for the prediction
of uncertainties in autonomous driving conditions 
c applications of ml for the planning task in cavs
cavs are equipped with onboard data processing com
patibilities and they intelligently process the data collected
from heterogeneous sensors for efﬁcient route planning and
for other optimized operations using different ml and dl
techniques the key goal of route planning is to reach the
destination in a small amount of time while avoiding trafﬁc
congestion potholes and other vehicles by navigating through
gps and consuming less fuel as possible in the literature
motion planning of autonomous vehicles is studied in three
dimensions  ﬁnding a path for reaching destination point
 searching for the fastest manoeuvre and  determining
the most feasible trajectory  moreover to avoid collisions
between vehicles in cavs predicting the trajectories of other
vehicles is a crucial task for the planning trajectory of an
autonomous vehicle  for instance li presented a hybrid
approach to model uncertainty in vehicle trajectory prediction
for cavs application using deep learning and kernel density
estimation 
d applications of ml for the decision making and control
in recent years dl based algorithms have been exten
sively used for control of autonomous vehicles that are reﬁned
through millions of kilometers of test drives for instance
bojarski et al presented a cnn based endtoend learning
framework for selfdriving cars  the model was able to
drive the car on local roads with or without markings and on
highways with small training data in a similar study cnn is
trained for endtoend learning of lane keeping for autonomous
cars  recently researchers have now started working
on utilizing deep reinforcement learning rl for perform
ing actions and decision making in driving conditions 
bouton et al proposed a generic approach to enforce prob
abilistic guarantees on rl learning for which they derived
an exploration strategy that restricts the rl agent to choose
among only those actions that satisfy a desired probabilistic
speciﬁcation criteria prior to training  moreover human
like speed control of autonomous vehicles using deep rl with
double qlearning is presented in  that uses scenes gener
ated by naturalistic driving data for learning in  authors
presented an integrated framework that uses a deep rl based
approach for dynamic orchestration of networking caching
and computing resources for connected vehicles
in addition mlbased methods have been used for many
other applications in cavs for example adaptive trafﬁc ﬂow
in which smart infrastructure integrates vv signals from the
moving cars to optimize speed limits trafﬁclight timing and
the number of lanes in each direction on the basis of the actual
trafﬁc load the trafﬁc ﬂow can be further improved in cavs
by using cooperative adaptive cruise control technology 
also vehicles can take advantage of cruise control and save
fuel by following one another in the form of vehicles pla
toons moreover dl based methods have been proposed for
intrusion detection for invehicle security of can bus 
the overview of intelligent and connected vehicles current
and future perspectives are presented in 
autonomous vehicles are evolving through four stages of
development the ﬁrst stage includes passive warning and
convenience systems such as front and backward facing cam
eras crosstrafﬁc warning mechanism radar for blind spot
detection etc these warning systems use different computer
vision and machine learning techniques to perceive the sur
rounding views of the vehicle on the road and to recognize
trafﬁc signs static and moving objects in the second stage
these systems are used to assist the active control system of
the vehicle while parking braking and to prevent backing
over unseen objects in the third stage the vehicle is equipped
with some semiautonomous operationsas the vehicle may
behave unexpectedly and the on seat driver should be able to
resume control in the ﬁnal stage the vehicle is designed to
perform fully autonomous operations
cavs together formulate the settings of the selfdriving
vehicular network and there is a strong synergy between
them  in addition autonomous vehicles are an important
component of future vehicular networks that are equipped
with complex sensory equipment the autonomous vehicu
lar networks are predictive and adaptive to their environments
and are designed with two fundamental goals ie autonomy
and interactivity the ﬁrst goal enables the network to mon
itor plan and control itself and the later ensures that the
infrastructure is transparent and friendly to interact with
the deployment of ml in cavs entails the following
stages
a data collection input data is collected using sen
sors or from other digital repositories in autonomous
vehicles input data is collected using a complex sen
sory network eg cameras radar gps etc see
figure  in a connected vehicular ecosystem there is
also intervehicle information communication
b preprocessing
the
heterogeneous
data
video
imagery network and trafﬁc information etc col
lected by the sensors is then digitally processed and
appropriate features eg trafﬁc signs information and
trafﬁc ﬂow information etc are extracted
c model training using the extracted features from the
input data a ml model is trained to recognize and dis
tinguish between different objects events encountered
in the driving environment eg recognizing moving
objects like pedestrian vehicles and cyclists etc and
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
fig 
the illustration of the generalization of attack surfaces in ml systems generic model top autonomous vehicles model middle and connected
vehicles model bottom
fig 
the taxonomy of adversarial examples perturbation methods and benchmarks datasets and models
distinguishing between trafﬁc signs ie stop or speed
limit sign etc
d decision or action a decision or an action eg stop
ping the car at the stop sign and predicting trafﬁc
ﬂow based on the knowledge acquired by the vehic
ular network is performed according to the learned
knowledge and underlying system
we present an illustration of the generalization of attack
surfaces in ml systems from generic models to the more spe
ciﬁc cases of autonomous and connected vehicles in figure 
as we shall discuss later in the paper each of these stages
is vulnerable to adversarial intrusion since an adversary can
try to manipulate the data collection and processing system
tamper the model or its outputs
iv adversarial ml attacks and the adversarial
ml threat for cavs
a comprehensive overview of adversarial ml in the context
of cavs is presented in this section
a adversarial examples
formally adversarial examples are deﬁned as inputs to a
deployed mldl model created by an attacker by adding an
imperceptible perturbation in the actual input to compromise
the integrity of the mldl model an adversarial sample x 
is created by adding a small carefully crafted perturbation δ
to the correctly classiﬁed sample x the perturbation δ is cal
culated by approximating the optimization problem given in
eq  iteratively until the crafted adversarial example gets
classiﬁed by ml classiﬁer f  in targeted class t a tax
onomy of adversarial examples perturbation methods and
benchmarks is presented in figure 
x  x  arg min
δ δ f x  δ  t
 adversarial attacks an adversarial attack affecting the
training phase of the learning process is termed as poisoning
attack where an attacker compromises the learning process of
the mldl scheme by manipulating the training data 
whereas the adversarial attack on the inference phase of the
learning process is termed as evasion attack where an attacker
manipulates the test data or realtime inputs to the deployed
model for producing a false result  usually examples used
for fooling the mldl schemes at inference time are called
adversarial examples
 adversarial perturbations the adversarial perturbation
crafting is divided in three major categories namely local
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
search combinatorial optimization and convex relaxation
this division is based on solving the objective function given
in eq  local search is the most common method of gener
ating adversarial perturbations where the adversarial examples
are generated by solving the objective function provided in
eq  to obtain a lower bound on the adversarial perturbation
by using gradientbased methods a prime example of local
search adversarial example crafting is the fast gradient sign
method fgsm where an adversarial example is created by
taking a step in the direction of the gradient  in another
study the authors demonstrated that adversarial images are
very easy to be constructed using evolutionary algorithms
or gradient ascent  combinatorial optimization is also
a method for creating adversarial examples where we ﬁnd
the exact solution of the optimization problem provided in
eq  a major shortcoming of this method is the increase in
the computational complexity with the increase of the num
ber of examples in the dataset recently khalil et al 
launched a successful adversarial attack based on combina
torial and integer programming on binarized neural networks
but the performance of the proposed attack reduces as the size
and dimensions of data increase recently convex relaxation is
also used to generate  and defend  against adversar
ial examples where the upper bound on the objective function
provided in eq  is calculated
 different aspects of perturbations
the adversarial
examples are designed to look like the original ones and
imperceptible to humans in this regard the addition of small
perturbations is of utmost importance whereas the literature
suggests that even onepixel perturbation is often sufﬁcient to
fool the deep model trained for classiﬁcation task  here
we analyze different aspects of adversarial perturbations
a perturbation scope adversarial perturbations are gen
erated from two aspects  perturbations for each
legitimate input and  universal perturbations for the
complete datasets ie for each original cleaned sample
to date most of the studies considered the ﬁrst scope of
adversarial perturbations
b perturbation limitation similarly there are two types of
limitations optimizing the system at a low perturbations
scale and optimizing the system at a low perturbations
scale with constrained optimization
c the magnitude of the perturbations is mainly measured
using three norms l l and l norm in lnorm
based attacks the attacker aims to minimize the squared
error between the original and adversarial example l
norm measures the euclidean distance between the adver
sarial example and the original sample and results in a
very small amount of noise added to the adversarial sam
ple lattacks are perhaps the simplest type of attacks
which aim to limit or minimize the extent to which the
maximum change for all pixels in adversarial examples is
achieved also this constraint forces to only make very
small changes to each pixel lnormbased attacks work
by minimizing the number of perturbed pixels in an image
and force the modiﬁcations only to very few pixels
to ensure tightly constrained action space available to an
adversary imperceptibility of perturbations is important to
develop an attack considering the important constraints 
what constraints are placed on the attackers starting point
and  where did this initial example come from gilmer et al
identiﬁed four salient features described below of adversarial
perturbations 
a indistinguishable perturbation the attacker does not
have to select a starting point but it is given a draw from
the data distribution and introduces such perturbation in
the input sample that is indistinguishable by a human
b contentpreserving perturbation the attacker does not
have to select a starting point but it is given a draw from
the data distribution and creates such perturbation as long
as the original content of the sample is preserved
c nonsuspicious input the attacker can generate any type
of desired perturbed input sample as long as it remains
undetectable to a human
d contentconstrained input the attacker can generate any
type of desired perturbed input sample as long as it
maintains some content payload ie it must be a pic
ture of dog but not necessarily a particular dog this
includes payloadconstrained input where human percep
tion might not be important rather the intended function
of the input example remains intact
e unconstrained input there is no constraint on the input
and an attacker can produce any type of input example
to get the desired output or behavior from the system
 adversarial
ml
benchmarks
in
this
section
we
describe the benchmarks datasets and victim ml models used
for evaluating adversarial examples researchers mostly adopt
an inconsistent approach and report the performance of the
attacks on diverse datasets and victim models the widely used
benchmark datasets and victim models are described below
 datasets
mnist
cifar
and
imagenet
are
the
widely
used
datasets
in
adversarial ml research and are also regarded as the
standard deep learning datasets
 victim models the widely used victim mldl models
for evaluating adversarial examples are lenet 
alexnet
vgg
googlenet
caffenet  and resnet 
b threat models for adversarial ml attacks on cavs
threat modeling is the procedure of answering a few com
mon and straight forward questions related to the system being
developed or deployed from a hypothetical attackers point of
view threat modeling is a fundamental component of security
analysis it requires that some fundamental questions related
to the threat are addressed  in particular a threat model
should identify
 the system principals what is the system and who are the
stakeholders
 the system goals what does the system intend to do
 the system adversities what potential bad things can hap
pen due to adverse situations or motivated adversaries
 the system invariants what must be always true about
the system even if bad things happen
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
fig 
the taxonomy of various types of threat models used in literature to design adversarial ml attacks this ﬁgure also provides the information needed
by a defender to ensure the robustness of mlbased autonomous system
the key goal of threat modeling is to optimize the secu
rity of the system by determining security goals identifying
potential threats and vulnerabilities and to develop counter
measures for preventing or mitigating their associated effects
on the system answering these questions requires careful
logical thoughts and signiﬁcant expertise and time
as the focus of this paper is on highlighting the potential
vulnerabilities of using ml techniques in cavs the scope of
our study is restricted to the adversarial ml threat in cavs in
the remainder of this section we discuss the various facets of
the adversarial ml threats in cavs a taxonomy aggregating
these issues is illustrated in figure 
 adversarial attack type in the literature the attacks
on learning systems are generally categorized into three
dimensions 
a inﬂuence it includes causative trying to get control
over training data and exploratory exploiting mis
classiﬁcations of the model without affecting the training
process attacks
b speciﬁcity it involves targeted and indiscriminate attacks
on a speciﬁc instance
c security violation it is concerned with the integrity of
assets and availability of the service attack
the ﬁrst dimension describes the capabilities of the adver
sary and whether the attacker has the ability to affect the
learning by poisoning training data instead the attacker
exploits the model by sending new samples and observing
their responses to get the intended behavior the second axis
indicates the speciﬁc intentions of the attacker ie whether
the attacker is interested in realizing a targeted attack on one
particular sample or he aims to cause learned model t fail in an
indiscriminate fashion the third dimension detail the types of
security violation an attacker can cause eg the attacker may
aim to bypass harmful messages to bypass through the ﬁlter as
false negatives or realizing denial of service by causing benign
samples misclassiﬁed as false positives
 adversarial
knowledge
based
on
the
adversarial
knowledge available to the adversaries the adversarial ml
attacks are divided into three types namely whitebox gray
box and blackbox attacks whitebox attacks assume com
plete knowledge about the underlying ml model including
information about the optimization technique the trained
ml model model architecture activation function hyper
parameters layer weights and training data graybox attacks
assume a partial knowledge about the targeted model whereas
the blackbox adversarial attack assumes the adversary has
zero knowledge and no access to the underlying ml model
and the training data black box attack refers to the real
world knowledge where there is not much information about
the targeted mldl scheme is available in such cases the
adversary acts as a normal user and tries to infer from
the output of the ml system blackbox adversarial attacks
make use of transferability property of adversarial exam
ples where it is assumed that adversarial examples created
for one mldl model will affect other models trained on
datasets with a similar distribution to that of the original
model 
 adversarial capabilities adversarial capabilities are
important to be identiﬁed in security practice as they deﬁne
the strength of the adversaries to compromise the security
of the system in general an adversary can be stronger or
weaker based on the knowledge and access to the system
adversarial capabilities advocate how and what type of attacks
an adversary can realize using what type of attack vector on
which attack surface the attacks can be launched at two
main phases namely inference and training inference time
attacks are exploratory attacks that do not modify the under
lying model instead they inﬂuence it to produce incorrect
outputs inference attacks vary with the availability of system
knowledge the training time attacks aim at tampering with
the model itself or inﬂuence its learning process and involve
two types of attack methods  in the ﬁrst type adversarial
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
examples are injected in the training data and in the second
type training data is directly modiﬁed
 adversarial speciﬁcity another classiﬁcation of the
adversarial attacks is based on the speciﬁcity of the adver
sarial examples where adversarial attacks are classiﬁed as
targeted and nontargeted attacks the attacks where adversar
ial perturbations are added to compromise the performance of
a speciﬁc class in the data are known as the targeted adversarial
attacks targeted adversarial attacks are launched by adver
saries to create targeted misclassiﬁcation ie a speciﬁc road
sign will be misclassiﬁed by the selfdriving vehicle while the
rest of the road sign classiﬁcation system will function cor
rectly or sourcetarget misclassiﬁcation ie a certain road
trafﬁc sign will be always classiﬁed in a predetermined wrong
class by the road sign classiﬁer in a selfdriving vehicle
whereas adversarial perturbations created for deteriorating the
performance of the model irrespective of any class of data
are known as nontargeted adversarial attacks nontargeted
attacks are launched by adversaries to reduce the classiﬁca
tion conﬁdence ie a trafﬁc sign will be detected with less
accuracy which was previously detected with high accuracy
and misclassiﬁcation ie a road trafﬁc sign will be classiﬁed
in any other class than its original one
 adversarial falsiﬁcation the adversary can attempt
two types of falsiﬁcation attacks namely false positive
attacks and false negative attacks  in the ﬁrst attack an
adversary generates a negative sample which can be misclas
siﬁed as a positive one lets assume such attack has been
launched on the image classiﬁcation system of an autonomous
vehicle a false positive will be an adversarial image pre
dicted to be of a class with high conﬁdence to whom it did
not belong and is unrecognizable to humans on the contrary
while attempting false negative attacks the adversary gener
ates a positive sample which can be misclassiﬁed as a negative
one in adversarial ml this type of attack is referred to as an
evasion attack
 attack frequency the adversarial attacks can be single
step or consist of an iterative optimization process compared
to single step attacks iterative adversarial attacks are stronger
however they require frequent interactions for querying the
ml system and subsequently require a large amount of time
and computational resources for their efﬁcient generation
 adversarial goals the last component of the threat
modeling is the articulation of the adversarys goals the clas
sical approach to model adversarial goals includes modeling of
the adversarys desires to impact the conﬁdentiality integrity
and availability known as the cia model and a fourth yet
important dimension is the privacy 
c review of existing adversarial ml attacks
 adversarial ml attacks on conventional ml schemes
a pioneering work on adversarial ml was performed by
dalvi et al  in  where they proposed a mini
mum distance evasion of the linear classiﬁer and tested there
proposed attack on spam classiﬁcation system highlighting the
threat of adversarial ml examples a similar contribution was
made by lowd and meek  in  where they proposed
adversarial classiﬁer reverse engineering technique for con
structing an adversarial attack on classiﬁcation problems in
 barreno et al  discussed the security of ml in
adversarial environments and provided a taxonomy of attacks
on ml schemes along with the potential defenses against
them in  huang et al  provided the ﬁrst con
solidated review of adversarial ml where they discussed the
limitations on the classiﬁers and adversaries in realworld set
tings biggio et al  proposed poisoning attack on support
vector machines svm to increase the test error in svm
their attack successfully altered the test error of svm with
linear and nonlinear kernels the same authors also proposed
an evasion attack where they used a gradientbased approach
for evading pdf malware detectors  and tested their attack
on svm and simple neural networks
 adversarial ml attacks on dnns adversarial ml
attacks on dnns were ﬁrst observed by szegedy et al 
where they demonstrated that dnns can be fooled by mini
mally perturbing their input images at test time the proposed
attack was a gradientbased attack where minimum distance
based adversarial examples were crafted to fool the image
classiﬁers another gradientbased attack was proposed by
goodfellow et al  in this attack they formulated adversar
ial ml as a minmax problem and adversarial examples were
produced by calculating the lower bound on the adversarial
perturbations this method was termed as fgsm and is still
considered a very effective algorithm for creating adversarial
examples adversarial training was also introduced in the same
paper as a defensive mechanism against adversarial exam
ples kurakin et al  highlighted the fragility of mldl
schemes in realworld settings using images taken from a cell
phone camera for adversarial example generation the adver
sarial samples were created by using the basic iterative method
bim an extended version of fgsm the resultant adversar
ial examples were able to fool the stateofart image classiﬁer
in  authors demonstrated that only rotation and trans
lation are sufﬁcient for fooling stateoftheart deep learning
based image classiﬁcation models ie convolutional neural
networkscnns in a similar study  ten stateoftheart
dnns were shown to be fragile to the basic geometric trans
formation eg translation rotation and blurring liu et al
presented a trojaning attack on neural networks that works by
modifying the neurons of the trained model instead of affecting
the training process  authors used trojan as a backdoor
to control the trojaned ml model as desired and tested it on
an autonomous vehicle the car misbehaves when a speciﬁc
billboard trojan trigger is encountered by it on the roadside
papernot et al  exploited the mapping between the
input and output of dnns to construct a whitebox jacobian
saliencybased adversarial attack jsma scheme to fool the
dnn classiﬁers the same authors also proposed another
defense against adversarial perturbations by using defensive
distillation defensive distillation is a training method in which
a model is trained to predict the classiﬁcation probabilities
of another model which was trained on the baseline standard
to give more importance to accuracy papernot et al 
also proposed a blackbox adversarial ml attack where they
exploited the transferability property of adversarial examples
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
table iv
summary of the stateoftheart attacks
to fool the mldl classiﬁers this blackbox adversarial
attack was based on the substitute model training which
not only fools the mldl classiﬁers but also breaks the
distillation defensive mechanism carlini and wagner 
proposed a suite of three adversarial attacks termed as cw
attacks on dnns by exploiting three distinct distance mea
sures l l and l these attacks have not only evaded
the dnn classiﬁers but also evaded the defensive distillation
successfully this demonstrated that defensive distillation is
not an appropriate method for building robustness in another
paper carlini and wagner  presented that the proposed
adversarial attacks in  have successfully evaded the ten
well known defensive schemes against adversarial examples
right now these attacks are also considered as stateofart
adversarial ml attacks furthermore carlini and wagner
successfully demonstrated an adversarial attack on speech
recognition system by adding small noise in the audio sig
nal that forces the underlying ml model to generate intended
commandstext  in  an adversarial patch afﬁxed to
an original image forces the deep model to misclassify that
image such universal targeted patches fool classiﬁers with
out requiring knowledge of the other items in the scene such
patches can be created ofﬂine and then broadly shared more
details on adversarial ml attacks can be found in  
    a summary of different stateofthe
art adversarial perturbation generation methods is provided in
table iv
d adversarial ml attacks on cavs
ml and dl act as core ingredients for performing many
key tasks in selfdriving vehicles beyond providing deeply
embedded information for the decision making process within
the vehicles components they also play an important role in
vi and vv and vx communications as described in ear
lier sections mldl schemes are very vulnerable to small
carefully crafted adversarial perturbations selfdriving vehi
cles are also threatened by this security risk along with other
traditional security risks adversarial ml has affected many
application domains including imaging text networking and
audio as highlighted in table v
 autonomous vehicles accidents due to unintended
adversarial conditions the autonomous vehicles developed
so far are not robust to unintended adversarial conditions and
there have been few reported fatalities caused by the malfunc
tioning of dnnbased autonomous vehicles where adversarial
table v
domains affected by adversarial machine
learning ml and their applications
examples were unintentionally created by the dnn operating
the autonomous vehicle in  during hyundai competition
an autonomous vehicle crashed because of a sensor failure due
to shifting in the angle of the car and direction of the sun
another incident was reported in  where a tesla autopilot
was not able to handle the image contrast which resulted in
the death of the driver it was also reported that the tesla
autopilot unable to differentiate between the bright sky and a
white truck which resulted in a horrible accident a similar
accident happened to google selfdriving car where the car
was unable to estimate the relative speed which resulted in a
collision with a bus in  uber selfdriving car also faced
an accident due to malfunctioning in the dnnbased system
which resulted in a pedestrian fatality table vi provides a
detailed description of accidents caused by malfunctions in
different components of selfdriving vehicles
 physical
world
attacks
on
autonomous
vehicles
aung et al  used fgsm and jsma schemes to
generate adversarial trafﬁc signs to successfully evade the
dnnbased trafﬁc sign detection schemes to highlight the
problem of adversarial examples in autonomous driving
sitawarin et al  proposed a realworld adversarial ml
attack by altering the trafﬁc signs and logos with adversar
ial perturbations while keeping the visual perception of the
trafﬁc and logo signs in another work sitawarin et al 
httpsbitlyswlxuy
httpscnnmonievob
httpsbitlyuoyx
httpsbitlyswmbn
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
table vi
accidents caused by selfdriving vehicles due to
unintended adversarial conditions
proposed a technique for generating outofdistribution adver
sarial examples to perform an evasion attack on mlbased
sign recognition system of autonomous vehicles they also
proposed a lenticular printing attack where they exploited the
camera height in autonomous vehicles to create an illusion of
false trafﬁc signs in the physical environment to fool the sign
recognition system of autonomous vehicles
object detection is another integral part of the perception
module of autonomous vehicles where stateoftheart dnn
based schemes such as mask rcnn  and yolo 
are used for object detection zhang et al  proposed
a camouﬂage physical world adversarial attack by approxi
mately imitating how a simulator applies camouﬂage to the
vehicle and then minimized the approximated detection score
by using local search for optimal camouﬂage the proposed
adversarial attack successfully fooled imagebased object
detection systems another physical world adversarial exam
ple generation scheme on object detection is performed by
song et al  where the perturbed stop sign remained
hidden from the stateofart object detectors like mask rcnn
and yolo they produced adversarial perturbations by the
robust physical perturbations rp  algorithm recently
zhou et al  proposed deepbillboard a systematic way
for generating adversarial advertisement billboards to inject a
malfunction in the steering angle of the autonomous vehicle
the proposed adversarial billboard misled the average steer
ing angle by  degrees table vii provides a summary of
stateoftheart adversarial attacks on selfdriving vehicles in
a recent study  imitation learning has been shown robust
enough for autonomous vehicles to drive in a realistic envi
ronment authors proposed a model named chauffeurnet that
learns to drive the vehicle by imitating best and synthesizing
worst
v towards developing adversarially
robust ml solutions
as discussed above despite the outstanding performance
of ml techniques in many settings including human level
accuracy at recognizing images these techniques exhibit strict
vulnerability to carefully crafted adversarial examples in this
section we present an outline of approaches for developing
adversarially robust ml solutions we deﬁne the robustness as
the ability of the ml model to restrain adversarial examples
in the literature defenses against adversarial attacks have
been divided into two broad categories  reactive detect
adversarial observations input after deep models are trained
and  proactive make the deep model robust against adver
sarial examples before the attack
alternatively these techniques can also be broadly divided
into three categories  modifying data  adding auxil
iary models and  modifying models the reader is referred
to figure  for a visual depiction of a taxonomy of robust
ml solutions in which various techniques that fall in these
categories are also listed these categories are detailed next
a modifying data
the methods falling under this category mainly deal with
modiﬁcation of either the training data eg adversarial
retraining and its features or test data eg data pre
processing widely used approaches that utilize such methods
are described below
 adversarial retraining the training with adversarial
examples has been ﬁrstly proposed by goodfellow et al 
and huang et al  as a defense strategy to make deep
neural networks dnns robust against adversarial attacks
they trained the model by augmenting adversarial examples
in the training set furthermore goodfellow et al showed
that adversarial training could provide better regularization for
dnns in   the adversarial robustness of ml models
was evaluated on the mnist dataset having  classes while
in  a comprehensive evaluation of adversarial training
was performed on a considerably large dataset ie imagenet
having  classes the authors used  of the dataset for
adversarial training and this strategy increased the robustness
of dnns for single step adversarial attack eg fgsm 
however the strategy failed for iterative adversarial exam
ples generation methods such as the basic iterative method
bim 
 input reconstruction the idea of input reconstruc
tion is to clean the adversarial examples to transform them
back to legitimate ones once the adversarial examples have
been transformed they will not affect the prediction of dnn
models for robustifying dnn a technique named deep con
tractive autoencoder has been proposed in  they trained
a denoising autoencoder for cleaning adversarial perturbations
 feature squeezing xu et al  leveraged the obser
vation that input feature spaces are typically unnecessarily
large and provide a vast room for an adversary to construct
adversarial perturbations and thereby proposed feature squeez
ing as a defense strategy to adversarial examples the available
feature space to an adversary can be reduced using feature
squeezing that combines samples having heterogeneous fea
ture vectors in the original space into a single space they
perform feature squeezing at two levels  reducing color
bit depth  spatial domain smoothing using both local and
nonlocal method also they evaluated eleven stateoftheart
adversarial perturbations generation methods on three differ
ent datasets ie mnist cifar and imagenet however
this defense strategy was found to be less effective in a later
study 
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
table vii
adversarial attacks on selfdriving vehicles summary of stateoftheart
 features masking in  authors proposed to add a
masking layer before the softmax layer of the classiﬁer that is
mainly responsible for the classiﬁcation task the purpose of
adding the masking layer was to mask the most sensitive fea
tures of input that are more prone to adversarial perturbations
by forcing the corresponding weights of this layer to zero
 developing adversarially robust features this method
has been recently proposed as an effective approach to make
dnns resilient against adversarial attacks  authors
leveraged the connections between the natural spectral geo
metrical property of the dataset and the metric of interest
for developing adversarially robust features they empirically
demonstrated that the spectral approach can be effectively used
to generate adversarially robust features that can be ultimately
used to develop robust models
 manifold projection in this method input examples are
projected on the manifold of learned data from another ml
model generally the manifold is provided by a generative
model for instance song et al  leveraged generative
models to clean the adversarial perturbations from malicious
images and then the cleaned images are given to the non
modiﬁed ml model furthermore this paper ascertains that
regardless of the attack type and targeted model the adversar
ial examples lie in the low probability regions of the training
data distribution in a similar study  authors used gen
erative adversarial networks gans for cleaning adversarial
perturbations similarly meng and chen proposed a frame
work named magnet that includes one or more detectors and
a reformer network  the detector network is used to clas
sify normal and adversarial examples by learning the manifold
of normal examples whereas the reformer network moves
adversarial examples towards the learned manifold
b modifying model
the methods that fall in this category mainly modify the
parametersfeatures learned by the trained model eg defen
sive distillation a few prominent such methods are described
next
 network distillation
papernot et al  adopted
network distillation as a procedure to defend against adversar
ial attacks and presented a defense method known as defensive
distillation the notion of distillation was originally proposed
by hinton et al  as a mechanism for effectively transfer
ring knowledge from a larger network to a smaller one the
defense method developed by papernot et al uses the prob
ability distribution vector generated by the ﬁrst model as an
input to the original dnn model this increases the resilience
of the dnn model towards very small perturbations however
carlini and wagner showed that the defensive distillation
method does not work against their proposed attack 
 network veriﬁcation network veriﬁcation aims to ver
ify the properties of dnn ie whether an input satisﬁes or
violates certain property because it may restrain new unseen
adversarial perturbations for instance a network veriﬁcation
method for robustifying dnn models using relu activation
is presented in  to verify the properties of the deep
model the authors used the satisﬁability modulo theory smt
solver and showed that the network veriﬁcation problem is
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
fig 
taxonomy of robust machine learning ml methods categorized into three classes  modifying data  adding auxiliary models and
 modifying models
npcomplete the assumption of using relu with certain
modiﬁcations is addressed in 
 gradient regularization ross and doshivelez 
proposed using input gradient regularization as a defense strat
egy against adversarial attacks in the proposed approach they
used differentiable dnn models and penalized the variation
that results in the output with a change in the input as a result
adversarial examples with small perturbations were unlikely to
modify the output of deep models but this increases the train
ing complexity with a factor of two the notion of penalizing
the gradient of loss function of models with respect to the
inputs for robustiﬁcation has been already been investigated
in 
 classiﬁer robustifying in this method classiﬁcation
models that are robust to adversarial attacks are designed
from the ground up instead of detecting or transform
ing them bradshaw et al  utilized the uncertainty
around the adversarial examples and developed a hybrid
model using gaussian processes gps with rbf kernels
on top of dnns and showed that their approach is robust
against adversarial attacks the latent variable in gps is
expressed using a gaussian distribution and is parameter
ized by mean and covariance and encoded with rbf kernels
schott et al  proposed the ﬁrst adversarially robust
classiﬁer for mnist dataset where robustness is achieved by
using analysis by synthesis through learned classconditional
data distribution this work highlights the lack of research
that
provides
guaranteed
robustness
against
adversarial
attacks
 explainable
and
interpretable
ml
in
a
recent
study  an adversarial example detection approach is
presented for a face recognition task that leverages the inter
pretability of dnn models the key in this approach is
the identiﬁcation of critical neurons for an individual task
that is performed by establishing a bidirectional correspon
dence inference between the neurons of a dnn model and
its attributes then the activation values of these neurons are
ampliﬁed to augment the reasoning part and the values of
other neurons are decreased to conceal the uninterpretable part
recently nicholas carlini showed that this approach does not
defend against untargeted adversarial perturbations generated
using lnorm with a bound of  
 masking ml model in a recent study  authors
formulated the problem of adversarial ml as learning and
masking problem and presented a classiﬁer masking method
for secure learning to mask the deep model they introduced
noise in the dnns logit output that was able to defend against
low distortion attacks
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
c adding auxiliary models
these methods aim to utilize additional ml models to
enhance the robustness of the main model eg using gen
erative models for adversarial detection such widely used
methods are described as follows
 adversarial detection in adversarial detection strategy
a binary classiﬁer detector is trained eg dnn to identify
the input as a legitimate or an adversarial one  
in  authors used a simple dnnbased binary adversar
ial detector as an auxiliary network to the main model in a
similar study  authors introduced an outlier class while
training the dnn model the model then detects the adversar
ial examples by classifying them as an outlier this defense
approach has been used in a number of studies in the literature
 ensembling defenses as adversarial examples can be
developed in a multifacet fashion therefore multiple defense
methods can be combined together parallelly or sequentially
to defend against them  pixeldefend  is a prime
example of ensemble defense in which an adversarial detector
and an input reconstructor are integrated to restrain adver
sarial examples however he et al showed that an ensemble
of weak defense strategies does not provide a strong defense
to adversarial attacks  further they demonstrated that
adaptive adversarial examples transfer across several defense
or detection proposals
 using generative ml models goodfellow et al 
ﬁrstly coined the idea of using generative training to defend
adversarial attacks however in the same study they argued
that being generative is not sufﬁcient and presented an alterna
tive hypothesis of ensemble training that works by ensembling
multiple instances of original dnn models in  an
approach named cowboy is presented to detect and defend
against adversarial examples they transformed adversarial
samples back to data manifold by cleaning them using a gan
trained on the same dataset furthermore authors empirically
showed that adversarial examples lie outside the data manifold
learned by the gan ie the discriminator of gan consis
tently scores the adversarial perturbations lower than the real
samples across multiple attacks and datasets in another similar
study  a ganbased framework named defensegan
is trained for modeling the distribution of legitimate images
during inference time defensegan ﬁnds a similar output
without adversarial perturbations that is then fed to the origi
nal classiﬁer also the authors of both of these studies claimed
that their method is independent of the dnn model and attack
type and that it can be used in existing settings the sum
mary of various stateoftheart adversarial defense studies is
presented in table viii
d potential of adversarial defenses for cavs
the adversarial defense methods described in the above
sections are general ie they are developed to make dnn
resilient against adversarial attacks however these methods
have a great potential to be used for the robust application
of dl models in cavs settings and can be used for robus
tifying various applications as described in section iii of
mldl in cavs ecosystem for instance defense methods
fig 
the taxonomy of different adversarial defense evaluation methods
and recommendations
aiming at robustifying the dnn classiﬁer can be used for
developing adversarially robust objection detection systems
also in cavs the presence of adversaries who may want to
harm the cavs environment is more common eg consider
an adversary trying to get the control of the autonomous car
in an attempt to force the vehicle to cause an accident etc
and the above mentioned general adversarial defense methods
can provide robustness to mldl applications in cavs
however more research is needed to design implement and
experiment with new adversarial defenses that are customized
from the groundup for cavs such defenses should bene
ﬁt from existing general adversarial defense techniques while
taking cavs safety delay and computational constraints into
considerations we believe that such defenses can hasten the
deployment of ml models in practical cavs settings
e adversarial defense evaluation methods and
recommendations
this section presents different potential methods for per
forming the evaluation of adversarial defenses along with an
outline of common evaluation recommendations as depicted
in figure 
 principles for performing defense evaluations in a
recent study  carlini et al provided recommendations
for evaluating adversarial defenses and thereby provided three
common reasons to evaluate the performance of adversarial
defenses these recommendations are brieﬂy described below
a defending against the adversary defending against
adversaries attempting adversarial attacks on the system is
crucial as it is a matter of security concern in realworld
applications if the mlbased systems are deployed without
considering the security threats then the adversaries willing to
harm the system will continue to practice attacking the system
as long as there are incentives the nature and sovereignty
of attacks vary with adversarial capabilities and knowledge
etc in this regard proper and wellthought threat modeling
described in detail in an earlier section is of paramount
importance
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
table viii
summary of stateoftheart adversarial defense approaches
b testing worstcase robustness in realworld settings
testing the worstcase robustness of ml models from the
perspective of an adversary is crucial as realworld systems
exhibit randomness that is hard to be predicted compared
to the random testing approach worstcase analysis can be a
powerful tool to distinguish a system that fails one time in
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
a billion trials from a system that never fails for instance
if a powerful adversary who is attempting to harm a system
to get intentional misbehavior fails to do so then it provides
strong evidence that the system will not misbehave in case of
previously unforeseen randomness
c measuring progress of ml towards human level
abilities to advance ml techniques it is important to under
stand why ml algorithms fail in a particular setting in the
literature we see that the performance gap between ml meth
ods and humans is considerably small on many complex tasks
eg natural image classiﬁcation  mastering the game
of go using reinforcement learning  and human level
accuracy in the medical domain   however in
case of evaluating adversarial robustness the performance gap
between humans and ml systems is very large this is so true
for the cases where ml models exhibit superhuman accuracy
ie an adversarial attack can completely evade the prediction
performance of the system this leads to the belief that there
exists a fundamental difference between the decision making
process of humans and ml models so keeping this aspect in
mind adversarial robustness is the measure of ml progress
that is orthogonal to performance
 common evaluation recommendations in this section
we provide a brief discussion on the common evaluation rec
ommendations and we refer interested readers to the recent
article of carlini et al  for a detailed and comprehen
sive description on evaluation recommendations and pitfalls
for adversarial robustness as authors promised to update this
paper timely therefore we also refer interested readers to fol
lowing url for an updated version of this paper to avoid
unintended consequences and pitfalls of evaluation methods
the following evaluation recommendations can be adopted
a use
both
targeted
and
untargeted
attacks
adversarial robustness should be evaluated on both targeted
and untargeted attacks in any case it is important to explic
itly state which attack were considered while evaluating
theoretically an untargeted attack is considered to be strictly
easier than a targeted attack but practically performing an
untargeted attack can give better results than targeting any
of n  classes many untargeted attacks mainly work by
minimizing the prediction conﬁdence of the correct label
contrarily targeted attacks work by maximizing the prediction
conﬁdence of some other class
b perform
ablation
perform
ablation
analysis
by
removing a combination of defense components and verifying
that the attack succeeds on a similar but undefended model
this is useful to develop a straight forward understanding
of the goals of the evaluation and assess the effectiveness
of combining multiple defense strategies for robustifying the
model
c diverse test settings perform the evaluation in diverse
settings ie test the robustness to random noise validate
broader threat models and carefully evaluate the attack hyper
parameters and select those that provide the best performance
it is also important to verify that the attack converges under
selected hyperparameters also investigate whether attack
httpsgithubcomevaluatingadversarialrobustnessadvevalpaper
results are sensitive to a speciﬁc set of hyperparameters in
addition experiment witg at least one hard label attack and
one gradient free attack
d evaluate defense on broader domains for a defense
to be truly effective consider evaluating the proposed defense
method on broader domains other than images for instance
the majority of works on adversarial machine learning mainly
investigate the imaging domain state explicitly if the defense
is only capable of defending adversarial perturbations in a
speciﬁc domain eg images
e ensemble over randomness it is important to cre
ate adversarial examples by ensembling over the randomness
of those defenses that randomize aspects of dnn inference
the introduced randomness enforces stochasticity and stan
dard attacks become hard to be realized verify that the
attack remains successful when randomness is assigned a ﬁxed
value also deﬁne the threat model and the availability of
randomness knowledge to the adversary
f transferability attack
select a similar substitute
model to the defended model and perform transferability of
the attack because the adversarial examples are often trans
ferable across different models ie an adversarial sample
constructed for one model often appears adversarial to another
model with identical architecture  this is true regard
less of the fact that the other model is trained on completely
different data distribution
g upper bound of robustness to provide upper bound
on robustness apply adaptive attacks ie give access to a
full defense apply the strongest attack for a given threat
model and defense being evaluated also verify that adap
tive attacks perform better than others and evaluate their
performance in multiple settings eg the combination of
transfer randomnoise and blackbox attacks for instance
ruan et al evaluated the robustness of dnn and presented an
approximate approach to provide lower and upper bounds on
robustness for l norm with provable guarantees 
f testing of ml models and autonomous vehicles
 behavior testing of models in a recent study sun et al
proposed four novel testing criteria for verifying structural fea
tures of dnn using mcdc coverage criteria  they
validated proposed methods by generating test cases guided
by their proposed coverage criteria using both symbolic and
gradientbased approach and showed that their method was
able to capture undesired behaviors of dnn similarly a
set of multigranularity testing criteria named deepgauge is
presented in  that works by rendering a multifaceted
testbed the security analysis of neural networks based system
using symbolic intervals is presented in  which uses
interval arithmetics and symbolic intervals together with other
optimization methods to minimize conﬁdence bound of over
estimation of outputs a coverage guided fuzzing method
for testing neural networks for goals eg ﬁnding numerical
mcdc modiﬁed conditiondecision coverage is a method of mea
suring the extent to which safetycritical software has been adequately
tested
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward
errors generating disagreements and determining the undesir
able behavior of models is presented in  in  the
ﬁrst approach utilizing differential fuzzing testing is presented
for exploiting incorrect behavior of dl systems
 automated testing of ml empowered autonomous
vehicles an overview to ensure a completely secure func
tionality of autonomous vehicles in a realworld environment
the development of automated testing tools is required as the
backbone of autonomous vehicles leverage different ml tech
niques for building decision systems at different levels eg
perception decision making and control etc in this section
we provide an overview of various studies performing test of
autonomous vehicles
tian et al  proposed and investigated a tool named
deeptest to perform testing of dnn empowered autonomous
vehicles to automatically detect erroneous behaviors of the
vehicle that can potentially cause fatal accidents their
proposed tool automatically generates test cases using changes
in realworld road conditions such as weather and lighting con
ditions and then systematically explores different components
of dnn logic that maximize the number of activated neurons
furthermore they tested three dnns that won top positions
in udacity selfdriving car challenge and found various erro
neous behaviors in different realworld road conditions eg
rain fog blurring etc that led to fatal accidents in 
used a ganbased approach to generate synthetic scenes of
different driving conditions for testing autonomous cars a
metamorphic testing approach for evaluating the software part
of selfdriving vehicles is presented in 
a generic framework for testing security and robustness
of ml models for computer vision systems depicting real
istic properties is presented in  authors evaluated the
security of ﬁfteen state of the art computer vision systems
in black box setting including nvidias dave selfdriving
system moreover it has been provably demonstrated that there
exists a tradeoff between adversarial robustness to pertur
bations and the standard accuracy of the model in a fairly
simple and natural setting  a simulationbased frame
work for generating adversarial test cases to evaluate the
closedloop properties of ml enabled autonomous vehicles
is presented in  in  authors generated adversar
ial driving scenes using bayesian optimization to improve
selfdriving behavior utilizing visionbased imitation learning
an autoencoderbased approach for automatic identiﬁcation
of unusual events using small dashcam video and the inertial
sensor is presented in  that can potentially be used to
develop a robust autonomous driving system various factors
and challenges impacting driveability of autonomous vehicles
along with an overview of available datasets for training self
driving is presented in  and challenges in designing such
datasets are described in  furthermore dreossi et al
suggested that while robustifying the ml systems the effect
of adversarial ml should be studied by considering the seman
tics and context of the whole system  for example in dl
empowered autonomous vehicle not every adversarial obser
vation might lead to harmful actions moreover one might be
interested in those adversarial examples that can signiﬁcantly
modify the desired semantics of the whole system
vi open research issues
the advancement of ml research and its state of the art
performance in various complex domains in particular the
advent of more sophisticated dl methods might be an inherent
panacea to the conventional challenges of vehicular networks
however mldl methods cannot be naively applied to vehic
ular networks that possess unique characteristics and adaption
of these methods for learning such distinguishing features of
vehicular networks is a challenging task  in this section
we highlight a few promising areas of research that require
further investigation
a efﬁcient distributed data storage
in the connected vehicular ecosystem the data is generated
and stored in a distributed fashion that raises a question about
the applicability of mldl models at a global level as ml
models are developed with the assumption that data is easily
accessible and managed by a central entity there is a need to
utilize distributed learning methods for connected vehicles so
that data may be scalably acquired from multiple units in the
ecosystem
b interpretable ml
another major security vulnerability in cavs is the lack
of interpretability of ml schemes ml techniques in general
and dl techniques speciﬁcally are based on the idea of func
tion approximation where the approximation of the empirical
function is performed using dnn architectures current works
in mldl lack interpretability which is resulting in a major
hurdle in the progress of mldl empowered cavs the lack
of interpretability is exploited by the adversaries to construct
adversarial examples for fooling the deployed mldl schemes
in autonomous vehicles ie physical attacks on selfdriving
vehicles as discussed above development of secure explain
able and interpretable ml techniques for securitycritical
applications of cavs is another open research issue
c defensive and secure ml
despite many defense proposals presented in the literature
for adversarial attacks developing adversarially robust ml
models remains yet another open research problem almost
every defense has been shown to be only effective for a
speciﬁc attack type and fails for stronger or unseen attacks
moreover most defenses address the problem of adversar
ial attacks for computer vision tasks but adversarial ml is
being developed for many other vertical application domains
therefore development of efﬁcient and effective novel defense
strategies is essentially required particularly for safetycritical
applications eg communication between connected vehicles
d privacy preserving ml
preserving privacy in any usercentric application is of high
concern privacy means that models should not reveal any
additional information about the subjects involved in col
lected training data aka differential privacy  as cavs
involve human subjects ml model learning should be capable
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee communications surveys  tutorials vol  no  second quarter 
of preserving the privacy of drivers passengers and pedestri
ans where privacy breaches can results in extremely harmful
consequences
e security centric proxy metrics
development of securitycentric proxy metrics to evaluate
security threats against systems is fundamentally important
currently there is no way to formalize different types of
perturbation properties eg indistinguishable and content
preserving etc in addition there is no function to determine
that a speciﬁc transformation is contentpreserving similarly
the process of measuring perceptual similarity between two
images is very complex and widely used perceptual metrics
are shallow functions that fail to account for many subtle
distinctions of human perception 
f fair and accountable ml
the literature on ml reveals that mlbased results and
predictions lack fairness and accountability the fairness prop
erty ensures that the ml model did not nurture discrimination
against speciﬁc cases eg favoring cyclists over pedestrians
this bias in ml predictions is introduced by the biased train
ing data and results in social bias and higher error rate for a
particular demographic group for example researchers iden
tiﬁed a risk of bias in the perception system of autonomous
vehicles to recognize pedestrians with dark skin  this
is an experimental work in which authors evaluated dif
ferent models developed by other academic researchers for
autonomous vehicles despite the fact that this work does not
use an actual object detection model that is being used by
autonomous vehicles in the market nor did it use the train
ing data being used by autonomous vehicle manufactures this
study highlights a major vulnerability of ml models used in
autonomous vehicles and raises serious concerns about their
applicability in realworld settings where a selfdriving vehi
cle may encounter people from a variety of demographic
backgrounds
the accountability of ml models is associated with their
interpretability property as we are interested in developing
such models that can explain their predictions using the
models internal parameters the notion of accountability is
fundamentally important to understand ml model failures for
adversarial examples
g robustifying ml models against distribution drifts
to restrict the integrity attacks ml models should be made
robust against distribution drifts which refer to the situation
where train and test data distributions are different this dif
ference between the training and test distributions gives rise
to adversarial examples these examples can also be consid
ered as the worst case distribution drifts  it is fairly
clear that the data collection process in the vehicular ecosys
tem is temporal and dynamic in nature so such distribution
drifts are highly possible and will affect the robustness of
the underlying ml systems moreover such drifts can be
exploited by the adversaries to create adversarial samples dur
ing inference for example in  authors investigated this
distribution drift by introducing positively connotated words
in spam emails to evade detection moreover modiﬁcation of
the training distribution is also possible in a similar way and
distribution drift violates the widely known presumption that
we can achieve low learning error when a large training data is
available ford et al  have presented empirical and the
oretical evidence that adversarial examples are a consequence
of test error in noise caused by a distributional shift in the
data to ensure that the adversarial defense is trustworthy it
must provide defense against data distribution shifts as the
perception system of cavs is mainly based on datadriven
modeling using historical training data it is highly susceptible
to the problem of distribution drifts therefore robustifying
ml models against the aforementioned distribution drifts is
very important one way to counter this problem is to leverage
deep reinforcement learning rl algorithms for developing
the perception system of autonomous vehicles but this is not
yet practically possible as the state and action spaces in real
istic settings road and vehicular environment are continuous
and very complex therefore ﬁne control is required for the
efﬁcacy of the system  however the work on lever
aging deep rlbased methods for autonomous vehicles is
building up for instance sallab et al proposed a deep rl
based framework for autonomous vehicles that enables the
vehicle to handle partially observable scenarios  they
investigated the effectiveness of their system using an open
source d car racing simulator torcs and demonstrated
that their model was able to learn complex road curvatures
and simple intervehicle interactions on the counter side
deep rlbased systems have been shown vulnerable to policy
induction attacks 
vii conclusion
the recent discoveries that machine learning ml tech
niques are vulnerable to adversarial perturbations have raised
questions on the security of connected and autonomous vehi
cles cavs which utilize ml techniques for various tasks
ranging from environmental perception to objection recogni
tion and movement prediction the safetycritical nature of
cavs clearly demands that the technology it uses should be
robust to all kinds of potential security threatsbe they acci
dental intentional or adversarial in this work we present
for the ﬁrst time a comprehensive analysis of the challenges
posed by adversarial ml attacks for cavs aggregating insights
from both the ml and cav literature our major contribu
tions include a broad description of the ml pipeline used
in cavs description of the various adversarial attacks that
can be launched on the various components of the cav ml
pipeline a detailed taxonomy of the adversarial ml threat for
cavs a comprehensive survey of adversarial ml attacks and
defenses proposed in literature finally open research chal
lenges and future directions are discussed to provide readers
with the opportunity to develop robust and efﬁcient solutions
for the application of ml models in cavs
httptorcssourceforgenet
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
qayyum et al securing cavs challenges posed by adversarial ml and way forward

ieee reviews in biomedical engineering vol  
speech technology for healthcare
opportunities challenges and state of the art
siddique latif
 junaid qadir
 adnan qayyum
 muhammad usama
 and shahzad younis
methodological review
abstractspeech
technology
is
not
appropriately
explored
even
though
modern
advances
in
speech
technologyespecially those driven by deep learning
dl technologyoffer unprecedented opportunities for
transforming the healthcare industry in this paper we have
focused on the enormous potential of speech technology
for revolutionising the healthcare domain more speciﬁ
cally we review the stateoftheart approaches in auto
matic speech recognition asr speech synthesis or text
to speech tts and health detection and monitoring using
speech signals we also present a comprehensive overview
of various challenges hindering the growth of speech
based services in healthcare to make speechbased
healthcare solutions more prevalent we discuss open is
sues and suggest some possible research directions aimed
at fully leveraging the advantages of other technologies for
making speechbased healthcare solutions more effective
index termsdeep learning automatic speech recogni
tion asr speech synthesis healthcare speech biomark
ers remote monitoring
i introduction
t
he current healthcare system is unable to provide uni
versal access to all patients and facing several problems
these problems include  the increasing portion of ageing
population which is expected that the number of people aged
 or older will rise from  million in  to  billion in
   the increasing burden of chronic diseases which
is expected to globally grow from  to  by  
 the lack of human resources ie doctors and nurses and
healthcare facilities especially in developing nations  the
expensive provision of highquality care  and  the absence
manuscript received february   revised may   ac
cepted june   date of publication july   date of current
version january   corresponding author siddique latif
siddique latif is with the university of southern queensland usq
springﬁeld qld  australia and also with the distributed sens
ing systems group data csiro pullenvale qld  australia
email siddiquelatifusqeduau
junaid qadir adnan qayyum and muhammad usama are with infor
mation technology university lahore  pakistan email junaid
qadirituedupk adnanqayyumituedupk muhammadusamaitu
edupk
shahzad younis is with the national university of sciences  tech
nology islamabad  pakistan email muhammadshahzad
seecsedupk
digital object identiﬁer rbme
it is anticipated that the world will have a shortage of  million healthcare
workers by  
of datadriven patientcentred clinical methods due to which
people are being assessed on population averages  to address
these challenges technologybased health can be utilised to
provide support to the healthcare system especially speech
processing has great potential to provide innovative solutions
in healthcare to facilitate both patients and doctors
broadly speaking human speech is the most natural mode of
human communication it provides information about linguis
tic content and paralinguistic states and traits the linguistic
content represents the intended message that the speaker wishes
to convey or communicate paralinguistics content of speech
provides a much rich array of information related to speakers
identity gender and age research efforts are exploring the
intelligent modelling of speech signals for various important
applications speech processing research is currently gaining
interest to utilise computational paralinguistic analysis for the
assessment of different health conditions the prime reason
to use speech for healthcare is that it can be easily available
collected transmitted and stored  most importantly various
physical and mental diseases cause changes in human speech
which are measurable with the help of speech technology
speech technology involving the processing and analysis
of human speech is a major area of research these days
it encompasses various areas of research such as automatic
speech recognition asr speaker recognitionveriﬁcation text
to speech tts conversion and identiﬁcation of language age
and gender using speech research on speech technology has
endeavoured to empower machines to involve in verbal human
machine interactions hci these days speech technology
based interfaces have become widely adopted worldwide in
various routinelyused devices and applications with services
such as apples siri and google voice search used by millions
of users  researchers are now aiming to transform the
current verbal hci interfaces into the next generation medical
companions that react with humans more naturally and monitor
users mental and physical health at their home work hospital
or anywhere in all these areas deep learning dl is emerging
as an essential component of stateoftheart approaches
recent progress in speech processing along with other ad
vanced technologies including the internet of things iot
and communications systems can ﬁx the current dysfunctional
healthcare system in particular recent breakthroughs in dl the
advent of iot and the advancement in communication systems
have opened up various promising opportunities for healthcare
   ieee personal use is permitted but republicationredistribution requires ieee permission
see httpswwwieeeorgpublicationsrightsindexhtml for more information
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
latif et al speech technology for healthcare opportunities challenges and state of the art
fig 
organisation of paper
systems it will create huge opportunities for speech technology
to be utilised for remote diagnostics and monitoring chronic
disease management and independent care for the elderly and
much more this paper aims to cover the stateoftheart speech
technology and its applications in the ﬁeld of healthcare
the main contribution of this paper is to highlight the
substantial potential of speech technology for improving the
stateoftheart in healthcare to the best of our knowledge this
is the ﬁrst comprehensive paper that reviews the stateofthe
art research from the different speechrelated ﬁeldsincluding
automatic speech recognition asr speech synthesis or text
to speech tts and speech biomarkersto show their po
tential for healthcare this work builds upon previous papers
with a limited focus that aimed to demonstrate the potential of
speech recognition for healthcare  or discuss the use
of dl for healthrelated subchallenges on publicly available
datasets  we feel that this paper is especially timely due to
the recent advancements in speech technology and dl along
with problems faced by an increasingly burdened healthcare
system that is crying out for technological augmentation
the organisation of the paper see fig  is described next
in section ii a brief premier on speech technology is presented
followed by a discussion of the potential opportunities of speech
technology in healthcare in section iii next we cover the
stateoftheart works on speech technology for healthcare and
some of its prominent healthcare solutions which is followed by
challenges that are causing hurdles for speech technology to be
utilised in healthcare in section v before concluding the paper
we discuss important open issues and future direction that can
help researchers to make the use of speech technology more
effective in section vi
ii primer on speech technology
speech technology aims to enable machines to recognise
analyse and understand human speech the area has been
developing for decades as a subﬁeld of signal processing and
has seen much progress in the last decade or so due to the huge
progress made under deep learning paradigms typically speech
technology systems include three major components as shown
fig 
major components of speech technology based systems
in fig  that include preprocessing feature extraction and
ml algorithms development
a preprocessing
preprocessing of speech signals is considered as an important
step in designing robust and efﬁcient systems for various appli
cations it usually involves noise suppression silence removal
and channel equalisation etc the performance of speechbased
systems can be improved with the use of these preprocessing
techniques   it has been also validated that removing
silence pauses and noise even helps mldl models in achieving
better performance  in the case of speech synthesis text
processing is even more complex it involves text normalisa
tion tokenisation sentence segmentation etc  it is equally
important in speech synthesis to improve system performance
b feature extraction
the representation of speech signals into meaningful in
formative and a reasonably limited number of features is a
crucial component for developing any system for speechbased
applications despite the fact that there is no unique taxonomy of
speech features it is common to divide features into two types
ie linguistic and acoustic features the extraction procedures
for these two types of features are signiﬁcantly different and
their performance greatly depends upon the type of problem at
hand
linguistic features represent information in spoken words
this usually includes speciﬁc words their grammatical alter
ations or higher semantic and pragmatic markers  a variety
of techniques exists for the analysis of speech using linguistic
features for example keyword spotting aims at the reliable
detection of a particular word in a given speech   these
words are chosen from daily life and considered sufﬁcient to
represent the speakers states and related events
acoustic features are very popular and widely being used
these features are primarily extracted using the models of the
human auditory system human hearingrelated properties such
as lower sensitivity at lower frequencies spectral amplitude
compression nonlinear frequency scale and large spectral inte
gration are also considered in acoustic features 
ongoing research on speech analysis has categorised the
acoustic features into three categories prosodic spectral and
temporal and features related to the voice quality  
prosody refers to melody and rhythm of speech and prosodic
features include the feature related to the length tone accent
stress intonation and few others   these features can
be used to detect the irregularities in the rhythm and timing
of speech for instance nonverbal speech cues such as inter
ruptions natural turns counting the number of interjections
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee reviews in biomedical engineering vol  
table i
summary of some popular dl models
and response times can help to identify irregular speech pat
terns  in contrast to temporal features spectral features are
computed by converting the speech signal into the frequency
domain most popular temporal and spectral features include
energy  entropy  zerocrossing rate zcr  spec
tral centroid spectral rolloff and spectral ﬂux  similarly
voice qualityrelated features include jitter shimmer unvoiced
rate and harmonictonoise ratio hnr etc
recently the speech community also started using raw speech
instead of handengineered features for these features they
use dl models to extract datadriven features related to the
task at hand such features have shown promising results for
different speechrelated tasks including asr  emotion de
tection  and speaker identiﬁcation  however the per
formance of such methods needs to be explored and compared
with various handengineered features for healthrelated tasks
c deep learning
in speech technology the hidden markov model hmm and
gaussian mixture model gmm based models gmmhmm
have ruled for decades a disruptive breakthrough happened in
speech technology in the last decade due to dl and now dl
models have become an essential component of asr tts and
other speech processing and analysis tasks this section is aimed
to present an introductory and higherlevel overview of dl for
an indepth description the interested readers are referred to
classical resources  however we presented the summary
of different dl architecture in table i dl is distinguished from
legacy artiﬁcial neural networks anns in terms of having
two or more layers between input and output layers the basic
component of a deep neural network dnn is the neuron unit
the neurons in each layer are fully connected with the neurons
of the adjacent layers to create a network the input signal is
passed through the network with intermediate computation and
approximate function y  fx θ by learning the best value
of the parameters θ a multilayer network or dnn creates a
pipeline of nonlinear transformations with the ability to learn
intermediate representations suitable for a given task at hand
in  an idea of the learning hierarchy of feature rep
resentations in different layers of the deep learning models
was initiated by hinton  and models like deep belief net
works dbn  and stacked autoencoders sae  were
proposed these deep typologies take the advantages of un
supervised layerbylayer pretraining which is followed by
ﬁnetuning of the entire network using backpropagation these
models were widely utilised in speech technology and still being
considered for speech modelling  more recently research
in speech technology has been focused on endtoend learning
paradigms from raw speech using convolutional neural networks
cnns they can learn ﬁlterbank from raw speech and able to
capture more generalised discriminative and contextual repre
sentation from raw waveform 
convolutional neural networks cnns were originated
from image processing for processing data in gridlike topology
they are also extended for natural language processing nlp
and speech processing the building block of cnns is a con
volutional layer that consists of multiple ﬁlters and it computes
local feature maps from the input the convolutional operation
in cnns can be deﬁned as
hkij  wk q  bk
where hkij is the i jth element for the kth output feature
map q represents the input feature maps and wk and bk denote
the kth ﬁlter and bias respectively the symbol represents
the d convolution operation the second component of cnns
is the pooling layer to facilitates nonlinear subsampling oper
ations is to reduce the dimension of each feature maps while
retaining the most important features finally fully connected
layers are used to achieve the required prediction for regression
or classiﬁcation tasks in speech processing it is very common to
use cnn in conjunction with recurrent neural networks rnns
recurrent neural networks rnns deﬁne a special dl
architecture that uses recurrent connections within layers with
the capability of processing previously processed inputs in con
trast to hidden markov models hmms rnns have stronger
representational memory  and are better suited for mod
elling sequences structures like speech for an input sequence
xt  x    xt  at time step t rnns calculate the hidden
state ht by using the previous hidden state ht and produce a
output vector sequence yt  y    yt  the equations for
standard rnns are given below
ht  hwxhxt  whhht  bh
yt  wxhxt  by
where w terms denote the weight matrices b represents bias
vector and h deﬁnes the hidden layer function simple rnns
face vanishing gradient problem and fail to model the longterm
temporal contingencies to deal with this problem multiple
specialised rnn architectures were proposed these include
long shortterm memory lstm  and gated recurrent units
grus  with gating mechanism to add and forget the mem
ory selectively bidirectional rnns  were also proposed
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
latif et al speech technology for healthcare opportunities challenges and state of the art
fig 
graphical illustration of different machine learning mldeep learning dl models
by passing the input sequence through two different recurrent
hidden layers to enable both past and future modelling these
gated rnns solved the issue of the vanishing or exploding gradi
ent problems and can learn longterm contextual dependencies
from the input sequence  and are widely used in speech
technology  
generative models
including
variational autoencoders
vaes   generative adversarial networks gans
and autoregressive generative models   are being used
in speech technology gans are becoming very popular in
speech technology due to their ability to learn and generate data
distributions they include two neural networksa generator
g and a discriminator d both these networks play a minmax
adversarial game deﬁned by the following optimisation
min
g max
d
exlogdx  eylog dgy
for speech synthesis autoregressive generative models like
wavenet  provide stateoftheart results and are becoming
increasingly popular they are directed probabilistic models and
can model joint distribution using the following chainrule
px 
t
t
pxtx      xt θ
where xt is the tth variable of a waveform x  x  xt 
and θ are the parameters of the autoregressive model some
otherpopularautoregressivemodelsincludepixelrnnand
pixelcnn  a graphical depiction of various mldl models
can be seen in fig 
iii speech for healthcare opportunities and
applications
the current healthcare system is struggling to provide quality
health services at an affordable price the effectiveness of health
services can be signiﬁcantly enhanced by using the opportunities
offered by speech technology  such opportunities are high
lighted in fig  and this section provide a detailed discussion
on these opportunities
a fixing speech and hearing impairments
humans express their feelings thoughts and ideas by speak
ing speech is produced by the action of coordinated muscles
in the head neck chest and abdomen the development of
speech is a gradual process that involves years of practice
during this process a human child learns how to regulate these
muscles to produce understandable speech individuals that are
unable to properly regulate these muscles face speech disorders
disorders related to voice and language also affect human com
munication  hearing problems are also a cause of imperfect
communications among humans individuals who do not hear
someone with normal hearing thresholds of  db or better in
both ears face hearing impairments according to the world
health organisation who over  of the worlds population
 million people has hearing loss and it is expected that this
number will increase up to  million people by  
speech technology can be utilised to assist individuals with
a hearing problem or a voice speech or language disorder to
communicate effectively  asr plays an important role in
the applications of speech therapy which require to decode the
user utterances  similarly speech synthesis provides can
teach users how a word or sentence should be pronounced which
reinforcing the correct pronunciation in the speech therapy ac
tivities in this way systems based on speech synthesis and asr
can be used to augment the quality of human communication in
healthcare   such assisting systems aim at improving
the intelligibility of pathologic speech by producing speech
similar to the voice of the speaker  speech technology
can also be used for design interfaces for childrens speech
therapy  dysarthria one of the major speech disorders that
arise as a secondary condition among individuals with cerebral
palsy amyotrophic lateral sclerosis als stroke survivors
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee reviews in biomedical engineering vol  
fig 
prominent opportunities of speech processing in healthcare
multiplesclerosisalzheimersparkinsonsandtraumaticbrain
injury it produces weakness or difﬁculty controlling the muscles
involved in speech production studies demonstrate that speech
technologybased systems can also help people with such disor
ders 
b speech interfaces for doctors and patients
speech interface describes an automated software that uses
either simulated human speech or human speech to interact
with humans they provide services in handsfree eyesfree
and keyboardfree situations with  of a healthcare profes
sionals time is spent on clinical documentation overwhelmed
clinicians often spend more time on clinical documentation
comparedtodirectpatientcareafactthatcandrainandde
motivate clinicians speech interfaces can provide a convenient
integration in healthcare to reduce the burden of medical doctors
the implementation of such interfaces can bring a lot of beneﬁts
to the healthcare industry from timesaving to costreducing
first of all practitioners and nurses will be able to become
more efﬁcient in the process of transcripts  secondly it will
increase productivity in healthcare systems  another beneﬁt
is that it will also reduce the amount of time by a doctor to see
the patients by using readily available information similarly
speech technology is a major mean of reducing the cost of
traditional medical transcription in healthcare systems more
than  of institutions were able to save more than  million
over the period of two or more years  voicebased assistants
can maintain patients electronic medical records emr and
provide relevant information when needed in a recent con
trolled observational study  participants found that speech
recognition in clinical documentation can saves time increases
efﬁciency and allows to make more detailed notes with relevant
details speech technologybased interfaces can help the patients
during their hospital stay and after discharge in particular
speech interfaces can facilitate patients recovering at home
especially when they have restricted mobility through support
for environment control such as adjusting a rooms temperature
controlling audio levels requesting nursing assistance and in
decision support  
c speech processing for psychological disorders
the term psychological disorder which refers to psychiatric
disorders or mental disorders are behavioural or psychological
symptoms or patterns which impact multiple areas of life
humans feel a vast range of comfortable and uncomfortable
emotions  and it has been argued that emotional discomfort
is a universal human experience  emotions are transient and
continually ﬂuctuating which may cause both positive and neg
ative effects on human life  on the other end psychological
disorders like stress depression anxiety suicidal behaviour and
distress which can lead to disabling conditions and impairment
in people distress is major emotional suffering and highly
prevalent in patients with a chronic disease like cancer 
despite the fact that psychological disorders can cause serious
consequences routine screening has not been widely adopted in
healthcare due to heavy cost and time requirements 
recent studies have shown the promise of using speech as an
effective biomarker for the diagnosis of psychological disorders
spoken speech can provide a wide range of acoustic features that
canbeeffectivelyutilisedforhumanemotiondetection
and diagnosis and monitoring of depression anxiety stress dis
tress and suicidal behaviour  stateoftheart deep learning
models have improved the performance of emotion recognition
depression anxiety stress distress and suicidal behaviour de
tection using speech   particularly the combination of
cnns and lstm has shown great performance in modelling
affective behaviours and related disorders from speech 
 here cnn is mainly used to extract temporal features
and contextual modelling is performed using lstm cnns are
also being employed in an endtoend fashion to extract features
from raw speech related to the problem at hand eg depression
detection  convolutional layer in cnns acts a datadriven
ﬁlterbank that can produce more generalised features compared
to the standard artiﬁcial neural networks anns and other
featurebased approaches  in this way deep learning models
are playing an important role in modelling as well as diagnosis
of different psychological disorder using speech signal this
demonstrates that the speech technology has great potentials to
automate the screening and monitoring of mental illnesses and
related disorders hence alleviating many healthcare challenges
d home and elder care
life expectancy is greatly increasing worldwide which is
causing a higher number of older people in our society 
the increased share of the elderly population is shifting the
cause of death from parasitic and infectious diseases to chronic
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
latif et al speech technology for healthcare opportunities challenges and state of the art
table ii
comparison of recent studies on asr
illnesses   ageing also causes physical limitations that
need to be compensated by the assistance of someone or with the
services of aged care centres elderly people feel isolation fear
and a sense of helplessness both inhome and at oldage care
centres which cause severe consequences on both physical and
mental health speechbased assistants are a valuable tool for
seniors staying at home or age care centres especially for those
who are not able to use other technologybased services that may
require the dexterity of the hands mobility andor good vision
such systems can also provide them with independence and a
better quality of life with physical or cognitive disease 
e access to healthcare services particularly in
developing countries
millions of people in developing countries unnecessarily suf
fer and eventually die from such illnesses that have effective cure
and prevention  generally people in developing countries
havepoorliteracyskillsiereadingwritingithasbeenshown
that people with low health literacy have a oneinthree chance
of misunderstanding the prescribed medication  there is
a direct correlation between mortality rates and poor health
literacy approximately  to  increased mortality risk for
individuals with poor health literacy  language diversity
is another challenge in developing countries that reduces the
potential beneﬁts of healthcare services such as text messaging
and ehealth portals  such healthcare services are also not
much useful for lowliterates the blind the visually impaired
and those that are not computer literate speech is a plausi
ble interaction modality for illiterate users and speechbased
healthcare services can be ideal for inhabitants of the developing
countries
iv speech for healthcare stateoftheart
a automatic speechrecognition asr
automatic speech recognition asr is the analogue of
machine ear which enables a computer to recognise uttered
speech and transform it into the corresponding sequence of
words or subwords asr has witnessed a steady improvement
in performance due to the development of cuttingedge ml
algorithms traditionally hmm and gmm based models were
the main stock of research for asr dnnbased asr systems
have become the stateoftheart by showing huge improvements
compared to previous conventional system  developing and
training asr systems however is complicated and requires
a lot of preprocessing various attempts have been made to
reduce the complexity of asr paving the way for endtoend
speech recognition  nowadays endtoend asr systems
are extensively used and studied for asr in different languages
such as english mandarin japanese or french  similarly
sequencetosequence models are also gaining popularity in
the automatic speech recognition asr community  vari
ous sequencetosequence models including recurrent neural
network transducer rnnt  neural transducer 
listen attend and spell las  recurrent neural aligner
rnaandmonotonicalignmentshavebeenexplored
in the literature in addition transformers  based models are
also gaining success in asr ﬁeld due to their better perfor
mance we presented the performance comparison of different
stateoftheart models in terms of worderrorrate wer in
table ii these systems demonstrate promising results on dif
ferent datasets which shows the feasibility of their integration
into healthcare applications
a major application of asr in healthcare is to facilitate
the generation of clinical documentations  the medical
errors caused by bad handwriting can be avoided using speech
recognition for medical documentations  such selftyping
systems are also believed to enhance documentation quality and
efﬁciency as well as improve the satisfaction level of health
professionals in clinics or hospitals 
different research studies explored the feasibility of asr sys
tems for clinical documentation for instance in  authors
evaluated a webbased asr system in a university hospital for
clinical documentation in the german language they found that
medical documentation with asr increases in documentation
speed and amount and it also has a positive impact on participant
mood in contrast to selftyping hodgson et al  explored
the use of asr for medical transcription of the doctorpatient
conversation they used   hours of speech and demon
strated that the proposed models achieved promising results
on important medical utterances and therefore can be used
practically in a clinical setting for transcribing medical conversa
tions in  authors performed a case study in a specialised
outpatient department and found that asr software supports
medical doctors by quickly producing patient discharge letters
without impairing user satisfaction
the efﬁciency of speech recognition is evaluated by hoyt
et al  for documenting outpatient encounters in the ehr
system at a military hospital and its  outlying clinics seventy
ﬁve clinicians participated to evaluate speech recognition for
clinical documentation among these participants  of the
clinicians continued to use speech recognition in their rou
tine practices and reported that speech recognition for clinical
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee reviews in biomedical engineering vol  
documentation is more convenient accurate and expeditious
for instance speech recognition helped in improving note qual
ity and allowed for closing a patient encounter on the same
day similarly authors in  showed that medical speech
recognition can perform on a par with humans authors in 
developed a webbased prototype to generate medical reports in
the brazilian portuguese language using google web speech
api and microsoft bing speech api they found that a system
based on google api achieved an error rate of  which
wassigniﬁcantlybetterthanthoseachievedbythemicrosoftapi
 few other studies  also highlighted the potential
of using asr for clinical documentation
all of these studies highlight several beneﬁts of using asr
for clinical documentation however most of these studies are
pilot projects although the use of asr can drive interactive
clinical documentation however careful evaluation is required
for ehr  there is still a need to improve the efﬁciency
of asr for medical documentation to avoid errors that have the
potential to cause clinical harms furthermore improved system
interoperability and workﬂow are needed for their successful
integration in the clinical setting 
b speech biomarkers
human voice incorporates features that can plausibly be
used to discriminate on the basis of gender age intelligence
socioeconomic status regionalethnic origin education and
occupation  most importantly for health outcomes it
provides information about various voice disorders which can
be diagnosed by detecting anomalous voice quality pitch and
loudness that is inappropriate for an individuals age gender
cultural background or geographic location  other speech
related disorders include cognitivecommunication disorders
communication disorders swallowing disorders and an autism
spectrum disorder speech technologybased solutions have
been playing an important role in the diagnostic and monitoring
of these disorders nowadays dl models have become the
stateoftheart technique in this domain
automatic detection of vocal fold pathologies is of great
interest to the voice community as well as the medical commu
nity due to its low cost and noninvasive nature these systems
can be used by clinicians to detect the existence of any voice
pathologies even in the early stages fang et al  retrospec
tively collected normal pathological voice samples of  common
clinical voice disorders and evaluated both ml models and
dnns they found that dnns outperformed other ml models
including svm and gmms authors in  used convolutional
dbn for voice pathology and showed that cnn can effec
tively extract features from spectrograms of voice recordings
suitable for diagnosing of voice disorders harar et al 
conducted a preliminary study on voice pathology using dnns
and showed that the use of combined cnnlstm provides
promising results in  the authors investigated a voice
pathology detection system using dl on a mobile multimedia
healthcare system and voices samples captured using mobile
devices more speciﬁcally the authors used a cnn architecture
and reported signiﬁcantly improved results in other work some
researchers   designed voice pathology detection
systems for smart cities but their work used classical ml models
in their architectures
acoustic analysis of speech is also used for the diagnosis
of alzheimers disease which is cognitive impairment and the
most common cause of dementia it has a high prevalence that
is increasing rapidly towards an epidemic level the research
community is trying to utilise speech technology to solve this
issue in  lopezdeipina et al proposed a nonlinear
multitask approach using a multilayer perceptron mlp and
cnns for alzheimers detection the authors evaluated the
proposed models using different speech features and reported
promising results in  fraser et al explored the use of
linguistic features for the identiﬁcation of alzheimers they
achieved stateoftheart results and found that linguistic analy
sis using modern ml is increasingly useful in assessment and
clustering of alzheimers
speech analysis is also being utilised for parkinsons disease
pd detection for instance authors in  designed to diag
nosis pd using speech signal they used dbns for classiﬁcation
and achieved signiﬁcantly improved results attesting the power
of dbn for speech analysis frid et al  used raw speech
for pd detection using cnns they found that relatively small
 ms of raw speech contains much information regarding the
pd that can be used for classiﬁcation speech technology is
also being used for the diagnosis of autism spectrum disorder
asd in children different studies used dl and speech signals
for asd detection   also to assist children with
asd 
human speech provides a wide range of prosodic and spectral
features that can be effectively utilised for emotion recognition
depression distress anxiety and stress detection acoustic fea
tures including spectral prosodic cepstral glottal and teager
energy operators teo were evaluated in for clinical depres
sion detection in adolescents  authors found that teo
based features produced more promising results compared to
all other features in  the authors showed that the prosody
and voice qualityrelated speech features can be used for the
identiﬁcation of suicidal and nonsuicidal adolescents in 
behaviour prediction of cancerafﬂicted patients is performed
using different speech features they showed that speech can
effectively be utilised for behavioural prediction in cancer pa
tients various other studies  utilised speech feature
for identiﬁcation stress anxiety and depression in english and
also in other languages
most of the abovementioned studies have used publicly
available datasets and showed that speech technology can be
effectively utilised as biomarkers for the detection of various
diseases however these systems have not been evaluated in
reallife settings it is important for researchers to focus on the
design of systems that can be utilised in clinics and medical
hospitals and on reporting reallife performance evaluations
c remote monitoring
the rising burden on the global healthcare system along
with the limited availability of trained healthcare profession
als is increasing the demand for infrastructure and technology
that can facilitate the remote monitoring of patients speech
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
latif et al speech technology for healthcare opportunities challenges and state of the art
technologybased remote monitoring services have been ex
plored in this regard by the research community in 
hossain used speech along with and facial expressions which
are captured in a multisensory environment the author tested
the proposed framework on  people and was able to detect
the patients state with an average recognition of  in
another work vatanparvar et al  designed a speech privacy
preservation method for speechbased remote health monitoring
using gan and reported promising results a remote system for
monitoring of speechlanguage intervention is proposed in 
for the parents of children with asd for remote monitoring and
assessment of cognitive function in senior people a system was
proposed by rapcan et al in  the authors used telephone
speech recordings and showed that the system can achieve
similar results compared to speech recorded in a controlled
environment the sweethome project was proposed in 
which used noiserobust multisource asr to detect distressed
sentences in a realistic environment of a smart home to monitor
distress situations
various studies also have proposed speech remote monitoring
systems by exploiting the advanced communication technolo
gies a g enabled emotionaware healthcare framework was
proposed in  the authors evaluated the proposed health
care framework on  universitylevel students who were asked
to express the emotion of pain they used both speech and video
as the input of the system and achieved  of accuracy
a privacyenhanced emotion recognition system for remote
advisory is presented in  the authors showed that the pro
posed system can solve privacy issues while achieving promis
ing results similarly an edgecloud based privacypreserving
automatic emotion recognition system is proposed which use
both speech and visual features  they used cnns for
emotion classiﬁcation and achieved improved results compared
to the stateoftheart systems some other studies 
have also used speech signal for remote patients monitoring
however most of these studies evaluated the proposed models
in a controlled setup therefore to ensure a safe and robust
operation it is very important to evaluate these systems in
reallife settings
d speech synthesis
speech synthesis also known as texttospeech tts is an
important technology that aims to convert text into speech
most of the tts systems use acoustic or linguistic features
as an intermediate representation to generate the waveform
traditionally the speech waveform was vocoded from these in
termediate representation using heuristic methods  or using
handcrafted vocoders   recently tacotron  
used wavenet  as a vocoder to generate waveform from
melspectrograms wavenet is an autoregressive generative
model that can generate relatively realistic humanlike speech
by using linguistic features it has the downside of a long infer
ence time due to its autoregressive architecture to address this
issue various models such as fftnet  wavernn 
and waveglow  have been proposed nowadays these
neural vocoders have replaced the use of traditional heuristic
methods and can dramatically enhance the quality of generated
table iii
mean opinion score mos evaluations comparison for
various systems
speech researchers are also focusing on synthesising more
natural speech by transferring prosody  style  and
expressions  all these studies have highlighted the great
progress made by tts systems that shows their suitability in
healthcare we also compared the performance in terms of mean
opinion score mos of different stateoftheart tts systems
in table iii which depicts that these systems are achieving mos
almost similar to the ground truth speech
texttospeech tts solutions can assist healthcares mis
sion of bettering patient care through the use of assistive and
digital tools it can further enhance digital health technology by
speechbasedhealthappswebsitesandemergencycallsystems
etc patients can be verbally reminded about important alerts
using tts which increases the usability and accessibility of
portable health trackers  different studies evaluated the
feasibility of tts assistive healthcare system for instance
liu et al  designed a smartphonebased system to help
visually impaired people while using android phones in 
the authors presented a design of a ttsbased interactive med
ication reminder and tracking system for wrist devices they
evaluated the system for both native and nonnative english
speakers in controlled experiments and achieved very promising
results a voice interactive assistant was designed in  to
improve adherence to medical treatments the authors designed
this system for stroke patients and tested among several healthy
subjects for an initial assessment however the ﬁnal product
was reported to be still under development
tts health assistive tools can dramatically improve people
health and required costs for example a ttsbased system can
facilitate patients by offering them an audio version of digital
text   this is especially helpful for illiterate individ
uals language learners and the elderly population and people
with learning disabilities or reduced vision such systems can
alsohelppeoplebyprovidinganaudioversionofimportantmed
ical information such as descriptions of diseases prescriptions
and drug information leaﬂets this avoids drug misuse while
making patients cautious about their health  ttsbased
systems also allow patients to accurately communicate their
needs which helps to establish a cognitive connection among
doctors and patients 
e some healthcare solution using speech technology
as outlined above speech technology ﬁnds its market in
healthcare particularly due to potential and impactful use cases
various voiceenabled healthcare solutions are developed that
can help improve the lives of thousands of individuals we
presented the details of some prominent solutions in table iv
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee reviews in biomedical engineering vol  
table iv
some prominent speech technology based healthcare solutions
fig 
challenges of deep learning dl empowered speech processing in healthcare
these solutions are being used by both doctors and patients to
change the traditional setting of health provision the devel
opment of speechbased solutions is continuously growing that
will signiﬁcantly impact the current healthcare system in the
next several years
v speech for healthcare challenges
despite the promising potentials of speech technology in the
health domain there are various hurdles in largescale deploy
ment of speechenabled solutions in this section we discuss
these challenges that need to be addressed to make the rapid
adoption of speech technology in healthcare a taxonomy is
depicted in fig 
a speech based adversarial attacks
even though modern dlbased speech solutions offer great
beneﬁts to the current healthcare system there are still questions
about the security of the underlying dl algorithms as recent
works have shown that dl models are prone to adversarial
attacks adversarial attacks are launched by creating adversar
ial examples in which nonrandom imperceptible perturbations
are added to input samples through optimization algorithms that
aim to fool the classiﬁer and inﬂuence it to make incorrect
decisions these attacks are powerful enough to signiﬁcantly
bring down the performance of the stateoftheart dnn based
systems  a popular method for generating such adversarial
attacks is to generate the perturbation by utilizing gradient
based methodsmany popular attacks such as fast gradient
sign method fgsm  jacobianbased saliency map at
tack jsma  deepfool  and carlini and wagner
attacks  follow this method many more sophisticated
attacks also exist including those that rely on nongradient based
methods 
researchers have also proposed various adversarial attacks
against speechbased systems for example carlini and wag
ner  evaluated an iterative optimisationbased adversarial
attack against deepspeech  a stateoftheart asr model
with  success rate some other popular adversarial attacks
against speechbased systems include  the success
of these adversarial attacks highlights the vulnerability of speech
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
latif et al speech technology for healthcare opportunities challenges and state of the art
technology to for healthcare therefore it is necessary to design
such systems that preserve patients privacy in the healthcare
settings
b scarcity of speech data
to achieve generalisation in dl models a large amount of
data is essential in the case of speech processing and analysis
the available datasets are typically very limited  even for
a very developed ﬁeld of asr we have transcribed datasets
for very few languages compared to the number of spoken lan
guages worldwide there are more than   spoken languages
globally however only  languages are spoken by  of
the worlds population in speech processing we do not even
have speech datasets for  languages   therefore
research in language and speech analysis research is facing
the problem of data scarcity  this imbalance variation
diversity and dynamics in speech and languages cause hurdles
in designing speechbased healthcare systems for example the
performance of asr systems degrades when they are evaluated
across different languages  therefore we need to design
more adaptive healthcare solutions using asr trained on multi
ple languages data the datasets related to speech disorders are
also very few and have very small sizes   to solve this
issue techniques such as transfer learning selftaught learning
etc can be utilised to improve the generalisability of the models
c interoperability challenges
in current healthcare systems the data generated from differ
ent medical devices clinical reports medical correspondence
electronic health records ehrs these medical data are typ
ically fragmented or isolated within hospitals and laborato
ries the interoperability of these medical records is prohibited
among different health services providers  on the contrary
different ehrs medical devices and other it systems are also
not interoperable if data sharing is allowed among different hos
pitals  for the effective utilisation of speech in healthcare
we need to enable interoperability in current healthcare sys
tems this would boost the speed of diagnostic procedures and
provide a complete history of patients to medical practitioners
therefore the attention of researchers and other stakeholders
working in the healthcare sector is required to ﬁnd solutions for
interoperability challenges
d cultural and language barriers
cultural and language diversity reduces the potential use of
speech technology in digital healthcare digital health is not only
a technological but cultural transformation cultural barrier is a
major challenge for digital transformation which becomes more
prevalent in rural and developing areas the transformation of
people from the classical method to digital health is slowed down
by ignoring the importance of cultural changes and the human
factors  therefore it is important to consider cultural
barriers while designing healthcare solutions in addition to
cultural barriers language diversity problem is another major
online available httpswwwethnologuecomstatistics
problemitisfoundthatthelinguisticdifferencesamongpatients
and medical doctors can cause patients to misinterpret med
ications and suffer unnecessary complications  therefore
healthcare solutions based speech technology must be trained on
multiple languages to work effectively in such situations how
ever the development of speech technologybased healthcare
systems becomes more challenging for rarely spoken languages
therefore it is very important to consider language diversity
while designing speechbased healthcare solutions
vi open issues and future directions
speech technology is expected to drive the change in the
healthcare system by changing the conventional ways of medical
treatments however there are some open issues that require
serious attention and consideration of the researchers there
fore in this section we highlighted such open issues and with
important pointers and future research directions for the research
community
a privacy and ethical concerns
when people use speechbased services such as speech recog
nition or voice authentication they provide complete possession
to their voice recordings to the respective device or software in
these services speech can be used by an adversary or attacker
to extract users information such as speakers identity gender
ethnicity information and emotional state the adversary can
use this information for undesired purposes such as to fool
voiceauthentication systems similarly users speech can also
be edited or used to create a fake speech that the person never
spoke several other privacyrelated concerns arise while using
speech technologybased services  in healthcare systems
information is more personal and very sensitive and people
are more vulnerable to the misuse of their data therefore
it is important to utilise speech processing in healthcare by
considering both privacy and ethical concerns in this regard
privacypreserving dl algorithms can be utilised to protect
speaker identity   gender identity  similarly
federated learning  is another alternative solution to pre
serve users privacy in federated learning training data remains
decentralised using multiple participating devices
b adoptability and affordability issues
speechbased digital healthcare solutions are intended to be
used by all types of users including people with no literacy or
education about smart devices usability of healthcare solutions
effects adoption of various innovative digital healthcare products
orservicesthereforeitiscrucialfordeveloperstoconsider
these issues while designing hci interface for speech based
healthcare solutions it is also important to provide speech
technologybased services at an affordable cost as it directly
impacts on the adaptability of these solutions 
c iot based solutions
the paradigm of internet of things iot offers unprece
dented opportunities for digital healthcare solutions by provid
ing an abstraction of inﬁnite physical smart and virtual objects
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee reviews in biomedical engineering vol  
these objects can capture store and securely transmit health
related information to a public or private cloud and facilitate
a new level of automation for the convenience of users most
importantly iotbased solutions are very effective in terms
of energy consumption cpu and memory usage  it is
anticipated that iot will disrupt the current healthcare systems
by providing various cuttingedge and highly individualised
digital healthcare solutions  these solutions can be utilised
for remote monitoring and diagnostics chronic diseases man
agement elderly care and much more therefore it is very
important to utilise the opportunities offered by iot to enhance
the effectiveness of speechbased healthcare services
d potentials with g
healthcare expenditure takes a big portion of the national
budgets of various countries for instance roughly  of
north americas and  of the global economys gross do
mestic product gdp account for healthcare spending 
technologyenabled healthcare solutions can provide health
services outside the hospital setting at remote locations which
can promote adherence to medications and reduce cost and
readmission rates  telehealth services by utilising g lte
have shown sound economic beneﬁts  which will be
further fuelled by the increasing amount of smartphones and
expeditiously improving connectivity with g network it is
anticipated that g will provide a consistent user experience not
only in dense areas but also in remote locations this will pave
the path for telehealth services available everywhere therefore
it is important for researchers working on speech processing for
health to consider the opportunities offered by communication
technologies while designing healthcare solutions
e sustainability issues
speech technologybased healthcare solutions have great po
tentials in healthcare and they are getting great interest and
attention among industries and healthcare service providers
however it is important to understand how any particular speech
technologybased healthcare solution can attain a certain level
of adoption to achieve scale the sustainability of any new
digital health solutions is always considered uncertain as they
involve different various public and private stakeholders 
the sustainability of such projects and products become more
uncertain in developing countries where people avoid to use
digital technology therefore a proper collaboration is always
needed among stakeholders to support the project to make a
transitionfrompilotstagetoaselfsustainablelongtermproject
vii conclusion
speech technology has unprecedented opportunities for the
health domain and these potential opportunities can be reaped
to ﬁx the current healthcare system that is continuously facing an
increasing burden of the ageing population and chronic diseases
in this paper we highlighted the potentials of speech technology
for healthcare and presented a stateoftheart work on health
care from different speechrelated including automatic speech
recognition asr speech synthesis and speech processing
for different speechrelated disorders the reviewed literature
showed that the research on speech processing for healthcare is
rapidly evolving with very promising results however these
results are mainly from some pilot projects or using some
publicly available datasets and the available healthcare solutions
based on speech technology are being used on a very small
scale there are various factors hindering the growth of speech
technology in healthcare that we discussed in detail in this paper
most importantly we presented open issues and based on that
we outlined future strategies for making speech technologies
even more effective in healthcare which include the utilisation
of other emerging technologies like internet of things iot and
communication technologies like g
ieee network  januaryfebruary 
   ieee
abstract
the holy grail of networking is to create cog
nitive networks that organize manage and drive 
themselves such a vision now seems attainable 
thanks in large part to the progress in the field of 
machine learning ml which has now already 
disrupted a number of industries and revolu
tionized practically all fields of research but are 
the ml models foolproof and robust to security 
attacks to be in charge of managing the network 
unfortunately many modern ml models are eas
ily misled by simple and easilycrafted adversarial 
perturbations which does not bode well for the 
future of mlbased cognitive networks unless ml 
vulnerabilities for the cognitive networking envi
ronment are identified addressed and fixed the 
purpose of this article is to highlight the problem 
of unsecure ml and to sensitize the readers to the 
danger of adversarial ml by showing how an eas
ily crafted adversarial ml example can compro
mise the operations of the cognitive selfdriving 
network in this article we demonstrate adversar
ial attacks on two simple yet representative cog
nitive networking applications namely intrusion 
detection and network traffic classification we 
also provide some guidelines to design secure ml 
models for cognitive networks that are robust to 
adversarial attacks on the ml pipeline of cognitive 
networks
introduction
the cognitive networking idea  a recurring motif 
in networking research that has been expressed 
in various guises such as autonomic networking 
selforganized networking knowledgebased net
working and most recently as selfdriving network
ing  now this idea appears to be within grasp 
thanks to the tremendous strides made in the field 
of machine learning ml that have transformed 
the entire fields of vision language speech 
and information processing many proponents 
are optimistic that ml will play a central role in 
enabling the future selfdriving cognitive networks 
by comprehensively automating the cognitive net
working tasks such as realtime telemetry network 
automation network intent modeling and net
work decision making 
a broad illustration of the various tasks involved 
in the operations of cognitive selfdriving networks 
is provided in fig  many of these highlighted 
tasks require a datadriven learning and inference 
process hence they can benefit from using a ml 
pipeline involving methods such as deep super
vised ml and reinforcement learning
however despite the great promise and suc
cess of ml methods the recent discovery of the 
susceptibility of ml models to security problems 
has dampened the optimism around the use of 
ml in cognitive networking the major reasons 
for the security vulnerabilities of ml models are 
the underlying implicit assumption that the train
ing and test data are similar in distribution and 
that the test examples are benign and not adver
sarial 
an adversarial example is defined as an 
imperceptible minor perturbation of the input that 
an adversary especially crafts to maximize the pre
diction error of the ml model  deep neural 
networks dnns in particular have been shown 
to be very vulnerable to such adversarial examples 
 it is worth noting that dnns are not the only 
ml models vulnerable to adversarial examples 
the problem is much broader and many other 
ml systems including reinforcementlearning rl 
and generative models  are also susceptible to 
adversarial examples 
adversarial ml is now a fastexpanding field 
attracting significant attention from the industry 
and academia  although ml vulnerabilities in 
domains such as vision image and audio are now 
well known relatively little attention has focused 
on adversarial attacks on cognitive networking 
ml models an illustration of the ml pipeline in 
cognitive selfdriving networks along with poten
tial security attacks that may be launched on its 
components is depicted next in fig  
due to the rising popularity of cognitive net
working and selfdriving networks ml models 
used in the context of cognitive networks have 
become highprofile targets for malevolent adver
saries who are interested in compromising the 
integrity and availability of these ml models the 
resulting threat becomes more serious when cog
nitive networking breaks through into safetycrit
ical networks such as selfdriving vehicles and 
vehicular networks internet of things smart city 
services and cyberphysical systems then it will 
no longer be only computer systems and their 
accessories that are at risk but the security of 
everything and everyone will be threatened 
the main contribution of this article is to high
the adversarial machine learning conundrum can the insecurity of ml become the 
achilles heel of cognitive networks
muhammad usama junaid qadir ala alfuqaha and mounir hamdi
accepted from open call
digital object identifier
mnet
muhammad usama and junaid qadir are with the information technology university itupunjab  
alaalfuqaha and mounir hamdi are with hamad bin khalifa university
ieee network  januaryfebruary 
light the vulnerability of mlbased functionality in 
modern cognitive networks to adversarial attacks 
and to review the state of the art in the applica
tion of adversarial ml techniques in networking 
we also provide recommendations for develop
ing robust ml models for selfdriving cognitive 
networks in this article we only consider the 
adversarial ml attacks on the network telemetry 
component of the cognitive selfdriving network 
as other cognitive selfdriving networking com
ponents rely on the data provided by this criti
cal component any fault in the telemetry part 
will result in less efficient selfdriving networks 
since realtime telemetry uses supervised ml 
schemes we have chosen anomalybased intru
sion detection and network traffic classification 
as case studies to highlight the adversarial ml 
threat on cognitive selfdriving networks adver
sarial ml attacks on other components of cogni
tive selfdriving networks which are mostly based 
on reinforcement learning are left as a future 
direction we also propose a concrete novel net
workspecifi
 c adversarial ml attack on an anoma
lybased intrusion detection system and network 
traffic classification to highlight potential issues 
that may arise when adversarial ml attacks are 
launched on future mlbased cognitive selfdriv
ing networks for cognitive networking to really 
take off
  it is extremely important that the under
lying technology has to be robust to all kinds of 
potential problems be they accidental intention
al or adversarial 
background 
in this section we discuss the challenges posed 
by adversarial ml attacks and then propose 
a taxonomy of adversarial ml attacks we will 
then survey the proposed adversarial attacks and 
defenses after that we highlight the stateof
theart in adversarial ml attacks on selfdriving 
cognitive networks to emphasize that this area of 
research needs special attention as networking 
moves from traditional networking to selfdriving 
cognitive networks
challenges posed by adversarial ml attacks 
ml adds substantially to the worries of securi
ty practitioners by expanding an alreadybroad 
attack surface comprising standard but still potent 
attacks in addition the future denselyconnected 
iotera cognitive networking will likely expose 
new vulnerabilities and a wider attack surface 
through its emphasis on massive connectivity pre
vious research has shown that a motivated wellre
sourced adversary can arbitrarily alter data and 
labels to compromise ml models completely and 
induce an error rate of up to  percent  
another important reason for adversarial ml 
attacks is the lack of a better understanding of 
how modern ml frameworks such as dnns oper
ate multiple explanations for the sensitivity of the 
ml models to adversarial examples have been 
provided in the literature  including the non
linearity of the dnn models which can assign 
random labels in areas that are underexplored 
in the training set but such a hypothesis fails to 
explain the transferability of adversarial examples 
from one ml model to another in addition it is 
not only the nonlinear dnn models that suffer 
from these attacks but linear models have also 
 
been shown to be vulnerable to adversarial exam
ples  while the reasons for the capitulation of 
the ml models to adversarial examples are still 
not well known it is clear that these adversari
al attacks pose a grave danger to the security of 
future cognitive networks which requires immedi
ate attention from the community 
adversarial examples are especially challeng
ing due to the asymmetric nature of adversarial 
ml attacks the asymmetry implies that the job 
of the defender is to secure the entire attack 
surface all the time but the attacker only has to 
fi
 nd a single kink in the surface the attacker also 
attacks surreptitiously much like in guerrilla war
fare using previouslyunseen attacks at a time of 
its own choosing the attacker constructs these 
attacks creatively by adding adversarial noise to 
incur the worstcase domain shifts in the input in 
a bid to elicit incorrect results by the ml model 
this stacks the odds in favor of the attacker and 
the battle becomes a manifestly unfair one to 
prove that the ml model is secure against attacks 
the defender has to anticipate the threat models 
and provide formal proof that demonstrates the 
fortitude to withstand the assumed threats 
with the well known attacks proposed in the 
literature  the bar of eff
 ort required for launch
ing new attacks has lowered since the same 
canned attacks can be used by others although 
sommer and paxson  were probably right 
in  to downplay the potential of security 
attacks on ml saying exploiting the specifi
 cs of a 
machine learning implementation requires signif
icant eff
 ort time and expertise on the attackers 
side the danger is real now when an attack can 
be launched on mlbased implementations with 
minimal eff
 ort time and expertise
taxonomy of security attacks on machine learning 
in this section we aim to communicate the big 
picture of adversarial ml security by referring to 
the ml pipeline for cognitive networking fig  
and a taxonomy of adversarial ml related issues 
that we developed fig  
based on the attacks location on the ml pipe
line security attacks on ml models can be clas
sifi
 ed into two categories first in a poisoning or 
training attack the attacker can access and adver
sarially poison the training data in a bid to max
imize the classification error attacks during the 
training phase can also include theft of the intel
lectual property ip if the training is outsourced 
figure  the cognitive selfdriving networking components and their related 
tasks are highlighted to provide the reader with a basic understanding of 
how cognitive selfdriving networks can be realized supervised and rein
forcement learning techniques are expected to play a vital role in achieving 
most of the tasks 
realtime 
telemetry
datadriven 
analysis
network 
decision making
operatoruser 
intent
actions
traﬃc logs
logs
deployed network
 the transferability of an 
adversarial example refers to 
the property that adversarial 
examples produced to mis
lead a particular ml model 
can be used to mislead other 
ml models as well even if 
their architectures greatly 
diff
 er from each other
ieee network  januaryfebruary 
to some external provider second in an evasion
or inference attack on the other hand the attacks 
attempt to perturb the textinference input 
through the creation of adversarial examples to 
compromise the ml model the attacks can also 
attempt to steal the ml model ip through a side 
channel through successive polling other types 
of attacks may involve obtaining physical access 
and intrusion into the hardware 
based on the adversarys knowledge adver
sarial ml attacks can be categorized into two 
types in a whitebox attack it is assumed that 
the adversary has perfect knowledge of the ml 
architecture trainingtesting data and the hyper
parameters of the model in contrast in a black
box attack it is considered that the adversary 
has partial access or no access to the deployed 
model based on the knowledgeaccess of the 
adversary blackbox attacks are further divided 
into two categories namely querybased attacks 
and zeroquery attacks a blackbox attack where 
an adversary can act as a standard user and 
query the ml model for a response and later use 
that queryresponse pair to generate an adver
sarial example is known as a querybased attack 
the zeroquery attack is defined as a blackbox 
attack where the adversary has no access to the 
deployed ml model but has only a few test sam
ples available to craft adversarial examples against 
a deployed ml model 
based on the adversarial intent speciﬁ
 city we 
can further divide evasion attacks into two classes 
in a targeted attack the attacker aims to fool the 
ml classifi
 er to classify all adversarial samples in 
one class by maximizing the probability of the 
targeted attack for example an adversary that 
wants to disguise the intrusive traffic as normal 
network traffi
  c can create a perturbation that max
imizes the classifi
 cation probability of the normal 
traffic class in a nontargeted attack the attack
er aims to fool the ml classifier by assigning an 
adversarial sample to any other class except the 
original one these attacks are performed by min
imizing the probability of the original class that 
ensures that the adversarial sample will not get 
classifi
 ed in the original class 
all classifi
 cation schemes depicted in the tax
onomy are directly related to the intentgoal of 
the adversary most of the existing adversarial 
ml attacks are whitebox attacks which are later 
converted to blackbox attacks by exploiting the 
transferability property of adversarial examples 
 the transferability property of adversarial ml 
means that adversarial perturbations generated 
for one ml model will often mislead other unseen 
ml models related research has been carried 
out on adversarial pattern recognition for more 
than a decade and even before that there was a 
smattering of works focused on performing ml in 
the presence of malicious errors 
brief review of the adversarial ml literature
adversarial ml attacks proposed in lit
erature ml models especially those that are 
dnnbased are very vulnerable to adversarial 
perturbations an adversarial sample x is created 
by adding a small carefully crafted perturbation d
to the correctly classifi
 ed sample x the perturba
tion d is calculated by approximating the optimi
zation problem given in equation  iteratively until 
the crafted adversarial example gets classifi
 ed by 
ml classifi
 er f in targeted class t 
x  x  argmin
δx
δ  f x  δ  t
 
 
in  szegedy et al  reported that the 
dnn inputoutput mapping is fairly discontinuous 
and dnns are not robust to small perturbations 
in the input this triggered an extraordinary inter
est in adversarial ml attacks in  goodfellow 
et al  proposed a nontargeted elementwise 
adversarial example generation method where 
the adversarial perturbation is generated by per
forming only a singlestep gradient update in the 
direction of the gradient at each element of the 
input example this method of generating adver
sarial ml attacks is called the fast gradient sign 
method fgsm kurakin et al  proposed 
the basic iterative method bim attack which 
improves the fgsm attack by introducing an 
iterative small perturbation optimization meth
od for generating adversarial examples paper
figure  the ml pipeline in cognitive networking through which we learn insights from raw network 
telemetry data by passing it through preprocessing and feature extraction stages and then construct a 
ml model for some specifi
 c task eg intrusion detection since our focus is on adversarial ml attacks 
we also highlight which parts of the pipeline are vulnerable to poisoning and evasion attacks 
cognitive
network 
test data 
unseen 
network data 
network 
telemetry 
data 
network data 
analysis
preprocessing
feature 
extraction
ml model 
construction
oﬄine
training and
tuning 
ml task
eg trained 
classiﬁer 
inferences
eg traﬃc
classiﬁcation 
y
r
a
s
r
e
v
d
a
poisoning attack
evasion attack
adversary
model theft
ieee network  januaryfebruary 
not et al  proposed a targeted saliency map 
based attack where a saliency map is used in an 
iterative manner to find the most significant fea
tures of the input that when fractionally perturbed 
cause dnns to misclassify this adversarial attack 
is known as the jacobian saliency map based 
attack jsma carlini et al  proposed three 
targeted and iterative adversarial ml attacks by 
exploiting the three different distance matrices 
l l and l and highlighted that the defensive 
distillation method  deployed to increase the 
robustness of dnns is not enough for building 
deterrence against adversarial ml attacks most of 
the adversarial ml attacks are whitebox attacks 
which are later converted to blackbox attacks 
by exploiting the property of transferability of 
adversarial examples more details on available 
adversarial ml attacks and their applications are 
reviewed in  
adversarial ml defenses proposed in the lit
erature in response to adversarial ml attacks 
researchers have come up with some defenses 
some of which focus on detection while others 
focus on prevention generally defenses against 
adversarial examples are divided into two broader 
categories as shown in fig  these categories are 
reactive defenses and proactive defenses reac
tive defenses involve retraining or reconfiguring 
the ml model after the adversarial ml attack or 
timely detection of the adversarial attack in order 
to save critical information proactive defenses 
involve preemption of adversarial attacks and 
preparing the ml model to defend against them 
the three major techniques of proactive defens
es are adversarial training feature squeezing and 
defensive distillation 
the technique of adversarial training proposed 
by goodfellow et al  requires that classifiers 
be preemptively trained on adversarial perturba
tions this defense provides robustness against 
adversarial examples the classifier is trained on 
but any perturbation on which the classifier has 
not been trained can still evade the classifier xu 
et al  proposed feature squeezing as another 
approach for hardening the ml schemes against 
adversarial attacks feature squeezing is a pro
cess of reducing the search space available to the 
adversary by fusing samples that correspond to 
different feature vectors in the original space into 
a single sample another solution called network 
distillation was proposed by papernot et al  
as a defense against adversarial perturbations 
which focused on hiding the gradients between 
the presoftmax and the softmax output to pro
vide robustness against gradientbased attacks 
on dnns this defense however was breached 
by carlini et al  who proposed adversarial 
perturbation techniques that successfully evaded 
defensive distillation based dnns
even though the onerous job of thwarting 
attacks currently appears to be a sisyphean task 
with no end in sight  for example although one 
can use adversarial training to train a dnn this is 
a onestep solution since further adversarial exam
ples can still be constructed for the new dnn 
model starting a cat and mouse game  the reali
zation of the cognitive networking vision requires 
and should motivate the development of robust 
ml solutions
the adversarial ml challenge for cognitive networks 
adversarial ml attacks have not yet been 
explored thoroughly for cognitive networking 
although a few works have highlighted the adver
sarial ml threat for cognitive networks especially 
the realtime network telemetry component of 
selfdriving cognitive networks in this article we 
focus on the challenge posed by adversarial ml 
to the security of cognitive networking applica
tions such as network traffic classification systems 
and automatic intrusion detection 
although numerous security attacks have been 
demonstrated on intrusion detection systems 
ids  little attention has focused on apply
ing adversarial ml attacks on ids similarly there 
does not exist much literature on adversarial ml 
attacks on network traffic classification another 
major component of realtime network teleme
try ahmed et al  highlighted the problem of 
adversarial ml attacks on network traffic classifi
cation where they have launched an adversarial 
ml attack on a support vector machine svm 
based network traffic classifier and showed that a 
smaller perturbation in the test example can suc
cessfully evade the classifiers decision boundary 
and compromises the integrity of the classifier 
figure  a taxonomy of adversarial ml attacks is provided in which we subclassify adversarial attacks and adversarial defense strategies
adversarial 
attacks
location speciﬁc 
attacks
knowledge
speciﬁc attacks
training attack 
poisoning attack
inference attack
evasion attack
whitebox attack
blackbox attack
intent speciﬁc 
attack
targeted attack
nontargeted 
attack
adversarial 
defenses
reactive
defenses
proactive 
defenses
retraining 
timely 
detection
defensive 
distillation
feature 
squeezing
adversarial 
training 
adversarial 
ml
 corona et al  provides 
a detailed survey and cate
gorizes the security attacks 
on ids into six categories 
evasion overstimulation 
poisoning denial of service 
response hijacking and 
reverse engineering 
ieee network  januaryfebruary 
in our previous work  we performed fgsm 
bim and jsma attacks on a malware classifier to 
highlight that malware classification in cognitive 
selforganizing networks is extremely vulnerable 
to adversarial ml attacks it has been shown in 
previous work that nominal feature perturbations 
are sufficient to fool a dnn that was previously 
classifying malware with  percent accuracy with 
 probability  
case studies adversarial ml attack on 
intrusion detection and network traffic 
classification systems 
in this section we present a concrete adversarial 
ml attack that is specific to networking applica
tions instead of focusing broadly on the expansive 
functional area of realtime telemetry of cognitive 
selfdriving networking we limit our focus to using 
ml for two surrogate realtime telemetry cognitive 
networking problems anomalybased intrusion 
detection and network traffic classification the 
purpose of these case studies is to highlight the 
ease with which an adversarial ml attack can be 
launched and to show that many cognitive network
ing based ml applications in their current form may 
not provide any robustness against adversarial per
turbations while our explicit focus is on ids and 
network traffic classification applications our insights 
apply more broadly to diverse supervised unsuper
vised and reinforcement learning techniques 
we formulated the network anomalybased 
intrusion detection problem as a binary classifi
cation problem where the classification is per
formed between two classes namely normal 
or dos denial of services svm and dnn are 
employed for performing the classification task 
the reason for selecting svm and dnn to per
form classification is to highlight the fact that both 
traditional and more recent ml techniques svm 
and dnn respectively are highly susceptible to 
small carefullycrafted adversarial examples 
for the network traffic classification we for
mulated it as a multiclass classification problem 
where the classification is performed between 
ten network traffic classes namely www mail 
bulk serv db int pp attack mmedia and 
games we employed svm and dnn for per
forming the classification task 
threat model 
adversary knowledge for both case studies 
we only consider evasion attacks on ml classifi
ers with whitebox settings where by definition 
the adversary has complete knowledge about the 
classifiers architecture hyperparameters and test 
data we trained an svm classifier with the radial 
basis function rbf kernel and utilized stochastic 
gradient descent for learning the parameters of 
the dnn 
adversary goal we assume that the adver
sary wants to compromise the integrity and 
availability of the deployed ml based intrusion 
detection and traffic classification systems for 
the ids case study the adversary perturbs the 
anomalous traffic ie dos class while ensur
ing the functional behavior in such a way that 
the classifier mistakes it as a normal traffic class 
for the traffic classification case study the goal 
of the adversary is to perturb the mail traffic 
in such a way that the classifier misclassifies it 
in any other traffic class although we used the 
mail class to perform the adversarial ml attack 
the proposed attack works equally well for any 
other target class in the dataset 
adversarial sample crafting 
for the ids case study we employed the con
cept of mutual information ix y a measure 
of the statistical dependence between two ran
dom variables to find the most discriminant 
features in both the normal and the dos class
es once the most discriminant features are 
identified we reduce the distance between 
them by using constrained l norm minimiza
tion on the discriminant feature set of the dos 
traffic to form a perturbation d the calcu
lated perturbation d is then added to a dos 
test example x to create an adversarial dos 
sample x when the adversarial sample x is 
subjected to the trained classifier f which 
was previously classifying correctly the clas
sifier classifies the dos adversarial example 
in the normal traffic class figure  illustrates 
the steps of the proposed adversarial example 
generation technique for the traffic classifi
cation case study we followed a similar pro
cedure as shown in fig  where we created 
adversarial examples for mail class
figure  performance of ids and network traffic classification before and after adversarial ml attacks
test 
data
mutual 
information
  
top most 
discriminant 
feature set m
of dos traﬃc
top most 
discriminant 
feature set n of 
normal traﬃc 
successful 
adversarial 
example
failed adversarial example
yes
no
ieee network  januaryfebruary 
experimental performance evaluation 
adversarial ml attack on ids to evaluate 
the performance of the proposed adversarial ml 
attack on the ids classifier we used the nslkdd 
intrusion detection dataset httpwwwunbca
cicdatasetsnslhtml we extracted only two class
es normal and dos for performing this exper
iment after the preprocessing  traffic features 
were extracted in total to train the svm and the 
dnn classifiers once the classifiers are trained 
we launched an adversarial ml attack in which we 
generated  adversarial examples  per
cent of the complete test data for the dos class 
by perturbing only  out of the  traffic features 
the size of the perturbation was constrained to be 
less than  to ensure the functional behavior 
of the dos traffic samples figure a provides a 
description of various performance measures such 
as accuracy f score recall and precision of the 
svm and the dnn classifiers before and after the 
attack on the ids classifier 
the proposed adversarial attack completely 
fooled the svm classifier as its dos class classifi
cation accuracy went below  percent the rest 
of the adversarial samples were classified as false 
positives in the normal traffic category in the 
case of a dnnbased intrusion detection classifier 
the proposed attack successfully evaded the dnn 
classifier the dos class classification accuracy of 
dnn faced a  percent drop in accuracy the 
accuracy deterioration would have been more 
devastating if the number of modified features 
was increased this decay in performance of 
dnn highlights that a very small carefully crafted 
input can lead dnn to a very serious malfunc
tion these huge drops in the performance of the 
svm and dnn classifiers highlight the security 
risk that adversarial ml poses to these mlbased 
techniques in cognitive networking applications 
adversarial ml attack on traffic classifica
tion we also evaluated the performance of the 
proposed adversarial ml attack on network traf
fic classification we used the highly cited inter
net traffic classification dataset by moore et al 
 the dataset consists of  traffic flows 
divided into  classes namely www mail 
bulk serv db int pp attack mmedia and 
games further details about the dataset are pro
vided in  we deployed svm rbf kernel 
and dnn for the classification task and achieved 
 percent and  percent classification accura
cy respectively we used  percent of the traffic 
for training the classifiers and  percent of the 
samples for testing the performance of the clas
sifiers for dnn we used four dense layers with 
 neurons per layer with relu as an activa
tion function since we trained dnn for class 
classification we used softmax as an activation 
function in the last layer to obtain classification 
figure  adversarial sample crafting technique where we assume whitebox settings and adversarial control over test data we employ 
mutual information ix y for extracting discriminating features and minimize l norm between most discriminating features of nor
mal and dos classes to create an adversarial perturbation for the dos traffic 
 
ieee network  januaryfebruary 
probabilities we used categorical crossentropy 
as a loss function to train the dnn with stochastic 
gradient descent sgd as an optimizer 
adversarial examples are generated for the 
mail class which is classified by the svm clas
sifier with  percent accuracy and the dnn 
classifier with  percent accuracy the total 
number of mail traffic samples in the test 
set is  and we produced  adversarial 
examples by following the procedure provided 
in fig  the adversarial samples successfully 
evaded the svm and dnn based classifiers 
where for svm the classification accuracy of 
the mail class has fallen from  percent to 
nearly  percent for dnn the classifica
tion accuracy of the mail class has dropped 
from  percent to  percent this drop in 
performance clearly highlights that the real
time telemetry component of the cognitive 
selfdriving network is highly vulnerable to 
adversarial ml attacks figure b depicts the 
performance drop in the class classification 
performance of svm and dnn 
for both ids and network traffic classification 
we reported results with a  percent confidence 
interval the confidence interval measures the 
uncertainty associated with the success of adver
sarial ml attacks it is evident from fig  that after 
the adversarial ml attack the uncertainty in ids 
and network traffic classification has increased 
which fulfills our goal of compromising the con
fidence of ids and network traffic classification
discussion
developing robustbydesign ml for cognitive networks 
it is important for ml algorithms used for mis
sioncritical applications in cognitive networking 
to be robust and resilient ml researchers in other 
application domains have started to work on 
robustbydesign models and algorithms and we 
should have similar if not higher standards for 
cognitive networking applications there does not 
exist much work on guidelines for evaluating the 
defenses against adversarial ml attacks particular
ly against cognitive networks in the following we 
provide some guidelines leveraging the insights 
shared by carlini et al  on how to effectively 
evaluate the robustness of ml schemes
	 check the adversarial threat model used 
in the defense under review for evaluating 
what kind of knowledge the adversary has 
about the targeted ml model
	 does the defense under review consider the 
presence of an adaptive adversary in the 
selfdriving cognitive networking environ
ment
	 does the defense under review provide 
robustness against gradientbased adversarial 
attacks 
	 evaluate the defense under consideration 
using different threat model assumptions and 
for different performance metrics
	 evaluate the defense under consideration 
against strong adversarial attacks ie optimi
zationbased attacks and not against weak 
attacks out of distribution adversarial exam
ples transferable adversarial examples to 
check whether the transferability property of 
adversarial examples is blocked or not
developing new metrics for ml in cognitive networks 
traditionally the metric used to evaluate the per
formance of an ml model nearly always has been 
a variant of the metric of prediction accuracy that 
is how often is the model correct in its prediction 
or classification to be sure accuracy can be mea
sured in various ways such as precision specifici
ty sensitivity recall but using accuracy alone as a 
metric can only inform us of the averagecase per
formance this has the implicit assumption that the 
distribution of the test data will be similar to the dis
tribution of the training data this assumption obvi
ously fails to hold when an adversary intentionally 
changes the test data with the explicit goal of defeat
ing the ml model there is therefore a need to also 
focus on evaluating a systems worst case perfor
mance and measure the adversarial resilience of the 
ml model we should move away from only using 
traditional ml metrics related to accuracy and preci
sion toward a greater emphasis on robustness trans
parency and resilience here we recommend some 
new metrics for ensuring the appropriate applica
tion and validation of ml schemes in selfdriving 
cognitive networking there can be more metrics 
depending on the design of the mlbased selfdriv
ing cognitive networking application
inference stability this is a measure that com
pares the output of the victims model before and 
after the adversarial attack inference stability is 
calculated by measuring the distribution similar
ity before and after the adversarial attack and 
defense divergence to the average is a popular 
way of computing the similarity between distri
butions for selfdriving cognitive networks infer
ence stability will provide information about the 
attack and recovery of the system from the adver
sarial ml attack
classification confidence variance this is 
a measure intended to demonstrate how the 
model is impacted by the adversarial attack and 
defensive technique more precisely classifica
tion confidence variance provides the change in 
the confidence of the classification of an example 
after the adversarial attack and after the adversari
al defense is applied
misclassification ratio this is a measure 
intended for quantifying the success of an adver
sarial attack it gives a measure of how many 
adversarial examples have successfully evaded 
the classifier it is also an important measure from 
the defenders perspective as the misclassification 
ratio provides a quantitative measure for testing 
the defense against adversarial attacks
semantic insights 
despite its success in other domains ml has 
traditionally not been as successful in terms of 
deployments in the real world for detecting anom
alies one important reason behind this is that for 
anomaly detection semantic knowledge under
lying the prediction and not only the prediction 
itself is important for operational networks as 
there is a need to also focus on evaluating a systems worst case performance and measure the adver
sarial resilience of the ml model we should move away from only using traditional ml metrics related 
to accuracy and precision toward a greater emphasis on robustness transparency and resilience
ieee network  januaryfebruary 
highlighted by sommer and paxson in  who 
emphasized the need of interpretability of ml in 
the context of intrusion detection and anomaly 
detection systems in general
the broader challenge for  
adversarial ml for cognitive networks 
in this article we highlighted the threat of adversarial 
examples on the mlbased realtime network telem
etry component of selfdriving cognitive networks 
realtime network telemetry consists of supervised 
ml and feature engineering but there are more 
complex tasks in selfdriving cognitive networks ie 
datadriven analysis and decision making in order 
to perform these tasks the network must have the 
ability to interact and adapt according to network 
conditions  deep reinforcement learning drl 
provides the ability to interact learn and adapt 
to the everchanging network conditions and it is 
expected to be heavily utilized in future selfdriving 
cognitive networks unfortunately drl also lacks 
robustness against adversarial examples and it has 
been recently shown  that adversarial examples 
can affect the performance of drl the threat of 
adversarial examples and brittleness of the known 
defenses is one of the major hurdles in the progress 
of cognitive selfdriving networks
conclusions 
in this article we introduced the problem of 
adversarial machine learning ml attacks on 
the ml models used in cognitive selfdriving net
works after introducing adversarial ml attacks 
we developed novel networkingspecific attacks 
on two surrogate realtime telemetry problems of 
selfdriving cognitive networks to highlight their 
vulnerability to adversarial examples this vulner
ability to adversarial ml attacks may turn out to 
be the achilles heel of cognitive networks unless 
the networking and ml communities get togeth
er to inoculate future cognitive networking from 
the malaise of adversarial ml attacks the devel
opment of effective defenses against adversarial 
ml attacks even though tough is not impossible 
since attackers are often constrained in how effec
tively they can attack a model and there has been 
some positive progress on this front this gives us 
guarded optimism that we may finally be able to 
develop a future of robust resilient and depend
able mlbased cognitive networking 
received april   accepted april   date of publication may   date of current version june  
digital object identifier 
access
unsupervised machine learning for networking
techniques applications and
research challenges
muhammad usama
 junaid qadir
 aunn raza hunain arif
koklim alvin yau
 yehia elkhatib
 amir hussain and ala alfuqaha
information technology university itupunjab lahore  pakistan
national university of science and technology nust islamabad  pakistan
sunway university subang jaya  malaysia
the school of computing and communications lancaster university lancaster la wa uk
school of computing edinburgh napier university edinburgh eh bn uk
taibah valley taibah university medina  saudi arabia
information and computing technology ict division college of science and engineering cse hamad bin khalifa university doha qatar
department of computer science western michigan university kalamazoo mi  usa
corresponding author ala alfuqaha aalfuqahahbkueduqa
the publication of this article was funded by the qatar national library qnl the statements made herein are solely the responsibility of
the authors
abstract
while machine learning and artiﬁcial intelligence have long been applied in networking
research the bulk of such works has focused on supervised learning recently there has been a rising
trend of employing unsupervised machine learning using unstructured raw network data to improve network
performance and provide services such as trafﬁc engineering anomaly detection internet trafﬁc classiﬁca
tion and quality of service optimization the growing interest in applying unsupervised learning techniques
in networking stems from their great success in other ﬁelds such as computer vision natural language
processing speech recognition and optimal control eg for developing autonomous selfdriving cars
in addition unsupervised learning can unconstrain us from the need for labeled data and manual handcrafted
feature engineering thereby facilitating ﬂexible general and automated methods of machine learning the
focus of this survey paper is to provide an overview of applications of unsupervised learning in the domain of
networking we provide a comprehensive survey highlighting recent advancements in unsupervised learning
techniques and describe their applications in various learning tasks in the context of networking we also
provide a discussion on future directions and open research issues while identifying potential pitfalls while
a few survey papers focusing on applications of machine learning in networking have previously been
published a survey of similar scope and breadth is missing in the literature through this timely review
we aim to advance the current state of knowledge by carefully synthesizing insights from previous survey
papers while providing contemporary coverage of the recent advances and innovations
index terms machine learning deep learning unsupervised learning computer networks
i introduction
networkssuch
as
the
internet
and
mobile
telecom
networksserve the function of the central hub of modern
human societies which the various threads of modern
life weave around with networks becoming increasingly
dynamic heterogeneous and complex the management of
such networks has become less amenable to manual admin
istration and it can beneﬁt from leveraging support from
the associate editor coordinating the review of this manuscript and
approving it for publication was nuno garcia
methods for optimization and automated decisionmaking
from the ﬁelds of artiﬁcial intelligence ai and machine
learning ml such ai and ml techniques have already
transformed multiple ﬁeldseg computer vision natural
language processing nlp speech recognition and opti
mal control eg for developing autonomous selfdriving
vehicleswith the success of these techniques mainly
attributed to ﬁrstly signiﬁcant advances in unsupervised
ml techniques such as deep learning secondly the ready
availability of large amounts of unstructured raw data
amenable to processing by unsupervised learning algorithms
volume  
 
  ieee translations and content mining are permitted for academic research only
personal use is also permitted but republicationredistribution requires ieee permission
see httpwwwieeeorgpublications_standardspublicationsrightsindexhtml for more information
m usama et al unsupervised machine learning for networking techniques applications and research challenges
and ﬁnally advances in computing technologies through
advances such as cloud computing graphics processing unit
gpu technology and other hardware enhancements it is
anticipated that ai and ml will also make a similar impact
on the networking ecosystem and will help realize a future
vision of cognitive networks   in which networks will
selforganize and will autonomously implement intelligent
networkwide behavior to solve problems such as routing
scheduling resource allocation and anomaly detection the
initial attempts towards creating cognitive or intelligent
networks have relied mostly on supervised ml methods
which are efﬁcient and powerful but are limited in scope
by their need for labeled data with network data becom
ing increasingly voluminous with a disproportionate rise
in unstructured unlabeled data there is a groundswell of
interest in leveraging unsupervised ml methods to utilize
unlabeled data in addition to labeled data where available
to optimize network performance  the rising interest in
applying unsupervised ml in networking applications also
stems from the need to liberate ml applications from restric
tive demands of supervised ml another reason of employing
unsupervised ml in networking is the expensiveness of
curating labeled network data at scale since labeled data
may be unavailable and manual annotation is prohibitively
inconvenient in addition to be outdated quickly due to the
highly dynamic nature of computer networks 
we are already witnessing the failure of human network
administrators to manage and monitor all bits and pieces
of network  and the problem will only exacerbate with
further growth in the size of networks with paradigms such as
becoming the internet of things iot an mlbased network
management system nms is desirable in such large net
works so that faultsbottlenecksanomalies may be predicted
in advance with reasonable accuracy in this regard networks
already have ample amount of untapped data which can pro
vide us with decisionmaking insights making networks more
efﬁcient and selfadapting with unsupervised ml the pipe
dream is that every algorithm for adjusting network parame
ters be it tcp congestion window or rerouting network traf
ﬁc during peak time will optimize itself in a selforganizing
fashion according to the environment and application user
and network quality of service qos requirements and
constraints  unsupervised ml methods in concert with
existing supervised ml methods can provide a more efﬁcient
method that lets a network manage monitor and optimize
itself while keeping the human administrators in the loop with
the provisioning of timely actionable information
next generation networks are expected to be selfdriven
which means they have the ability to selfconﬁgure optimize
and heal  all these selfdriven properties can be achieved
by building artiﬁcial intelligence in the system using ml
techniques selfdriven networks are supposed to utilize the
network data to perform networking chores and most of
the network data is imbalanced and unlabeled in order to
develop a reliable datadriven network data quality must be
taken care before subjecting it to an appropriate unsupervised
ml  unsupervised ml techniques facilitate the analy
sis of raw datasets thereby helping in generating analytic
insights from unlabeled data recent advances in hierarchical
learning clustering algorithms factor analysis latent models
and outlier detection have helped signiﬁcantly advance the
state of the art in unsupervised ml techniques in particular
recent unsupervised ml advancessuch as the development
of deep learning techniques have however signif
icantly advanced the ml state of the art by facilitating the
processing of raw data without requiring careful engineering
and domain expertise for feature crafting deep learning is
a class of machine learning where hierarchical architectures
are used for unsupervised feature learning and these learned
features are then used for classiﬁcation and other related tasks
 the versatility of deep learning and distributed ml
can be seen in the diversity of their applications that range
from selfdriving cars to the reconstruction of brain circuits
 unsupervised learning is also often used in conjunction
with supervised learning in semisupervised learning setting
to preprocess the data before analysis and thereby help in
crafting a good feature representation and in ﬁnding patterns
and structures in unlabeled data
the rapid advances in deep neural networks the democ
ratization of enormous computing capabilities through cloud
computing and distributed computing and the ability to store
and process large swathes of data have motivated a surging
interest in applying unsupervised ml techniques in the net
working ﬁeld the ﬁeld of networking also appears to be well
suited to and amenable to applications of unsupervised ml
techniques due to the largely distributed decisionmaking
nature of its protocols the availability of large amounts of
network data and the urgent need for intelligentcognitive
networking consider the case of routing in networks net
works these days have evolved to be very complex and
they incorporate multiple physical paths for redundancy and
utilize complex routing methodologies to direct the trafﬁc
the application trafﬁc does not always take the optimal
path we would expect leading to unexpected and inefﬁcient
routing performance to tame such complexity unsupervised
ml techniques can autonomously selforganize the network
taking into account a number of factors such as realtime
network congestion statistics as well as application qos
requirements 
the purpose of this paper is to highlight the important
advances in unsupervised learning and after providing a
tutorial introduction to these techniques to review how such
techniques have been or could be used for various tasks in
modern nextgeneration networks comprising both computer
networks as well as mobile telecom networks
a contribution of the paper
to the best of our knowledge there does not exist a survey that
speciﬁcally focuses on the important applications of unsu
pervised ml techniques in networks even though a number
of surveys exist that focus on speciﬁc ml applications per
taining to networkingfor instance surveys on using ml
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
table  comparison of our paper with existing survey and review papers legend means covered  means not covered means partially covered
for cognitive radios  trafﬁc identiﬁcation and classiﬁca
tion  and anomaly detection   previous survey
papers have either focused on speciﬁc unsupervised learning
techniques eg  have provided a survey of the applica
tions of neural networks in wireless networks or on some
speciﬁc applications of computer networking  have pro
vided a survey of the applications of ml in cyber intru
sion detection our survey paper is timely since there is
great interest in deploying automated and selftaught unsu
pervised learning models in the industry and academia due
to relatively limited applications of unsupervised learning
in networkingin particular the deep learning trend has
not yet impacted networking in a major wayunsupervised
learning techniques hold a lot of promises for advancing
the state of the art in networking in terms of adaptability
ﬂexibility and efﬁciency the novelty of this survey is that it
covers many different important applications of unsupervised
ml techniques in computer networks and provides readers
with a comprehensive discussion of the unsupervised ml
trends as well as the suitability of various unsupervised ml
techniques a tabulated comparison of our paper with other
existing survey and review articles is presented in table 
b organization of the paper
the organization of this paper is depicted in figure 
section ii provides a discussion on various unsupervised ml
techniques namely hierarchical learning data clustering
latent variable models and outlier detection section iii
presents a survey of the applications of unsupervised ml
speciﬁcally in the domain of computer networks section iv
describes future work and opportunities with respect to the
use of unsupervised ml in future networking section v dis
cusses a few major pitfalls of the unsupervised ml approach
and its models finally section vi concludes this paper for
the readers facilitation table  shows all the acronyms used
in this survey for convenient referencing
ii techniques for unsupervised learning
in this section we will introduce some widely used
unsupervised learning techniques and their applications in
computer networks we have divided unsupervised learning
techniques into six major categories hierarchical learning
data clustering latent variable models dimensionality reduc
tion and outlier detection figure  depicts a taxonomy of
unsupervised learning techniques and also the relevant sec
tions in which these techniques are discussed to provide a
better understanding of the application of unsupervised ml
techniques in networking we have added few subsections
highlighting signiﬁcant applications of unsupervised ml
techniques in networking domain
a hierarchical learning
hierarchical learning is deﬁned as learning simple and
complex features from a hierarchy of multiple linear and
nonlinear activations in learning models a feature is a mea
surable property of the input data desired features are ideally
informative discriminative and independent in statistics
features are also known as explanatory or independent vari
ables  feature learning also known as data representa
tion learning is a set of techniques that can learn one or more
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
figure  outline of the paper
figure  taxonomy of unsupervised learning techniques
features from input data  it involves the transformation
of raw data into a quantiﬁable and comparable representation
which is speciﬁc to the property of the input but general
enough for comparison to similar inputs conventionally
features are handcrafted speciﬁc to the application on hand
it relies on domain knowledge but even then they do not
generalize well to the variation of realworld data which
gives rise to automated learning of generalized features from
the underlying structure of the input data like other learning
algorithms feature learning is also divided among domains
of supervised and unsupervised learning depending on the
type of available data almost all unsupervised learning
algorithms undergo a stage of feature extraction in order to
learn data representation from unlabeled data and generate
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
table  list of common acronyms used
a feature vector on the basis of which further tasks are
performed
hierarchical learning is intimately related to how deep
learning is performed in modern multilayer neural networks
in particular deep learning techniques beneﬁts from the
fundamental concept of artiﬁcial neural networks anns
a deep structure consists of multiple hidden layers with mul
tiple neurons in each layer a nonlinear activation function
a cost function and a backpropagation algorithm deep
learning  is a hierarchical technique that models high
level abstraction in data using many layers of linear and
nonlinear transformations with deep enough stack of these
transformation layers a machine can selflearn a very com
plex model or representation of data learning takes place
in hidden layers and the optimal weights and biases of the
neurons are updated in two passes namely the forward pass
and backward pass a typical ann and typical cyclic and
acyclic topologies of interconnection between neurons are
shown in figure  a brief taxonomy of unsupervised nns
is presented in figure 
an ann has three types of layers namely input
hidden
and
output
each
having
different
activation
parameters learning is the process of assigning optimal
activation parameters enabling ann to perform input to
output mapping for a given problem an ann may require
multiple hidden layers involving a long chain of computa
tions ie its depth  deep learning has revolutionized
ml and is now increasingly being used in diverse settings
eg object identiﬁcation in images speech transcription into
text matching users interests with items such as news items
movies products and making recommendations etc but
until  relatively few people were interested in deep
learning due to the high computational cost of deep learning
procedures it was widely believed that training deep learning
architectures in an unsupervised manner was intractable and
supervised the training of deep nns dnn also showed poor
performance with large generalization errors  however
recent advances  have shown that deep learning
can be performed efﬁciently by separate unsupervised pre
training of each layer with the results revolutionizing the ﬁeld
of ml starting from the input observation layer which acts
as an input to the subsequent layers pretraining tends to learn
data distributions while the usual supervised stage performs
a local search for ﬁnetuning
 unsupervised multilayer feed forward nn
unsupervised multilayer feedforward nn with reference
to graph theory has a directed graph topology as shown
in figure  it consists of no cycles ie does not have a feed
back path in input propagation through nn such kind of nn
is often used to approximate a nonlinear mapping between
inputs and required outputs autoencoders are the prime
examples of unsupervised multilayer feedforward nns
a autoencoders
an autoencoder is an unsupervised learning algorithm for
ann used to learn compressed and encoded representation
of data mostly for dimensionality reduction and for unsu
pervised pretraining of feedforward nns autoencoders are
generally designed using approximation function and trained
using backpropagation and stochastic gradient descent sgd
techniques autoencoders are the ﬁrst of their kind to use
the backpropagation algorithm to train with unlabeled data
autoencoders aim to learn a compact representation of the
function of input using the same number of input and output
units with usually less hidden units to encode a feature vector
they learn the input data function by recreating the input
at the output which is called encodingdecoding to learn
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
figure  illustration of an ann left different types of ann topologies right
figure  taxonomy of unsupervised neural networks
at the time of training nn in short a simple autoencoder
learns a lowdimensional representation of the input data by
exploiting similar recurring patterns
autoencoders have different variants  such as vari
ational autoencoders sparse autoencoders and denoising
autoencoders variational autoencoder is an unsupervised
learning technique used clustering dimensionality reduction
and visualization and for learning complex distributions 
in a sparse autoencoder a sparse penalty on the latent layer
is applied for extracting a unique statistical feature from
unlabeled data finally denoising autoencoders are used to
learn the mapping of a corrupted data point to its original
location in the data space in an unsupervised manner for
manifold learning and reconstruction distribution learning
 unsupervised competitive learning nn
unsupervised competitive learning nns is a winnertakeall
neuron scheme where each neuron competes for the right of
the response to a subset of the input data this scheme is used
to remove the redundancies from the unstructured data two
major techniques of unsupervised competitive learning nns
are selforganizing maps and adaptive resonance theory nns
a selforganizing kohonen maps
selforganizing maps som also known as kohonens
maps   are a special class of nns that uses the
concept of competitive learning in which output neurons
compete amongst themselves to be activated in a realvalued
output results having only single neuron or group of neu
rons called winning neuron this is achieved by creat
ing lateral inhibition connections negative feedback paths
between neurons  in this orientation the network deter
mines the winning neuron within several iterations subse
quently it is forced to reorganize itself based on the input data
distribution hence they are called selforganizing maps
they were initially inspired by the human brain which has
specialized regions in which different sensory inputs are rep
resentedprocessed by topologically ordered computational
maps in som neurons are arranged on vertices of a lattice
commonly one or two dimensions the network is forced
to represent higherdimensional data in lowerdimensional
representation by preserving the topological properties of
input data by using neighborhood function while transform
ing the input into a topological space in which neuron posi
tions in the space are representatives of intrinsic statistical
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
features that tell us about the inherently nonlinear nature
of soms
training a network comprising som is essentially a
threestage process after random initialization of weighted
connections the three stages are as follow 
 competition each neuron in the network computes its
value using a discriminant function which provides the
basis of competition among the neurons neuron with
the largest discriminant value in the competition group
is declared the winner
 cooperation the winner neuron then locates the center
of the topological neighborhood of excited neurons in
the previous stage providing a basis for cooperation
among excited neighboring neurons
 adaption the excited neurons in the neighborhood
increasedecrease their individual values of the discrimi
nant function in regard to input data distribution through
subtle adjustments such that the response of the winning
neuron is enhanced for similar subsequent input adap
tion stage is distinguishable into two substages  the
ordering or selforganizing phase in which weight vec
tors are reordered according to topological space and
 the convergence phase in which the map is ﬁne
tuned and declared accurate to provide statistical quan
tiﬁcation of the input space this is the phase in which
the map is declared to be converged and hence trained
one essential requirement in training a som is the
redundancy of the input data to learn about the underlying
structure of neuron activation patterns moreover sufﬁcient
quantity of data is required for creating distinguishable clus
ters withstanding enough data for classiﬁcation problem
there exist a problem of gray area between clusters and cre
ation of inﬁnitely small clusters where input data has minimal
patterns
b adaptive resonance theory
adaptive resonance theory art is another different cat
egory of nn models that is based on the theory of human
cognitive information processing it can be explained as an
algorithm of incremental clustering which aims at forming
multidimensional clusters automatically discriminating and
creating new categories based on input data primarily art
models are classiﬁed as an unsupervised learning model
however there exist art variants that employ supervised
and semisupervised learning approaches as well the main
setback of most nn models is that they lose old information
updatingdiminishing weights as new information arrives
therefore an ideal model should be ﬂexible enough to accom
modate new information without losing the old one and this
is called the plasticitystability problem art models provide
a solution to this problem by selforganizing in real time and
creating a competitive environment for neurons automati
cally discriminatingcreating new clusters among neurons to
accommodate any new information
art
model
resonates
around
topdown
observer
expectations and bottomup sensory information while
keeping their difference within the threshold limits of vigi
lance parameter which in result is considered as the member
of the expected class of neurons  learning of an art
model primarily consists of a comparison ﬁeld recognition
ﬁeld vigilance threshold parameter and a reset module
the comparison ﬁeld takes an input vector which in result is
passed to best match in the recognition ﬁeld the best match
is the current winning neuron each neuron in the recognition
ﬁeld passes a negative output in proportion to the quality of
the match which inhibits other outputs therefore exhibiting
lateral inhibitions competitions once the winning neuron
is selected after a competition with the best match to the input
vector the reset module compares the quality of the match to
the vigilance threshold if the winning neuron is within the
threshold it is selected as the output else the winning neuron
is reset and the process is started again to ﬁnd the next best
match to the input vector in case where no neuron is capable
to pass the threshold test a search procedure begins in which
the reset module disables recognition neurons one at a time to
ﬁnd a correct match whose weight can be adjusted to accom
modate the new match therefore art models are called self
organizing and can deal with the plasticitystability dilemma
 unsupervised deep nn
in recent years unsupervised deep nn has become the most
successful unsupervised structure due to its application in
many benchmarking problems and applications  three
major types of unsupervised deep nns are deep belief nns
deep autoencoders and convolutional nns
a deep belief nn
deep belief neural network or simply deep belief networks
dbn is a probabilitybased generative graph model that is
composed of hierarchical layers of stochastic latent variables
having binary valued activations which are referred as hidden
units or feature detectors the top layers in dbns have
undirected symmetric connections between them forming
an associative memory dbns provide a breakthrough in
unsupervised learning paradigm in the learning stage dbn
learns to reconstruct its input each layer acting as feature
detectors dbn can be trained by greedy layerwise training
starting from the top layer with raw input subsequent layers
are trained with the input data from the previously visible
layer  once the network is trained in an unsupervised
manner and learned the distribution of the data it can be
ﬁnetuned using supervised learning methods or supervised
layers can be concatenated in order to achieve the desired task
for instance classiﬁcation
b deep autoencoder
another famous type of dbn is the deep autoencoder which
is composed of two symmetric dbnsthe ﬁrst of which is
used to encode the input vector while the second decodes
by the end of the training of the deep autoencoder it tends
to reconstruct the input vector at the output neurons and
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
therefore the central layer between both dbns is the actual
compressed feature vector
c convolutional nn
convolutional nn cnn are feed forward nn in which
neurons are adapted to respond to overlapping regions in
twodimensional input ﬁelds such as visual or audio input
it is commonly achieved by local sparse connections among
successive layers and tied shared weights followed by rec
tifying and pooling layers which results in transformation
invariant feature extraction another advantage of cnn over
simple multilayer nn is that it is comparatively easier to train
due to sparsely connected layers with the same number of
hidden units cnn represents the most signiﬁcant type of
architecture for computer vision as they solve two challenges
with the conventional nns  scalable and computationally
tractable
algorithms
are
needed
for
processing
high
dimensional images and  algorithms should be transfor
mation invariant since objects in an image can occur at an
arbitrary position however most cnns are composed of
supervised feature detectors in the lower and middle hidden
layers in order to extract features in an unsupervised manner
a hybrid of cnn and dbn called convolutional deep belief
network cdbn is proposed in  making probabilistic
maxpooling to cover larger input area and convolution as
an inference algorithm makes this model scalable with higher
dimensional input learning is processed in an unsupervised
manner as proposed in  ie greedy layerwise lower to
higher training with unlabeled data
cdbn is a promising scalable generative model for learn
ing translation invariant hierarchical representation from any
highdimensional unlabeled data in an unsupervised man
ner taking advantage of both worlds ie dbn and cnn
cnn being widely employed for computer vision applica
tions can be employed in computer networks for optimiza
tion of quality of experience qoe and quality of service
qos of multimedia content delivery over networks which
is an open research problem for nextgeneration computer
networks 
 unsupervised recurrent nn
recurrent nn rnn is the most complex type of nn
and hence the nearest match to an actual human brain that
processes sequential inputs it can learn temporal behaviors
of a given training data rnn employs an internal memory
per neuron to process such sequential inputs in order to
exhibit the effect of the previous event on the next compared
to feed forward nns rnn is a stateful network it may
contain computational cycles among states and uses time
as the parameter in the transition function from one unit to
another being complex and recently developed it is an open
research problem to create domainspeciﬁc rnn models and
train them with sequential data speciﬁcally there are two
maxpooling is an algorithm of selecting the most responsive receptive
ﬁeld of a given interest region
perspectives of rnn to be discussed in the scope of this
survey namely the depth of the architecture and the training
of the network the depth in the case of a simple artiﬁcial
nn is the presence of hierarchical nonlinear intermediate
layers between the input and output signals in the case of an
rnn there are different hypotheses explaining the concept
of depth one hypothesis suggests that rnns are inherently
deep in nature when expanded with respect to sequential
input there are a series of nonlinear computations between
the input at time ti and the output at time ti  k
however at an individual discrete time step certain tran
sitions are neither deep nor nonlinear there exist inputto
hidden hiddentohidden and hiddentooutput transitions
which are shallow in the sense that there are no intermediate
nonlinear layers at discrete time step in this regard different
deep architectures are proposed in  that introduce inter
mediate nonlinear transitional layers in between the input
hidden and output layers another novel approach is also
proposed by stacking hidden units to create a hierarchical
representation of hidden units which mimic the deep nature
of standard deep nns
due to the inherently complex nature of rnn to the best
of our knowledge there is no widely adopted approach for
training rnns and many novel methods both supervised
and unsupervised are introduced to train rnns considering
unsupervised learning of rnn in the scope of this paper 
employ long shortterm memory lstm rnn to be trained
in an unsupervised manner using unsupervised learning algo
rithms namely binary information gain optimization and
non parametric entropy optimization in order to make a
network to discriminate between a set of temporal sequences
and cluster them into groups results have shown remarkable
ability of rnns for learning temporal sequences and cluster
ing them based on a variety of features two major types of
unsupervised recurrent nn are hopﬁeld nn and boltzmann
machine
a hopfield nn
hopﬁeld nn is a cyclic recurrent nn where each node is
connected to others hopﬁeld nn provides an abstraction
of circular shift register memory with nonlinear activation
functions to form a global energy function with guaranteed
convergence to local minima hopﬁeld nns are used for
ﬁnding clusters in the data without a supervisor
b boltzmann machine
the boltzmann machine is a stochastic symmetric recur
rent nn that is used for search and learning problems
due to binary vector based simple learning algorithm of
boltzmann machine very interesting features representing
the complex unstructured data can be learned  since
the boltzmann machine uses multiple hidden layers as fea
ture detectors the learning algorithm becomes very slow
to avoid slow learning and to achieve faster feature detection
instead of boltzmann machine a faster version namely the
restricted boltzmann machine rbm is used for practical
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
figure  clustering process
problems  restricted boltzmann machine learns a prob
ability distribution over its input data but since it is restricted
in its layer to layer connectivity rbm loses its property of
recurrence it is faster than a boltzmann machine because it
only uses one hidden layer as a feature detector layer rbm
is used for dimensionality reduction clustering and feature
learning in computer networks
 significant applications of hierarchical
learning in networks
annsdnns are the most researched topic when creat
ing intelligent systems in computer vision and natural lan
guage processing whereas their application in computer
networks are very limited they are employed in differ
ent networking applications such as classiﬁcation of trafﬁc
anomalyintrusion detection detecting distributed denial of
service ddos attacks and resource management in cogni
tive radios  the motivation of using dnn for learning
and predicting in networks is the unsupervised training that
detects hidden patterns in ample amount of data that is near
to impossible for a human to handcraft features catering for
all scenarios moreover many new research shows that a
single model is not enough for the need of some applications
so developing a hybrid nn architecture having pros and
cons of different models creates a new efﬁcient nn which
provides even better results such an approach is used in 
in which a hybrid model of art and rnn is employed to
learn and predict trafﬁc volume in a computer network in
real time realtime prediction is essential to adaptive ﬂow
control which is achieved by using hybrid techniques so that
art can learn new input patterns without retraining the
entire network and can predict accurately in the time series
of rnn furthermore dnns are also being used in resource
allocation and qoeqos optimizations using nn for opti
mization efﬁcient resource allocation without affecting the
user experience can be crucial in the time when resources are
scarce authors of   propose a simple dbn for opti
mizing multimedia content delivery over wireless networks
by keeping qoe optimal for end users table  also provides
a tabulated description of hierarchical learning in networking
applications however these are just a few notable examples
of deep learning and neural networks in networks refer to
section iii for more applications and detailed discussion on
deep learning and neural networks in computer networks
b data clustering
clustering is an unsupervised learning task that aims to ﬁnd
hidden patterns in unlabeled input data in the form of clus
ters  simply put it encompasses the arrangement of data
in meaningful natural groupings on the basis of the similarity
between different features as illustrated in figure  to learn
about its structure clustering involves the organization of
data in such a way that there are high intracluster and low
intercluster similarity the resulting structured data is termed
as dataconcept  clustering is used in numerous applica
tions from the ﬁelds of ml data mining network analysis
pattern recognition and computer vision the various tech
niques used for data clustering are described in more detail
later in section iib in networking clustering techniques
are widely deployed for applications such as trafﬁc analysis
and anomaly detection in all kinds of networks eg wireless
sensor networks and mobile adhoc networks with anomaly
detection 
clustering improves performance in various applications
mcgregor et al  propose an efﬁcient packet tracing
approach using the expectationmaximization em proba
bilistic clustering algorithm which groups ﬂows packets
into a small number of clusters where the goal is to analyze
network trafﬁc using a set of representative clusters
a brief overview of different types of clustering methods
and their relationships can be seen in figure  clustering can
be divided into three main types  namely hierarchical
clustering bayesian clustering and partitional clustering
hierarchical clustering creates a hierarchical decomposition
of data whereas bayesian clustering forms a probabilistic
model of the data that decides the fate of a new test point
probabilistically in contrast partitional clustering constructs
multiple partitions and evaluates them on the basis of certain
criterion or characteristic such as the euclidean distance
before delving into the general subtypes of clustering
there are two unique clustering techniques which need to be
discussed namely densitybased clustering and gridbased
clustering in some cases densitybased clustering is classi
ﬁed as a partitional clustering technique however we have
kept it separate considering its applications in networking
densitybased models target the most densely populated area
of data space and separate it from areas having low densities
thus forming clusters   use densitybased clustering
to cluster data stream in real time which is important in many
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
table  applications of hierarchical learning deep learning in networking applications
figure  clustering taxonomy
applications eg intrusion detection in networks another
technique is gridbased clustering which divides the data
space into cells to form a gridlike structure subsequently
all clustering actions are performed on this grid  
also present a novel approach that uses a customized grid
based clustering algorithm to detect anomalies in networks
 proposed a novel method for clustering the time series
data this scheme was based on a distance measure between
temporal features of the time series
we move on next to describe three major types of data clus
tering approaches as per the taxonomy is shown in figure 
 hierarchical clustering
hierarchical clustering is a wellknown strategy in data min
ing and statistical analysis in which data is clustered into a
hierarchy of clusters using an agglomerative bottomup or a
divisive topdown approach almost all hierarchical clus
tering algorithms are unsupervised and deterministic the
primary advantage of hierarchical clustering over unsuper
vised kmeans and em algorithms is that it does not require
the number of clusters to be speciﬁed beforehand however
this advantage comes at the cost of computational efﬁciency
common hierarchical clustering algorithms have at least
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
quadratic computational complexity compared to the linear
complexity of kmeans and em algorithms hierarchical
clustering methods have a pitfall these methods fail to accu
rately classify messy highdimensional data as its heuristic
may fail due to the structural imperfections of empirical
data furthermore the computational complexity of the com
mon agglomerative hierarchical algorithms is nphard som
as discussed in section iia is a modern approach that can
overcome the shortcomings of hierarchical models 
 bayesian clustering
bayesian clustering is a probabilistic clustering strategy
where the posterior distribution of the data is learned on the
basis of a prior probability distribution bayesian clustering
is divided into two major categories namely parametric and
nonparametric  the major difference between para
metric and nonparametric techniques is the dimensionality
of parameter space if there are ﬁnite dimensions in the
parameter space the underlying technique is called bayesian
parametric otherwise the underlying technique is called
bayesian nonparametric a major pitfall with the bayesian
clustering approach is that the choice of the wrong prior prob
ability distributions can distort the projection of the data 
performed bayesian nonparametric clustering of network
trafﬁc data to determine the network application type
 partitional clustering
partitional clustering corresponds to a special class of cluster
ing algorithms that decomposes data into a set of disjoint clus
ters given n observations the clustering algorithm partitions
a data into k  n clusters  partitional clustering is further
classiﬁed into kmeans clustering and mixture models
a kmeans clustering
kmeans clustering is a simple yet widely used approach
for classiﬁcation it takes a statistical vector as an input to
deduce classiﬁcation models or classiﬁers kmeans cluster
ing tends to distribute m observations into n clusters where
each observation belongs to the nearest cluster the member
ship of observation to a cluster is determined using the cluster
mean kmeans clustering is used in numerous applications
in the domains of network analysis and trafﬁc classiﬁca
tion  used kmeans clustering in conjunction with super
vised id decision tree learning models to detect anomalies
in a network an id decision tree is an iterative supervised
decision tree algorithm based on the concept learning system
kmeans clustering provided excellent results when used
in trafﬁc classiﬁcation  showed that kmeans cluster
ing performs well in trafﬁc classiﬁcation with an accuracy
of 
kmeans clustering is also used in the domain of network
security and intrusion detection reference  proposed
a kmeans algorithm for intrusion detection experimental
results on a subset of kdd dataset shows that the detec
tion rate stays above  while the false alarm rate stays
below  results and analysis of experiments on kmeans
algorithm have demonstrated a better ability to search clusters
globally
another variation of kmeans is known as kmedoids
in which rather than taking the mean of the clusters the most
centrally located data point of a cluster is considered as the
reference point of the corresponding cluster  few of
the applications of kmedoids in the spectrum of anomaly
detection can be seen here  
b mixture models
mixture models are powerful probabilistic models for uni
variate and multivariate data mixture models are used to
make statistical inferences and deductions about the prop
erties of the subpopulations given only observations on the
pooled population they have also used to statistically model
data in the domains of pattern recognition computer vision
ml etc finite mixtures which are a basic type of mixture
model naturally model observations that are produced by
a set of alternative random sources inferring and deduc
ing different parameters from these sources based on their
respective observations lead to clustering of the set of obser
vations this approach to clustering tackles drawbacks of
heuristicbased clustering methods and hence it is proven to
be an efﬁcient method for node classiﬁcation in any large
scale network and has shown to yield effective results com
pared to techniques commonly used for instance kmeans
and hierarchical agglomerative methods rely on supervised
design decisions such as the number of clusters or validity
of models  moreover combining the em algorithm with
mixture models produces remarkable results in deciphering
the structure and topology of the vertices connected through a
multidimensional network  reference  used gaus
sian mixture model gmm to outperform signature based
anomaly detection in network trafﬁc data
 significant applications of
clustering in networks
clustering can be found in mostly all unsupervised learning
problems and there are diverse applications of clustering
in the domain of computer networks two major network
ing applications where signiﬁcant use of clustering can be
seen are intrusion detection and internet trafﬁc classiﬁca
tion one novel way to detect anomaly is proposed in 
this approach preprocesses the data using genetic algo
rithm ga combined with hierarchical clustering approach
called balanced iterative reducing using clustering hier
archies birch to provide an efﬁcient classiﬁer based on
support vector machine svm this hierarchical cluster
ing approach stores abstracted data points instead of the
whole dataset thus giving more accurate and quick clas
siﬁcation compared to all past methods producing bet
ter results in detecting anomalies another approach 
discusses the use of gridbased and densitybased cluster
ing for anomaly and intrusion detection using unsupervised
learning reference  used kshape clustering scheme
for analyzing spatiotemporal heterogeneity in mobile usage
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
table  applications of data clustering in networking applications
basically a scalable parallel framework for clustering large
datasets with high dimensions is proposed and then improved
by inculcating frequency pattern trees table  also provides
a tabulated description of data clustering applications in net
works these are just a few notable examples of clustering
approaches in networks refer to section iii for the detailed
discussion on some salient clustering applications in the con
text of networks
c latent variable models
a latent variable model is a statistical model that relates
the manifest variables with a set of latent or hidden vari
ables latent variable model allows us to express relatively
complex distributions in terms of tractable joint distributions
over an expanded variable space  underlying variables
of a process are represented in higher dimensional space
using a ﬁxed transformation and stochastic variations are
known as latent variable models where the distribution in
higher dimension is due to small number of hidden variables
acting in a combination  these models are used for
data visualization dimensionality reduction optimization
distribution learning blind signal separation and factor anal
ysis next we will begin our discussion on various latent
variable models namely mixture distribution factor analysis
blind signal separation nonnegative matrix factorization
bayesian networks  probabilistic graph models pgm
hidden markov model hmm and nonlinear dimensional
ity reduction techniques which further includes generative
topographic mapping multidimensional scaling principal
curves isomap localliy linear embedding and tdistributed
stochastic neighbor embedding
 mixture distribution
mixture distribution is an important latent variable model
that is used for estimating the underlying density function
mixture distribution provides a general framework for den
sity estimation by using the simpler parametric distributions
expectation maximization em algorithm is used for esti
mating the mixture distribution model  through max
imization of the loglikelihood of the mixture distribution
model
 factor analysis
another important type of latent variable model is factor
analysis which is a density estimation model it has been
used quite often in collaborative ﬁltering and dimensionality
reduction it is different from other latent variable models
in terms of the allowed variance for different dimensions
as most latent variable models for dimensionality reduction
in conventional settings use a ﬁxed variance gaussian noise
model in the factor analysis model latent variables have
diagonal covariance rather than isotropic covariance
 blind signal separation
blind signal separation bss also referred to as blind
source separation is the identiﬁcation and separation of
independent source signals from mixed input signals with
out or very little information about the mixing process
figure  depicts the basic bss process in which source
signals are extracted from a mixture of signals it is a funda
mental and challenging problem in the domain of signal pro
cessing although the concept is extensively used in all types of
multidimensional data processing most common techniques
employed for bss are principal component analysis pca
and independent component analysis ica
a principal component analysis pca is a statisti
cal procedure that utilizes orthogonal transformation on
the data to convert n number of possibly correlated vari
ables into lesser k number of uncorrelated variables named
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
figure  blind signal separation bss a mixed signal composed of various input signals mixed by some
mixing process is blindly processed ie with no or minimal information about the mixing process to
show the original signals
principal components principal components are arranged in
the descending order of their variability ﬁrst one catering
for the most variable and the last one for the least being a
primary technique for exploratory data analysis pca takes a
cloud of data in n dimensions and rotates it such that maxi
mum variability in the data is visible using this technique
it brings out the strong patterns in the dataset so that these
patterns are more recognizable thereby making the data easier
to explore and visualize
pca has primarily been used for dimensionality reduction
in which input data of n dimensions is reduced to k dimen
sions without losing critical information in the data the
choice of the number of principal components is a question
of the design decision much research has been conducted on
selecting the number of components such as crossvalidation
approximations  optimally k is chosen such that the
ratio of the average squared projection error to the total
variation in the data is less than or equal to  by which
 of the variance is retained in the k principal components
but depending on the application domain different designs
can increasedecrease the ratio while maximizing the required
output commonly many features of a dataset are often
highly correlated hence pca results in retaining  of the
variance while signiﬁcantly reducing the data dimensions
b independent component analysis ica is another tech
nique for bss that focuses on separating multivariate input
data into additive components with the underlying assump
tion that the components are nongaussian and statistically
independent the most common example to understand ica
is the cocktail party problem in which there are n people
talking simultaneously in a room and one tries to listen to
a single voice ica actually separates source signals from
input mixed signal by either minimizing the statistical depen
dence or maximizing the nongaussian property among the
components in the input signals by keeping the underly
ing assumptions valid statistically ica can be seen as the
extension of pca while pca tries to maximize the second
moment variance of data hence relying heavily on gaussian
features on the other hand ica exploits inherently non
gaussian features of the data and tries to maximize the fourth
moment of linear combination of inputs to extract nonnormal
source components in the data 
 nonnegative matrix factorization
nonnegative matrix factorization nmf is a technique to
factorize a large matrix into two or more smaller matrices
with no negative values that is when multiplied it recon
structs the approximate original matrix nmf is a novel
method in decomposing multivariate data making it easy
and straightforward for exploratory analysis by nmf hid
den patterns and intrinsic features within the data can be
identiﬁed by decomposing them into smaller chunks enhanc
ing the interpretability of data for analysis with posi
tivity constraints however there exist many classes of
algorithms  for nmf having different generalization
properties for example two of them are analyzed in 
one of which minimizes the least square error and while the
other focuses on the kullbackleibler divergence keeping
algorithm convergence intact
 hidden markov model
hidden markov models hmm are stochastic models of
great utility especially in domains where we wish to analyze
temporal or dynamic processes such as speech recognition
primary users pu arrival pattern in cognitive radio net
works crns etc hmms are highly relevant to crns since
many environmental parameters in crns are not directly
observable an hmmbased approach can analytically model
a markovian stochastic process in which we do not have
access to the actual states which are assumed to be unob
served or hidden instead we can observe a state that is
stochastically dependent on the hidden state it is for this
reason that an hmm is deﬁned to be a doubly stochastic
process
 bayesian networks  probabilistic
graph models pgm
in bayesian learning we try to ﬁnd the posterior proba
bility distributions for all parameter settings in this setup
we ensure that we have a posterior probability for every
possible parameter setting it is computationally expensive
but we can use complicated models with a small dataset and
still avoid overﬁtting posterior probabilities are calculated by
dividing the product of sampling distribution and prior dis
tribution by marginal likelihood in simple words posterior
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
probabilities are calculated using bayes theorem the basis
of reinforcement learning was also derived by using bayes
theorem  since bayesian learning is computationally
expensive a new research trend is approximate bayesian
learning  authors in  have given a comprehensive
survey of different approximate bayesian inference algo
rithms with the emergence of bayesian deep learning frame
work the deployment of bayes learning based solution is
increasing rapidly
probabilistic graph modeling is a concept associated with
bayesian learning a model representing the probabilistic
relationship between random variables through a graph is
known as a probabilistic graph model pgm nodes and
edges in the graph represent a random variable and their prob
abilistic dependence respectively pgm are of two types
directed pgm and undirected pgm bayes networks also
fall in the regime of directed pgm pgm is used in many
important areas such as computer vision speech processing
and communication systems bayesian learning combined
with pgm and latent variable models forms a probabilistic
framework where deep learning is used as a substrate for mak
ing improved learning architecture for recommender systems
topic modeling and control systems 
 significant applications of latent variable
models in networks
in  authors have applied latent structure on email corpus
to ﬁnd interpretable latent structure as well as evaluating
its predictive accuracy on missing data task a dynamic
latent model for a social network is represented in 
characterization of the endtoend delay using a weibull
mixture model is discussed in  mixture models for end
host trafﬁc analysis have been explored in  bss is a
set of statistical algorithms that are widely used in differ
ent application domains to perform different tasks such as
dimensionality reduction correlating and mapping features
etc  employed pca for internet trafﬁc classiﬁcation in
order to separate different types of ﬂows in a network packet
stream similarly authors of  used a semisupervised
approach where pca is used for feature learning and an
svm classiﬁer for intrusion detection in an autonomous
network system another approach for detecting anomalies
and intrusions proposed in  uses nmf to factorize differ
ent ﬂow features and cluster them accordingly furthermore
ica has been widely used in telecommunication networks to
separate mixed and noisy source signals for efﬁcient service
for example  extends a variant of ica called efﬁcient
fast ica efica for detecting and estimating the symbol
signals from the mixed cdma signals received from the
source endpoint
in other literature pca uses a probabilistic approach to
ﬁnd the degree of conﬁdence in detecting an anomaly in
wireless networks  furthermore pca is also chosen
as a method of clustering and designing wireless sensor
networks wsns with multiple sink nodes  however
these are just a few notable examples of bss in networks
refer to section iii for more applications and detailed discus
sion on bss techniques in the networking domain
bayesian learning has been applied for classifying inter
net trafﬁc where internet trafﬁc is classiﬁed based on the
posterior probability distributions for early trafﬁc identiﬁ
cation in campus network real discretized conditional proba
bility has been used to construct a bayesian classiﬁer 
hostlevel intrusion detection using bayesian networks is
proposed in  authors in  purposed a bayesian
learning based feature vector selection for anomalies classi
ﬁcation in bgp port scan attacks prevention scheme using
a bayesian learning approach is discussed in  inter
net threat detection estimation system is presented in 
a new approach towards outlier detection using bayesian
belief networks is described in  application of bayesian
networks in mimo systems has been explored in 
location estimation using bayesian network in lan is dis
cussed in  similarly bayes theory and pgm are both
used in lowdensity parity check ldpc and turbo codes
which are the fundamental components of information coding
theory table  also provides a tabulated description of latent
variable models applications in networking
d dimensionality reduction
representing data in fewer dimensions is another well
established task of unsupervised learning real world data
often have high dimensionsin many datasets these dimen
sions can run into thousands even millions of potentially
correlated dimensions  however it is observed that the
intrinsic dimensionality governing parameters of the data is
less than the total number of dimensions in order to ﬁnd the
essential pattern of the underlying data by extracting intrinsic
dimensions it is necessary that the real essence is not lost
eg it may be the case that a phenomenon is observable
only in higherdimensional data and is suppressed in lower
dimensions these phenomena are said to suffer from the
curse of dimensionality  while dimensionality reduc
tion is sometimes used interchangeably with feature selection
  a subtle difference exists between the two 
feature selection is traditionally performed as a supervised
task with a domain expert helping in handcrafting a set of
critical features of the data such an approach generally
can perform well but is not scalable and prone to judgment
bias dimensionality reduction on the other hand is more
generally an unsupervised task where instead of choosing
a subset of features it creates new features dimensions as
a function of all features said differently feature selection
considers supervised data labels while dimensionality reduc
tion focuses on the data points and their distributions in an
ndimensional space
there exist different techniques for reducing data dimen
sions  including projection of higher dimensional points
onto lower dimensions independent representation and
sparse representation which should be capable of recon
structing the approximate data dimensionality reduction is
useful for data modeling compression and visualization
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
table  applications of latent variable models in networking applications
by creating representative functional dimensions of the data
and eliminating redundant ones it becomes easier to visualize
and form a learning model independent representation tries
to disconnect the source of variation underlying the data
distribution such that the dimensions of the representation
are statistically independent  sparse representation tech
nique represents the data vectors in linear combinations of
small basis vectors
it is worth noting here that many of the latent variable mod
els eg pca ica factor analysis also function as tech
niques for dimensionality reduction in addition to techniques
such as pca icawhich infer the latent inherent structure
of the data through a linear projection of the dataa number
of nonlinear dimensionality reduction techniques have also
been developed and will be focused upon in this section to
avoid repetition of linear dimensionality reduction techniques
that have already been covered as part of the previous subsec
tion linear dimensionality reduction techniques are useful in
many settings but these methods may miss important nonlin
ear structure in the data due to their subspace assumption
which posits that the highdimensional data points lie on a
linear subspace for example on a d or d plane such
an assumption fails in high dimensions when data points are
random but highly correlated with neighbors in such environ
ments nonlinear dimensionality reductions through manifold
learning techniqueswhich can be construed as an attempt
to generalize linear frameworks like pca so that nonlinear
structure in data can also be recognizedbecome desirable
even though some supervised variants also exist manifold
learning is mostly performed in an unsupervised fashion
using the nonlinear manifold substructure learned from the
highdimensional structure of the data from the data itself
without the use of any predetermined classiﬁer or labeled
data some nonlinear dimensionality reduction manifold
learning techniques are described below
 isomap
isomap is a nonlinear dimensionality reduction technique that
ﬁnds the underlying low dimensional geometric information
about a dataset algorithmic features of pca and mds
are combined to learn the low dimensional nonlinear man
ifold structure in the data  isomap uses geodesic dis
tance along the shortest path to calculate the low dimension
representation shortest path which can be computed using
dijkstras algorithm
 generative topographic model
generative topographic mapping gtm represents the
nonlinear latent variable mapping from continuous low
dimensional distributions embedded in high dimensional
spaces  data space in gtm is represented as reference
vectors and these vectors are a projection of latent points in
data space it is a probabilistic variant of som and works
by calculating the euclidean distance between data points
gtm optimizes the loglikelihood function and the resulting
probability deﬁnes the density in data space
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
table  applications of dimensionality reduction in networking applications
 locally linear embedding
locally linear embedding lle  is an unsupervised
nonlinear dimensionality reduction algorithm lle repre
sents data in lower dimensions yet preserving the higher
dimensional embedding lle depicts data in a single global
coordinate of lower dimensional mapping of input data lle
is used to visualize multidimensional dimensional manifolds
and feature extraction
 principal curves
the principal curve is a nonlinear dataset summarizing tech
nique where nonparametric curves pass through the middle
of multidimensional dataset providing the summary of the
dataset  these smooth curves minimize the average
squared orthogonal distance between data points this process
also resembles the maximum likelihood for nonlinear regres
sion in the presence of gaussian noise 
 nonlinear multidimensional scaling
nonlinear multidimensional scaling nmds  is a non
linear latent variable representation scheme it works as an
alternative scheme for factor analysis in factor analysis
a multivariate normal distribution is assumed and similari
ties between different objects are expressed as a correlation
matrix whereas nmds does not impose such a condition
and it is designed to reach the optimal low dimensional con
ﬁguration where similarities and dissimilarities among matri
ces can be observed nmds is also used in data visualization
and mining tools for depicting the multidimensional data in 
dimensions based on the similarities in the distance matrix
 tdistributed stochastic neighbor embedding
tdistributed stochastic neighbor embedding tsne is
another nonlinear dimensionality reduction scheme it is used
to represent high dimensional data in  or  dimensions
tsne constructs a probability distribution in high dimen
sional space and constructs a similar distribution in lower
dimensions and minimizes the kullbackâăşleibler kl
divergence between two distributions which is a useful
way to measure the difference between two probability
distributions 
table  also provides a tabulated description of dimen
sionality reduction applications in networking the applica
tions of nonlinear dimensionality reduction methods are later
described in detail in section iiid
e outlier detection
outlier detection is an important application of unsupervised
learning a sample point that is distant from other samples is
called an outlier an outlier may occur due to noise measure
ment error heavy tail distributions and a mixture of two dis
tributions there are two popular underlying techniques for
unsupervised outlier detection upon which many algorithms
are designed namely the nearest neighbor based technique
and clustering based method
 nearest neighbor based outlier detection
the nearest neighbor method works on estimating the
euclidean distances or average distance of every sample from
all other samples in the dataset there are many algorithms
based on nearest neighbor based techniques with the most
famous extension of the nearest neighbor being a knearest
neighbor technique in which only k nearest neighbors par
ticipate in the outlier detection  local outlier factor is
another outlier detection algorithm which works as an exten
sion of the knearest neighbor algorithm connectivitybased
outlier factors  inﬂuenced outlierness  and local
outlier probability models  are few famous examples of
the nearest neighbor based techniques
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
 cluster based outlier detection
clustering based methods use the conventional kmeans
clustering technique to ﬁnd dense locations in the data and
then perform density estimation on those clusters after den
sity estimation a heuristic is used to classify the formed clus
ter according to the cluster size anomaly score is computed
by calculating the distance between every point and its cluster
head local density cluster based outlier factor  cluster
ing based multivariate gaussian outlier score   and
histogram based outlier score  are the famous cluster
based outlier detection models in literature svm and pca
are also suggested for outlier detection in literature
 significant applications of outlier
detection in networks
outlier detection algorithms are used in many different appli
cations such as intrusion detection fraud detection data leak
age prevention surveillance energy consumption anomalies
forensic analysis critical state detection in designs elec
trocardiogram and computed tomography scan for tumor
detection unsupervised anomaly detection is performed by
estimating the distances and densities of the provided non
annotated data  more applications of outlier detection
schemes will be discussed in section iii
f lessons learnt
key lessons drawn from the review of unsupervised learning
techniques are summarized below
 hierarchical learning techniques are the most pop
ular schemes in literature for feature detection and
extraction
 learning the joint distribution of a complex distribution
over an expanded variable space is a difﬁcult task
latent variable models have been the recommended
and wellestablished schemes in literature for this prob
lem these models are also used for dimensionality
reduction and better representation of data
 visualization of unlabeled multidimensional data is
another unsupervised task in this research we have
explored the dimensionality reduction as an underlying
scheme for developing better multidimensional data
visualization tools
iii applications of unsupervised
learning in networking
in this section we will introduce some signiﬁcant appli
cations of the unsupervised learning techniques that have
been discussed in section ii in the context of computer net
works we highlight the broad spectrum of applications in
networking and emphasize the importance of mlbased tech
niques rather than classical hardcoded statistical methods
for achieving more efﬁciency adaptability and performance
enhancement
a internet traffic classification
internet trafﬁc classiﬁcation is of prime importance in net
working as it provides a way to understand develop and
measure the internet internet trafﬁc classiﬁcation is an
important component for service providers to understand
the characteristics of the service such as quality of service
quality of experience user behavior network security and
many other key factors related to the overall structure of a
network  in this subsection we will survey the unsuper
vised learning applications in network trafﬁc classiﬁcation
as networks evolve at a rapid pace malicious intruders are
also evolving their strategies numerous novel hacking and
intrusion techniques are being regularly introduced causing
severe ﬁnancial jolts to companies and headaches to their
administrators tackling these unknown intrusions through
accurate trafﬁc classiﬁcation on the network edge therefore
becomes a critical challenge and an important component of
the network security domain initially when networks used
to be small simple portbased classiﬁcation technique that
tried to identify the associated application with the corre
sponding packet based on its port number was used however
this approach is now obsolete because recent malicious soft
ware uses a dynamic portnegotiation mechanism to bypass
ﬁrewalls and security applications a number of contrast
ing internet trafﬁc classiﬁcation techniques have been pro
posed since then and some important ones are discussed
next
most of the modern trafﬁc classiﬁcation methods use
different ml and clustering techniques to produce accurate
clusters of packets depending on their applications thus pro
ducing efﬁcient packet classiﬁcation  the main purpose
of classifying networks trafﬁc is to recognize the destination
application of the corresponding packet and to control the
ﬂow of the trafﬁc when needed such as prioritizing one ﬂow
over others another important aspect of trafﬁc classiﬁcation
is to detect intrusions and malicious attacks or screen out
forbidden applications packets
the ﬁrst step in classifying internet trafﬁc is selecting
accurate features which is an extremely important yet com
plex task accurate feature selection helps ml algorithms
to avoid problems like class imbalance low efﬁciency and
low classiﬁcation rate there are three major feature selec
tion methods in internet trafﬁc for classiﬁcation the ﬁl
ter method the wrapper based method and the embedded
method these methods are based on different ml and
genetic learning algorithms  two major concerns in
feature selection for internet trafﬁc classiﬁcation are the
large size of data and imbalanced trafﬁc classes to deal
with these issues and to ensure accurate feature selection
a minmax ensemble feature selection scheme is proposed
in  a new informationtheoretic approach for feature
selection for skewed datasets is described in  this
algorithm has resolved the multiclass imbalance issue but
it does not resolve the issues of feature selection in 
an unsupervised autoencoder based scheme has outperformed
previous feature learning schemes autoencoders were used
as a generative model and were trained in a way that the
bottleneck layer learned a latent representation of the feature
set these features were then used for malware classiﬁcation
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
and anomaly detection to produce results that improved the
state of the art in feature selection 
much work has been done on classifying trafﬁc based on
supervised ml techniques initially in  the concept of
clustering bidirectional ﬂows of packets came out with the
use of em probabilistic clustering algorithm which clusters
the ﬂows depending on various attributes such as packet size
statistics interarrival statistics byte counts and connection
duration etc  furthermore clustering is combined with
the above model  this strategy uses naïve bayes clus
tering to classify trafﬁc in an automated fashion recently
unsupervised ml techniques have also been introduced in
the domain of network security for classifying trafﬁc major
developments include a hybrid model to classify trafﬁc in
more unsupervised manner  which uses both labeled
and unlabeled data to train the classiﬁer making it more
durable and efﬁcient however later on completely unsuper
vised methods for trafﬁc classiﬁcation have been proposed
and still much work is going on in this area initially a com
pletely unsupervised approach for trafﬁc classiﬁcation was
employed using the kmeans clustering algorithm combined
with log transformation to classify data into corresponding
clusters then  highlighted that using kmeans and this
method for trafﬁc classiﬁcation can improve accuracy by
 to achieve an overall  accuracy
another improved and faster approach was proposed
in   which examines the size of the ﬁrst ﬁve
packets and determines the application correctly using unsu
pervised learning techniques this approach has shown to
produce better results than the stateoftheart trafﬁc classi
ﬁer and also has removed its drawbacks such as dealing
with outliers or unknown packets etc another similar auto
mated trafﬁc classiﬁer and application identiﬁer can be seen
in  and they use the autoclass unsupervised bayesian
classiﬁer which automatically learns the inherent natural
classes in a dataset
in  another novel strategy for trafﬁc classiﬁcation
known as network trafﬁc classiﬁcation using correlation was
proposed  which uses nonparametric nn combined
with statistical measurement of correlation within data to
efﬁciently classify trafﬁc the presented approach addressed
the three major drawbacks of supervised and unsupervised
learning classiﬁcation models ﬁrstly they are inappropriate
for sparse complex networks as labeling of training data takes
too much computation and time secondly many supervised
schemes such as svm are not robust to training data size and
lastly and most importantly all supervised and unsupervised
algorithms perform poorly if there are few training samples
thus classifying the trafﬁc using correlations appears to
be more efﬁcient and adapting  compared four ann
approaches for computer network trafﬁc and modeled the
internet trafﬁc like a time series and used mathematical
methods to predict the time series a greedy layerwise train
ing for unsupervised stacked autoencoder produced excellent
classiﬁcation results but at the cost of signiﬁcant system
complexity genetic algorithm combined with constraint
clustering process is used for internet trafﬁc data characteri
zation  in another work a twophased ml approach for
internet trafﬁc classiﬁcation using kmeans and c deci
sion tree is presented in  where the average accuracy of
classiﬁcation was 
a new approach for internet trafﬁc classiﬁcation has been
introduced in  by  in which unidirectional and bidi
rectional information is extracted from the collected trafﬁc
and kmeans clustering is performed on the basis of statistical
properties of the extracted ﬂows a supervised classiﬁer then
classiﬁes these clusters another unsupervised learning based
algorithm for internet trafﬁc detection is described in 
where a restricted boltzmann machine based svm is pro
posed for trafﬁc detection this paper model the detection as
a classiﬁcation problem results were compared with ann
and decision tree algorithms on the basis of precision and
recall application of deep learning algorithms in internet
trafﬁc classiﬁcation has been discussed in  with this work
also outlining the open research challenges in applying deep
learning for internet trafﬁc classiﬁcation these problems
are related to training the models for big data since internet
data for deep learning falls in big data regime optimiza
tion issues of the designed models given the uncertainty in
internet trafﬁc and scalability of deep learning architectures
in internet trafﬁc classiﬁcation to cope with the challenges
of developing a ﬂexible highperformance platform that can
capture data from a highspeed network operating at more
than  gbps  have introduced a platform for high
speed packet to tuple sequence conversion which can sig
niﬁcantly advance the state of the art in realtime network
trafﬁc classiﬁcation in another work  used stacked
autoencoders for internet trafﬁc classiﬁcation and produced
more than  accurate results for the two classes in kdd
 dataset
deep belief network combined with gaussian model
employed for internet trafﬁc prediction in wireless mesh
backbone network has been shown to outperform the pre
vious maximum likelihood estimation technique for trafﬁc
prediction  given the uncertainty of wlan channel
trafﬁc classiﬁcation is very tricky  proposed a new
variant of gaussian mixture model by incorporating universal
background model and used it for the ﬁrst time to classify
the wlan trafﬁc a brief overview of the different internet
trafﬁc classiﬁcation systems classiﬁed on the basis of unsu
pervised technique and tasks discussed earlier is presented in
the table 
b anomalyintrusion detection
the increasing use of networks in every domain has increased
the risk of network intrusions which makes user privacy and
the security of critical data vulnerable to attacks according
to the annual computer crime and security survey  
conducted by the combined teams of csi computer security
institute and fbi federal bureau of investigation total
ﬁnancial losses faced by companies due to the security attacks
and network intrusions were estimated as us  million
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
table  internet traffic classification with respect to unsupervised learning techniques and tasks
moreover according to the symantec internet security
threat report  approximately  new vulnerabilities
were identiﬁed in the year  in addition more than
 million new variants of malware programs and  major
breaches were detected exposing  million identities there
fore insecurity in todays networking environment has given
rise to the everevolving domain of network security and
intrusionanomaly detection 
in general intrusion detection systems ids recognize
or identify any act of security breach within a computer or a
network speciﬁcally all requests which could compromise
the conﬁdentiality and availability of data or resources of a
system or a particular network generally intrusion detection
systems can be categorized into three types  signature
based intrusion detection systems  anomaly detection
systems and  compoundhybrid detection systems which
include selective attributes of both preceding systems
signature detection also known as misuse detection is a
technique that was initially used for tracing and identify
ing misuses of users important data computer resources
and intrusions in the network based on the previously col
lected or stored signatures of intrusion attempts the most
important beneﬁt of a signaturebased system is that a com
puter administrator can exactly identify the type of attack a
computer is currently experiencing based on the sequence
of the packets deﬁned by stored signatures however it is
nearly impossible to maintain the signature database of all
evolving possible attacks thus this pitfall of the signature
based technique has given rise to anomaly detection systems
anomaly detection system ads is a modern intrusion
and anomaly detection system initially it creates a baseline
image of a system proﬁle its network and user program
activity then on the basis of this baseline image ads classi
ﬁes any activity deviating from this behavior as an intrusion
few beneﬁts of this technique are ﬁrstly they are capable
of detecting insider attacks such as using system resources
through another user proﬁle secondly each ads is based on
a customized user proﬁle which makes it very difﬁcult for
attackers to ascertain which types of attacks would not set an
alarm and lastly it detects unknown behavior in a computer
system rather than detecting intrusions thus it is capable of
detecting any unknown sophisticated attack which is different
from the users usual behavior however these beneﬁts come
with a tradeoff in which the process of training a system on
a users normal proﬁle and maintaining those proﬁles is a
time consuming and challenging task if an inappropriate user
proﬁle is created it can result in poor performance since
ads detects any behavior that does not align with a users
normal proﬁle its false alarm rate can be high lastly another
pitfall of ads is that a malicious user can train ads gradually
to accept inappropriate trafﬁc as normal
as anomaly and intrusion detection have been a popular
research area since the origin of networking and internet
numerous supervised as well as unsupervised  learning
techniques have been applied to efﬁciently detect intrusions
and malicious activities however latest research focuses on
the application of unsupervised learning techniques in this
area due to the challenge and promise of using big data for
optimizing networks
initial work focuses on the application of basic unsu
pervised clustering algorithms for detecting intrusions and
anomalies in  an unsupervised approach was proposed
based on density and gridbased clustering to accurately
classify the highdimensional dataset in a set of clusters
those points which do not fall in any cluster are marked
as abnormal  this approach has produced good results
but the false positive rate was very high in followup work
another improved approach that used fuzzy rough cmeans
clustering was introduced   kmeans clustering is
also another famous approach used for detecting anomalies
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
which were later proposed in   which showed great
accuracy and outperformed existing unsupervised methods
however later in  an improved method which used
kmeans clustering combined with the c decision tree
algorithm was proposed  to produce more efﬁcient
results than prior approaches  combines cluster centers
and nearest neighbors for effective feature representation
which ensures a better intrusion detection however a limi
tation with this approach is that it is not able to detect user to
resource and remote to local attacks another scheme using
unsupervised learning approach for anomaly detection is pre
sented in  the presented scheme combines subspace
clustering and correlation analysis to detect anomalies and
provide protection against unknown anomalies this exper
iment used wide backbone networks data  spanning
over six years and produced better results than previous
kmeans based techniques work presented in  shows
that for different intrusions schemes there are a small set
of measurements required to differentiate between normal
and anomalous trafﬁc the authors used two coclustering
schemes to perform clustering and to determine which
measurement subset contributed the most towards accurate
detection
another famous approach for increasing detection accu
racy is ensemble learning work presented in  employed
many hybrid incremental ml approaches with gradient
boosting and ensemble learning to achieve better detection
performance authors in  surveyed anomaly detection
research from  to  and ﬁnd out the unique algo
rithmic similarity for anomaly detection in internet traf
ﬁc most of the algorithms studied have following sim
ilarities  removal of redundant information in training
phase to ensure better learning performance  feature selec
tion usually performed using unsupervised techniques and
increases the accuracy of detection  use ensembles clas
siﬁers or hybrid classiﬁers rather than baseline algorithms
to get better results authors in  have developed an
artiﬁcial immune system based intrusion detection system
they have used densitybased spatial clustering of applica
tions with noise to develop an immune system against the
network intrusion detection
the application of unsupervised intrusion detection in
cloud network is presented in  where authors have pro
posed a fuzzy clustering ann to detect the less frequent
attacks and improve the detection stability in cloud networks
another application of unsupervised intrusion detection sys
tem for clouds is surveyed in  where fuzzy logic based
intrusion detection system using supervised and unsupervised
ann is proposed for intrusion detection this approach is
used for dos and ddos attacks where the scale of the attack
is very large network intrusion anomaly detection system
nids based on kmeans clustering are surveyed in 
this survey is unique as it provides distance and similarity
measure of the intrusion detection and this perspective has not
been studied before  unsupervised learning based appli
cations of anomaly detection schemes for wireless personal
area networks wireless sensor networks cyberphysical sys
tems and wlans are surveyed in 
another paper  reviewing anomaly detection has pre
sented the application of unsupervised svm and clustering
based applications in network intrusion detection systems
unsupervised discretization algorithm is used in bayesian
network classiﬁer for intrusion detection which is based on
bayesian model averaging  the authors show that the
proposed algorithm performs better than the naïve bayes
classiﬁer in terms of accuracy on the nslkdd intru
sion detection dataset border gateway protocol bgp
the core internet interautonomous systems interas rout
ing protocolis also error prone to intrusions and anoma
lies to detect these bgp anomalies many supervised and
unsupervised ml solutions such as hidden markov models
and principal component analysis have been proposed in
literature  another problem for anomaly detection is
low volume attacks which have become a big challenge for
network trafﬁc anomaly detection while longrange depen
dencies lrd are used to identify these low volume attacks
lrd usually works on aggregated trafﬁc volume but since
the volume of trafﬁc is low the attacks can pass undetected
to accurately identify low volume abnormalities  pro
posed the examination of lrd behavior of control plane and
data plane separately to identify low volume attacks
other than clustering another widely used unsupervised
technique for detecting malicious and abnormal behavior in
networks is soms the specialty of soms is that they can
automatically organize a variety of inputs and deduce patterns
among themselves and subsequently determine whether the
new input ﬁts in the deduced pattern or not thus detecting
abnormal inputs   soms have also been used
in hostbased intrusion detection systems in which intruders
and abusers are identiﬁed at a host system through incom
ing data trafﬁc  later on a more robust and efﬁcient
technique was proposed to analyze data patterns in tcp
trafﬁc  furthermore complex nns have also been
applied to solve the same problem and remarkable results
have been produced a few examples include the application
of art combined with som  the use of pca can also
be seen in detecting intrusions  nmf has also been
used for detecting intruders and abusers  and lastly
dimensionality reduction techniques have also been applied
to eradicate intrusions and anomalies in the system  for
more applications refer to table  which classiﬁes different
network anomaly and intrusion detection systems on the basis
of unsupervised learning techniques discussed earlier
c network operations optimizations
and analytics
network management comprises of all the operations
included in initializing monitoring and managing of a com
puter network based on its network functions which are the
primary requirements of the network operations the general
purpose of network management and monitoring systems
is to ensure that basic network functions are fulﬁlled and
volume  
m usama et al unsupervised machine learning for networking techniques applications and research challenges
table  anomaly  network intrusion detection systems anids with respect to unsupervised learning techniques
if there is any malfunctioning in the network it should be
reported and addressed accordingly following is a summary
of different network optimization tasks achieved through
unsupervised learning models
 qosqoe optimization
qos and qoe are measures of service performance and end
user experience respectively qos mainly deals with the
performance as seen by the user being measured quantita
tively while qoe is a qualitative measure of subjective met
rics experienced by the user qosqoe for internet services
especially multimedia content delivery services is crucial in
order to maximize the user experience with the dynamic and
bursty nature of internet trafﬁc computer networks should
be able to adapt to these changes without compromising
enduser experiences as qoe is quite subjective it heavily
relies on the underlying qos which is affected by different
network parameters see discussions stats and author profiles for this publication at httpswwwresearchgatenetpublication
vector indexing algorithm for post processing of otdr data
conference paper  july 
citation
reads
 authors
muhammad usama
 publications    citations   
see profile
sajid sheikh muhammad
national university of computer and emerging sciences
 publications    citations   
see profile
all content following this page was uploaded by muhammad usama on  september 
the user has requested enhancement of the downloaded file
vector indexing algorithm for post 
processing of otdr data 
muhammad usama s sheikh muhammad
dept of electrical engineering
national university of computer and emerging sciences fastnu lahore pakistan 
 
abstractthe paper details the vector indexing 
algorithm for post processing of data in optical time 
domain reflectometer post processing is necessary in 
otdr for event detection and feature extraction 
from the acquired traces the vector indexing 
algorithm uses the acquired data trace to extract 
accurate event location and improve upon the spatial 
resolution of the otdr the proposed algorithm has 
been tested on our selfdeveloped otdr board and 
its performance has been benchmarked against the 
real measured event locations   
keywords optical time domain reflectometer 
otdr fiber under test fut vector index event 
detection feature extraction  
 
i 
introduction 
optical 
time 
domain 
reflectometery 
or 
backscattering has been widely used for measuring 
the distribution of attenuation along an optical fiber 
since   otdr is a valuable technique for 
characterizing losses and locating faults in fiber 
communication links  otdr testing is the most 
common method available for determining the exact 
location of break in an installed fiber optic cable 
when the cable jacket is not visibly damaged  
otdrs are used to measure a fibers length endto
end loss location of optical loss and reflectivity of 
components along the fiber  otdr works on the 
principle of rayleigh backscattering the basic idea 
lies in transmitting a short pulse of light through a 
fiber and examining the time dependent response of 
the resulting backscattered signal    
 a small part of injected light is captured by the 
core of the fiber and propagates backwards any 
change in the backscattered level along the fiber is 
due to a defect or an alteration in the properties of 
the fiber often called an event otdr measures 
the backscatter light as a function of time from the 
initial pulse injection performance metrics for 
comparing and contrasting various approaches in 
optical time domain reflectometery exists and 
primarily uses one way fiber attenuation range 
ldb which results in a reflectometer output snr 
of unity    
as the users of optical fiber have migrated to 
longer transmission wavelengths because of lower 
loss and as higher quality fibers have become 
available there is literally less backscattered light to 
be measured  event detection and classification 
becomes tough for minute reflections in otdr 
signal processing as the rayleigh backscatter is 
about db lower than the launch power  variety 
of techniques has been used to detect such weak 
signals a composite coding scheme for snr 
enhancement has been used for such weak signal 
detection and tested for our inhouse built otdr 
the notion lies in combining complementary 
correlation codes with the simplex codes to achieve 
higher gain than conventional coding techniques 
  
 research in the postprocessing algorithm for 
otdr revolves around the ways of improving the 
method of extracting the event information and 
features from the otdr signature in this paper an 
algorithm is presented for the detection of the 
discontinuities in otdr signature that will describe 
optical fiber attenuation characteristic buried in high 
level additive signal such algorithms are employed 
to post process the output of an otdr that will not 
only locate the position of the connector splice 
crack bend and cut along the fiber it will also 
provide loss characteristic of each individual event 
an otdr output consists of two parameters the 
distance in km and attenuation in db an otdr 
plot its output in a graph format on the otdr 
screen with distance on xaxis and attenuation on 
yaxis a conventional otdr trace is shown in 
figure  
 
fig  examplary otdr trace  
 in upcoming sections existing techniques for 
post processing of otdr data our proposed 
methodology and experimental testbed is discussed 
followed by a section on main requirements for post 
processing and finally the achieved results are 
quantified in the experimental results section 
ii 
existing event detection techniques 
three distinct techniques exist which are useful 
for the post processing of otdr output data   
a least square approximation 
least square approximation is the most famous 
method used in post processing algorithms for 
th european conference on network and optical communications  th conference on optical cabling and infrastructure  nococi 
isbn  july   graz austria
th european conference on network and optical communications  th conference on optical cabling and infrastructure  nococi 
isbn  july   graz austria
th european conference on network and optical communications  th conference on optical cabling and infrastructure  nococi 
isbn  july   graz austria
th european conference on network and optical communications  th conference on optical cabling and infrastructure  nococi 
isbn  july   graz austria
otdrs best line fit is calculated for noisy data 
which ensures minimum mean square error 
mmse then it is subjected to threshold 
detection sharp changes in the backscatter data are 
identified and extracted a general rule with least 
square approximation is that an events magnitude 
should be at least double the magnitude of noise to 
be accurately located  if data is very noisy the 
line fitted to the data may not represent the true 
slope and would produce inaccurate results the 
accuracy of processing is difficult to ensure in 
acquired low snr data 
b wavelet analysis 
wavelet analysis method is used for finding 
discontinuities in the otdr signatures data curve 
data is subjected to wavelet transform and the 
coefficients are subjected to a threshold value filter 
to extract the high frequency information as sharp 
changes lies in the high frequency portion 
denoising is performed and finally the positions of 
the sharp changes are located by using maximum 
mold algorithm  the whole process is 
summarized in the figure  
 
fig   event detection using wavelet transform 
     another approach using morlets complex 
wavelet transform has also been used which 
incorporates two important properties  
a the phase of the wavelet transform wt 
of an exponentially decaying function ft 
is independent of time shifting since ft 
is a homogeneous function 
b the phase of the wt of a gaussian white 
noise has a special distribution in π π  
property a is applied for estimating attenuation 
parameters and property b is used to identify end 
of fiber a binary detection criterion is established 
based on phase of wt of the otdr data to detect 
events 
morlets 
complex 
wavelet 
transform 
approach faces difficulties in limited operation time 
and uncertainty in detected events    
c waveshape analysis 
waveshape analysis is the most advanced 
approach in otdr event detection algorithms 
wave shape analysis algorithm is the highly 
sophisticated method of data processing that 
accurately locates the events in the data based on 
inflection points in the data previously discussed 
algorithm can give inappropriate events or even 
miss some events wave shape algorithm has the 
capacity to overcome these shortcomings wave 
shape algorithm can accurately locate and measure 
events having magnitude one half of the magnitude 
of the noise in the data  this improvement in 
performance is achieved by analyzing the curve 
shape of whole data this technique produces 
superior amplitude measurements of the event 
wave shape analysis is the proprietary algorithm of 
nettek otdr 
iii 
vector indexing algorithm 
the proposed algorithm works on vector index 
matching fiber response consist of two parameters 
namely distance and backscatter power which are 
plotted on xaxis and yaxis simultaneously the 
response out of otdr board will be discrete in 
nature and looks like exponentially decaying signal 
as shown in fig the events in the signature curve 
are abrupt changes in the consecutive recorded 
values first otdr curve data is stored in two 
separate vectors distance vector and backscatter 
vector simultaneously since the sudden changes in 
information exist in the backscatter vector the 
numerical difference operation is applied on it prior 
to threshold detection values crossing the threshold 
limit are events and cardinality of each event is 
mapped 
on 
the 
distance 
vector 
to 
find 
corresponding distance of the event meanwhile the 
value of sample before the event and the value after 
the event are gathered and linear interpolation is 
performed to find the exact sample that crosses the 
threshold this helps to improve the efficiency and 
accuracy in terms of distance measurement the 
computational complexity is reduced and the spatial 
resolution capability of event detection improves 
the details of vector indexing algorithm are being 
provided through the pseudo code 
vector indexing algorithm 
 
input    backscatter vector 
  
      distance vector 
 
     threshold  
output distance from source to event location 
 
      attenuation of events 
begin 
 store the cardinality of backscatter vector 
in c 
  
foreach counter  c  
 apply numerical difference operation on 
backscatter vector store in result vector 
end foreach 
 
 pad zero to starting index of the result vector 
 
 store the cardinality of result in c 
 
 while counter  c 
 compare the result index values with threshold 
 
   
if result value is greater than threshold 
store the value and its index in output 
vector 
 
 else print no event is detected 
  
endwhile 
  
foreach counterdistance 
compare the index number of the value 
stored in output with distance vector 
 
extract the value of the matched index 
 
perform interpolation 
 
 
store to event array 
end foreach 
end 
nococi  isbn 
iv 
experimental setup 
to experimentally verify our post processing 
algorithm an inhouse otdr board was built a 
pigtailed pulsed type laser photo diode was used as 
an optical source and laser power was coupled into 
the fiber spool by using a fiber directional coupler 
an ingaas pin photo diode receiver was used to 
detect the response from the fiber to the front end  
a transimpedance amplifier is used to convert the 
receivers current into voltage then a bit two 
port adc was used to sample the incoming voltage 
to mbps with a  bit resolution offering enough 
dynamic range to detect the events properly whole 
assembly source coupler receiver tia and adc 
was built on the daughter board called analog front 
end afe showed in figure    
 
fig  afe daughter board 
for signal processing an onboard signal 
processor blackfin bf dsp was used which 
performs control decoding and post signal 
processing functions meanwhile xilinx spartan iii 
fpga was also used to perform downconversion 
of mbps for the processor and additionally fpga 
control triggering capturing received optical signals 
and averaging fpga is controlled by adsp which 
uses its control signals to initiate the acquisition 
process whole assembly adsp fpga and 
memories was built on a separate board as shown 
in figure  
 
fig   signal processing board 
afe and signal processing board was connected 
together via dspafe connector sram and 
prom are used for data storage and they are 
connected and controlled by fpga figure  is a 
picture of the inhouse build otdr including the 
afe and signal processing board  
 
fig   self developed otdr board 
  trace is captured by shooting controlled coded 
pulse into the fiber and response is collected for a 
specified time period and stored in sram after that 
averaging is performed to get the final trace and 
then post processing algorithm is employed to 
extract events 
v 
post processing of otdr data 
a offset compensation  
             once the trace is acquired it needs to be 
converted in final presentable form by performing 
logarithmic operation on the otdr signal the 
logarithmic operations are sensitive to any fixeddc 
offset added to the signal all adcs have some 
inherent fixeddc offset which is defined as the 
difference between the ideal least significant bit 
lsb transition to the actual transition point if the 
offset is not properly removed the logged trace rolls 
up when the backscatter reaches the noise floor it is 
necessary to remove the adc offset before post 
processing after the offset is removed the final 
trace needs to be analyzed for events and their 
parameters offset compensation is an important 
task in post processing of acquired traces as it 
ensures offset errors removed and a linear trace 
display 
b trace analysis  
 
the purpose of the trace analysis step is to 
find different reflective and nonreflective events 
along the fiber and to measure their locations and 
losses nonreflective events are of two types 
namely loss and gain for each nonreflective event 
the insertion loss is measured the accurate method 
of determining the nonreflective event is to find 
four marker locations two before the event and two 
after the event 
for each nonreflective event the insertion loss 
il needs to be measured the accurate method for 
determining the loss is to find four marker locations 
two before the event and two after the event least 
square ls fits are found for sections of fiber 
between each pair of markers as shown in figure  
 
nococi  isbn 
 
fig  use of markers and ls fitting 
the red lines show the fits between markers m 
and m and between m and m the loss is found 
as the difference between the two fits from which 
expected fiber loss needs to be subtracted a user 
defined input loss threshold puts a lower limit for 
the identification of a nonreflective event 
reflective events begin with a slope rising sharply 
hitting the peak and then falling back to the normal 
value this identifies reflective event    
vi 
experimental results 
in this section the experimental results are 
discussed which are gathered by employing 
proposed post processing algorithm to the otdr 
data from live optical fibers of km each named 
as fiber under test fut and fut once the 
signatures are acquired and converted into the final 
presentable form by performing filtering averaging 
correlation and logarithmic operations they need to 
be analyzed for events since the logarithmic 
operation is sensitive to any fixeddc offset that 
may have been added to the otdr signal the 
source of such offset is usually the adc all 
adcs have some inherent offset value if the offset 
is not removed properly the logged trace rolls up or 
down when the backscatter reaches the noise floor 
level it is very important point in acquiring the 
final trace that offset must be removed the 
signature of fut is given in figure  
 
 
fig   signature of fiber under test fut 
after the post processing algorithm the resultant 
detected events are shown by the normalized bar 
plot in figure  
 
fig   bar plot of detected events in fut 
similarly proposed algorithm is applied on 
fut and results are gathered the trace plot and 
detected events for fut are shown in figure  and 
 respectively 
fig   signature of fut 
 
fig   bar plot of detected events in fut 
results are compared in terms of distance with 
the actual values of distance and the values of the 
events 
from 
commercially 
available 
otdr 
specifying the distance from the point of injection 
is critically important in the post processing of 
otdr data increasing the spatial resolution of the 
distance measurement has been achieved through 
the vector indexing algorithm table  summarizes 
the experimental results showing that the vector 
indexing algorithm on the otdr curve data is 
practical feasible and highly accurate 
nococi  isbn 
table i 
note 
event type  
 blind spot  
 reflective events 
 
                nonreflective events  end of fiber 
 
blind spot occurs when the receiver is saturated 
by a very high reflection and its duration depends 
upon the pulse width selected and recovery time of 
otdr detector the sudden change due to 
reflective event is followed by a return of the 
rayleigh backscatter to its nominal value for 
reflective events the reflectance threshold is set by 
the otdr user at the start of testing events having 
threshold less than the specified threshold are not 
identified nonreflective events are identified by 
subjecting the numerical difference values to the 
lower loss threshold end of fiber eof is 
identified by using eof threshold depending upon 
the user defined input parameters at the start of 
testing detection thus remains dependent on the 
threshold definition for different types of events  
vii 
conclusion 
in this paper we have focused our work on the 
post processing algorithm for event detection and 
feature extraction from acquired otdr traces by 
using numerical difference operation combined with 
vector index matching improvement in event 
detection feature extraction and spatial resolution 
has been achieved the performance results on 
experimental setup indicate that the implementation 
of the vector indexing algorithm shall allow 
accurate event detection and classification hence 
the proposed vector indexing algorithm provides an 
effective solution for event detection in optical time 
domain reflectometers 
ieee geoscience and remote sensing letters vol  
waveformer spectralspatial wavelet transformer
for hyperspectral image classification
muhammad ahmad  usman ghous muhammad usama and manuel mazzara
abstract transformers have proven effective for hyperspec
tral image classification hsic but often incorporate average
pooling that results in information loss this letter presents
waveformer a novel transformerbased approach that leverages
wavelet transforms for invertible downsampling this preserves
data integrity while enabling attention learning specifically
waveformer unifies downsampling with wavelet transforms to
decompress feature maps without loss this provides an efficient
tradeoff between performance and computation furthermore
the wavelet decomposition enhances the interaction between
structural and shape information in image patches and chan
nel maps to evaluate waveformer we conducted extensive
experiments on two benchmark hyperspectral datasets our
results demonstrate that waveformer achieves stateoftheart
classification accuracy obtaining overall accuracies of 
and  on the pavia university and the university of
houston datasets respectively by integrating wavelet transforms
waveformer presents a new transformer architecture for hyper
spectral imagery that achieves superior classification without
information loss from average pooling
index
terms hyperspectral
image
classification
hsic
spatialspectral feature spatialspectral transformers ssts
wavelet transformer waveformer
i introduction
h
yperspectral imaging hsi has emerged as a
powerful remote sensing technique capturing contiguous
spectral information across various wavelengths its appli
cations span diverse fields including remote sensing 
 earth observation  urban planning  agricul
ture  forestry  targetobject detection  mineral
exploration  environmental monitoring   and cli
mate change  notably hsi excels in capturing detailed
spatial and spectral information although its sensors charac
terized by high spectral resolution may face challenges in
achieving optimal spatial resolution especially in complex
scenarios
hyperspectral image classification hsic involves catego
rizing pixels based on their spectral and spatial characteristics
manuscript
received
november
revised
january
accepted  january  date of publication  january  date of current
version  february  corresponding author muhammad ahmad
muhammad ahmad usman ghous and muhammad usama are with
the department of computer science national university of computer
and emerging sciences nuces islamabad  pakistan email
mahmadgmailcom usmanghousnuedupk musamanuedupk
manuel mazzara is with the institute of software development and
engineering
innopolis
university
innopolis
russia
email
mmazzarainnopolisru
digital object identifier lgrs
facilitating object identification traditionally hsic used
both traditional machine learning tml and deep learning
dl techniques  dl particularly convolutional neural
networks cnns addresses challenges in handling multi
modal data however cnns struggle with capturing longterm
dependencies for spectrally similar classes recurrent neural
networks rnns can model these dependencies but lack the
ability for simultaneous model training a vital consideration
for the extensive hsi data comprising numerous samples 
on the other hand transformers using selfattention mech
anisms  represent stateoftheart networks for handling
dependencies and enabling parallel training specifically tai
lored for hsic challenges vision transformers vits have
emerged as promising candidates vits use selfattention
to capture relationships in image sequences represented as
patches proving beneficial for modeling longrange depen
dencies across the entire hsi cubes   however
vits encounter challenges related to scale invariance and
texture features their fixedsize input may hinder recognizing
objects at different scales and their emphasis on global context
may limit their effectiveness in extracting finegrained texture
details  in addition the extensive data requirements for
vits may pose challenges in scenarios where a large number
of training samples are not readily available for hsic 
to address the aforementioned issues this letter pro
poses waveformer a novel approach that combines the
strengths of wavelets and transformers for improved hsic
it introduces spatialspectral wavelet convolution within a
transformer architecture enhancing the interaction between
structural and shape information of image tokens this
leads to more accurate classification compared with the
traditional transformerbased models waveformer extracts
waveletbased multiscale spatialspectral features from the
hsi data which are then input into a classification model the
combination of wavelets and transformers allows waveformer
to capture both local and global relationships in the data
resulting in improved classification accuracy in this letter
we made the following contributions
 this work introduces waveformer which integrates
wavelet transformation and transformers for hsic
within the transformer architecture the waveformer
model incorporates a trainable spatialspectral wavelet
network thereby improving the interaction between the
structural and shape information of hsi tokens and class
tokens
   ieee personal use is permitted but republicationredistribution requires ieee permission
see httpswwwieeeorgpublicationsrightsindexhtml for more information
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee geoscience and remote sensing letters vol  
 the
proposed
method
extracts
multiscale
spatialspectral
features
based
on
wavelets
from
the hsi cube these features are subsequently input
into a classification model to capture a broader range
of information beneficial for hsic
 this
work
showcases
the
combined
impact
of
waveletbased feature extraction and transformerbased
modeling of global relationships indicating the potential
for improved accuracy compared with the traditional
transformer approaches for hsic
ii problem formulation
let us consider hsi data comprising b spectral bands each
with a spatial resolution of m  n pixels the hsi data
cube x rmnb is first divided into overlapping d
patches each patch is centered at a spatial location α β
and covers a spatial extent of s  s pixels across all bbands
the total number of d patches m extracted from x ie
x rssb is m sn s a patch located at
α β is denoted as pαβ and spans spatially from αs
to α  s  in width and β s  to β  s 
in height the labeling of these patches is determined by the
label assigned to the central pixel within each patch the
transformed patches as explained in algorithm are then
processed by the baseline dcnn model specifically the
activation value at spatial location x y z in the jth feature
map of the ith layer vxyz
i j
 is computed as
vxyz
i j
 φ
bi j 
dl
x
τ
ν
x
λν
γ
x
ργ
δ
x
σδ
wσρλ
i jτ  vxσyρzλ
iτ
where φ is the activation function bi j is the bias for the jth
feature map at the ith layer dl is the number of feature maps
in the lth layer and wi j is the depth of the kernel for the
jth feature map at the ith layer γ  δ and ν define
the width height and depth of the kernel respectively along
the spatialspectral dimension
algorithm  wavelet transformation
input image patch x patch
 set l   and initialize empty output array o
 for i   to s do
for j   to b do
coffs  wavedecx patchi   j haar l
oi   j  wavereccoffs haar
end
 end
the d feature maps vxyz
i j
are transformed into
ˆ
x 
x ed with reduced channel dimensions via embedding matrix
ed rdd ie ˆ
x rmnd decomposed into four
wavelet subbands which is downsampled through wavelet
transformation note that here we used the classical haar
wavelet as expressed in  and  concretely the wavelet
transformation is applied using a lowpass filter denoted as
fl 
 
 and a highpass filter denoted
as fh 
 
 along the rows of the input
data ˆ
x this process results in the creation of two subbands
namely ˆ
x l and ˆ
x h subsequently the same lowpass filter
fl and highpass filter fh are used this time along the
columns of the derived subbands ˆ
x l and ˆ
x h this leads
to the formation of four subbands in total
ˆ
x ll
ˆ
x l h
ˆ
x h l and ˆ
x h h each of these wavelet subbands can be
viewed as a downsampled version of the original input ˆ
x
they collectively preserve all the input details without any
loss of information the four wavelet subbands are created
ˆ
x ll ˆ
x l h ˆ
x h l and ˆ
x h h these feature maps are then
linearly transformed into downsampled keys k w rmd
and values v w
rmd where m
 m  n
denotes the total number of patches multiheaded selfattention
learning attention is then performed on the queries and their
respective downsampled keys and values for each attention
head
headj  attentionq j k w
j  v w
j 
 softmax
 q j k w j t
dh
v w
j
where k w
j and v w
j represent the downsampled keys and values
specific to the jth head respectively it is worth noting that the
collective output of selfattention learning for each head can be
understood as the incorporation of longrange contextualized
information from the input data finally the features are
fed into a fully connected layer for classification and the
softmax function is applied to generate the class probability
distributions from which the final groundtruth maps are gen
erated the waveformer captures the essence of the wavelet
for hsic by integrating spatialspectral information through
attention mechanisms and linear projections waveformer can
effectively process the hsi cube with reduced computational
complexity making it suitable for resourceconstrained envi
ronments fig  explains the complete model in detail
iii experimental results and discussion
a comparison with cnnbased networks
a uniform experimental methodology is imperative when
evaluating cnnbased approaches it is crucial to uphold
consistency in the distribution of samples assigned to training
validation and testing each comparative model underwent
training and validation using  of the samples respec
tively while the remaining  were used for classification
based on    pixel patches the performance evaluation
of waveformer is conducted on the university of houston
dataset to compare the performance against several models d
cnn  hybrid inception net  d inception net 
d inception net  d cnn  and hybrid cnn 
fig  presents a graphical representation of accuracy and loss
convergence over  training epochs for both the training and
validation sets in addition the results highlight the advantage
of decoupling spatialspectral information proving to be a
superior approach in approximating information within an hsi
cube compared with the alternative strategy of convolutions at
distinct layers of the architectures when contrasted with the
d models fig  illustrates that the proposed waveformer
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ahmad et al waveformer spectralspatial wavelet transformer for hisc
fig 
hsi cube was initially partitioned into overlapping d patches each of which was centered at a spatial point and covered a s  s pixel extent
over all the spectral bands wavelet transform was applied to these patches using haar wavelets resulting in four subbands that captured different frequency
components and spatial features the subbands were then concatenated to generate a new d representation locally contextualized feature maps were
produced through a d convolution to define spatial locality within this representation to incorporate longrange contextualized information these feature
maps were further translated into downsampled keys and values and multiheaded attention learning was performed
fig 
accuracy and loss trends on the university of houston dataset
achieves comparable results notably achieving impressive
scores of  approx in particular models using d
convolutions exhibit varying performance on the uh dataset
with d cnn achieving oa aa and κ scores of  and
the d inception net attaining oa aa and κ scores of 
the marginal difference in accuracy between the proposed
model and comparative methods is noteworthy and can be
attributed to the computational efficiency of waveformer its
ability to mitigate overfitting and its enhanced capacity to
model spatial and spectral dependencies effectively
b comparison with transformerbased networks
for comparison we selected several stateoftheart net
works including attention is all you need transformer
 spectralformer  hyperspectral image transformer
classification networks hits  and csit a multiscale vit
for hsic  the transformer architecture uses a standard
vit  adapted for pixelwise hsi input with five encoder
blocks spectralformer retains the original five transformer
encoder architecture with pixelwise embeddings and cross
layer fusion hit incorporates two depthwise convolution
table i
pavia university proposed waveformer versus comparative
models all these models are evaluated using    patch size
with  trainingvalidationtest samples respectively
layers for spatial processing and one pointwise convolution
layer for spectral processing relying solely on patchwise input
csit uses a consistent backbone transformer architecture in
each branchfour heads in the smallscale branch and six
heads in the largescale branch token sequences are input
into two crossattention transformers each with a fourhead
attention layer and multilayer perceptron layer csit is evalu
ated with and without crossspectral attention fusion csaf
modules all the results use the specified parameter configu
rations from the original papers to enable direct comparison
the comprehensive results of the earlier mentioned models
are provided in tables i and ii in summary the proposed
waveformer model demonstrates remarkable performance
outperforming the stateoftheart vitbased models across a
spectrum of evaluation metrics encompassing overall accu
racy oa average accuracy aa and the κ coefficient
a thorough analysis of the quantitative performance reveals
authorized licensed use limited to national university fast downloaded on april  at  utc from ieee xplore  restrictions apply 
ieee geoscience and remote sensing letters vol  
fig 
proposed waveformer achieves  on the uh dataset showing competitive performance compared with the recent stateoftheart cnn models
for hsic a twodimensional inception net  training time   test time   oa   aa   and kappa  
b threedimensional inception net  training time   test time   oa   aa   kappa   c hybrid
inception net  training time   test time   oa   aa   and kappa   d d cnn  training time 
 test time   oa   aa   and kappa   e d cnn  training time   test time   oa 
 aa   and kappa   f hybrid cnn  training time   test time   oa   aa   and
kappa   g waveformer training time   test time   oa   aa   and kappa  
table ii
university of houston proposed waveformer versus
comparative models all these models are evaluated using
   patch size with  trainingvalidationtest
samples respectively
that waveformer consistently achieves superior results across
diverse categories exhibiting substantial improvement in accu
racy as evidenced in table ii notably while performance
differences remain relatively modest in the pu dataset due
to the abundance of samples the uh dataset poses a signifi
cant challenge to modeling capabilities for example when
assessing the challenging uh dataset waveformer outper
forms the baseline vit by more than  and it surpasses
spectralformer by approximately  furthermore the aa
achieved by the waveformer exceeds that of both vit and
spectralformer by margins ranging from  emphasizing
the potential efficacy of spatialspectral feature extraction
in a comparative context with the most recent spatialspectral
transformer and csit models the waveformer consistently
presents results showcasing its proficiency in both the spectral
and spectralspatial feature extraction tasks it is worth noting
that while hit excels in identifying landcover or landuse
classes with spectralspatial information the waveformer
approaches similar levels of performance to sum up these
findings emphasize the robustness and effectiveness of the
waveformer model in the field of hsic particularly in
scenarios where the extraction of spatialspectral information
holds importance especially when considering the limited
availability of training samples
iv conclusion
this letter introduced waveformer which combines the
power of wavelet transforms and vit for hsic by extracting
multiscale spatialspectral features using wavelets and feeding
them into a transformer encoder waveformer can capture both
the local texture patterns and global contextual relationships
in an endtoend trainable model a notable innovation is the
use of wavelet convolution within the transformers attention
mechanism allowing for enhanced integration of spectral
and structural information extensive experiments demonstrate
waveformer achieves the stateoftheart performance partic
ularly for challenging datasets with limited training data where
its multiscale extraction of spatialspectral cues proves valu
able beyond superior classification accuracy waveformer
attains robustness and generalizability that hold promise for
addressing real problems in remote sensing future work
could explore selfsupervised pretraining and network opti
mizations to maximize waveformers potential when data are
scarce
