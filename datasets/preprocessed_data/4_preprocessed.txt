adversarial ml attack on self organizing cellular
networks
salahuddin farooq  muhammad usama junaid qadir muhammad ali imran
information technology university lahore punjab pakistan
university of glasgow scotland uk
email mscs muhammadusama junaidqadirituedupk muhammadimranglasgowacuk
abstractdeep neural networks dnn have been widely
adopted in selforganizing networks son for automating differ
ent networking tasks recently it has been shown that dnn lack
robustness against adversarial examples where an adversary can
fool the dnn model into incorrect classiﬁcation by introducing a
small imperceptible perturbation to the original example son is
expected to use dnn for multiple fundamental cellular tasks and
many dnnbased solutions for performing son tasks have been
proposed in the literature have not been tested against adversarial
examples in this paper we have tested and explained the
robustness of son against adversarial example and investigated
the performance of an important son use case in the face
of adversarial attacks we have also generated explanations
of incorrect classiﬁcations by utilizing an explainable artiﬁcial
intelligence ai technique
index termsadversarial machine learning self organizing
cellular networks
i introduction
driven by ambitious bandwidth and latency targets and the
development of new domains such as iot and connected vehi
cles g networks are becoming increasingly complex as they
incorporate disparate emerging trends such as network densi
ﬁcation and coexistence with existing cellular technologies
these networks also perform several challenging activities
such as planning dimensioning deployment testing network
optimization comprehensive performance monitoring failure
detection failure correction and general maintenancewhich
currently utilize large human resources in the loop this
results in a network that is both costlythus dissatisfying
for the cellular operator and errorpronebringing customer
dissatisfaction and resulting in increased churn 
in such scenarios artiﬁcial intelligence ai driven self
organized networks provides an attractive alternative by
providing the tools for performing automation with self
organization and intelligence the main objectives of the son
are to build an intelligent network that can guarantee the net
work resilience with reduced complexity simpliﬁed network
management and properly optimized network conﬁgurations
 son technology leverages advance in machine learning
ml and deep learning dl techniques to overcome the
multiple challenges of operating modern network through their
integral capability of handling and analyzing big data
even though ml and dl models can greatly outperform
traditional methods in obtaining excellent accuracy in benign
environments it is also important to verify the robustness of
these models in adversarial settings particularly since it has
been shown in recent work that adversarial examples can be
generated by malicious adversaries to fool the dl models very
easily by applying small perturbations to the original inputs
  more formally an adversarial sample xis created
by following the equation  where imperceptible perturbation
is denoted as δ legitimate test example is denoted as x the
deployed trained classiﬁer is described by f and t describes
the wrong class adversary wants to achieve
x x  arg min
ηx η fx  η  t
deep neural networks dnn work in a black box manner
and this lack of transparency can be a major drawback for
the security critical domains hence explainable ai xai
or blackbox model interpretability plays an important part
in mitigating this threat of adversaries tomsett et al 
proposed this phenomenon that xai and adversarial machine
learning aml are conceptually linked and insights into one
ot them can provide insights into the other this is because
most vulnerable features after adversarial attacks together
with the help of xai and aml can be identiﬁed and ulti
mately any relevant defensive technique can be applied this
interpretability becomes more important now because of the
recent adaptation of explainable ai at government levels like
general data protection regulation gdpr which expresses
the importance of explanations of the logic involved when
automated decision making takes place 
the main contributions of our work are
 experimentally validated the impact of adversarial attacks
in the domain of son
 demonstrated that the explainable ai and adversarial ml
are linked with each other and adversarial ml can be used
to describe feature representations of a dnn model
 to the best of our knowledge this study is ﬁrst in the
domain of son to test adversarial machine learning
aml
in the section ii we have provided a brief review of
the related research that focuses on son adversarial ml
and explainable ai section iii describes the methodology
gdpr is an eu law regulation aiming at data protection and privacy for
all individual citizens of the european union and the european economic
area
arxivv  cscr   sep 
where we have discussed the assumed threat model ml
models used for a son use case of detection of abnormal key
performance indicator kpi and dataset details used in this
experiment section iv provides the performance evaluation
of the adversarial attacks on the abnormal kpi detector before
and after the adversarial attack section iv provides the results
of adversarial training used as a defense against adversarial
attacks section v concludes the study and provides future
directions
ii related work
a son
to provide best cellular services to the endusers efﬁcient
network optimization is a continuous process of planning
parametric conﬁguration changes operations and maintenance
with the help of large human interventions therefore the
son is introduced as an intelligent network that provides
scalability agility and stability to maintain the operators and
consumers desired objectives  a fundamental property of
the son is the ability to interact and learn from the networking
environment to adapt to the changing circumstances
three main functions of son selfconﬁguration self
healing and selfoptimization perform these automatic tasks
 selfconﬁguration manages tasks of automatic conﬁgura
tion of cellular network nodes the main use cases are plan
ning and modifying the radio and transport parameters self
optimization manages solutions that target cellular network
performance optimization based on the operator speciﬁcations
the main use cases of this category are handover parameters
optimization qosrelated parameters optimization and load
balancing whereas selfhealing manages tasks to automatic
detection and rectiﬁcation of failures in network
in the context of cellular systems dnns are applied in
all three categories of son feng et al  used dnn to
implement cell outage detection daroczy et al  used
ml to predict radio access bearer rab sessions drops well
before the end of the session other important work for son
in cellular networks using dnn include resource optimization
 and mobility management  recently chen et al 
combined adversarial training with variational autoencoders to
unsupervised learning the behavior of abnormal kpi on the
internet
an adversary can affect dnn models of son through
internal and external attacks in the case of internal attacks
adversaries can corrupt training data and classiﬁers of dnn
models of son directly however these internal attacks are
not easily possible due to the difﬁcult task of adding adver
sarial examples directly into the input of the dnn model
whereas external attacks can utilize vulnerabilities of data
collection process of cellular networks base stations collect
measurement reports and pass it son function that uses this
collected data to implement its different functionalities for
network optimization adversarial examples can be injected
into this data collection process with the help of a rogue
base station shaik et al  demonstrated the security vul
nerabilities of sonenabled lte networks they injected the
fake data into the son ecosystem with the help of a rogue
base station there work is mainly concerning dos attacks on
cellular networks and user devices
b adversarial attacks on sons and cognitive networks
most of the current research of adversarial machine learning
is relevant to computer vision tasks such as szegedy et al 
shows that deep neural network can change its prediction by
using nonrandom perturbation in its inputs these changes are
imperceptible due to the extremely low probability of negative
adversaries in every test set goodfellow et al  and papernot
et al  extended this initial study and proposed fast
gradient sign method fgsm and jacobianbased saliency
map attack jsma respectively for generating adversarial
examples fgsm is a technique for crafting an adversarial
example where one step gradient update is performed in the
direction of the sign associated with the gradient at each
feature in the test example the fgsm perturbation η is
given as
η  ϵsignxjθx l
whereas jsma is based on the concept of saliency maps
this algorithm tries to ﬁnd input dimensions or features that
are most vulnerable due to possible perturbations by creating
a saliency map and an iterated process to ﬁnd misclassiﬁcation
in the model
jx  fx
x
 f jx
xi 
some recent studies of adversarial examples are performed
in the ﬁeld of network intrusion detection systems nids
in these studies signiﬁcant degradation in accuracy is ob
served for intrusion detection systems after exposing dnns
to adversarial examples  whereas usama et al 
investigated the vulnerability of cognitive self organizing
networks cson utilizing mldl techniques against adver
sarial attacks in this study we have performed fgsm and
jsma attack on dnnbased abnormal kpi detector to show
that adversarial attacks can be fatal for this important use case
of son
c adversarial defense methods
many methods have been proposed for making ml models
more robust and mitigating adversarial examples adversarial
training  and defensive distillation  are two famous de
fense techniques we have implemented adversarial training
as a defensive technique for our experiments the basic idea
of adversarial training is to train the model using adversarial
examples and assign the same labels of the original examples
to the adversarial examples
d explainable ai
current work of explainable ai or blackbox model inter
pretability lies within two categories global and local inter
pretability global interpretability describes the understanding
of the whole logic of a model and follows the entire reasoning
leading to all the different possible outcomes whereas local
interpretability is used to generate an individual explanation to
justify why the model made a speciﬁc decision for an instance
 some recent studies explored the link between xai
and aml tomsett et al  proposed this phenomenon that
xai and adversarial machine learning aml are conceptually
linked and insights in one can provide insights in the other
domain giurgiu et al  used recurrent neural networks and
attention mechanism for explaining the failure predictions in
time series data marino et al  proposed a methodology to
explain incorrect classiﬁcations made by intrusion detection
systems ids using the adversarial approach in this paper
we have used explainable ai to provide a deeper understanding
of the features involved in the adversarial ml attack on dnn
based kpi detector
iii methodology
in this section we will describe our procedure for perform
ing two types of adversarial attacks on abnormal kpi detector
but before that we will describe the threat model and the
dataset used in this experiment
a threat model
this subsection describes the major assumptions considered
for performing an adversarial attack on the use case of son
 adversary knowledge we have used two whitebox
attack algorithms which mean adversary has complete
knowledge about the model architecture features and
test data
 adversarial goals and defense our goal in this ex
periment is to check the vulnerabilities of son against
adversarial examples we have achieved this by measur
ing accuracy before and after implementing attacks we
have experimentally validated a defensive technique to
mitigate the effect of adversarial examples
b son use case  detection of abnormal kpi
figure  states the generic ﬂow chart of son methodology
consisting of its main use cases of selfoptimization and self
conﬁguration of a lte long term evolution network 
two main functions of lte architecture are i evolved uni
versal terrestrial radio access network eutran and ii
evolved packet core epc eutran consists of multiple
base stations termed as enodeb and user equipment ue
ue is typically a smartphone or an iot device for using call
or data services after setting up a connection to a cell of the
cellular network a cell is a speciﬁc terrestrial area controlled
by each enodeb
key performance indicators kpis explain the quality of
services qos and quality of experience qoe of these
connected devices for example kpis that are relevant to
call or data services setup and services completion belong to
accessibility and retainability classes of kpis respectively
the calculation of these kpis is based on the measurement
reports which are collected through various internal and
external data collection methods son continuously monitors
these kpis and in case of any abnormality automatically starts
relevant optimization and conﬁguration tasks
figure 
son methodology flow chart son function continuously
monitors the kpis and starts automatic optimization and conﬁguration actions
based on kpi measurements
erab drop rate is one of the signiﬁcant kpis to judge
user experience and belongs to the retainability class of kpis
effective and timely detection of this indicator is essential to
avoid users churn brief description of this kpi is mentioned
below
when a user equipment ue has data to send or receive
it sets up an end to end communication channel called eps
radio access bearer erab between itself and the core
network part of epc this erab is the access layer bearer for
carrying service data of a ue after the utilization of cellular
services ue releases its radio access bearer rab this
rab is considered as a drop if it is released abnormally ie
ongoing session is dropped requiring the user to initiate a new
connection to resume services this drop rate is measured as a
fraction of the total number of abnormal releases with normal
releases
erab drop rate     erab abnormal releases
erab normal releases
c dataset and data preprocessing
for the use case of erab drop rate detection records
are extracted from live lte network each row contains an
hourly record of a speciﬁc enodeb with a sudden increase in
erab drop rate is labeled as an anomaly initial experiments
involve total  records of two lte enodebs  records
are labeled as normal and  as anomalies based on domain
knowledge each sample has  features which are divided
into three main categories of i time and location ii de
pendent features erab drop reasons and iii independent
features signal strengths latency and the number of users
this dataset has binary and nominal data variables and we
have applied onehot encoding to convert nominal features to
numeric features since dnns cannot operate on nominal data
directly this resulted in the transformation of the feature
dataset into a feature dataset after onehot encoding
after analyzing the data we have noticed varying distri
butions of each feature for example the mean and standard
distribution of some features are larger by seven orders of
magnitude from some other features without performing
normalization these features would dominate other features
to mitigate this effect we have used minmax scaling using
scikitlearn library to normalize data for our use case of
anomaly detection in the dataset of erab drop rate we have
used multilayer perceptron mlp classiﬁer with the activation
function of relu using keras and tensorﬂow sequential
model the mlp model is composed of three hidden layers
of  neural units the output layer contains two neurons
since labels have two normal and abnormal classes for
regularization dropout with a rate of  and earlystopping
is used
iv performance evaluation
in this section we have provided a detailed evaluation of
our experiment results
a evaluation metric
we have used accuracy for performance evaluation of
results accuracy is deﬁned as the percentage of correctly
classiﬁed records over the total number of records after
training the dnn model and testing its accuracy we have
implemented both fgsm and jsma attacks for evaluation of
the impact of adversarial examples at the dataset accuracy is
again measured after implementation of adversarial training
as a defensive technique
b experiment results
 impact on accuracy figure  and ﬁgure  describe the
experimental results after implementing adversarial examples
and defensive technique of adversarial training at the dataset it
is clear that adversarial examples have signiﬁcantly degraded
the performance of dnns used in son we have observed
jsma caused more performance degradation than fgsm
however jsma requires more computation time for crafting
an adversarial example our results in ﬁgure  and  also
depict the performance of dnnbased abnormal kpi after
the adversarial training it is evident from the results that
adversarial training has performed better against fgsm as
compared to jsma
 features explanations most affected features are calcu
lated through the technique mentioned in  we have ranked
and sorted the features with their importance after generating
the adversarial test set this importance is calculated by
subtracting the original test set from the adversarial test set
the indexes where adversaries have no impact the value
of this subtraction is zero however for indexes which are
affected by the attack the value of this subtraction is nonzero
by calculating these nonzero values most affected features
are calculated
figure 
performance of abnormal kpi detector before and after fgsm
attack the ﬁgure also provides the results of adversarial training which tells
the recovery of the abnormal kpi detector
figure 
performance of abnormal kpi detector before and after jsma
attack the ﬁgure also provides the results of adversarial training which tells
the recovery of the abnormal kpi detector
as expected fgsm changed almost all features  out of
 however it is not possible to avoid human observation
when the scale of the adversary is on such a large level
whereas jsma changed six features and degraded the perfor
mance of model badly we have observed the most affected
features and compared them with the domain knowledge of
cellular networks for instance we have an understanding
from the dataset that most of the erab drops are due to the
transport network layer tnl problems and almost identical
features of tnl drops are observed after examining the most
vulnerable features by jsma attack
v conclusions
in this paper we have performed fgsm and jsma attack
on dnnbased abnormal kpi detector our results indicate
more than  drop in the performance of dnnbased
abnormal kpi detector making it very evident that dnn used
for detection does not provide robustness against adversarial
perturbation a prominent recovery in the performance of
abnormal kpi detector is noticed after we have used adver
sarial training as a defense against adversarial examples we
have also provided the reasons why adversarial attacks are so
effective against abnormal kpi detector by utilizing insights
from explainable ai our results also trhow the light on a
previously ignored area of machine learning security in the
son and provide good insights for developing a robust ml
based son solution
